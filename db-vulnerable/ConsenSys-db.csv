nameчseverityчdescriptionчrecommendationчimpactчfunction
No Limit for Minting AmountчhighчIn token contract `FiatTokenV1`, there is no limit set for amount of tokens can be minted, as a result, the minter can mint unlimited tokens, disrupting the token supply and value.\\n```\\nfunction mint(address to, uint256 amount) public onlyRole(MINTER\\_ROLE) {\\n \\_mint(to, amount);\\n}\\n```\\nчAdd a limit for the number of tokens the minter can mint.чч```\\nfunction mint(address to, uint256 amount) public onlyRole(MINTER\\_ROLE) {\\n \\_mint(to, amount);\\n}\\n```\\n
Private Key Is Exposed in the Deployment and Upgrade ScriptчhighчIn the contract deploying and upgrading script, private key is used to broadcast the transaction, this would expose private key of the deployer and upgrader account on the machine running the script, therefore compromising these accounts.\\n```\\nuint256 deployerPrivateKey = vm.envUint(\"PRIVATE\\_KEY\");\\n```\\n\\n```\\nuint256 deployerPrivateKey = vm.envUint(\"PRIVATE\\_KEY\");\\nvm.startBroadcast(deployerPrivateKey);\\n```\\nчHave Forge sending a raw transaction to the cold wallet of the account, the wallet signs the transaction then return the signed transactions to Forge and broadcaster. Alternatively use different wallet for deployment and upgrade and stop using the wallet after the script is completeчч```\\nuint256 deployerPrivateKey = vm.envUint(\"PRIVATE\\_KEY\");\\n```\\n
Critical Functions Are Public and Without Access ControlчmediumчCritical functions in RescuableV1(rescue) and `BlacklistableV1` `(blacklist,unblacklist)` are public and unauthenticated, any one can call these function to steal funds and blacklist other accounts. Although the child contract `FiatTokenV1` has authenticated the overridden functions and protected them from public access, other contracts inheriting `RescuableV1` and `BlacklistableV1` might have risks from the unauthenticated public functions\\n```\\nfunction rescue(IERC20 token, address to, uint256 amount) public virtual {\\n```\\n\\n```\\nfunction blacklist(address account) public virtual {\\n \\_blacklisted[account] = true;\\n emit Blacklisted(account);\\n}\\n\\n/\\*\\*\\n \\* @dev Removes account from blacklist\\n \\* @param account The address to remove from the blacklist\\n \\*/\\nfunction unBlacklist(address account) public virtual {\\n \\_blacklisted[account] = false;\\n emit UnBlacklisted(account);\\n}\\n```\\nчMake these functions internal and in the child contract add correspondent public function with authentication to call the inherited functionsчч```\\nfunction rescue(IERC20 token, address to, uint256 amount) public virtual {\\n```\\n
Unecessary Parent ContractsчlowчContract `BlacklistableV1` and `RescuableV1` extends `ContextUpgradeable` and `ERC20Upgradeable,` which are not used in any of contract functions and are already inherited by the child contract `FiatTokenV1`.\\n```\\nabstract contract BlacklistableV1 is Initializable, ContextUpgradeable, ERC20Upgradeable {\\n```\\n\\n```\\nabstract contract RescuableV1 is Initializable, ContextUpgradeable, ERC20Upgradeable {\\n```\\n\\n```\\ncontract FiatTokenV1 is\\n Initializable,\\n ERC20Upgradeable,\\n ERC20PausableUpgradeable,\\n ERC20BurnableUpgradeable,\\n AccessControlUpgradeable,\\n ERC20PermitUpgradeable,\\n UUPSUpgradeable,\\n BlacklistableV1,\\n RescuableV1\\n{\\n```\\nчRemove the unnecessary parent contractsчч```\\nabstract contract BlacklistableV1 is Initializable, ContextUpgradeable, ERC20Upgradeable {\\n```\\n
Redundant _disableInitializers in ConstructorчlowчContract `FiatTokenV1` inherits from contracts `BlacklistableV1` and `RescuableV1`, the two parent contracts both have `_disableInitializers` in their constructors to prevent uninitialized contract being initialized by the attackers, it's not necessary to have `_disableInitializers` in the FiatTokenV1's constructor, which is redundant and inefficient.\\n```\\nconstructor() {\\n \\_disableInitializers();\\n}\\n```\\nчRemove constructor from `FiatTokenV1`чч```\\nconstructor() {\\n \\_disableInitializers();\\n}\\n```\\n
Incorrect Final Block Number Can Be FinalizedчhighчIn the data finalization function `finalizeCompressedBlocksWithProof`, `finalizationData.finalBlockNumber` is the final block number of the compressed block data to be finalized. However, there is no check in the contract or the prover to ensure `finalBlockNumber` is correct when there is no new data submitted in the finalization, i.e., `submissionDataLength == 0` . The prover can submit an incorrect final block number and, as a result, the finalized block number (currentL2BlockNumber) would be incorrect. Consequently, the prover can skip block data in the finalization.\\n```\\ncurrentL2BlockNumber = \\_finalizationData.finalBlockNumber;\\n```\\n\\n```\\nif (stateRootHashes[currentL2BlockNumber] != \\_finalizationData.parentStateRootHash) {\\n revert StartingRootHashDoesNotMatch();\\n}\\n```\\nчResolution\\nfixed by adding a recommended check of `finalBlockNumber` matching the last block number of the submitted data in `_finalizeCompressedBlocks` and a check in the prover and adding `finalBlockNumber` and `lastFinalizedBlockNumber` in the public input of the verifier in the finalization in PR-24\\nIn `_finalizeCompressedBlocks`, check if `finalBlockNumber` is equal to the last block number (finalBlockInData) of the last item of submitted block data. Another solution is to have the prover show that finalBlockNumberis correct in the proof by providing the last finalized block number (lastFinalizedBlockNumber) and verify it by adding `finalBlockNumber` and `lastFinalizedBlockNumber` in the public input of the verifier in the finalization.чч```\\ncurrentL2BlockNumber = \\_finalizationData.finalBlockNumber;\\n```\\n
Finalization Fails for the First Batch of Data Submitted After Migration to the Updated ContractчhighчWhen submitting the initial batch of compressed block data after the contract update, the finalization will fail.\\nIn function `_finalizeCompressedBlocks`, `startingDataParentHash = dataParents[_finalizationData.dataHashes[0]]` will be empty and, therefore, `startingParentFinalStateRootHash = dataFinalStateRootHashes[startingDataParentHash]` will be empty too. The check `_finalizationData.parentStateRootHash == stateRootHashes[currentL2BlockNumber]` requires `_finalizationData.parentStateRootHash == _initialStateRootHash`, which is not empty, so the condition `startingParentFinalStateRootHash != _finalizationData.parentStateRootHash` is true, and we revert with the error FinalStateRootHashDoesNotMatch:\\n```\\nif (stateRootHashes[currentL2BlockNumber] != \\_finalizationData.parentStateRootHash) {\\n revert StartingRootHashDoesNotMatch();\\n}\\n```\\n\\n```\\nif (finalizationDataDataHashesLength != 0) {\\n bytes32 startingDataParentHash = dataParents[\\_finalizationData.dataHashes[0]];\\n\\n if (startingDataParentHash != \\_finalizationData.dataParentHash) {\\n revert ParentHashesDoesNotMatch(startingDataParentHash, \\_finalizationData.dataParentHash);\\n }\\n\\n bytes32 startingParentFinalStateRootHash = dataFinalStateRootHashes[startingDataParentHash];\\n\\n if (startingParentFinalStateRootHash != \\_finalizationData.parentStateRootHash) {\\n revert FinalStateRootHashDoesNotMatch(startingParentFinalStateRootHash, \\_finalizationData.parentStateRootHash);\\n }\\n```\\nчSet the correct initial value for `dataFinalStateRootHashes` for the initial batch of compressed block data.чч```\\nif (stateRootHashes[currentL2BlockNumber] != \\_finalizationData.parentStateRootHash) {\\n revert StartingRootHashDoesNotMatch();\\n}\\n```\\n
Prover Can Censor L2 → L1 Messages  Partially AddressedчhighчIn L2 → L1 messaging, messages are grouped and added to a Merkle tree by the prover. During finalization, the operator (coordinator) submits the Merkle root to L1, and the user SDK rebuilds the tree to which the message is added and generates a Merkle proof to claim against the root finalized on L1. However, the prover can skip messages when building the tree. Consequently, the user cannot claim the skipped message, which might result in frozen funds.\\nCurrently, the prover is a single entity owned by Linea. Hence, this would require malice or negligence on Linea's part.\\n```\\n\\_addL2MerkleRoots(\\_finalizationData.l2MerkleRoots, \\_finalizationData.l2MerkleTreesDepth);\\n\\_anchorL2MessagingBlocks(\\_finalizationData.l2MessagingBlocksOffsets, lastFinalizedBlock);\\n```\\nчDecentralize the prover, so messages can be included by different provers.чч```\\n\\_addL2MerkleRoots(\\_finalizationData.l2MerkleRoots, \\_finalizationData.l2MerkleTreesDepth);\\n\\_anchorL2MessagingBlocks(\\_finalizationData.l2MessagingBlocksOffsets, lastFinalizedBlock);\\n```\\n
Malicious Operator Might Finalize Data From a Forked Linea ChainчhighчA malicious operator (prover) can add and finalize block data from a forked Linea chain, so transactions on the forked chain can be finalized, causing a loss of funds from the L1.\\nFor example, a malicious operator forks the canonical chain, then the attacker sends the forked chain Ether to L1 with `sendMessage` from the forked L2. The operator then submits the block data to L1 and finalizes it with `finalizeCompressedBlocksWithProof`, using the finalization data and proof from the forked chain. (Note that the malicious prover sets the forked chain `chainId` in its circuit as a constant.) The L1 contract (LineaRollup) doesn't know whether the data and the proof are from the canonical L2 or the forked one. The finalization succeeds, and the attacker can claim the bridged forked chain Ether and steal funds from L1.\\nAs there is currently only one operator and it is owned by the Linea team, this kind of attack is unlikely to happen. However, when the operator and the coordinator are decentralized, the likelihood of this attack increases.\\n```\\nuint256 publicInput = uint256(\\n keccak256(\\n abi.encode(\\n shnarf,\\n \\_finalizationData.parentStateRootHash,\\n \\_finalizationData.lastFinalizedTimestamp,\\n \\_finalizationData.finalBlockNumber,\\n \\_finalizationData.finalTimestamp,\\n \\_finalizationData.l1RollingHash,\\n \\_finalizationData.l1RollingHashMessageNumber,\\n keccak256(abi.encodePacked(\\_finalizationData.l2MerkleRoots))\\n )\\n```\\n\\n```\\n\\_addL2MerkleRoots(\\_finalizationData.l2MerkleRoots, \\_finalizationData.l2MerkleTreesDepth);\\n```\\nчAdd `chainId` in the `FinalizationData` as a public input of the verifier function `_verifyProof`, so the proof from the forked Linea chain will not pass the verification because the `chainId` won't match.чч```\\nuint256 publicInput = uint256(\\n keccak256(\\n abi.encode(\\n shnarf,\\n \\_finalizationData.parentStateRootHash,\\n \\_finalizationData.lastFinalizedTimestamp,\\n \\_finalizationData.finalBlockNumber,\\n \\_finalizationData.finalTimestamp,\\n \\_finalizationData.l1RollingHash,\\n \\_finalizationData.l1RollingHashMessageNumber,\\n keccak256(abi.encodePacked(\\_finalizationData.l2MerkleRoots))\\n )\\n```\\n
The Compressed Block Data Is Not Verified Against Data in the Prover During Data Submission  AcknowledgedчmediumчWhen the sequencer submits the batched block data with the `submitData` function, it's expected to check that the submitted commitment of the compressed block data `keccak(_submissionData.compressedData)` and the commitment of the block data used in the prover (snarkHash) commit to the same data. This is done by proof of equivalence; the `x` is calculated by hashing `keccak(_submissionData.compressedData)` and `snarkHash`, and `y` is provided by the prover. Then it's verified that P(x) = `y`, where `P` is a polynomial that encodes the compressed data (_submissionData.compressedData). However, in the `submitData` function, `y` is evaluated by `_calculateY` but it is not checked against the `y` provided by the prover. In fact, the prover doesn't provide `y` to the function; instead `x` and `y` are provided to the prover who would evaluate `y'` and compare it with `y` from the contract, then `x` and `y` are included in the public input for the proof verification in the finalization.\\n```\\nshnarf = keccak256(\\n      abi.encode(\\n        shnarf,\\n        _submissionData.snarkHash,\\n        _submissionData.finalStateRootHash,\\n        compressedDataComputedX,\\n        _calculateY(_submissionData.compressedData, compressedDataComputedX)\\n      )\\n );     \\n```\\n\\nThe only difference is if the two commitments don't commit to the same block data (meaning the data submitted doesn't match the data used in the prover), `submitData` would fail – while in the current implementation, it would fail in the proof verification during the finalization. As a result, if the data submitted doesn't match the data in the prover in the finalization, the operator has to submit the correct data again in order to finalize it. Linea stated they will verify it in the data submission, once EIP-4844 is implemented.\\n```\\nfunction \\_submitData(SubmissionData calldata \\_submissionData) internal returns (bytes32 shnarf) {\\n shnarf = dataShnarfHashes[\\_submissionData.dataParentHash];\\n\\n bytes32 parentFinalStateRootHash = dataFinalStateRootHashes[\\_submissionData.dataParentHash];\\n uint256 lastFinalizedBlock = currentL2BlockNumber;\\n\\n if (\\_submissionData.firstBlockInData <= lastFinalizedBlock) {\\n revert FirstBlockLessThanOrEqualToLastFinalizedBlock(\\_submissionData.firstBlockInData, lastFinalizedBlock);\\n }\\n\\n if (\\_submissionData.firstBlockInData > \\_submissionData.finalBlockInData) {\\n revert FirstBlockGreaterThanFinalBlock(\\_submissionData.firstBlockInData, \\_submissionData.finalBlockInData);\\n }\\n\\n if (\\_submissionData.parentStateRootHash != parentFinalStateRootHash) {\\n revert StateRootHashInvalid(parentFinalStateRootHash, \\_submissionData.parentStateRootHash);\\n }\\n\\n bytes32 currentDataHash = keccak256(\\_submissionData.compressedData);\\n\\n if (dataFinalStateRootHashes[currentDataHash] != EMPTY\\_HASH) {\\n revert DataAlreadySubmitted(currentDataHash);\\n }\\n\\n dataParents[currentDataHash] = \\_submissionData.dataParentHash;\\n dataFinalStateRootHashes[currentDataHash] = \\_submissionData.finalStateRootHash;\\n\\n bytes32 compressedDataComputedX = keccak256(abi.encode(\\_submissionData.snarkHash, currentDataHash));\\n\\n shnarf = keccak256(\\n abi.encode(\\n shnarf,\\n \\_submissionData.snarkHash,\\n \\_submissionData.finalStateRootHash,\\n compressedDataComputedX,\\n \\_calculateY(\\_submissionData.compressedData, compressedDataComputedX)\\n )\\n );\\n\\n dataShnarfHashes[currentDataHash] = shnarf;\\n\\n emit DataSubmitted(currentDataHash, \\_submissionData.firstBlockInData, \\_submissionData.finalBlockInData);\\n}\\n```\\n\\n```\\nfunction \\_calculateY(\\n bytes calldata \\_data,\\n bytes32 \\_compressedDataComputedX\\n) internal pure returns (bytes32 compressedDataComputedY) {\\n if (\\_data.length % 0x20 != 0) {\\n revert BytesLengthNotMultipleOf32();\\n }\\n\\n bytes4 errorSelector = ILineaRollup.FirstByteIsNotZero.selector;\\n assembly {\\n for {\\n let i := \\_data.length\\n } gt(i, 0) {\\n\\n } {\\n i := sub(i, 0x20)\\n let chunk := calldataload(add(\\_data.offset, i))\\n if iszero(iszero(and(chunk, 0xFF00000000000000000000000000000000000000000000000000000000000000))) {\\n let ptr := mload(0x40)\\n mstore(ptr, errorSelector)\\n revert(ptr, 0x4)\\n }\\n compressedDataComputedY := addmod(\\n mulmod(compressedDataComputedY, \\_compressedDataComputedX, Y\\_MODULUS),\\n chunk,\\n Y\\_MODULUS\\n )\\n }\\n }\\n}\\n```\\nчAdd the compressed block data verification in the `submitData` function.чч```\\nshnarf = keccak256(\\n      abi.encode(\\n        shnarf,\\n        _submissionData.snarkHash,\\n        _submissionData.finalStateRootHash,\\n        compressedDataComputedX,\\n        _calculateY(_submissionData.compressedData, compressedDataComputedX)\\n      )\\n );     \\n```\\n
Empty Compressed Data Allowed in Data SubmissionчmediumчIn `submitData`, the coordinator can submit data with empty `compressedData` in `_submissionData`, which is not a desired purpose of this function and may cause undefined system behavior.\\n```\\nfunction submitData(\\n SubmissionData calldata \\_submissionData\\n)\\n external\\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\\n onlyRole(OPERATOR\\_ROLE)\\n{\\n \\_submitData(\\_submissionData);\\n}\\n```\\nчAdd a check to disallow data submission with empty `compressedData`.чч```\\nfunction submitData(\\n SubmissionData calldata \\_submissionData\\n)\\n external\\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\\n onlyRole(OPERATOR\\_ROLE)\\n{\\n \\_submitData(\\_submissionData);\\n}\\n```\\n
Limiting the Price in the buy and onTokenTransfer FunctionsчmediumчWhen an investor tries to `buy` the tokens in the `Crowdinvesting` contract, the `buy` function does not allow to limit the amount of tokens that can be spent during this particular transaction:\\n```\\nfunction buy(uint256 \\_amount, address \\_tokenReceiver) public whenNotPaused nonReentrant {\\n // rounding up to the next whole number. Investor is charged up to one currency bit more in case of a fractional currency bit.\\n uint256 currencyAmount = Math.ceilDiv(\\_amount \\* getPrice(), 10 \\*\\* token.decimals());\\n```\\n\\nThe owner of the price oracle can front-run the transaction and twist the price.\\nOf course, the buyer can try to regulate that limit with the token allowance, but there may be some exceptions. Sometimes, users want to give more allowance and buy in multiple transactions over time. Or even give an infinite allowance (not recommended) out of convenience.\\nThe same issue can be found in the `onTokenTransfer` function. This function works differently because the amount of currency is fixed, and the amount of tokens minted is undefined. Because of that, limiting the allowance won't help, so the user doesn't know how many tokens can be bought.чIt's recommended to explicitly limit the amount of tokens that can be transferred from the buyer for the `buy` function. And allow users to define a minimal amount of tokens bought in the `onTokenTransfer` function.чч```\\nfunction buy(uint256 \\_amount, address \\_tokenReceiver) public whenNotPaused nonReentrant {\\n // rounding up to the next whole number. Investor is charged up to one currency bit more in case of a fractional currency bit.\\n uint256 currencyAmount = Math.ceilDiv(\\_amount \\* getPrice(), 10 \\*\\* token.decimals());\\n```\\n
Potential Re-Entrancy Attack in the Crowdinvesting ContractчlowчThe attack requires a set of pre-requisites:\\nThe currency token should have a re-entrancy opportunity inside the token transfer.\\nThe re-entrancy can be done on a token transfer from the `_msgSender()` to the `feeCollector`, so there are not a lot of attackers who can potentially execute it.\\nThe owner should be involved in the attack, so it's most likely an attack by the owner.\\n```\\nfunction buy(uint256 \\_amount, address \\_tokenReceiver) public whenNotPaused nonReentrant {\\n // rounding up to the next whole number. Investor is charged up to one currency bit more in case of a fractional currency bit.\\n uint256 currencyAmount = Math.ceilDiv(\\_amount \\* getPrice(), 10 \\*\\* token.decimals());\\n\\n (uint256 fee, address feeCollector) = \\_getFeeAndFeeReceiver(currencyAmount);\\n if (fee != 0) {\\n currency.safeTransferFrom(\\_msgSender(), feeCollector, fee);\\n }\\n\\n currency.safeTransferFrom(\\_msgSender(), currencyReceiver, currencyAmount - fee);\\n \\_checkAndDeliver(\\_amount, \\_tokenReceiver);\\n\\n emit TokensBought(\\_msgSender(), \\_amount, currencyAmount);\\n}\\n```\\n\\nSo on the token transfer to the `feeCollector` above, the `currency` parameter can be changed by the `owner`. And the following token transfer (currency.safeTransferFrom(_msgSender(), currencyReceiver, currencyAmount - fee);) will be made in a different `currency`.\\nA possible scenario of the attack could look as follows:\\nMalicious owner sells tokens for a valuable currency. People are placing allowance for the tokens.\\nThe owner changes the currency to a new one with a much lower price and re-entrancy during transfer.\\nWhen a victim wants to buy tokens, the owner reenters on fee transfer and returns the old currency.\\nThe victim transfers the updated currency that is more expensive.чSave the currency in memory at the beginning of the function and use it further.чч```\\nfunction buy(uint256 \\_amount, address \\_tokenReceiver) public whenNotPaused nonReentrant {\\n // rounding up to the next whole number. Investor is charged up to one currency bit more in case of a fractional currency bit.\\n uint256 currencyAmount = Math.ceilDiv(\\_amount \\* getPrice(), 10 \\*\\* token.decimals());\\n\\n (uint256 fee, address feeCollector) = \\_getFeeAndFeeReceiver(currencyAmount);\\n if (fee != 0) {\\n currency.safeTransferFrom(\\_msgSender(), feeCollector, fee);\\n }\\n\\n currency.safeTransferFrom(\\_msgSender(), currencyReceiver, currencyAmount - fee);\\n \\_checkAndDeliver(\\_amount, \\_tokenReceiver);\\n\\n emit TokensBought(\\_msgSender(), \\_amount, currencyAmount);\\n}\\n```\\n
Lack of Validation of PrivateOffer Initialization ParametersчlowчThe `PrivateOffer` contract allows to create a customised deal for a specific investor. The `initialize()` function receives parameters to set up the `PrivateOffer` accordingly.\\nThe following parameters lack of validation during initialization:\\n`tokenAmount`\\n`token`\\n`currency`\\n`tokenAmount`\\n```\\nuint256 currencyAmount = Math.ceilDiv(\\n \\_arguments.tokenAmount \\* \\_arguments.tokenPrice,\\n 10 \\*\\* \\_arguments.token.decimals()\\n);\\n```\\n\\n`tokenAmount` is not validated at all. It should be verified to be greater than zero.\\n`token`\\n`token` is not validated at all. It should be verified to be different than zero address.\\n`currency`\\n`currency` is not validated at all. The documentation mentions a restricted list of supported currencies. It should be enforced by checking this parameter against a whitelist of `currency` addresses.чEnhance the validation of the following parameters: `tokenAmount`, `token`, `currency`.чч```\\nuint256 currencyAmount = Math.ceilDiv(\\n \\_arguments.tokenAmount \\* \\_arguments.tokenPrice,\\n 10 \\*\\* \\_arguments.token.decimals()\\n);\\n```\\n
Lack of Validation of Crowdinvesting Initialization ParametersчlowчThe `Crowdinvesting` contract allows everyone who meets the requirements to buy tokens at a fixed price. The `initialize()` function receives parameters to set up the `Crowdinvesting` accordingly.\\nThe following parameters lack of validation during initialization:\\n`tokenPrice`\\n`minAmountPerBuyer`\\n`lastBuyDate`\\n`currency`\\n`tokenPrice`\\n```\\nrequire(\\_arguments.tokenPrice != 0, \"\\_tokenPrice needs to be a non-zero amount\");\\n```\\n\\n`tokenPrice` is checked to be different to zero. It should be verified to be in between `priceMin` and `priceMax` when these parameters are provided.\\n`minAmountPerBuyer`\\n```\\nrequire(\\n \\_arguments.minAmountPerBuyer <= \\_arguments.maxAmountPerBuyer,\\n \"\\_minAmountPerBuyer needs to be smaller or equal to \\_maxAmountPerBuyer\"\\n);\\n```\\n\\n`minAmountPerBuyer` is checked to be below or equal to `maxAmountPerBuyer`. It should be verified to not be zero.\\n`lastBuyDate`\\n```\\nlastBuyDate = \\_arguments.lastBuyDate;\\n```\\n\\n`lastBuyDate` is not validated at all. It should be verified to be greater than the current `block.timestamp`. Currently, a `Crowdinvesting` contract with `lastBuyDate` parameter set to a value (different than zero) below `block.timestamp` will not be able to sell any token.\\n```\\nfunction \\_checkAndDeliver(uint256 \\_amount, address \\_tokenReceiver) internal {\\n require(tokensSold + \\_amount <= maxAmountOfTokenToBeSold, \"Not enough tokens to sell left\");\\n require(tokensBought[\\_tokenReceiver] + \\_amount >= minAmountPerBuyer, \"Buyer needs to buy at least minAmount\");\\n require(\\n tokensBought[\\_tokenReceiver] + \\_amount <= maxAmountPerBuyer,\\n \"Total amount of bought tokens needs to be lower than or equal to maxAmount\"\\n );\\n\\n if (lastBuyDate != 0 && block.timestamp > lastBuyDate) {\\n revert(\"Last buy date has passed: not selling tokens anymore.\");\\n }\\n\\n tokensSold += \\_amount;\\n tokensBought[\\_tokenReceiver] += \\_amount;\\n\\n token.mint(\\_tokenReceiver, \\_amount);\\n}\\n```\\n\\n`currency`\\n```\\nrequire(address(\\_arguments.currency) != address(0), \"currency can not be zero address\");\\n```\\n\\n`currency` is checked to be different than zero. The documentation mentions a restricted list of supported currencies. It should be enforced by checking this parameter against a whitelist of `currency` addresses.чEnhance the validation of the following parameters: `tokenPrice`, `tokenPrice`, `lastBuyDate`, `currency`.чч```\\nrequire(\\_arguments.tokenPrice != 0, \"\\_tokenPrice needs to be a non-zero amount\");\\n```\\n
Missing Events on Important State ChangesчmediumчThroughout the code base, various important settings-related state changes are not surfaced by events.\\nIn RocketDAONodeTrusted:\\n```\\nfunction bootstrapMember(string memory _id, string memory _url, address _nodeAddress) override external onlyGuardian onlyBootstrapMode onlyRegisteredNode(_nodeAddress) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets add them\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalInvite(_id, _url, _nodeAddress);\\n}\\n\\n\\n// Bootstrap mode - Uint Setting\\nfunction bootstrapSettingUint(string memory _settingContractName, string memory _settingPath, uint256 _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets update the settings\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingUint(_settingContractName, _settingPath, _value);\\n}\\n\\n// Bootstrap mode - Bool Setting\\nfunction bootstrapSettingBool(string memory _settingContractName, string memory _settingPath, bool _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets update the settings\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingBool(_settingContractName, _settingPath, _value);\\n}\\n```\\n\\nIn RocketDAOProtocol:\\n```\\nfunction bootstrapSettingMulti(string[] memory _settingContractNames, string[] memory _settingPaths, SettingType[] memory _types, bytes[] memory _values) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\\n  // Ok good to go, lets update the settings\\n  RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalSettingMulti(_settingContractNames, _settingPaths, _types, _values);\\n}\\n\\n/// @notice Bootstrap mode - Uint Setting\\nfunction bootstrapSettingUint(string memory _settingContractName, string memory _settingPath, uint256 _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\\n    // Ok good to go, lets update the settings\\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalSettingUint(_settingContractName, _settingPath, _value);\\n}\\n```\\n\\nTreasury address setter:\\n```\\nfunction bootstrapTreasuryNewContract(string memory _contractName, address _recipientAddress, uint256 _amountPerPeriod, uint256 _periodLength, uint256 _startTime, uint256 _numPeriods) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalTreasuryNewContract(_contractName, _recipientAddress, _amountPerPeriod, _periodLength, _startTime, _numPeriods);\\n}\\n```\\n\\nBootstrap mode management:\\n```\\nfunction bootstrapDisable(bool _confirmDisableBootstrapMode) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\\n    require(_confirmDisableBootstrapMode == true, \"You must confirm disabling bootstrap mode, it can only be done once!\");\\n    setBool(keccak256(abi.encodePacked(daoNameSpace, \"bootstrapmode.disabled\")), true);\\n}\\n```\\n\\nOne-time treasury spends:\\n```\\nfunction bootstrapSpendTreasury(string memory _invoiceID, address _recipientAddress, uint256 _amount) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalTreasuryOneTimeSpend(_invoiceID, _recipientAddress, _amount);\\n}\\n```\\n\\n```\\nfunction setDelegate(address _newDelegate) external override onlyRegisteredNode(msg.sender) {\\n```\\n\\n```\\nfunction proposalSettingUint(string memory _settingNameSpace, string memory _settingPath, uint256 _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\\n```\\n\\n```\\nfunction proposalSettingBool(string memory _settingNameSpace, string memory _settingPath, bool _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\\n```\\n\\n```\\nfunction proposalSettingAddress(string memory _settingNameSpace, string memory _settingPath, address _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\\n```\\n\\n```\\nfunction proposalInvite(string calldata _id, address _memberAddress) override public onlyLatestContract(\"rocketDAOProtocolProposals\", msg.sender) {\\n    // Their proposal executed, record the block\\n```\\nчResolution\\nThe client implemented a fix in commit `1be41a88a40125baf58d8904770cd9eb9e0732bb` and provided the following statement:\\nRocketDAONodeTrusted is not a contract that is getting upgrade so this won't be fixed\\nRocketDAOProtocol has been updated to include events for each bootstrap function\\nRocketNetworkVoting has been updated to emit an event\\nRocketDAOSecurityProposals has been updated to emit events for all proposals\\nWe recommend emitting events on state changes, particularly when these are performed by an authorized party. The implementation of the recommendation should be analogous to the handling of events on state changes in the rest of the system, such as in the `RocketMinipoolPenalty` contract:\\n```\\nfunction setMaxPenaltyRate(uint256 _rate) external override onlyGuardian {\\n    // Update rate\\n    maxPenaltyRate = _rate;\\n    // Emit event\\n    emit MaxPenaltyRateUpdated(_rate, block.timestamp);\\n}\\n```\\nчч```\\nfunction bootstrapMember(string memory _id, string memory _url, address _nodeAddress) override external onlyGuardian onlyBootstrapMode onlyRegisteredNode(_nodeAddress) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets add them\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalInvite(_id, _url, _nodeAddress);\\n}\\n\\n\\n// Bootstrap mode - Uint Setting\\nfunction bootstrapSettingUint(string memory _settingContractName, string memory _settingPath, uint256 _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets update the settings\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingUint(_settingContractName, _settingPath, _value);\\n}\\n\\n// Bootstrap mode - Bool Setting\\nfunction bootstrapSettingBool(string memory _settingContractName, string memory _settingPath, bool _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets update the settings\\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingBool(_settingContractName, _settingPath, _value);\\n}\\n```\\n
RocketDAOProtocolProposal._propose() Should Revert if _blockNumber > block.numberчmediumчCurrently, the `RocketDAOProtocolProposal._propose()` function does not account for scenarios where `_blockNumber` is greater than `block.number`. This is a critical oversight, as voting power cannot be determined for future block numbers.\\n```\\nfunction _propose(string memory _proposalMessage, uint256 _blockNumber, uint256 _totalVotingPower, bytes calldata _payload) internal returns (uint256) {\\n```\\nчWe recommend updating the function to revert on transactions where `_blockNumber` exceeds `block.number`. This will prevent the creation of proposals with undefined voting power and maintain the integrity of the voting process.чч```\\nfunction _propose(string memory _proposalMessage, uint256 _blockNumber, uint256 _totalVotingPower, bytes calldata _payload) internal returns (uint256) {\\n```\\n
Unused Parameter and Improper Parameter Sanitization in RocketNetworkVoting.calculateVotingPower()чlowчThe `matchedETH` parameter in `RocketNetworkVoting.calculateVotingPower()` is unused.\\n```\\n// Get contracts\\nRocketDAOProtocolSettingsNodeInterface rocketDAOProtocolSettingsNode = RocketDAOProtocolSettingsNodeInterface(getContractAddress(\"rocketDAOProtocolSettingsNode\"));\\n```\\n\\nAdditionally, the `_block` parameter is not sanitized. Thus, if calling the function with a block number `_block` where `_block >= block.number`, the call will revert because of a division-by-zero error. Indeed, `rocketNetworkSnapshots.lookupRecent` will return a `rplPrice` of zero since the checkpoint does not exist. Consequently, the function `calculateVotingPower` will revert when computing the `maximumStake`.\\n```\\nkey = keccak256(abi.encodePacked(\"rpl.staked.node.amount\", _nodeAddress));\\nuint256 rplStake = uint256(rocketNetworkSnapshots.lookupRecent(key, uint32(_block), 5));\\n\\nreturn calculateVotingPower(rplStake, ethMatched, ethProvided, rplPrice);\\n```\\n\\n```\\nuint256 maximumStake = providedETH * maximumStakePercent / rplPrice;\\n```\\nчWe recommend removing the unused parameter to enhance code clarity. The presence of unused parameters can lead to potential confusion for future developers. Additionally, we recommend ensuring that the snapshotted `rplPrice` value exists before it is used to compute the `maximumStake` value.чч```\\n// Get contracts\\nRocketDAOProtocolSettingsNodeInterface rocketDAOProtocolSettingsNode = RocketDAOProtocolSettingsNodeInterface(getContractAddress(\"rocketDAOProtocolSettingsNode\"));\\n```\\n
Wrong/Misleading NatSpec DocumentationчlowчThe NatSpec documentation in several parts of the code base contains inaccuracies or is misleading. This issue can lead to misunderstandings about how the code functions, especially for developers who rely on these comments for clarity and guidance.\\nIn `RocketDAOProtocolProposal`, the NatSpec comments are potentially misleading:\\n```\\n/// @notice Get the votes against count of this proposal\\n/// @param _proposalID The ID of the proposal to query\\n```\\n\\n```\\n/// @notice Returns true if this proposal was supported by this node\\n/// @param _proposalID The ID of the proposal to query\\n/// @param _nodeAddress The node operator address to query\\nfunction getReceiptDirection(uint256 _proposalID, address _nodeAddress) override public view returns (VoteDirection) {\\n    return VoteDirection(getUint(keccak256(abi.encodePacked(daoProposalNameSpace, \"receipt.direction\", _proposalID, _nodeAddress))));\\n}\\n```\\n\\nIn RocketDAOProtocolVerifier, the NatSpec documentation is incomplete, which might leave out critical information about the function's purpose and behavior:\\n```\\n/// @notice Used by a verifier to challenge a specific index of a proposal's voting power tree\\n/// @param _proposalID The ID of the proposal being challenged\\n/// @param _index The global index of the node being challenged\\n```\\nчThe NatSpec documentation should be thoroughly reviewed and corrected where necessary. We recommend ensuring it accurately reflects the code's functionality and provides complete information.чч```\\n/// @notice Get the votes against count of this proposal\\n/// @param _proposalID The ID of the proposal to query\\n```\\n
RocketDAOProtocolSettingsRewards.setSettingRewardClaimPeriods() Cannot Be Invokedчlowч```\\nsetUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"periods\")), _periods);\\n```\\nчTo make this function useful and align it with its intended purpose, we recommend integrating its functionality into `RocketDAOProtocolProposals`. In addition, we recommend that this function emit an event upon successful change of settings, enhancing the transparency of the operation.чч```\\nsetUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"periods\")), _periods);\\n```\\n
No Protection of Uninitialized Implementation Contracts From AttackerчmediumчIn the contracts implement Openzeppelin's UUPS model, uninitialized implementation contract can be taken over by an attacker with `initialize` function, it's recommended to invoke the `_disableInitializers` function in the constructor to prevent the implementation contract from being used by the attacker. However all the contracts which implements `OwnablePausableUpgradeable` do not call `_disableInitializers` in the constructors\\n```\\ncontract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n\\n```\\ncontract Pool is IPool, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n\\n```\\ncontract StakedLyxToken is OwnablePausableUpgradeable, LSP4DigitalAssetMetadataInitAbstract, IStakedLyxToken, ReentrancyGuardUpgradeable {\\n```\\n\\netc.чInvoke `_disableInitializers` in the constructors of contracts which implement `OwnablePausableUpgradeable` including following:\\n```\\nPool\\nPoolValidators\\nFeeEscrow\\nReward\\nStakeLyxTokem\\nOracles \\nMerkleDistributor\\n```\\nчч```\\ncontract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n
Unsafe Function receiveFees  AcknowledgedчlowчIn the Pool contract, function `receiveFees` is used for compensate a potential penalty/slashing in the protocol by sending LYX back to the pool without minting sLYX, but the side effect is that anyone can send LYX to the pool which could mess up pool balance after all validator exited, in fact it can be replaced by a another function `receiveWithoutActivation` with access control which does the same thing.\\n```\\nfunction receiveFees() external payable override {}\\n```\\n\\n```\\nfunction receiveWithoutActivation() external payable override {\\n require(msg.sender == address(stakedLyxToken) || hasRole(DEFAULT\\_ADMIN\\_ROLE, msg.sender), \"Pool: access denied\");\\n}\\n```\\nчRemove function `receiveFees`чч```\\nfunction receiveFees() external payable override {}\\n```\\n
Unnecessary Matching in Unstake ProcessчlowчFunction `unstakeProcessed` in `StakedLyxToken` contract, when `unstakeAmount > totalPendingUnstake`, all the unstake requests should be able to be processed, thus no need to go through the matching, as a result, extra gas in the matching can be saved.\\n```\\nif (unstakeAmount > totalPendingUnstake) {\\n pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n unstakeAmount = totalPendingUnstake;\\n}\\n\\ntotalPendingUnstake -= unstakeAmount;\\ntotalUnstaked += unstakeAmount;\\nuint256 amountToFill = unstakeAmount;\\n\\nfor (uint256 i = unstakeRequestCurrentIndex; i <= unstakeRequestCount; i++) {\\n UnstakeRequest storage request = \\_unstakeRequests[i];\\n if (amountToFill > (request.amount - request.amountFilled)) {\\n amountToFill -= (request.amount - request.amountFilled);\\n continue;\\n } else {\\n if (amountToFill == (request.amount - request.amountFilled) && i < unstakeRequestCount) {\\n unstakeRequestCurrentIndex = i + 1;\\n } else {\\n request.amountFilled += uint128(amountToFill);\\n unstakeRequestCurrentIndex = i;\\n }\\n break;\\n }\\n}\\n```\\nчPut the matching part (line 393-411) into else branch of `if unstakeAmount > totalPendingUnstake`, change the if branch into following:\\n```\\nif (unstakeAmount > totalPendingUnstake) {\\n            pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n            unstakeAmount = totalPendingUnstake;\\n            totalPendingUnstake = 0;\\n            unstakeRequestCurrentIndex = unstakeRequestCount;\\n            _unstakeRequests[unstakeRequestCount].amountFilled = _unstakeRequests[unstakeRequestCount].amount;\\n } \\n```\\nчч```\\nif (unstakeAmount > totalPendingUnstake) {\\n pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n unstakeAmount = totalPendingUnstake;\\n}\\n\\ntotalPendingUnstake -= unstakeAmount;\\ntotalUnstaked += unstakeAmount;\\nuint256 amountToFill = unstakeAmount;\\n\\nfor (uint256 i = unstakeRequestCurrentIndex; i <= unstakeRequestCount; i++) {\\n UnstakeRequest storage request = \\_unstakeRequests[i];\\n if (amountToFill > (request.amount - request.amountFilled)) {\\n amountToFill -= (request.amount - request.amountFilled);\\n continue;\\n } else {\\n if (amountToFill == (request.amount - request.amountFilled) && i < unstakeRequestCount) {\\n unstakeRequestCurrentIndex = i + 1;\\n } else {\\n request.amountFilled += uint128(amountToFill);\\n unstakeRequestCurrentIndex = i;\\n }\\n break;\\n }\\n}\\n```\\n
No Protection of Uninitialized Implementation Contracts From AttackerчmediumчIn the contracts implement Openzeppelin's UUPS model, uninitialized implementation contract can be taken over by an attacker with `initialize` function, it's recommended to invoke the `_disableInitializers` function in the constructor to prevent the implementation contract from being used by the attacker. However all the contracts which implements `OwnablePausableUpgradeable` do not call `_disableInitializers` in the constructors\\n```\\ncontract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n\\n```\\ncontract Pool is IPool, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n\\n```\\ncontract StakedLyxToken is OwnablePausableUpgradeable, LSP4DigitalAssetMetadataInitAbstract, IStakedLyxToken, ReentrancyGuardUpgradeable {\\n```\\n\\netc.чInvoke `_disableInitializers` in the constructors of contracts which implement `OwnablePausableUpgradeable` including following:\\n```\\nPool\\nPoolValidators\\nFeeEscrow\\nReward\\nStakeLyxTokem\\nOracles \\nMerkleDistributor\\n```\\nчч```\\ncontract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\\n```\\n
Unnecessary Matching in Unstake ProcessчlowчFunction `unstakeProcessed` in `StakedLyxToken` contract, when `unstakeAmount > totalPendingUnstake`, all the unstake requests should be able to be processed, thus no need to go through the matching, as a result, extra gas in the matching can be saved.\\n```\\nif (unstakeAmount > totalPendingUnstake) {\\n pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n unstakeAmount = totalPendingUnstake;\\n}\\n\\ntotalPendingUnstake -= unstakeAmount;\\ntotalUnstaked += unstakeAmount;\\nuint256 amountToFill = unstakeAmount;\\n\\nfor (uint256 i = unstakeRequestCurrentIndex; i <= unstakeRequestCount; i++) {\\n UnstakeRequest storage request = \\_unstakeRequests[i];\\n if (amountToFill > (request.amount - request.amountFilled)) {\\n amountToFill -= (request.amount - request.amountFilled);\\n continue;\\n } else {\\n if (amountToFill == (request.amount - request.amountFilled) && i < unstakeRequestCount) {\\n unstakeRequestCurrentIndex = i + 1;\\n } else {\\n request.amountFilled += uint128(amountToFill);\\n unstakeRequestCurrentIndex = i;\\n }\\n break;\\n }\\n}\\n```\\nчPut the matching part (line 393-411) into else branch of `if unstakeAmount > totalPendingUnstake`, change the if branch into following:\\n```\\nif (unstakeAmount > totalPendingUnstake) {\\n            pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n            unstakeAmount = totalPendingUnstake;\\n            totalPendingUnstake = 0;\\n            unstakeRequestCurrentIndex = unstakeRequestCount;\\n            _unstakeRequests[unstakeRequestCount].amountFilled = _unstakeRequests[unstakeRequestCount].amount;\\n } \\n```\\nчч```\\nif (unstakeAmount > totalPendingUnstake) {\\n pool.receiveWithoutActivation{value: unstakeAmount - totalPendingUnstake}();\\n unstakeAmount = totalPendingUnstake;\\n}\\n\\ntotalPendingUnstake -= unstakeAmount;\\ntotalUnstaked += unstakeAmount;\\nuint256 amountToFill = unstakeAmount;\\n\\nfor (uint256 i = unstakeRequestCurrentIndex; i <= unstakeRequestCount; i++) {\\n UnstakeRequest storage request = \\_unstakeRequests[i];\\n if (amountToFill > (request.amount - request.amountFilled)) {\\n amountToFill -= (request.amount - request.amountFilled);\\n continue;\\n } else {\\n if (amountToFill == (request.amount - request.amountFilled) && i < unstakeRequestCount) {\\n unstakeRequestCurrentIndex = i + 1;\\n } else {\\n request.amountFilled += uint128(amountToFill);\\n unstakeRequestCurrentIndex = i;\\n }\\n break;\\n }\\n}\\n```\\n
Re-Entrancy Risks Associated With External Calls With Other Liquid Staking Systems.чhighчAs part of the strategy to integrate with Liquid Staking tokens for Ethereum staking, the Lybra Protocol vaults are required to make external calls to Liquid Staking systems.\\nFor example, the `depositEtherToMint` function in the vaults makes external calls to deposit Ether and receive the LSD tokens back. While external calls to untrusted third-party contracts may be dangerous, in this case, the Lybra Protocol already extends trust assumptions to these third parties simply through the act of accepting their tokens as collateral. Indeed, in some cases the contract addresses are even hardcoded into the contract and called directly instead of relying on some registry:\\n```\\ncontract LybraWstETHVault is LybraPeUSDVaultBase {\\n Ilido immutable lido;\\n //WstETH = 0x7f39C581F595B53c5cb19bD0b3f8dA6c935E2Ca0;\\n //Lido = 0xae7ab96520DE3A18E5e111B5EaAb095312D7fE84;\\n constructor(address \\_lido, address \\_asset, address \\_oracle, address \\_config) LybraPeUSDVaultBase(\\_asset, \\_oracle, \\_config) {\\n lido = Ilido(\\_lido);\\n }\\n\\n function depositEtherToMint(uint256 mintAmount) external payable override {\\n require(msg.value >= 1 ether, \"DNL\");\\n uint256 sharesAmount = lido.submit{value: msg.value}(address(configurator));\\n require(sharesAmount != 0, \"ZERO\\_DEPOSIT\");\\n lido.approve(address(collateralAsset), msg.value);\\n uint256 wstETHAmount = IWstETH(address(collateralAsset)).wrap(msg.value);\\n depositedAsset[msg.sender] += wstETHAmount;\\n if (mintAmount > 0) {\\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\\n }\\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,wstETHAmount, block.timestamp);\\n }\\n```\\n\\nIn that case, depending on the contract, it may be known what contract is being called, and the risk may be assessed as far as what logic may be executed.\\nHowever, in the cases of `BETH` and `rETH`, the calls are being made into a proxy and a contract registry of a DAO (RocketPool's DAO) respectively.\\n```\\ncontract LybraWBETHVault is LybraPeUSDVaultBase {\\n //WBETH = 0xa2e3356610840701bdf5611a53974510ae27e2e1\\n constructor(address \\_asset, address \\_oracle, address \\_config)\\n LybraPeUSDVaultBase(\\_asset, \\_oracle, \\_config) {}\\n\\n function depositEtherToMint(uint256 mintAmount) external payable override {\\n require(msg.value >= 1 ether, \"DNL\");\\n uint256 preBalance = collateralAsset.balanceOf(address(this));\\n IWBETH(address(collateralAsset)).deposit{value: msg.value}(address(configurator));\\n uint256 balance = collateralAsset.balanceOf(address(this));\\n depositedAsset[msg.sender] += balance - preBalance;\\n\\n if (mintAmount > 0) {\\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\\n }\\n\\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,balance - preBalance, block.timestamp);\\n }\\n```\\n\\n```\\nconstructor(address \\_rocketStorageAddress, address \\_rETH, address \\_oracle, address \\_config)\\n LybraPeUSDVaultBase(\\_rETH, \\_oracle, \\_config) {\\n rocketStorage = IRocketStorageInterface(\\_rocketStorageAddress);\\n}\\n\\nfunction depositEtherToMint(uint256 mintAmount) external payable override {\\n require(msg.value >= 1 ether, \"DNL\");\\n uint256 preBalance = collateralAsset.balanceOf(address(this));\\n IRocketDepositPool(rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \"rocketDepositPool\")))).deposit{value: msg.value}();\\n uint256 balance = collateralAsset.balanceOf(address(this));\\n depositedAsset[msg.sender] += balance - preBalance;\\n\\n if (mintAmount > 0) {\\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\\n }\\n\\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,balance - preBalance, block.timestamp);\\n}\\n```\\n\\nAs a result, it is impossible to make any guarantees for what logic will be executed during the external calls. Namely, reentrancy risks can't be ruled out, and the damage could be critical to the system. While the trust in these parties isn't in question, it would be best practice to avoid any additional reentrancy risks by placing reentrancy guards. Indeed, in the `LybraRETHVault` and `LybraWbETHVault` contracts, one can see the possible damage as the calls are surrounded in a `preBalance <-> balance` pattern.\\nThe whole of third party Liquid Staking systems' operations need not be compromised, only these particular parts would be enough to cause critical damage to the Lybra Protocol.чAfter conversations with the Lybra Finance team, it has been assessed that reentrancy guards are appropriate in this scenario to avoid any potential reentrancy risk, which is exactly the recommendation this audit team would provide.чч```\\ncontract LybraWstETHVault is LybraPeUSDVaultBase {\\n Ilido immutable lido;\\n //WstETH = 0x7f39C581F595B53c5cb19bD0b3f8dA6c935E2Ca0;\\n //Lido = 0xae7ab96520DE3A18E5e111B5EaAb095312D7fE84;\\n constructor(address \\_lido, address \\_asset, address \\_oracle, address \\_config) LybraPeUSDVaultBase(\\_asset, \\_oracle, \\_config) {\\n lido = Ilido(\\_lido);\\n }\\n\\n function depositEtherToMint(uint256 mintAmount) external payable override {\\n require(msg.value >= 1 ether, \"DNL\");\\n uint256 sharesAmount = lido.submit{value: msg.value}(address(configurator));\\n require(sharesAmount != 0, \"ZERO\\_DEPOSIT\");\\n lido.approve(address(collateralAsset), msg.value);\\n uint256 wstETHAmount = IWstETH(address(collateralAsset)).wrap(msg.value);\\n depositedAsset[msg.sender] += wstETHAmount;\\n if (mintAmount > 0) {\\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\\n }\\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,wstETHAmount, block.timestamp);\\n }\\n```\\n
The Deployer of GovernanceTimelock Gets Privileged Access to the System.чhighчThe `GovernanceTimelock` contract is responsible for Roles Based Access Control management and checks in the Lybra Protocol. It offers two functions specifically that check if an address has the required role - `checkRole` and checkOnlyRole:\\n```\\nfunction checkRole(bytes32 role, address \\_sender) public view returns(bool){\\n return hasRole(role, \\_sender) || hasRole(DAO, \\_sender);\\n}\\n\\nfunction checkOnlyRole(bytes32 role, address \\_sender) public view returns(bool){\\n return hasRole(role, \\_sender);\\n}\\n```\\n\\nIn `checkRole`, the contract also lets an address with the role `DAO` bypass the check altogether, making it a powerful role.\\nFor initial role management, when the `GovernanceTimelock` contract gets deployed, its constructor logic initializes a few roles, assigns relevant admin roles, and, notably, assigns the `DAO` role to the contract, and the `DAO` and the `GOV` role to the deployer.\\n```\\nconstructor(uint256 minDelay, address[] memory proposers, address[] memory executors, address admin) TimelockController(minDelay, proposers, executors, admin) {\\n \\n \\_setRoleAdmin(DAO, GOV);\\n \\_setRoleAdmin(TIMELOCK, GOV);\\n \\_setRoleAdmin(ADMIN, GOV);\\n \\_grantRole(DAO, address(this));\\n \\_grantRole(DAO, msg.sender);\\n \\_grantRole(GOV, msg.sender);\\n}\\n```\\n\\nThe assignment of such powerful roles to a single private key with the deployer has inherent risks. Specifically in our case, the `DAO` role alone as we saw may bypass many checks within the Lybra Protocol, and the `GOV` role even has role management privileges.\\nHowever, it does make sense to assign such roles at the beginning of the deployment to finish initialization and assign the rest of the roles. One could argue that having access to the `DAO` role in the early stages of the system's life could allow for quick disaster recovery in the event of incidents as well. Though, it is still dangerous to hold privileges for such a system in a single address as we have seen over the last years in security incidents that have to do with compromised keys.чWhile redesigning the deployment process to account for a lesser-privileged deployer would be ideal, the Lybra Finance team should at least transfer ownership as soon as the deployment is complete to minimize compromised private key risk.чч```\\nfunction checkRole(bytes32 role, address \\_sender) public view returns(bool){\\n return hasRole(role, \\_sender) || hasRole(DAO, \\_sender);\\n}\\n\\nfunction checkOnlyRole(bytes32 role, address \\_sender) public view returns(bool){\\n return hasRole(role, \\_sender);\\n}\\n```\\n
The configurator.getEUSDMaxLocked() Condition Can Be Bypassed During a FlashloanчmediumчWhen converting `EUSD` tokens to `peUSD`, there is a check that limits the total amount of `EUSD` that can be converted:\\n```\\nfunction convertToPeUSD(address user, uint256 eusdAmount) public {\\n require(\\_msgSender() == user || \\_msgSender() == address(this), \"MDM\");\\n require(eusdAmount != 0, \"ZA\");\\n require(EUSD.balanceOf(address(this)) + eusdAmount <= configurator.getEUSDMaxLocked(),\"ESL\");\\n```\\n\\nThe issue is that there is a way to bypass this restriction. An attacker can get a flash loan (in EUSD) from this contract, essentially reducing the visible amount of locked tokens (EUSD.balanceOf(address(this))).чMultiple approaches can solve this issue. One would be adding reentrancy protection. Another one could be keeping track of the borrowed amount for a flashloan.чч```\\nfunction convertToPeUSD(address user, uint256 eusdAmount) public {\\n require(\\_msgSender() == user || \\_msgSender() == address(this), \"MDM\");\\n require(eusdAmount != 0, \"ZA\");\\n require(EUSD.balanceOf(address(this)) + eusdAmount <= configurator.getEUSDMaxLocked(),\"ESL\");\\n```\\n
Liquidation Keepers Automatically Become eUSD Debt Providers for Other Liquidations.чmediumчOne of the most important mechanisms in the Lybra Protocol is the liquidation of poorly collateralized vaults. For example, if a vault is found to have a collateralization ratio that is too small, a liquidator may provide debt tokens to the protocol and retrieve the vault collateral at a discount:\\n```\\nfunction liquidation(address provider, address onBehalfOf, uint256 assetAmount) external virtual {\\n uint256 assetPrice = getAssetPrice();\\n uint256 onBehalfOfCollateralRatio = (depositedAsset[onBehalfOf] \\* assetPrice \\* 100) / borrowed[onBehalfOf];\\n require(onBehalfOfCollateralRatio < badCollateralRatio, \"Borrowers collateral ratio should below badCollateralRatio\");\\n\\n require(assetAmount \\* 2 <= depositedAsset[onBehalfOf], \"a max of 50% collateral can be liquidated\");\\n require(EUSD.allowance(provider, address(this)) != 0, \"provider should authorize to provide liquidation EUSD\");\\n uint256 eusdAmount = (assetAmount \\* assetPrice) / 1e18;\\n\\n \\_repay(provider, onBehalfOf, eusdAmount);\\n uint256 reducedAsset = assetAmount \\* 11 / 10;\\n totalDepositedAsset -= reducedAsset;\\n depositedAsset[onBehalfOf] -= reducedAsset;\\n uint256 reward2keeper;\\n if (provider == msg.sender) {\\n collateralAsset.safeTransfer(msg.sender, reducedAsset);\\n } else {\\n reward2keeper = (reducedAsset \\* configurator.vaultKeeperRatio(address(this))) / 110;\\n collateralAsset.safeTransfer(provider, reducedAsset - reward2keeper);\\n collateralAsset.safeTransfer(msg.sender, reward2keeper);\\n }\\n emit LiquidationRecord(provider, msg.sender, onBehalfOf, eusdAmount, reducedAsset, reward2keeper, false, block.timestamp);\\n}\\n```\\n\\nTo liquidate the vault, the liquidator needs to transfer debt tokens from the provider address, which in turn needs to have had approved allowance of the token for the vault:\\n```\\nrequire(EUSD.allowance(provider, address(this)) != 0, \"provider should authorize to provide liquidation EUSD\");\\n```\\n\\nThe allowance doesn't need to be large, it only needs to be non-zero. While it is true that in the `superLiquidation` function the allowance check is for `eusdAmount`, which is the amount associated with `assetAmount` (the requested amount of collateral to be liquidated), the liquidator could simply call the maximum of the allowance the provider has given to the vault and then repeat the liquidation process. The allowance does not actually decrease throughout the liquidation process.\\n```\\nrequire(EUSD.allowance(provider, address(this)) >= eusdAmount, \"provider should authorize to provide liquidation EUSD\");\\n```\\n\\nNotably, this address doesn't have to be the same one as the liquidator. In fact, there are no checks on whether the liquidator has an agreement or allowance from the provider to use their tokens in this particular vault's liquidation. The contract only checks to see if the provider has `EUSD` allowance for the vault, and how to split the rewards if the provider is different from the liquidator:\\n```\\nif (provider == msg.sender) {\\n collateralAsset.safeTransfer(msg.sender, reducedAsset);\\n} else {\\n reward2keeper = (reducedAsset \\* configurator.vaultKeeperRatio(address(this))) / 110;\\n collateralAsset.safeTransfer(provider, reducedAsset - reward2keeper);\\n collateralAsset.safeTransfer(msg.sender, reward2keeper);\\n}\\n```\\n\\nIn fact, this is a design choice of the system to treat the allowance to the vault as an agreement to become a public provider of debt tokens for the liquidation process. It is important to note that there are incentives associated with being a provider as they get the collateral asset at a discount.\\nHowever, it is not obvious from documentation at the time of the audit nor the code that an address having a non-zero `EUSD` allowance for the vault automatically allows other users to use that address as a provider. Indeed, many general-purpose liquidator bots use their tokens during liquidations, using the same address for both the liquidator and the provider. As a result, this would put that address at the behest of any other user who would want to utilize these tokens in liquidations. The user might not be comfortable doing this trade in any case, even at a discount.\\nIn fact, due to this mechanism, even during consciously initiated liquidations MEV bots could spot this opportunity and front-run the liquidator's transaction. A frontrunner could put themselves as the keeper and the original user as the provider, grabbing the `reward2keeper` fee and leaving the original address with fewer rewards and failed gas after the liquidation.чWhile the mechanism is understood to be done for convenience and access to liquidity as a design decision, this could put unaware users in unfortunate situations of having performed a trade without explicit consent. Specifically, the MEV attack vector could be executed and repeated without fail by a capable actor monitoring the mempool. Consider having a separate, explicit flag for allowing others to use a user's tokens during liquidation, thus also accommodating solo liquidators by removing the MEV attack vector. Consider explicitly mentioning these mechanisms in the documentation as well.чч```\\nfunction liquidation(address provider, address onBehalfOf, uint256 assetAmount) external virtual {\\n uint256 assetPrice = getAssetPrice();\\n uint256 onBehalfOfCollateralRatio = (depositedAsset[onBehalfOf] \\* assetPrice \\* 100) / borrowed[onBehalfOf];\\n require(onBehalfOfCollateralRatio < badCollateralRatio, \"Borrowers collateral ratio should below badCollateralRatio\");\\n\\n require(assetAmount \\* 2 <= depositedAsset[onBehalfOf], \"a max of 50% collateral can be liquidated\");\\n require(EUSD.allowance(provider, address(this)) != 0, \"provider should authorize to provide liquidation EUSD\");\\n uint256 eusdAmount = (assetAmount \\* assetPrice) / 1e18;\\n\\n \\_repay(provider, onBehalfOf, eusdAmount);\\n uint256 reducedAsset = assetAmount \\* 11 / 10;\\n totalDepositedAsset -= reducedAsset;\\n depositedAsset[onBehalfOf] -= reducedAsset;\\n uint256 reward2keeper;\\n if (provider == msg.sender) {\\n collateralAsset.safeTransfer(msg.sender, reducedAsset);\\n } else {\\n reward2keeper = (reducedAsset \\* configurator.vaultKeeperRatio(address(this))) / 110;\\n collateralAsset.safeTransfer(provider, reducedAsset - reward2keeper);\\n collateralAsset.safeTransfer(msg.sender, reward2keeper);\\n }\\n emit LiquidationRecord(provider, msg.sender, onBehalfOf, eusdAmount, reducedAsset, reward2keeper, false, block.timestamp);\\n}\\n```\\n
Use the Same Solidity Version Across Contracts.чlowчMost contracts use the same Solidity version with `pragma solidity ^0.8.17`. The only exception is the `StakingRewardsV2` contract which has `pragma solidity ^0.8`.\\n```\\npragma solidity ^0.8;\\n```\\nчIf all contracts will be tested and utilized together, it would be best to utilize and document the same version within all contract code to avoid any issues and inconsistencies that may arise across Solidity versions.чч```\\npragma solidity ^0.8;\\n```\\n
Missing Events.чlowчIn a few cases in the Lybra Protocol system, there are contracts that are missing events in significant scenarios, such as important configuration changes like a price oracle change. Consider implementing more events in the below examples.\\nNo events in the contract:\\n```\\ncontract esLBRBoost is Ownable {\\n esLBRLockSetting[] public esLBRLockSettings;\\n mapping(address => LockStatus) public userLockStatus;\\n IMiningIncentives public miningIncentives;\\n\\n // Define a struct for the lock settings\\n struct esLBRLockSetting {\\n uint256 duration;\\n uint256 miningBoost;\\n }\\n\\n // Define a struct for the user's lock status\\n struct LockStatus {\\n uint256 lockAmount;\\n uint256 unlockTime;\\n uint256 duration;\\n uint256 miningBoost;\\n }\\n\\n // Constructor to initialize the default lock settings\\n constructor(address \\_miningIncentives) {\\n```\\n\\nMissing an event during a premature unlock:\\n```\\nfunction unlockPrematurely() external {\\n require(block.timestamp + exitCycle - 3 days > time2fullRedemption[msg.sender], \"ENW\");\\n uint256 burnAmount = getReservedLBRForVesting(msg.sender) - getPreUnlockableAmount(msg.sender);\\n uint256 amount = getPreUnlockableAmount(msg.sender) + getClaimAbleLBR(msg.sender);\\n if (amount > 0) {\\n LBR.mint(msg.sender, amount);\\n }\\n unstakeRatio[msg.sender] = 0;\\n time2fullRedemption[msg.sender] = 0;\\n grabableAmount += burnAmount;\\n}\\n```\\n\\nMissing events for setting important configurations such as `setToken`, `setLBROracle`, and setPools:\\n```\\nfunction setToken(address \\_lbr, address \\_eslbr) external onlyOwner {\\n LBR = \\_lbr;\\n esLBR = \\_eslbr;\\n}\\n\\nfunction setLBROracle(address \\_lbrOracle) external onlyOwner {\\n lbrPriceFeed = AggregatorV3Interface(\\_lbrOracle);\\n}\\n\\nfunction setPools(address[] memory \\_vaults) external onlyOwner {\\n require(\\_vaults.length <= 10, \"EL\");\\n for (uint i = 0; i < \\_vaults.length; i++) {\\n require(configurator.mintVault(\\_vaults[i]), \"NOT\\_VAULT\");\\n }\\n vaults = \\_vaults;\\n}\\n```\\n\\nMissing events for setting important configurations such as `setRewardsDuration` and setBoost:\\n```\\n// Allows the owner to set the rewards duration\\nfunction setRewardsDuration(uint256 \\_duration) external onlyOwner {\\n require(finishAt < block.timestamp, \"reward duration not finished\");\\n duration = \\_duration;\\n}\\n\\n// Allows the owner to set the boost contract address\\nfunction setBoost(address \\_boost) external onlyOwner {\\n esLBRBoost = IesLBRBoost(\\_boost);\\n}\\n```\\n\\nMissing event during what is essentially staking `LBR` into `esLBR` (such as in ProtocolRewardsPool.stake()). Consider an appropriate event here such as StakeLBR:\\n```\\nif(useLBR) {\\n IesLBR(miningIncentives.LBR()).burn(msg.sender, lbrAmount);\\n IesLBR(miningIncentives.esLBR()).mint(msg.sender, lbrAmount);\\n}\\n```\\nчImplement additional events as appropriate.чч```\\ncontract esLBRBoost is Ownable {\\n esLBRLockSetting[] public esLBRLockSettings;\\n mapping(address => LockStatus) public userLockStatus;\\n IMiningIncentives public miningIncentives;\\n\\n // Define a struct for the lock settings\\n struct esLBRLockSetting {\\n uint256 duration;\\n uint256 miningBoost;\\n }\\n\\n // Define a struct for the user's lock status\\n struct LockStatus {\\n uint256 lockAmount;\\n uint256 unlockTime;\\n uint256 duration;\\n uint256 miningBoost;\\n }\\n\\n // Constructor to initialize the default lock settings\\n constructor(address \\_miningIncentives) {\\n```\\n
Incorrect InterfacesчlowчIn a few cases, incorrect interfaces are used on top of contracts. Though the effect is the same as the contracts are just tokens and follow the same interfaces, it is best practice to implement correct interfaces.\\n`IPeUSD` is used instead of `IEUSD`\\n```\\nIPeUSD public EUSD;\\n```\\n\\n`IPeUSD` is used instead of `IEUSD`\\n```\\nif (address(EUSD) == address(0)) EUSD = IPeUSD(\\_eusd);\\n```\\n\\n`IesLBR` instead of `ILBR`\\n```\\nIesLBR public LBR;\\n```\\n\\n`IesLBR` instead of `ILBR`\\n```\\nLBR = IesLBR(\\_lbr);\\n```\\nчImplement correct interfaces for consistency.чч```\\nIPeUSD public EUSD;\\n```\\n
Production Builds Allow Development and Localhost Origins; Snap Does Not Enforce Transport SecurityчmediumчThe snaps RPC access is restricted to certain origins only. However, there is no logic that disables development/test domains from origin checks in production builds.\\nSolflare Snap\\n../solflare-snap/src/index.js:L7-L17\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n\\nAptos Snap\\n../aptos-snap/src/index.js:L6-L15\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?risewallet\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n\\nSui Snap\\n../sui-snap/src/index.js:L8-L17\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?elliwallet\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\nчImplement logic that removes development/localhost origin from the allow list for production builds. Employ strict checks on the format of provided origin. Do not by default allow all subdomains.чч```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n
Production Builds Allow Development and Localhost Origins; Snap Does Not Enforce Transport Security  Partially AddressedчmediumчThe snaps RPC access is restricted to certain origins only. However, there is no logic that disables development/test domains from origin checks in production builds.\\nSolflare Snap\\n../solflare-snap/src/index.js:L7-L17\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n\\nAptos Snap\\n../aptos-snap/src/index.js:L6-L15\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?risewallet\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n\\nSui Snap\\n../sui-snap/src/index.js:L8-L17\\n```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?elliwallet\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\nчResolution\\nThe client has issued the following statement:\\nChangesets:\\nsolflare-wallet/solflare-snap@749d2b0\\nsolflare-wallet/aptos-snap@eef10b5\\nsolflare-wallet/sui-snap@898295f\\nStatement from the Assessment Team:\\nImplement logic that removes development/localhost origin from the allow list for production builds. Employ strict checks on the format of provided origin. Do not by default allow all subdomains.чч```\\nmodule.exports.onRpcRequest = async ({ origin, request }) => {\\n if (\\n !origin ||\\n (\\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\\n )\\n ) {\\n throw new Error('Invalid origin');\\n }\\n```\\n
All Roles Are Set to the Same Account.чlowчFrom talking to the team we know that all roles will be held by different timelock contracts. In the code they all are initiated to the same `admin` address. That would mean that most roles would need to be transferred. Given that each transfer take 2 transactions and there are 3 roles to transfer that would equate to 6 transactions just to properly set up the contract on deployment. That also increments the time it would take and space for making errors.\\nIt is also should be noted that the `regulator` role is not being initialized there at all.\\n```\\n// solhint-disable-next-line func-name-mixedcase\\nfunction \\_\\_DramAccessControl\\_init\\_unchained(\\n address admin\\n) internal onlyInitializing {\\n \\_grantRole(ADMIN\\_ROLE, admin);\\n \\_grantRole(ROLE\\_MANAGER\\_ROLE, admin);\\n \\_grantRole(SUPPLY\\_MANAGER\\_ROLE, admin);\\n}\\n```\\nчResolution\\nAll roles, including regulatory manager, are now set to different accounts. The modification can be found in commit `b70348e6998e35282212243ea639d174ced1ef2d`\\nWe suggest passing several addresses into the constructor and setting them to the correct addresses right away. Alternatively one can not set them at all and grant those roles later in order to avoid revoking the roles that admin should not have, such as `SUPPLY_MANAGER_ROLE`.чч```\\n// solhint-disable-next-line func-name-mixedcase\\nfunction \\_\\_DramAccessControl\\_init\\_unchained(\\n address admin\\n) internal onlyInitializing {\\n \\_grantRole(ADMIN\\_ROLE, admin);\\n \\_grantRole(ROLE\\_MANAGER\\_ROLE, admin);\\n \\_grantRole(SUPPLY\\_MANAGER\\_ROLE, admin);\\n}\\n```\\n
Setting MintCap to a Specific Value Is Prone to Front-Running.чlowч`Dram` stable coin is using the approval-like model to set the minting caps of different operators, thus it is prone to the same front-run issues as the approval mechanism. When using the `setMintCap` function directly operator could front-run the transaction and completely spend the old cap and then spend the new one again after setting the transaction goes through.\\n```\\nfunction setMintCap(\\n address operator,\\n uint256 amount\\n) external onlyRoleOrAdmin(ROLE\\_MANAGER\\_ROLE) {\\n \\_setMintCap(operator, amount);\\n}\\n```\\n\\nImagine the following scenario:\\nAlice has a mint cap of 10.\\nA transaction is sent to the mem-pool to set it to 5 (decrease the cap). The intent is that Alice should only be able to mint 5 tokens.\\nAlice frontruns this transaction and mints 10 tokens.\\nOnce transaction 2 goes through Alice mints 5 more tokens.\\nIn total Alice minted 15 tokens.чAvoid using setting the specific mint caps and rather use increase/decrease methods that are present in the code already.чч```\\nfunction setMintCap(\\n address operator,\\n uint256 amount\\n) external onlyRoleOrAdmin(ROLE\\_MANAGER\\_ROLE) {\\n \\_setMintCap(operator, amount);\\n}\\n```\\n
Incorrect Priviliges setOperatorAddresses  AcknowledgedчhighчThe function `setOperatorAddresses` instead of allowing the Operator to update its own, as well as the Fee Recipient address, incorrectly provides the privileges to the Fee Recipient. As a result, the Fee Recipient can modify the operator address as and when needed, to DoS the operator and exploit the system. Additionally, upon reviewing the documentation, we found that there are no administrative rights defined for the Fee Recipient, hence highlighting the incorrect privilege allocation.\\n```\\nfunction setOperatorAddresses(\\n uint256 \\_operatorIndex,\\n address \\_operatorAddress,\\n address \\_feeRecipientAddress\\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\\n \\_checkAddress(\\_operatorAddress);\\n \\_checkAddress(\\_feeRecipientAddress);\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n\\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\\n}\\n```\\nчThe modifier should be `onlyActiveOperatorOrAdmin` allowing only the operator itself or admin of the system, to update the necessary addresses.\\nAlso, for transferring crucial privileges from one address to another, the operator's address should follow a 2-step approach like transferring ownership.чч```\\nfunction setOperatorAddresses(\\n uint256 \\_operatorIndex,\\n address \\_operatorAddress,\\n address \\_feeRecipientAddress\\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\\n \\_checkAddress(\\_operatorAddress);\\n \\_checkAddress(\\_feeRecipientAddress);\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n\\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\\n}\\n```\\n
Unconstrained Snapshot While Setting Operator LimitчmediumчFunction `setOperatorLimit` as the name says, allows the `SYS_ADMIN` to set/update the staking limit for an operator. The function ensures that if the limit is being increased, the `_snapshot` must be ahead of the last validator edit(block.number at which the last validator edit occurred). However, the parameter `_snapshot` is unconstrained and can be any number. Also, the functions `addValidators` and `removeValidators` update the `block.number` signifying the last validator edit, but never constrain the new edits with it. Since there are no publicly available functions to access this value, makes the functionality even more confusing and may be unnecessary.\\n```\\nif (\\n operators.value[\\_operatorIndex].limit < \\_limit &&\\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\\n) {\\n revert LastEditAfterSnapshot();\\n}\\n```\\nчIf the functionality is not needed, consider removing it. Otherwise, add some necessary logic to either constrain the last validator edit or add public functions for the users to access it.чч```\\nif (\\n operators.value[\\_operatorIndex].limit < \\_limit &&\\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\\n) {\\n revert LastEditAfterSnapshot();\\n}\\n```\\n
Hardcoded Operator Limit LogicчmediumчThe contract defines some hardcoded limits which is not the right approach for upgradeable contracts and opens doors for accidental mistakes, if not handled with care.\\nThe operators for the current version are limited to 1. If the auditee team decides to open the system to work with more operators but fails to change the limit while upgrading, the upgraded contract will have no effect, and will still disallow any more operators to be added.\\n```\\nfunction addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n StakingContractStorageLib.OperatorInfo memory newOperator;\\n\\n if (operators.value.length == 1) {\\n revert MaximumOperatorCountAlreadyReached();\\n }\\n```\\n\\nAlso, the function `_depositOnOneOperator` hardcodes the operator Index as 0 since the contract only supports one operator.\\n```\\nfunction \\_depositOnOneOperator(uint256 \\_depositCount, uint256 \\_totalAvailableValidators) internal {\\n StakingContractStorageLib.setTotalAvailableValidators(\\_totalAvailableValidators - \\_depositCount);\\n \\_depositValidatorsOfOperator(0, \\_depositCount);\\n}\\n```\\nчA better approach could be to constrain the limit of operators that can be added with a storage variable or constant, provided at the time of contract initialization. The contract should also consider supporting dynamic operator deposits for future versions instead of the default hardcoded index.чч```\\nfunction addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n StakingContractStorageLib.OperatorInfo memory newOperator;\\n\\n if (operators.value.length == 1) {\\n revert MaximumOperatorCountAlreadyReached();\\n }\\n```\\n
StakingContract - PubKey Length Checks Not Always Enforcedчmediumч`addValidators` checks that the provided `bytes pubKey` is a multiple of the expected pubkey length while functions like `setWithdrawer` do not enforce similar length checks. This is an inconsistency that should be avoided.\\n`addValidators` enforcing input length checks\\n```\\nfunction addValidators(\\n uint256 \\_operatorIndex,\\n uint256 \\_keyCount,\\n bytes calldata \\_publicKeys,\\n bytes calldata \\_signatures\\n) external onlyActiveOperator(\\_operatorIndex) {\\n if (\\_keyCount == 0) {\\n revert InvalidArgument();\\n }\\n\\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\\n revert InvalidPublicKeys();\\n }\\n```\\n\\n`setWithdrawer` accepting any length for a `pubKey`. Note that `_getPubKeyRoot` will take any input provided and concat it the zero bytes.\\n```\\n/// @notice Set withdrawer for public key\\n/// @dev Only callable by current public key withdrawer\\n/// @param \\_publicKey Public key to change withdrawer\\n/// @param \\_newWithdrawer New withdrawer address\\nfunction setWithdrawer(bytes calldata \\_publicKey, address \\_newWithdrawer) external {\\n if (!StakingContractStorageLib.getWithdrawerCustomizationEnabled()) {\\n revert Forbidden();\\n }\\n \\_checkAddress(\\_newWithdrawer);\\n bytes32 pubkeyRoot = \\_getPubKeyRoot(\\_publicKey);\\n StakingContractStorageLib.WithdrawersSlot storage withdrawers = StakingContractStorageLib.getWithdrawers();\\n\\n if (withdrawers.value[pubkeyRoot] != msg.sender) {\\n revert Unauthorized();\\n }\\n\\n emit ChangedWithdrawer(\\_publicKey, \\_newWithdrawer);\\n\\n withdrawers.value[pubkeyRoot] = \\_newWithdrawer;\\n}\\n```\\n\\n```\\nfunction \\_getPubKeyRoot(bytes memory \\_publicKey) internal pure returns (bytes32) {\\n return sha256(abi.encodePacked(\\_publicKey, bytes16(0)));\\n}\\n```\\n\\nsimilarly, the withdraw family of functions does not enforce a pubkey length either. However, it is unlikely that someone finds a pubkey that matches a root for the attackers address.\\n```\\n/// @notice Withdraw the Execution Layer Fee for a given validator public key\\n/// @dev Funds are sent to the withdrawer account\\n/// @param \\_publicKey Validator to withdraw Execution Layer Fees from\\nfunction withdrawELFee(bytes calldata \\_publicKey) external {\\n \\_onlyWithdrawerOrAdmin(\\_publicKey);\\n \\_deployAndWithdraw(\\_publicKey, EXECUTION\\_LAYER\\_SALT\\_PREFIX, StakingContractStorageLib.getELDispatcher());\\n}\\n```\\n\\nNevertheless, the methods should be hardened so as not to give a malicious actor the freedom to use an unexpected input size for the `pubKey` argument.чEnforce pubkey length checks when accepting a single pubkey as bytes similar to the batch functions that check for a multiple of ´PUBLIC_KEY_LENGTH´. Alternatively, declare the function argument as `bytes48` (however, in this case inputs may be auto-padded to fit the expected length, pot. covering situations that otherwise would throw an error)чч```\\nfunction addValidators(\\n uint256 \\_operatorIndex,\\n uint256 \\_keyCount,\\n bytes calldata \\_publicKeys,\\n bytes calldata \\_signatures\\n) external onlyActiveOperator(\\_operatorIndex) {\\n if (\\_keyCount == 0) {\\n revert InvalidArgument();\\n }\\n\\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\\n revert InvalidPublicKeys();\\n }\\n```\\n
Unpredictable Behavior Due to Admin Front Running or General Bad TimingчmediumчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.\\nSome instances of this are more important than others, but in general, users of the system should have assurances about the behavior of the action they're about to take.\\nUpgradeable TU proxy\\nFee changes take effect immediately\\n```\\n/// @notice Change the Operator fee\\n/// @param \\_operatorFee Fee in Basis Point\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\n\\n```\\n/// @notice Change the Global fee\\n/// @param \\_globalFee Fee in Basis Point\\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\\n emit ChangedGlobalFee(\\_globalFee);\\n}\\n```\\nчThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.чч```\\n/// @notice Change the Operator fee\\n/// @param \\_operatorFee Fee in Basis Point\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\n
Potentially Uninitialized ImplementationsчmediumчMost contracts in the system are meant to be used with a proxy pattern. First, the implementations are deployed, and then proxies are deployed that delegatecall into the respective implementations following an initialization call (hardhat, with same transaction). However, the implementations are initialized explicitly nor are they protected from other actors claiming/initializing them. This allows anyone to call initialization functions on implementations for use with phishing attacks (i.e. contract implementation addresses are typically listed on the official project website as valid contracts) which may affect the reputation of the system.\\nNone of the implementations allow unprotected delegatecalls or selfdesturcts. lowering the severity of this finding.\\n```\\nfunction initialize\\_1(\\n address \\_admin,\\n address \\_treasury,\\n address \\_depositContract,\\n address \\_elDispatcher,\\n address \\_clDispatcher,\\n address \\_feeRecipientImplementation,\\n uint256 \\_globalFee,\\n uint256 \\_operatorFee,\\n uint256 globalCommissionLimitBPS,\\n uint256 operatorCommissionLimitBPS\\n) external init(1) {\\n```\\n\\n```\\n/// @notice Initializes the receiver\\n/// @param \\_dispatcher Address that will handle the fee dispatching\\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\\n if (initialized) {\\n revert AlreadyInitialized();\\n }\\n initialized = true;\\n dispatcher = IFeeDispatcher(\\_dispatcher);\\n publicKeyRoot = \\_publicKeyRoot;\\n stakingContract = msg.sender; // The staking contract always calls init\\n}\\n```\\n\\n```\\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\\n if (initialized) {\\n revert AlreadyInitialized();\\n }\\n initialized = true;\\n dispatcher = IFeeDispatcher(\\_dispatcher);\\n publicKeyRoot = \\_publicKeyRoot;\\n}\\n```\\nчPetrify contracts in the constructor and disallow other actors from claiming/initializing the implementations.чч```\\nfunction initialize\\_1(\\n address \\_admin,\\n address \\_treasury,\\n address \\_depositContract,\\n address \\_elDispatcher,\\n address \\_clDispatcher,\\n address \\_feeRecipientImplementation,\\n uint256 \\_globalFee,\\n uint256 \\_operatorFee,\\n uint256 globalCommissionLimitBPS,\\n uint256 operatorCommissionLimitBPS\\n) external init(1) {\\n```\\n
Operator May DoS the Withdrawal or Make It More ExpensiveчmediumчWhile collecting fees, the operator may:\\ncause DoS for the funds/rewards withdrawal by reverting the call, thus reverting the whole transaction. By doing this, it won't be receiving any rewards, but so the treasury and withdrawer.\\nmake the withdrawal more expensive by sending a huge chunk of `returndata`. As the `returndata` is copied into memory in the caller's context, it will add an extra gas overhead for the withdrawer making it more expensive.\\nor mint gas token\\n```\\nif (operatorFee > 0) {\\n (status, data) = operator.call{value: operatorFee}(\"\");\\n if (status == false) {\\n revert FeeRecipientReceiveError(data);\\n }\\n}\\n```\\nчA possible solution could be to make a low-level call in an inline assembly block, restricting the `returndata` to a couple of bytes, and instead of reverting on the failed call, emit an event, flagging the call that failed.чч```\\nif (operatorFee > 0) {\\n (status, data) = operator.call{value: operatorFee}(\"\");\\n if (status == false) {\\n revert FeeRecipientReceiveError(data);\\n }\\n}\\n```\\n
ConsensusLayerFeeDispatcher/ExecutionLayerFeeDispatcher - Should Hardcode autoPetrify With Highest Initializable Version Instead of User Provided ArgumentчlowчThe version to auto-initialize is not hardcoded with the constructor. On deployment, the deployer may accidentally use the wrong version, allowing anyone to call `initialize` on the contract.\\n```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n```\\n\\n```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n\\n/// @notice Initialize the contract by storing the staking contract and the public key in storage\\n/// @param \\_stakingContract Address of the Staking Contract\\nfunction initELD(address \\_stakingContract) external init(1) {\\n STAKING\\_CONTRACT\\_ADDRESS\\_SLOT.setAddress(\\_stakingContract);\\n}\\n```\\nчSimilar to the `init(1)` modifier, it is suggested to track the highest version as a `const int` with the contract and auto-initialize to the highest version in the constructor instead of taking the highest version as a deployment argument.чч```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n```\\n
StakingContract - Misleading CommentчlowчThe comment notes that the expected caller is `admin` while the modifier checks that `msg.sender` is an active operator.\\n```\\n/// @notice Ensures that the caller is the admin\\nmodifier onlyActiveOperator(uint256 \\_operatorIndex) {\\n \\_onlyActiveOperator(\\_operatorIndex);\\n \\_;\\n}\\n```\\nчRectify the comment to accurately describe the intention of the method/modifier.чч```\\n/// @notice Ensures that the caller is the admin\\nmodifier onlyActiveOperator(uint256 \\_operatorIndex) {\\n \\_onlyActiveOperator(\\_operatorIndex);\\n \\_;\\n}\\n```\\n
Impractical Checks for Global/Operator Fees and the Commission LimitsчlowчThe contract initialization sets up the global and operator fees and also their commission limits. However, the checks just make sure that the fees or commission limit is up to 100% which is not a very practical check. Any unusual value, for instance, if set to 100% will mean the whole rewards/funds will be non-exempted and taxed as global fees, which we believe will never be a case practically.\\n```\\nif (\\_globalFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setGlobalFee(\\_globalFee);\\nif (\\_operatorFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n```\\n\\n```\\nfunction initialize\\_2(uint256 globalCommissionLimitBPS, uint256 operatorCommissionLimitBPS) public init(2) {\\n if (globalCommissionLimitBPS > BASIS\\_POINTS) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalCommissionLimit(globalCommissionLimitBPS);\\n if (operatorCommissionLimitBPS > BASIS\\_POINTS) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorCommissionLimit(operatorCommissionLimitBPS);\\n}\\n```\\n\\n```\\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\\n emit ChangedGlobalFee(\\_globalFee);\\n}\\n```\\n\\n```\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\nчThe fees should be checked with a more practical limit. For instance, checking against a min - max limit, like 20% - 40%.чч```\\nif (\\_globalFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setGlobalFee(\\_globalFee);\\nif (\\_operatorFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n```\\n
Contracts Should Inherit From Their InterfacesчlowчThe following contracts should enforce correct interface implementation by inheriting from the interface declarations.\\n```\\n/// @title Ethereum Staking Contract\\n/// @author Kiln\\n/// @notice You can use this contract to store validator keys and have users fund them and trigger deposits.\\ncontract StakingContract {\\n using StakingContractStorageLib for bytes32;\\n```\\n\\n```\\ninterface IStakingContractFeeDetails {\\n function getWithdrawerFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external view returns (address);\\n\\n function getTreasury() external view returns (address);\\n\\n function getOperatorFeeRecipient(bytes32 pubKeyRoot) external view returns (address);\\n\\n function getGlobalFee() external view returns (uint256);\\n\\n function getOperatorFee() external view returns (uint256);\\n\\n function getExitRequestedFromRoot(bytes32 \\_publicKeyRoot) external view returns (bool);\\n\\n function getWithdrawnFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external view returns (bool);\\n\\n function toggleWithdrawnFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external;\\n}\\n```\\n\\n```\\ninterface IFeeRecipient {\\n function init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external;\\n\\n function withdraw() external;\\n}\\n```\\nчInherit from interface.чч```\\n/// @title Ethereum Staking Contract\\n/// @author Kiln\\n/// @notice You can use this contract to store validator keys and have users fund them and trigger deposits.\\ncontract StakingContract {\\n using StakingContractStorageLib for bytes32;\\n```\\n
Misleading Error StatementsчlowчThe contracts define custom errors to revert transactions on failed operations or invalid input, however, they convey little to no information, making it difficult for the off-chain monitoring tools to track relevant updates.\\n```\\nerror Forbidden();\\nerror InvalidFee();\\nerror Deactivated();\\nerror NoOperators();\\nerror InvalidCall();\\nerror Unauthorized();\\nerror DepositFailure();\\nerror DepositsStopped();\\nerror InvalidArgument();\\nerror UnsortedIndexes();\\nerror InvalidPublicKeys();\\nerror InvalidSignatures();\\nerror InvalidWithdrawer();\\nerror InvalidZeroAddress();\\nerror AlreadyInitialized();\\nerror InvalidDepositValue();\\nerror NotEnoughValidators();\\nerror InvalidValidatorCount();\\nerror DuplicateValidatorKey(bytes);\\nerror FundedValidatorDeletionAttempt();\\nerror OperatorLimitTooHigh(uint256 limit, uint256 keyCount);\\nerror MaximumOperatorCountAlreadyReached();\\nerror LastEditAfterSnapshot();\\nerror PublicKeyNotInContract();\\n```\\n\\nFor instance, the `init` modifier is used to initialize the contracts with the current Version. The Version initialization ensures that the provided version must be an increment of the previous version, if not, it reverts with an error as `AlreadyInitialized()`. However, the error doesn't convey an appropriate message correctly, as any version other than the expected version will signify that the version has already been initialized.\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != VERSION\\_SLOT.getUint256() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\n\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != VERSION\\_SLOT.getUint256() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\n\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != StakingContractStorageLib.getVersion() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\nчUse a more meaningful statement with enough information to track off-chain for all the custom errors in every contract in scope. For instance, add the current and supplied versions as indexed parameters, like: IncorrectVersionInitialization(current version, supplied version);\\nAlso, the function can be simplified as\\n```\\n function initELD(address \\_stakingContract) external init(VERSION\\_SLOT.getUint256() + 1) {\\n STAKING\\_CONTRACT\\_ADDRESS\\_SLOT.setAddress(\\_stakingContract);\\n }\\n```\\nчч```\\nerror Forbidden();\\nerror InvalidFee();\\nerror Deactivated();\\nerror NoOperators();\\nerror InvalidCall();\\nerror Unauthorized();\\nerror DepositFailure();\\nerror DepositsStopped();\\nerror InvalidArgument();\\nerror UnsortedIndexes();\\nerror InvalidPublicKeys();\\nerror InvalidSignatures();\\nerror InvalidWithdrawer();\\nerror InvalidZeroAddress();\\nerror AlreadyInitialized();\\nerror InvalidDepositValue();\\nerror NotEnoughValidators();\\nerror InvalidValidatorCount();\\nerror DuplicateValidatorKey(bytes);\\nerror FundedValidatorDeletionAttempt();\\nerror OperatorLimitTooHigh(uint256 limit, uint256 keyCount);\\nerror MaximumOperatorCountAlreadyReached();\\nerror LastEditAfterSnapshot();\\nerror PublicKeyNotInContract();\\n```\\n
Incorrect Priviliges setOperatorAddresses  AcknowledgedчhighчThe function `setOperatorAddresses` instead of allowing the Operator to update its own, as well as the Fee Recipient address, incorrectly provides the privileges to the Fee Recipient. As a result, the Fee Recipient can modify the operator address as and when needed, to DoS the operator and exploit the system. Additionally, upon reviewing the documentation, we found that there are no administrative rights defined for the Fee Recipient, hence highlighting the incorrect privilege allocation.\\n```\\nfunction setOperatorAddresses(\\n uint256 \\_operatorIndex,\\n address \\_operatorAddress,\\n address \\_feeRecipientAddress\\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\\n \\_checkAddress(\\_operatorAddress);\\n \\_checkAddress(\\_feeRecipientAddress);\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n\\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\\n}\\n```\\nчThe modifier should be `onlyActiveOperatorOrAdmin` allowing only the operator itself or admin of the system, to update the necessary addresses.\\nAlso, for transferring crucial privileges from one address to another, the operator's address should follow a 2-step approach like transferring ownership.чч```\\nfunction setOperatorAddresses(\\n uint256 \\_operatorIndex,\\n address \\_operatorAddress,\\n address \\_feeRecipientAddress\\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\\n \\_checkAddress(\\_operatorAddress);\\n \\_checkAddress(\\_feeRecipientAddress);\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n\\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\\n}\\n```\\n
Unconstrained Snapshot While Setting Operator LimitчmediumчFunction `setOperatorLimit` as the name says, allows the `SYS_ADMIN` to set/update the staking limit for an operator. The function ensures that if the limit is being increased, the `_snapshot` must be ahead of the last validator edit(block.number at which the last validator edit occurred). However, the parameter `_snapshot` is unconstrained and can be any number. Also, the functions `addValidators` and `removeValidators` update the `block.number` signifying the last validator edit, but never constrain the new edits with it. Since there are no publicly available functions to access this value, makes the functionality even more confusing and may be unnecessary.\\n```\\nif (\\n operators.value[\\_operatorIndex].limit < \\_limit &&\\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\\n) {\\n revert LastEditAfterSnapshot();\\n}\\n```\\nчIf the functionality is not needed, consider removing it. Otherwise, add some necessary logic to either constrain the last validator edit or add public functions for the users to access it.чч```\\nif (\\n operators.value[\\_operatorIndex].limit < \\_limit &&\\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\\n) {\\n revert LastEditAfterSnapshot();\\n}\\n```\\n
Hardcoded Operator Limit LogicчmediumчThe contract defines some hardcoded limits which is not the right approach for upgradeable contracts and opens doors for accidental mistakes, if not handled with care.\\nThe operators for the current version are limited to 1. If the auditee team decides to open the system to work with more operators but fails to change the limit while upgrading, the upgraded contract will have no effect, and will still disallow any more operators to be added.\\n```\\nfunction addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n StakingContractStorageLib.OperatorInfo memory newOperator;\\n\\n if (operators.value.length == 1) {\\n revert MaximumOperatorCountAlreadyReached();\\n }\\n```\\n\\nAlso, the function `_depositOnOneOperator` hardcodes the operator Index as 0 since the contract only supports one operator.\\n```\\nfunction \\_depositOnOneOperator(uint256 \\_depositCount, uint256 \\_totalAvailableValidators) internal {\\n StakingContractStorageLib.setTotalAvailableValidators(\\_totalAvailableValidators - \\_depositCount);\\n \\_depositValidatorsOfOperator(0, \\_depositCount);\\n}\\n```\\nчA better approach could be to constrain the limit of operators that can be added with a storage variable or constant, provided at the time of contract initialization. The contract should also consider supporting dynamic operator deposits for future versions instead of the default hardcoded index.чч```\\nfunction addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\\n StakingContractStorageLib.OperatorInfo memory newOperator;\\n\\n if (operators.value.length == 1) {\\n revert MaximumOperatorCountAlreadyReached();\\n }\\n```\\n
StakingContract - PubKey Length Checks Not Always Enforcedчmediumч`addValidators` checks that the provided `bytes pubKey` is a multiple of the expected pubkey length while functions like `setWithdrawer` do not enforce similar length checks. This is an inconsistency that should be avoided.\\n`addValidators` enforcing input length checks\\n```\\nfunction addValidators(\\n uint256 \\_operatorIndex,\\n uint256 \\_keyCount,\\n bytes calldata \\_publicKeys,\\n bytes calldata \\_signatures\\n) external onlyActiveOperator(\\_operatorIndex) {\\n if (\\_keyCount == 0) {\\n revert InvalidArgument();\\n }\\n\\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\\n revert InvalidPublicKeys();\\n }\\n```\\n\\n`setWithdrawer` accepting any length for a `pubKey`. Note that `_getPubKeyRoot` will take any input provided and concat it the zero bytes.\\n```\\n/// @notice Set withdrawer for public key\\n/// @dev Only callable by current public key withdrawer\\n/// @param \\_publicKey Public key to change withdrawer\\n/// @param \\_newWithdrawer New withdrawer address\\nfunction setWithdrawer(bytes calldata \\_publicKey, address \\_newWithdrawer) external {\\n if (!StakingContractStorageLib.getWithdrawerCustomizationEnabled()) {\\n revert Forbidden();\\n }\\n \\_checkAddress(\\_newWithdrawer);\\n bytes32 pubkeyRoot = \\_getPubKeyRoot(\\_publicKey);\\n StakingContractStorageLib.WithdrawersSlot storage withdrawers = StakingContractStorageLib.getWithdrawers();\\n\\n if (withdrawers.value[pubkeyRoot] != msg.sender) {\\n revert Unauthorized();\\n }\\n\\n emit ChangedWithdrawer(\\_publicKey, \\_newWithdrawer);\\n\\n withdrawers.value[pubkeyRoot] = \\_newWithdrawer;\\n}\\n```\\n\\n```\\nfunction \\_getPubKeyRoot(bytes memory \\_publicKey) internal pure returns (bytes32) {\\n return sha256(abi.encodePacked(\\_publicKey, bytes16(0)));\\n}\\n```\\n\\nsimilarly, the withdraw family of functions does not enforce a pubkey length either. However, it is unlikely that someone finds a pubkey that matches a root for the attackers address.\\n```\\n/// @notice Withdraw the Execution Layer Fee for a given validator public key\\n/// @dev Funds are sent to the withdrawer account\\n/// @param \\_publicKey Validator to withdraw Execution Layer Fees from\\nfunction withdrawELFee(bytes calldata \\_publicKey) external {\\n \\_onlyWithdrawerOrAdmin(\\_publicKey);\\n \\_deployAndWithdraw(\\_publicKey, EXECUTION\\_LAYER\\_SALT\\_PREFIX, StakingContractStorageLib.getELDispatcher());\\n}\\n```\\n\\nNevertheless, the methods should be hardened so as not to give a malicious actor the freedom to use an unexpected input size for the `pubKey` argument.чEnforce pubkey length checks when accepting a single pubkey as bytes similar to the batch functions that check for a multiple of ´PUBLIC_KEY_LENGTH´. Alternatively, declare the function argument as `bytes48` (however, in this case inputs may be auto-padded to fit the expected length, pot. covering situations that otherwise would throw an error)чч```\\nfunction addValidators(\\n uint256 \\_operatorIndex,\\n uint256 \\_keyCount,\\n bytes calldata \\_publicKeys,\\n bytes calldata \\_signatures\\n) external onlyActiveOperator(\\_operatorIndex) {\\n if (\\_keyCount == 0) {\\n revert InvalidArgument();\\n }\\n\\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\\n revert InvalidPublicKeys();\\n }\\n```\\n
Unpredictable Behavior Due to Admin Front Running or General Bad TimingчmediumчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.\\nSome instances of this are more important than others, but in general, users of the system should have assurances about the behavior of the action they're about to take.\\nUpgradeable TU proxy\\nFee changes take effect immediately\\n```\\n/// @notice Change the Operator fee\\n/// @param \\_operatorFee Fee in Basis Point\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\n\\n```\\n/// @notice Change the Global fee\\n/// @param \\_globalFee Fee in Basis Point\\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\\n emit ChangedGlobalFee(\\_globalFee);\\n}\\n```\\nчThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.чч```\\n/// @notice Change the Operator fee\\n/// @param \\_operatorFee Fee in Basis Point\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\n
Potentially Uninitialized ImplementationsчmediumчMost contracts in the system are meant to be used with a proxy pattern. First, the implementations are deployed, and then proxies are deployed that delegatecall into the respective implementations following an initialization call (hardhat, with same transaction). However, the implementations are initialized explicitly nor are they protected from other actors claiming/initializing them. This allows anyone to call initialization functions on implementations for use with phishing attacks (i.e. contract implementation addresses are typically listed on the official project website as valid contracts) which may affect the reputation of the system.\\nNone of the implementations allow unprotected delegatecalls or selfdesturcts. lowering the severity of this finding.\\n```\\nfunction initialize\\_1(\\n address \\_admin,\\n address \\_treasury,\\n address \\_depositContract,\\n address \\_elDispatcher,\\n address \\_clDispatcher,\\n address \\_feeRecipientImplementation,\\n uint256 \\_globalFee,\\n uint256 \\_operatorFee,\\n uint256 globalCommissionLimitBPS,\\n uint256 operatorCommissionLimitBPS\\n) external init(1) {\\n```\\n\\n```\\n/// @notice Initializes the receiver\\n/// @param \\_dispatcher Address that will handle the fee dispatching\\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\\n if (initialized) {\\n revert AlreadyInitialized();\\n }\\n initialized = true;\\n dispatcher = IFeeDispatcher(\\_dispatcher);\\n publicKeyRoot = \\_publicKeyRoot;\\n stakingContract = msg.sender; // The staking contract always calls init\\n}\\n```\\n\\n```\\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\\n if (initialized) {\\n revert AlreadyInitialized();\\n }\\n initialized = true;\\n dispatcher = IFeeDispatcher(\\_dispatcher);\\n publicKeyRoot = \\_publicKeyRoot;\\n}\\n```\\nчPetrify contracts in the constructor and disallow other actors from claiming/initializing the implementations.чч```\\nfunction initialize\\_1(\\n address \\_admin,\\n address \\_treasury,\\n address \\_depositContract,\\n address \\_elDispatcher,\\n address \\_clDispatcher,\\n address \\_feeRecipientImplementation,\\n uint256 \\_globalFee,\\n uint256 \\_operatorFee,\\n uint256 globalCommissionLimitBPS,\\n uint256 operatorCommissionLimitBPS\\n) external init(1) {\\n```\\n
Operator May DoS the Withdrawal or Make It More ExpensiveчmediumчWhile collecting fees, the operator may:\\ncause DoS for the funds/rewards withdrawal by reverting the call, thus reverting the whole transaction. By doing this, it won't be receiving any rewards, but so the treasury and withdrawer.\\nmake the withdrawal more expensive by sending a huge chunk of `returndata`. As the `returndata` is copied into memory in the caller's context, it will add an extra gas overhead for the withdrawer making it more expensive.\\nor mint gas token\\n```\\nif (operatorFee > 0) {\\n (status, data) = operator.call{value: operatorFee}(\"\");\\n if (status == false) {\\n revert FeeRecipientReceiveError(data);\\n }\\n}\\n```\\nчA possible solution could be to make a low-level call in an inline assembly block, restricting the `returndata` to a couple of bytes, and instead of reverting on the failed call, emit an event, flagging the call that failed.чч```\\nif (operatorFee > 0) {\\n (status, data) = operator.call{value: operatorFee}(\"\");\\n if (status == false) {\\n revert FeeRecipientReceiveError(data);\\n }\\n}\\n```\\n
ConsensusLayerFeeDispatcher/ExecutionLayerFeeDispatcher - Should Hardcode autoPetrify With Highest Initializable Version Instead of User Provided ArgumentчlowчThe version to auto-initialize is not hardcoded with the constructor. On deployment, the deployer may accidentally use the wrong version, allowing anyone to call `initialize` on the contract.\\n```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n```\\n\\n```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n\\n/// @notice Initialize the contract by storing the staking contract and the public key in storage\\n/// @param \\_stakingContract Address of the Staking Contract\\nfunction initELD(address \\_stakingContract) external init(1) {\\n STAKING\\_CONTRACT\\_ADDRESS\\_SLOT.setAddress(\\_stakingContract);\\n}\\n```\\nчSimilar to the `init(1)` modifier, it is suggested to track the highest version as a `const int` with the contract and auto-initialize to the highest version in the constructor instead of taking the highest version as a deployment argument.чч```\\n/// @notice Constructor method allowing us to prevent calls to initCLFR by setting the appropriate version\\nconstructor(uint256 \\_version) {\\n VERSION\\_SLOT.setUint256(\\_version);\\n}\\n```\\n
StakingContract - Misleading CommentчlowчThe comment notes that the expected caller is `admin` while the modifier checks that `msg.sender` is an active operator.\\n```\\n/// @notice Ensures that the caller is the admin\\nmodifier onlyActiveOperator(uint256 \\_operatorIndex) {\\n \\_onlyActiveOperator(\\_operatorIndex);\\n \\_;\\n}\\n```\\nчRectify the comment to accurately describe the intention of the method/modifier.чч```\\n/// @notice Ensures that the caller is the admin\\nmodifier onlyActiveOperator(uint256 \\_operatorIndex) {\\n \\_onlyActiveOperator(\\_operatorIndex);\\n \\_;\\n}\\n```\\n
Impractical Checks for Global/Operator Fees and the Commission LimitsчlowчThe contract initialization sets up the global and operator fees and also their commission limits. However, the checks just make sure that the fees or commission limit is up to 100% which is not a very practical check. Any unusual value, for instance, if set to 100% will mean the whole rewards/funds will be non-exempted and taxed as global fees, which we believe will never be a case practically.\\n```\\nif (\\_globalFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setGlobalFee(\\_globalFee);\\nif (\\_operatorFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n```\\n\\n```\\nfunction initialize\\_2(uint256 globalCommissionLimitBPS, uint256 operatorCommissionLimitBPS) public init(2) {\\n if (globalCommissionLimitBPS > BASIS\\_POINTS) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalCommissionLimit(globalCommissionLimitBPS);\\n if (operatorCommissionLimitBPS > BASIS\\_POINTS) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorCommissionLimit(operatorCommissionLimitBPS);\\n}\\n```\\n\\n```\\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\\n emit ChangedGlobalFee(\\_globalFee);\\n}\\n```\\n\\n```\\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\\n revert InvalidFee();\\n }\\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n emit ChangedOperatorFee(\\_operatorFee);\\n}\\n```\\nчThe fees should be checked with a more practical limit. For instance, checking against a min - max limit, like 20% - 40%.чч```\\nif (\\_globalFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setGlobalFee(\\_globalFee);\\nif (\\_operatorFee > BASIS\\_POINTS) {\\n revert InvalidFee();\\n}\\nStakingContractStorageLib.setOperatorFee(\\_operatorFee);\\n```\\n
Contracts Should Inherit From Their InterfacesчlowчThe following contracts should enforce correct interface implementation by inheriting from the interface declarations.\\n```\\n/// @title Ethereum Staking Contract\\n/// @author Kiln\\n/// @notice You can use this contract to store validator keys and have users fund them and trigger deposits.\\ncontract StakingContract {\\n using StakingContractStorageLib for bytes32;\\n```\\n\\n```\\ninterface IStakingContractFeeDetails {\\n function getWithdrawerFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external view returns (address);\\n\\n function getTreasury() external view returns (address);\\n\\n function getOperatorFeeRecipient(bytes32 pubKeyRoot) external view returns (address);\\n\\n function getGlobalFee() external view returns (uint256);\\n\\n function getOperatorFee() external view returns (uint256);\\n\\n function getExitRequestedFromRoot(bytes32 \\_publicKeyRoot) external view returns (bool);\\n\\n function getWithdrawnFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external view returns (bool);\\n\\n function toggleWithdrawnFromPublicKeyRoot(bytes32 \\_publicKeyRoot) external;\\n}\\n```\\n\\n```\\ninterface IFeeRecipient {\\n function init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external;\\n\\n function withdraw() external;\\n}\\n```\\nчInherit from interface.чч```\\n/// @title Ethereum Staking Contract\\n/// @author Kiln\\n/// @notice You can use this contract to store validator keys and have users fund them and trigger deposits.\\ncontract StakingContract {\\n using StakingContractStorageLib for bytes32;\\n```\\n
Misleading Error StatementsчlowчThe contracts define custom errors to revert transactions on failed operations or invalid input, however, they convey little to no information, making it difficult for the off-chain monitoring tools to track relevant updates.\\n```\\nerror Forbidden();\\nerror InvalidFee();\\nerror Deactivated();\\nerror NoOperators();\\nerror InvalidCall();\\nerror Unauthorized();\\nerror DepositFailure();\\nerror DepositsStopped();\\nerror InvalidArgument();\\nerror UnsortedIndexes();\\nerror InvalidPublicKeys();\\nerror InvalidSignatures();\\nerror InvalidWithdrawer();\\nerror InvalidZeroAddress();\\nerror AlreadyInitialized();\\nerror InvalidDepositValue();\\nerror NotEnoughValidators();\\nerror InvalidValidatorCount();\\nerror DuplicateValidatorKey(bytes);\\nerror FundedValidatorDeletionAttempt();\\nerror OperatorLimitTooHigh(uint256 limit, uint256 keyCount);\\nerror MaximumOperatorCountAlreadyReached();\\nerror LastEditAfterSnapshot();\\nerror PublicKeyNotInContract();\\n```\\n\\nFor instance, the `init` modifier is used to initialize the contracts with the current Version. The Version initialization ensures that the provided version must be an increment of the previous version, if not, it reverts with an error as `AlreadyInitialized()`. However, the error doesn't convey an appropriate message correctly, as any version other than the expected version will signify that the version has already been initialized.\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != VERSION\\_SLOT.getUint256() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\n\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != VERSION\\_SLOT.getUint256() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\n\\n```\\nmodifier init(uint256 \\_version) {\\n if (\\_version != StakingContractStorageLib.getVersion() + 1) {\\n revert AlreadyInitialized();\\n }\\n```\\nчUse a more meaningful statement with enough information to track off-chain for all the custom errors in every contract in scope. For instance, add the current and supplied versions as indexed parameters, like: IncorrectVersionInitialization(current version, supplied version);\\nAlso, the function can be simplified as\\n```\\n function initELD(address \\_stakingContract) external init(VERSION\\_SLOT.getUint256() + 1) {\\n STAKING\\_CONTRACT\\_ADDRESS\\_SLOT.setAddress(\\_stakingContract);\\n }\\n```\\nчч```\\nerror Forbidden();\\nerror InvalidFee();\\nerror Deactivated();\\nerror NoOperators();\\nerror InvalidCall();\\nerror Unauthorized();\\nerror DepositFailure();\\nerror DepositsStopped();\\nerror InvalidArgument();\\nerror UnsortedIndexes();\\nerror InvalidPublicKeys();\\nerror InvalidSignatures();\\nerror InvalidWithdrawer();\\nerror InvalidZeroAddress();\\nerror AlreadyInitialized();\\nerror InvalidDepositValue();\\nerror NotEnoughValidators();\\nerror InvalidValidatorCount();\\nerror DuplicateValidatorKey(bytes);\\nerror FundedValidatorDeletionAttempt();\\nerror OperatorLimitTooHigh(uint256 limit, uint256 keyCount);\\nerror MaximumOperatorCountAlreadyReached();\\nerror LastEditAfterSnapshot();\\nerror PublicKeyNotInContract();\\n```\\n
Architectural Pattern of Internal and External Functions Increases Attack SurfaceчlowчThere is an architectural pattern throughout the code of functions being defined in two places: an external wrapper (name) that verifies authorization and validates parameters, and an internal function (_name) that contains the implementation logic. This pattern separates concerns and avoids redundancy in the case that more than one external function reuses the same internal logic.\\nFor example, `VotingTokenLockupPlans.setupVoting` calls an internal function `_setupVoting` and sets the `holder` parameter to `msg.sender`.\\n```\\nfunction setupVoting(uint256 planId) external nonReentrant returns (address votingVault) {\\n votingVault = \\_setupVoting(msg.sender, planId);\\n```\\n\\n```\\nfunction \\_setupVoting(address holder, uint256 planId) internal returns (address) {\\n require(ownerOf(planId) == holder, '!owner');\\n```\\n\\nIn this case, however, there is no case in which `holder` should not be set to `msg.sender`. Because the internal function doesn't enforce this, it's theoretically possible that if another internal (or derived) function were compromised then it could call `_setupVoting` with `holder` set to `ownerOf(planId)`, even if `msg.sender` isn't the owner. This increases the attack surface through providing unneeded flexibility.\\nOther Examples\\n```\\nfunction segmentPlan(\\n uint256 planId,\\n uint256[] memory segmentAmounts\\n) external nonReentrant returns (uint256[] memory newPlanIds) {\\n newPlanIds = new uint256[](segmentAmounts.length);\\n for (uint256 i; i < segmentAmounts.length; i++) {\\n uint256 newPlanId = \\_segmentPlan(msg.sender, planId, segmentAmounts[i]);\\n```\\n\\n```\\nfunction \\_segmentPlan(address holder, uint256 planId, uint256 segmentAmount) internal returns (uint256 newPlanId) {\\n require(ownerOf(planId) == holder, '!owner');\\n```\\n\\n```\\nfunction revokePlans(uint256[] memory planIds) external nonReentrant {\\n for (uint256 i; i < planIds.length; i++) {\\n \\_revokePlan(msg.sender, planIds[i]);\\n```\\n\\n```\\nfunction \\_revokePlan(address vestingAdmin, uint256 planId) internal {\\n Plan memory plan = plans[planId];\\n require(vestingAdmin == plan.vestingAdmin, '!vestingAdmin');\\n```\\nчResolution\\nFixed as of commit `f4299cdba5e863c9ca2d69a3a7dd554ac34af292`.\\nTo reduce the attack surface, consider hard coding parameters such as `holder` to `msg.sender` in internal functions when extra flexibility isn't needed.чч```\\nfunction setupVoting(uint256 planId) external nonReentrant returns (address votingVault) {\\n votingVault = \\_setupVoting(msg.sender, planId);\\n```\\n
Revoking Vesting Will Trigger a Taxable EventчlowчResolution\\nFixed as of commit `f4299cdba5e863c9ca2d69a3a7dd554ac34af292`.\\nFrom the previous conversations with the Hedgey team, we identified that users should be in control of when taxable events happen. For that reason, one could redeem a plan in the past. Unfortunately, the recipient of the vesting plan can not always be in control of the redemption process. If for one reason or another the administrator of the vesting plan decides to revoke it, any vested funds will be sent to the vesting plan holder, triggering the taxable event and burning the NFT.\\n```\\nfunction \\_revokePlan(address vestingAdmin, uint256 planId) internal {\\n Plan memory plan = plans[planId];\\n require(vestingAdmin == plan.vestingAdmin, '!vestingAdmin');\\n (uint256 balance, uint256 remainder, ) = planBalanceOf(planId, block.timestamp, block.timestamp);\\n require(remainder > 0, '!Remainder');\\n address holder = ownerOf(planId);\\n delete plans[planId];\\n \\_burn(planId);\\n TransferHelper.withdrawTokens(plan.token, vestingAdmin, remainder);\\n TransferHelper.withdrawTokens(plan.token, holder, balance);\\n emit PlanRevoked(planId, balance, remainder);\\n}\\n```\\n\\n```\\nfunction \\_revokePlan(address vestingAdmin, uint256 planId) internal {\\n Plan memory plan = plans[planId];\\n require(vestingAdmin == plan.vestingAdmin, '!vestingAdmin');\\n (uint256 balance, uint256 remainder, ) = planBalanceOf(planId, block.timestamp, block.timestamp);\\n require(remainder > 0, '!Remainder');\\n address holder = ownerOf(planId);\\n delete plans[planId];\\n \\_burn(planId);\\n address vault = votingVaults[planId];\\n if (vault == address(0)) {\\n TransferHelper.withdrawTokens(plan.token, vestingAdmin, remainder);\\n TransferHelper.withdrawTokens(plan.token, holder, balance);\\n } else {\\n delete votingVaults[planId];\\n VotingVault(vault).withdrawTokens(vestingAdmin, remainder);\\n VotingVault(vault).withdrawTokens(holder, balance);\\n }\\n emit PlanRevoked(planId, balance, remainder);\\n}\\n```\\nчOne potential workaround is to only withdraw the unvested portion to the vesting admin while keeping the vested part in the contract. That being said `amount` and `rate` variables would need to be updated in order not to allow any additional vesting for the given plan. This way plan holders will not be entitled to more funds but will be able to redeem them at the time they choose.чч```\\nfunction \\_revokePlan(address vestingAdmin, uint256 planId) internal {\\n Plan memory plan = plans[planId];\\n require(vestingAdmin == plan.vestingAdmin, '!vestingAdmin');\\n (uint256 balance, uint256 remainder, ) = planBalanceOf(planId, block.timestamp, block.timestamp);\\n require(remainder > 0, '!Remainder');\\n address holder = ownerOf(planId);\\n delete plans[planId];\\n \\_burn(planId);\\n TransferHelper.withdrawTokens(plan.token, vestingAdmin, remainder);\\n TransferHelper.withdrawTokens(plan.token, holder, balance);\\n emit PlanRevoked(planId, balance, remainder);\\n}\\n```\\n
Use of selfdestruct Deprecated in VotingVaultчlowчThe `VotingVault.withdrawTokens` function invokes the `selfdestruct` operation when the vault is empty so that it can't be used again.\\nThe use ofselfdestruct has been deprecated and a breaking change in its future behavior is expected.\\n```\\nfunction withdrawTokens(address to, uint256 amount) external onlyController {\\n TransferHelper.withdrawTokens(token, to, amount);\\n if (IERC20(token).balanceOf(address(this)) == 0) selfdestruct;\\n}\\n```\\nчRemove the line that invokes `selfdestruct` and consider changing internal state so that future calls to `delegateTokens` always revert.чч```\\nfunction withdrawTokens(address to, uint256 amount) external onlyController {\\n TransferHelper.withdrawTokens(token, to, amount);\\n if (IERC20(token).balanceOf(address(this)) == 0) selfdestruct;\\n}\\n```\\n
Balance of msg.sender Is Used Instead of the from AddressчlowчThe `TransferHelper` library has methods that allow transferring tokens directly or on behalf of a different wallet that previously approved the transfer. Those functions also check the sender balance before conducting the transfer. In the second case, where the transfer happens on behalf of someone the code is checking not the actual token spender balance, but the `msg.sender` balance instead.\\n```\\nfunction transferTokens(\\n address token,\\n address from,\\n address to,\\n uint256 amount\\n) internal {\\n uint256 priorBalance = IERC20(token).balanceOf(address(to));\\n require(IERC20(token).balanceOf(msg.sender) >= amount, 'THL01');\\n```\\nчUse the `from` parameter instead of `msg.sender`.чч```\\nfunction transferTokens(\\n address token,\\n address from,\\n address to,\\n uint256 amount\\n) internal {\\n uint256 priorBalance = IERC20(token).balanceOf(address(to));\\n require(IERC20(token).balanceOf(msg.sender) >= amount, 'THL01');\\n```\\n
Bridge Token Would Be Locked and Cannot Bridge to Native TokenчhighчIf the bridge token B of a native token A is already deployed and `confirmDeployment` is called on the other layer and `setDeployed` sets A's `nativeToBridgedToken` value to `DEPLOYED_STATUS`. The bridge token B cannot bridge to native token A in `completeBridging` function, because A's `nativeToBridgedToken` value is not `NATIVE_STATUS`, as a result the native token won't be transferred to the receiver. User's bridge token will be locked in the original layer\\n```\\nif (nativeMappingValue == NATIVE\\_STATUS) {\\n // Token is native on the local chain\\n IERC20(\\_nativeToken).safeTransfer(\\_recipient, \\_amount);\\n} else {\\n bridgedToken = nativeMappingValue;\\n if (nativeMappingValue == EMPTY) {\\n // New token\\n bridgedToken = deployBridgedToken(\\_nativeToken, \\_tokenMetadata);\\n bridgedToNativeToken[bridgedToken] = \\_nativeToken;\\n nativeToBridgedToken[\\_nativeToken] = bridgedToken;\\n }\\n BridgedToken(bridgedToken).mint(\\_recipient, \\_amount);\\n}\\n```\\n\\n```\\nfunction setDeployed(address[] memory \\_nativeTokens) external onlyMessagingService fromRemoteTokenBridge {\\n address nativeToken;\\n for (uint256 i; i < \\_nativeTokens.length; i++) {\\n nativeToken = \\_nativeTokens[i];\\n nativeToBridgedToken[\\_nativeTokens[i]] = DEPLOYED\\_STATUS;\\n emit TokenDeployed(\\_nativeTokens[i]);\\n }\\n}\\n```\\nчAdd an condition `nativeMappingValue` = `DEPLOYED_STATUS` for native token transfer in `confirmDeployment`\\n```\\nif (nativeMappingValue == NATIVE_STATUS || nativeMappingValue == DEPLOYED_STATUS) {\\n   IERC20(_nativeToken).safeTransfer(_recipient, _amount);\\n```\\nчч```\\nif (nativeMappingValue == NATIVE\\_STATUS) {\\n // Token is native on the local chain\\n IERC20(\\_nativeToken).safeTransfer(\\_recipient, \\_amount);\\n} else {\\n bridgedToken = nativeMappingValue;\\n if (nativeMappingValue == EMPTY) {\\n // New token\\n bridgedToken = deployBridgedToken(\\_nativeToken, \\_tokenMetadata);\\n bridgedToNativeToken[bridgedToken] = \\_nativeToken;\\n nativeToBridgedToken[\\_nativeToken] = bridgedToken;\\n }\\n BridgedToken(bridgedToken).mint(\\_recipient, \\_amount);\\n}\\n```\\n
User Cannot Withdraw Funds if Bridging Failed or Delayed  Won't FixчhighчIf the bridging failed due to the single coordinator is down, censoring the message, or bridge token contract is set to a bad or wrong contract address by `setCustomContract`, user's funds will stuck in the `TokenBridge` contract until coordinator is online or stop censoring, there is no way to withdraw the deposited funds\\n```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\nчAdd withdraw functionality to let user withdraw the funds under above circumstances or at least add withdraw functionality for Admin (admin can send the funds to the user manually), ultimately decentralize coordinator and sequencer to reduce bridging failure risk.чч```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\n
Bridges Don't Support Multiple Native Tokens, Which May Lead to Incorrect BridgingчhighчCurrently, the system design does not support the scenarios where native tokens with the same addresses (which is possible with the same deployer and nonce) on different layers can be bridged.\\nFor instance, Let's consider, there is a native token `A` on `L1` which has already been bridged on `L2`. If anyone tries to bridge native token `B` on `L2` with the same address as token `A` , instead of creating a new bridge on `L1` and minting new tokens, the token bridge will transfer native token `A` on `L1` to the `_recipient` which is incorrect.\\nThe reason is the mappings don't differentiate between the native tokens on two different Layers.\\n```\\n  mapping(address => address) public nativeToBridgedToken;\\n  mapping(address => address) public bridgedToNativeToken;\\n```\\n\\n```\\nfunction completeBridging(\\n address \\_nativeToken,\\n uint256 \\_amount,\\n address \\_recipient,\\n bytes calldata \\_tokenMetadata\\n) external onlyMessagingService fromRemoteTokenBridge {\\n address nativeMappingValue = nativeToBridgedToken[\\_nativeToken];\\n address bridgedToken;\\n\\n if (nativeMappingValue == NATIVE\\_STATUS) {\\n // Token is native on the local chain\\n IERC20(\\_nativeToken).safeTransfer(\\_recipient, \\_amount);\\n } else {\\n```\\nчRedesign the approach to handle the same native tokens on different layers. One possible approach could be to define the set of mappings for each layer.чч```\\n  mapping(address => address) public nativeToBridgedToken;\\n  mapping(address => address) public bridgedToNativeToken;\\n```\\n
No Check for Initializing Parameters of TokenBridgeчhighчIn `TokenBridge` contract's `initialize` function, there is no check for initializing parameters including `_securityCouncil`, `_messageService`, `_tokenBeacon` and `_reservedTokens`. If any of these address is set to 0 or other invalid value, `TokenBridge` would not work, user may lose funds.\\n```\\nfunction initialize(\\n address \\_securityCouncil,\\n address \\_messageService,\\n address \\_tokenBeacon,\\n address[] calldata \\_reservedTokens\\n) external initializer {\\n \\_\\_Pausable\\_init();\\n \\_\\_Ownable\\_init();\\n setMessageService(\\_messageService);\\n tokenBeacon = \\_tokenBeacon;\\n for (uint256 i = 0; i < \\_reservedTokens.length; i++) {\\n setReserved(\\_reservedTokens[i]);\\n }\\n \\_transferOwnership(\\_securityCouncil);\\n}\\n```\\nчAdd non-zero address check for `_securityCouncil`, `_messageService`, `_tokenBeacon` and `_reservedTokens`чч```\\nfunction initialize(\\n address \\_securityCouncil,\\n address \\_messageService,\\n address \\_tokenBeacon,\\n address[] calldata \\_reservedTokens\\n) external initializer {\\n \\_\\_Pausable\\_init();\\n \\_\\_Ownable\\_init();\\n setMessageService(\\_messageService);\\n tokenBeacon = \\_tokenBeacon;\\n for (uint256 i = 0; i < \\_reservedTokens.length; i++) {\\n setReserved(\\_reservedTokens[i]);\\n }\\n \\_transferOwnership(\\_securityCouncil);\\n}\\n```\\n
Owner Can Update Arbitrary Status for New Native Token Without ConfirmationчhighчThe function `setCustomContract` allows the owner to update arbitrary status for new native tokens without confirmation, bypassing the bridge protocol.\\nIt can set `DEPLOYED_STATUS` for a new native token, even if there exists no bridged token for it.\\nIt can set `NATIVE_STATUS` for a new native token even if it's not.\\nIt can set `RESERVED_STATUS` disallowing any new native token to be bridged.\\n```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\nчThe function should not allow `_targetContract` to be any state codeчч```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\n
Owner May Exploit Bridged TokensчhighчThe function `setCustomContract` allows the owner, to define a custom ERC20 contract for the native token. However, it doesn't check whether the target contract has already been defined as a bridge to a native token or not. As a result, the owner may take advantage of the design flaw and bridge another new native token that has not been bridged yet, to an already existing target(already a bridge for another native token). Now, if a user tries to bridge this native token, the token bridge on the source chain will take the user's tokens, and instead of deploying a new bridge on the destination chain, tokens will be minted to the `_recipient` on an existing bridge defined by the owner, or it can be any random EOA address to create a DoS.\\nThe owner can also try to front-run calls to `completeBridging` for new Native Tokens on the destination chain, by setting a different bridge via `setCustomContract`. Although, the team states that the role will be controlled by a multi-sig which makes frontrunning less likely to happen.\\n```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\n\\n```\\n} else {\\n bridgedToken = nativeMappingValue;\\n if (nativeMappingValue == EMPTY) {\\n // New token\\n bridgedToken = deployBridgedToken(\\_nativeToken, \\_tokenMetadata);\\n bridgedToNativeToken[bridgedToken] = \\_nativeToken;\\n nativeToBridgedToken[\\_nativeToken] = bridgedToken;\\n }\\n BridgedToken(bridgedToken).mint(\\_recipient, \\_amount);\\n}\\n```\\nчMake sure, a native token should bridge to a single target contract. A possible approach could be to check whether the `bridgedToNativeToken` for a target is `EMPTY` or not. If it's not `EMPTY`, it means it's already a bridge for a native token and the function should revert. The same can be achieved by adding the modifier `isNewToken(_targetContract)`.\\nNote:- However, it doesn't resolve the issue of frontrunning, even if the likelihood is less.чч```\\nfunction setCustomContract(\\n address \\_nativeToken,\\n address \\_targetContract\\n) external onlyOwner isNewToken(\\_nativeToken) {\\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\\n}\\n```\\n
Updating Message Service Does Not Emit EventчmediumчResolution\\nThe recommendations are implemented by the Linea team in the pull request 69 with the final commit hash as `1fdd5cfc51c421ad9aaf8b2fd2b3e2ed86ffa898`\\nThe function `setMessageService` allows the owner to update the message service address. However, it does not emit any event reflecting the change. As a result, in case the owner gets compromised, it can silently add a malicious message service, exploiting users' funds. Since, there was no event emitted, off-chain monitoring tools wouldn't be able to trigger alarms and users would continue using rogue message service until and unless tracked manually.\\n```\\nfunction setMessageService(address \\_messageService) public onlyOwner {\\n messageService = IMessageService(\\_messageService);\\n}\\n```\\nчConsider emitting an event reflecting the update from the old message service to the new one.чч```\\nfunction setMessageService(address \\_messageService) public onlyOwner {\\n messageService = IMessageService(\\_messageService);\\n}\\n```\\n
Lock Solidity Version in pragmaчlowчContracts should be deployed with the same compiler version they have been tested with. Locking the pragma helps ensure that contracts do not accidentally get deployed using, for example, the latest compiler which may have higher risks of undiscovered bugs. Contracts may also be deployed by others and the pragma indicates the compiler version intended by the original authors.\\nSee Locking Pragmas in Ethereum Smart Contract Best Practices.\\n```\\npragma solidity ^0.8.19;\\n```\\n\\n```\\npragma solidity ^0.8.19;\\n```\\n\\n```\\npragma solidity ^0.8.19;\\n```\\n\\n```\\npragma solidity ^0.8.19;\\n```\\nчLock the Solidity version to the latest version before deploying the contracts to production.\\n```\\npragma solidity 0.8.19;\\n```\\nчч```\\npragma solidity ^0.8.19;\\n```\\n
TokenBridge Does Not Follow a 2-Step Approach for Ownership TransfersчlowчResolution\\nThe recommendations are implemented by the Linea team in the pull request 71 with the final commit hash as `8ebfd011675ea318b7067af52637192aa1126acd`\\n`TokenBridge` defines a privileged role Owner, however, it uses a single-step approach, which immediately transfers the ownership to the new address. If accidentally passed an incorrect address, the current owner will immediately lose control over the system as there is no fail-safe mechanism.\\nA safer approach would be to first propose the ownership to the new owner, and let the new owner accept the proposal to be the new owner. It will add a fail-safe mechanism for the current owner as in case it proposes ownership to an incorrect address, it will not immediately lose control, and may still propose again to a correct address.\\n```\\ncontract TokenBridge is ITokenBridge, PausableUpgradeable, OwnableUpgradeable {\\n```\\nчConsider moving to a 2-step approach for the ownership transfers as recommended above. Note:- Openzeppelin provides another helper utility as Ownable2StepUpgradeable which follows the recommended approachчч```\\ncontract TokenBridge is ITokenBridge, PausableUpgradeable, OwnableUpgradeable {\\n```\\n
Heavy Blocks May Affect Block Finalization, if the Gas Requirement Exceeds Block Gas LimitчhighчThe `sequencer` takes care of finalizing blocks by submitting proof, blocks' data, proof type, and parent state root hash. The team mentions that the blocks are finalized every 12s, and under general scenarios, the system will work fine. However, in cases where there are blocks containing lots of transactions and event logs, the function may require gas more than the block gas limit. As a consequence, it may affect block finalization or lead to a potential DoS.\\n```\\nfunction finalizeBlocks(\\n BlockData[] calldata \\_blocksData,\\n bytes calldata \\_proof,\\n uint256 \\_proofType,\\n bytes32 \\_parentStateRootHash\\n)\\n```\\nчWe advise the team to benchmark the cost associated per block for the finalization and how many blocks can be finalized in one rollup and add the limits accordingly for the prover/sequencer.чч```\\nfunction finalizeBlocks(\\n BlockData[] calldata \\_blocksData,\\n bytes calldata \\_proof,\\n uint256 \\_proofType,\\n bytes32 \\_parentStateRootHash\\n)\\n```\\n
Postman Can Incorrectly Deliver a Message While Still Collecting the FeesчhighчThe message service allows cross chain message delivery, where the user can define the parameters of the message as:\\nfrom: Sender of the message _to: Receiver of the message _fee: The fees, the sender wants to pay to the postman to deliver the message valueSent: The value in the native currency of the chain to be sent with the message messageNumber: Nonce value which increments for every message _calldata: Calldata for the message to be executed on the destination chain\\nThe postman estimates the gas before claiming/delivering the message on the destination chain, thus avoiding scenarios where the fees sent are less than the cost of claiming the message.\\nHowever, there is nothing that restricts the postman from sending the gas equal to the fees paid by the user. Although it contributes to the MEV, where the postman can select the messages with higher fees first and deliver them prior to others, it also opens up an opportunity where the postman can deliver a message incorrectly while still claiming the fees.\\nOne such scenario is, where the low-level call to target `_to` makes another sub-call to another address, let's say `x`. Let's assume, the `_to` address doesn't check, whether the call to address `x` was successful or not. Now, if the postman supplies a gas, which makes the top-level call succeed, but the low-level call to `x` fails silently, the postman will still be retrieving the fees of claiming the message, even though the message was not correctly delivered.\\n```\\n(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\\nif (!success) {\\n if (returnData.length > 0) {\\n assembly {\\n let data\\_size := mload(returnData)\\n revert(add(32, returnData), data\\_size)\\n }\\n } else {\\n revert MessageSendingFailed(\\_to);\\n }\\n}\\n```\\n\\n```\\n(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\\nif (!success) {\\n if (returnData.length > 0) {\\n assembly {\\n let data\\_size := mload(returnData)\\n revert(add(32, returnData), data\\_size)\\n }\\n } else {\\n revert MessageSendingFailed(\\_to);\\n }\\n}\\n```\\nчAnother parameter can be added to the message construct giving the user the option to define the amount of gas required to complete a transaction entirely. Also, a check can be added while claiming the message, to make sure the gas supplied by the postman is sufficient enough compared to the gas defined/demanded by the user. The cases, where the user can demand a huge amount of gas, can be simply avoided by doing the gas estimation, and if the demanded gas is more than the supplied fees, the postman will simply opt not to deliver the messageчч```\\n(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\\nif (!success) {\\n if (returnData.length > 0) {\\n assembly {\\n let data\\_size := mload(returnData)\\n revert(add(32, returnData), data\\_size)\\n }\\n } else {\\n revert MessageSendingFailed(\\_to);\\n }\\n}\\n```\\n
User's Funds Would Stuck if the Message Claim Failed on the Destination LayerчhighчWhen claiming the message on the destination layer, if the message failed to execute with various reasons (e.g. wrong target contract address, wrong contract logic, out of gas, malicious contract), the Ether sent with `sendMessage` on the original layer will be stuck, although the message can be retried later by the Postman or the user (could fail again)\\n```\\nuint256 messageNumber = nextMessageNumber;\\nuint256 valueSent = msg.value - \\_fee;\\n\\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\\n```\\n\\n```\\n(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\\nif (!success) {\\n if (returnData.length > 0) {\\n assembly {\\n let data\\_size := mload(returnData)\\n revert(add(32, returnData), data\\_size)\\n }\\n } else {\\n revert MessageSendingFailed(\\_to);\\n }\\n}\\n```\\n\\n```\\n(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\\nif (!success) {\\n if (returnData.length > 0) {\\n assembly {\\n let data\\_size := mload(returnData)\\n revert(add(32, returnData), data\\_size)\\n }\\n } else {\\n revert MessageSendingFailed(\\_to);\\n }\\n}\\n```\\nчAdd refund mechanism to refund users funds if the message failed to deliver on the destination layerчч```\\nuint256 messageNumber = nextMessageNumber;\\nuint256 valueSent = msg.value - \\_fee;\\n\\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\\n```\\n
Front Running finalizeBlocks When Sequencers Are DecentralizedчhighчWhen sequencer is decentralized in the future, one sequencer could front run another sequencer's `finalizeBlocks` transaction, without doing the actual proving and sequencing, and steal the reward for sequencing if there is one. Once the frontrunner's `finalizeBlocks` is executed, the original sequencer's transaction would fail as `currentL2BlockNumber` would increment by one and state root hash won't match, as a result the original sequencer's sequencing and proving work will be wasted.\\n```\\nfunction finalizeBlocks(\\n BlockData[] calldata \\_blocksData,\\n bytes calldata \\_proof,\\n uint256 \\_proofType,\\n bytes32 \\_parentStateRootHash\\n)\\n external\\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\\n onlyRole(OPERATOR\\_ROLE)\\n{\\n if (stateRootHashes[currentL2BlockNumber] != \\_parentStateRootHash) {\\n revert StartingRootHashDoesNotMatch();\\n }\\n\\n \\_finalizeBlocks(\\_blocksData, \\_proof, \\_proofType, \\_parentStateRootHash, true);\\n}\\n```\\nчAdd the sequencer's address as one parameters in `_finalizeBlocks` function, and include the sequencer's address in the public input hash of the proof in verification function `_verifyProof`.\\n```\\nfunction _finalizeBlocks(\\n   BlockData[] calldata _blocksData,\\n   bytes memory _proof,\\n   uint256 _proofType,\\n   bytes32 _parentStateRootHash,\\n   bool _shouldProve,\\n   address _sequencer\\n )\\n```\\n\\n```\\n_verifyProof(\\n        uint256(\\n          keccak256(\\n            abi.encode(\\n              keccak256(abi.encodePacked(blockHashes)),\\n              firstBlockNumber,\\n              keccak256(abi.encodePacked(timestampHashes)),\\n              keccak256(abi.encodePacked(hashOfRootHashes)),\\n              keccak256(abi.encodePacked(_sequencer)\\n            )\\n          )\\n        ) % MODULO_R,\\n        _proofType,\\n        _proof,\\n        _parentStateRootHash\\n      );\\n```\\nчч```\\nfunction finalizeBlocks(\\n BlockData[] calldata \\_blocksData,\\n bytes calldata \\_proof,\\n uint256 \\_proofType,\\n bytes32 \\_parentStateRootHash\\n)\\n external\\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\\n onlyRole(OPERATOR\\_ROLE)\\n{\\n if (stateRootHashes[currentL2BlockNumber] != \\_parentStateRootHash) {\\n revert StartingRootHashDoesNotMatch();\\n }\\n\\n \\_finalizeBlocks(\\_blocksData, \\_proof, \\_proofType, \\_parentStateRootHash, true);\\n}\\n```\\n
User Funds Would Stuck if the Single Coordinator Is Offline or Censoring MessagesчhighчWhen user sends message from L1 to L2, the coordinator needs to post the messages to L2, this happens in the anchoring message(addL1L2MessageHashes) on L2, then the user or Postman can claim the message on L2. since there is only a single coordinator, if the coordinator is down or censoring messages sent from L1 to L2, users funds can stuck in L1, until the coordinator come back online or stops censoring the message, as there is no message cancel feature or message expire feature. Although the operator can pause message sending on L1 once the coordinator is down, but if the message is sent and not posted to L2 before the pause it will still stuck.\\n```\\nuint256 messageNumber = nextMessageNumber;\\nuint256 valueSent = msg.value - \\_fee;\\n\\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\\n```\\n\\n```\\nfunction addL1L2MessageHashes(bytes32[] calldata \\_messageHashes) external onlyRole(L1\\_L2\\_MESSAGE\\_SETTER\\_ROLE) {\\n uint256 messageHashesLength = \\_messageHashes.length;\\n\\n if (messageHashesLength > 100) {\\n revert MessageHashesListLengthHigherThanOneHundred(messageHashesLength);\\n }\\n\\n for (uint256 i; i < messageHashesLength; ) {\\n bytes32 messageHash = \\_messageHashes[i];\\n if (inboxL1L2MessageStatus[messageHash] == INBOX\\_STATUS\\_UNKNOWN) {\\n inboxL1L2MessageStatus[messageHash] = INBOX\\_STATUS\\_RECEIVED;\\n }\\n unchecked {\\n i++;\\n }\\n }\\n\\n emit L1L2MessageHashesAddedToInbox(\\_messageHashes);\\n}\\n```\\nчDecentralize coordinator and sequencer or enable user cancel or drop the message if message deadline has expired.чч```\\nuint256 messageNumber = nextMessageNumber;\\nuint256 valueSent = msg.value - \\_fee;\\n\\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\\n```\\n
Changing Verifier Address Doesn't Emit EventчhighчIn function `setVerifierAddress`, after the verifier address is changed, there is no event emitted, which means if the operator (security council) changes the verifier to a buggy verifier, or if the security council is compromised, the attacker can change the verifier to a malicious one, the unsuspecting user would still use the service, potentially lose funds due to the fraud transactions would be verified.\\n```\\nfunction setVerifierAddress(address \\_newVerifierAddress, uint256 \\_proofType) external onlyRole(DEFAULT\\_ADMIN\\_ROLE) {\\n if (\\_newVerifierAddress == address(0)) {\\n revert ZeroAddressNotAllowed();\\n }\\n verifiers[\\_proofType] = \\_newVerifierAddress;\\n}\\n```\\nчEmits event after changing verifier address including old verifier address, new verifier address and the caller accountчч```\\nfunction setVerifierAddress(address \\_newVerifierAddress, uint256 \\_proofType) external onlyRole(DEFAULT\\_ADMIN\\_ROLE) {\\n if (\\_newVerifierAddress == address(0)) {\\n revert ZeroAddressNotAllowed();\\n }\\n verifiers[\\_proofType] = \\_newVerifierAddress;\\n}\\n```\\n
L2 Blocks With Incorrect Timestamp Could Be FinalizedчmediumчIn `_finalizeBlocks` of `ZkEvmV2`, the current block timestamp `blockInfo.l2BlockTimestamp` should be greater or equal than the last L2 block timestamp and less or equal than the L1 block timestamp when `_finalizeBlocks` is executed. However the first check is missing, blocks with incorrect timestamp could be finalized, causing unintended system behavior\\n```\\nif (blockInfo.l2BlockTimestamp >= block.timestamp) {\\n revert BlockTimestampError();\\n}\\n```\\nчAdd the missing timestamp checkчч```\\nif (blockInfo.l2BlockTimestamp >= block.timestamp) {\\n revert BlockTimestampError();\\n}\\n```\\n
Rate Limiting Affecting the Usability and User's Funds SafetyчmediumчIn `claimMessage` of `L1MessageService` and `sendMessage` function of `L1MessageService` contract, function `_addUsedAmount` is used to rate limit the Ether amount (1000 Eth) sent from L2 to L1 in a time period (24 hours), this is problematic, usually user sends the funds to L1 when they need to exit from L2 to L1 especially when some security issues happened affecting their funds safety on L2, if there is a limit, the limit can be reached quickly by some whale sending large amount of Ether to L1, while other users cannot withdraw their funds to L1, putting their funds at risk. In addition, the limit can only be set and changed by the security council and security council can also pause message service at any time, blocking user withdraw funds from L2, this makes the L2->L1 message service more centralized.\\n```\\n\\_addUsedAmount(\\_fee + \\_value);\\n```\\n\\n```\\n\\_addUsedAmount(msg.value);\\n```\\n\\n```\\nfunction \\_addUsedAmount(uint256 \\_usedAmount) internal {\\n uint256 currentPeriodAmountTemp;\\n\\n if (currentPeriodEnd < block.timestamp) {\\n // Update period before proceeding\\n currentPeriodEnd = block.timestamp + periodInSeconds;\\n currentPeriodAmountTemp = \\_usedAmount;\\n } else {\\n currentPeriodAmountTemp = currentPeriodAmountInWei + \\_usedAmount;\\n }\\n\\n if (currentPeriodAmountTemp > limitInWei) {\\n revert RateLimitExceeded();\\n }\\n\\n currentPeriodAmountInWei = currentPeriodAmountTemp;\\n}\\n```\\nчRemove rate limiting for L2->L1 message serviceчч```\\n\\_addUsedAmount(\\_fee + \\_value);\\n```\\n
Front Running claimMessage on L1 and L2чmediumчThe front-runner on L1 or L2 can front run the `claimMessage` transaction, as long as the `fee` is greater than the gas cost of the claiming the message and `feeRecipient` is not set, consequently the `fee` will be transferred to the message.sender(the front runner) once the message is claimed. As a result, postman would lose the incentive to deliver(claim) the message on the destination layer.\\n```\\nif (\\_fee > 0) {\\n address feeReceiver = \\_feeRecipient == address(0) ? msg.sender : \\_feeRecipient;\\n (bool feePaymentSuccess, ) = feeReceiver.call{ value: \\_fee }(\"\");\\n if (!feePaymentSuccess) {\\n revert FeePaymentFailed(feeReceiver);\\n }\\n```\\n\\n```\\nif (\\_fee > 0) {\\n address feeReceiver = \\_feeRecipient == address(0) ? msg.sender : \\_feeRecipient;\\n (bool feePaymentSuccess, ) = feeReceiver.call{ value: \\_fee }(\"\");\\n if (!feePaymentSuccess) {\\n revert FeePaymentFailed(feeReceiver);\\n }\\n}\\n```\\nчThere are a few protections against front running including flashbots service. Another option to mitigate front running is to avoid using msg.sender and have user use the signed `claimMessage` transaction by the Postman to claim the message on the destination layerчч```\\nif (\\_fee > 0) {\\n address feeReceiver = \\_feeRecipient == address(0) ? msg.sender : \\_feeRecipient;\\n (bool feePaymentSuccess, ) = feeReceiver.call{ value: \\_fee }(\"\");\\n if (!feePaymentSuccess) {\\n revert FeePaymentFailed(feeReceiver);\\n }\\n```\\n
Contracts Not Well Designed for UpgradesчmediumчInconsistent Storage Layout\\nThe Contracts introduce some buffer space in the storage layout to cope with the scenarios where new storage variables can be added if a need exists to upgrade the contracts to a newer version. This helps in reducing the chances of potential storage collisions. However, the storage layout concerning the buffer space is inconsistent, and multiple variations have been observed.\\n`PauseManager`, `RateLimitter`, and `MessageServiceBase` adds a buffer space of 10, contrary to other contracts which define the space as 50.\\n```\\nuint256[10] private \\_gap;\\n```\\n\\n```\\nuint256[10] private \\_gap;\\n```\\n\\n```\\nuint256[10] private \\_\\_base\\_gap;\\n```\\n\\n`L2MessageService` defines the buffer space prior to its existing storage variables.\\n```\\nuint256[50] private \\_\\_gap\\_L2MessageService;\\n```\\n\\nIf there exists a need to inherit from this contract in the future, the derived contract has to define the buffer space first, similar to `L2MessageService`. If it doesn't, `L2MessageService` can't have more storage variables. If it adds them, it will collide with the derived contract's storage slots.\\n2. `RateLimiter` and `MessageServiceBase` initializes values without the modifier `onlyInitializing`\\n```\\nfunction \\_\\_RateLimiter\\_init(uint256 \\_periodInSeconds, uint256 \\_limitInWei) internal {\\n```\\n\\n```\\nfunction \\_init\\_MessageServiceBase(address \\_messageService, address \\_remoteSender) internal {\\n```\\n\\nThe modifier `onlyInitializing` makes sure that the function should only be invoked by a function marked as `initializer`. However, it is absent here, which means these are normal internal functions that can be utilized in any other function, thus opening opportunities for errors.чDefine a consistent storage layout. Consider a positive number `n` for the number of buffer space slots, such that, it is equal to any arbitrary number `d - No. of occupied storage slots`. For instance, if the arbitrary number is 50, and the contract has 20 occupied storage slots, the buffer space can be 50-20 = 30. It will maintain a consistent storage layout throughout the inheritance hierarchy.\\nFollow a consistent approach to defining buffer space. Currently, all the contracts, define the buffer space after their occupied storage slots, so it should be maintained in the `L2MessageService` as well.\\nDefine functions `__RateLimiter_init` and `_init_MessageServiceBase` as `onlyInitializing`.чч```\\nuint256[10] private \\_gap;\\n```\\n
Potential Code CorrectionsчlowчFunction `_updateL1L2MessageStatusToReceived` and `addL1L2MessageHashes` allows status update for already received/sent/claimed messages.\\n```\\nfunction \\_updateL1L2MessageStatusToReceived(bytes32[] memory \\_messageHashes) internal {\\n uint256 messageHashArrayLength = \\_messageHashes.length;\\n\\n for (uint256 i; i < messageHashArrayLength; ) {\\n bytes32 messageHash = \\_messageHashes[i];\\n uint256 existingStatus = outboxL1L2MessageStatus[messageHash];\\n\\n if (existingStatus == INBOX\\_STATUS\\_UNKNOWN) {\\n revert L1L2MessageNotSent(messageHash);\\n }\\n\\n if (existingStatus != OUTBOX\\_STATUS\\_RECEIVED) {\\n outboxL1L2MessageStatus[messageHash] = OUTBOX\\_STATUS\\_RECEIVED;\\n }\\n\\n unchecked {\\n i++;\\n }\\n }\\n\\n emit L1L2MessagesReceivedOnL2(\\_messageHashes);\\n}\\n```\\n\\n```\\nfunction addL1L2MessageHashes(bytes32[] calldata \\_messageHashes) external onlyRole(L1\\_L2\\_MESSAGE\\_SETTER\\_ROLE) {\\n uint256 messageHashesLength = \\_messageHashes.length;\\n\\n if (messageHashesLength > 100) {\\n revert MessageHashesListLengthHigherThanOneHundred(messageHashesLength);\\n }\\n\\n for (uint256 i; i < messageHashesLength; ) {\\n bytes32 messageHash = \\_messageHashes[i];\\n if (inboxL1L2MessageStatus[messageHash] == INBOX\\_STATUS\\_UNKNOWN) {\\n inboxL1L2MessageStatus[messageHash] = INBOX\\_STATUS\\_RECEIVED;\\n }\\n unchecked {\\n i++;\\n }\\n }\\n\\n emit L1L2MessageHashesAddedToInbox(\\_messageHashes);\\n```\\n\\nIt may trigger false alarms, as they will still be a part of `L1L2MessagesReceivedOnL2` and `L1L2MessageHashesAddedToInbox`.\\n`_updateL1L2MessageStatusToReceived` checks the status of L1->L2 messages as:\\n```\\nif (existingStatus == INBOX\\_STATUS\\_UNKNOWN) {\\n revert L1L2MessageNotSent(messageHash);\\n}\\n```\\n\\nHowever, the status is need to be checked with `OUTBOX_STATUS_UNKNOWN` instead of `INBOX_STATUS_UNKNOWN` as it is an outbox message. This creates a hindrance in the code readability and should be fixed.\\nArray `timestampHashes` stores `l2BlockTimestamp` as integers, contrary to the hashes that the variable name states.\\n```\\ntimestampHashes[i] = blockInfo.l2BlockTimestamp;\\n```\\n\\nUnused error declaration\\n```\\n \\* dev Thrown when the decoding action is invalid.\\n \\*/\\n\\nerror InvalidAction();\\n```\\n\\nTransactionDecoder defines an error as `InvalidAction` which is supposed to be thrown when the decoding action is invalid, as stated in NATSPEC comment. However, it is currently unutilized.чOnly update the status for sent messages in `_updateL1L2MessageStatusToReceived`, and unknown messages in `addL1L2MessageHashes` and revert otherwise, to avoid off-chain accounting errors.\\nCheck the status of L1->L2 sent message with `OUTBOX_STATUS_UNKNOWN` to increase code readability.\\nEither store timestamp hashes in the variable `timestampHashes` or update the variable name likewise.\\nRemove the error declaration if it is not serving any purpose.чч```\\nfunction \\_updateL1L2MessageStatusToReceived(bytes32[] memory \\_messageHashes) internal {\\n uint256 messageHashArrayLength = \\_messageHashes.length;\\n\\n for (uint256 i; i < messageHashArrayLength; ) {\\n bytes32 messageHash = \\_messageHashes[i];\\n uint256 existingStatus = outboxL1L2MessageStatus[messageHash];\\n\\n if (existingStatus == INBOX\\_STATUS\\_UNKNOWN) {\\n revert L1L2MessageNotSent(messageHash);\\n }\\n\\n if (existingStatus != OUTBOX\\_STATUS\\_RECEIVED) {\\n outboxL1L2MessageStatus[messageHash] = OUTBOX\\_STATUS\\_RECEIVED;\\n }\\n\\n unchecked {\\n i++;\\n }\\n }\\n\\n emit L1L2MessagesReceivedOnL2(\\_messageHashes);\\n}\\n```\\n
TransactionDecoder Does Not Account for the Missing Elements While Decoding a TransactionчlowчThe library tries to decode calldata from different transaction types, by jumping to the position of calldata element in the rlp encoding. These positions are:\\nEIP1559: 8\\nEIP2930: 7\\nLegacy: 6\\n```\\ndata = it.\\_skipTo(8).\\_toBytes();\\n```\\n\\n```\\ndata = it.\\_skipTo(7).\\_toBytes();\\n```\\n\\n```\\ndata = it.\\_skipTo(6).\\_toBytes();\\n```\\n\\nHowever, the decoder doesn't check whether the required element is there or not in the encoding provided.\\nThe decoder uses the library RLPReader to skip to the desired element in encoding. However, it doesn't revert in case there are not enough elements to skip to, and will simply return byte `0x00`, while still completing unnecessary iterations.\\n```\\nfunction \\_skipTo(Iterator memory \\_self, uint256 \\_skipToNum) internal pure returns (RLPItem memory item) {\\n uint256 ptr = \\_self.nextPtr;\\n uint256 itemLength = \\_itemLength(ptr);\\n \\_self.nextPtr = ptr + itemLength;\\n\\n for (uint256 i; i < \\_skipToNum - 1; ) {\\n ptr = \\_self.nextPtr;\\n itemLength = \\_itemLength(ptr);\\n \\_self.nextPtr = ptr + itemLength;\\n\\n unchecked {\\n i++;\\n }\\n }\\n\\n item.len = itemLength;\\n item.memPtr = ptr;\\n}\\n```\\n\\nAlthough it doesn't impose any security issue, as `ZkEvmV2` tries to decode an array of bytes32 hashes from the rlp encoded transaction. However, it may still lead to errors in other use cases if not handled correctly.\\n```\\nCodecV2.\\_extractXDomainAddHashes(TransactionDecoder.decodeTransaction(\\_transactions[\\_batchReceptionIndices[i]]))\\n```\\nчrlp library should revert if there are not enough elements to skip to in the encoding.чч```\\ndata = it.\\_skipTo(8).\\_toBytes();\\n```\\n
Incomplete Message State Check When Claiming Messages on L1 and L2чlowчWhen claiming message on L1 orL2, `_updateL2L1MessageStatusToClaimed` and `_updateL1L2MessageStatusToClaimed` are called to update the message status, however the message state check only checks status `INBOX_STATUS_RECEIVED` and is missing status `INBOX_STATUS_UNKNOWN`, which means the message is not picked up by the coordinator or the message is not sent on L1 or L2 and should be reverted. As a result, the claiming message could be reverted with a incorrect reason.\\n```\\nfunction \\_updateL2L1MessageStatusToClaimed(bytes32 \\_messageHash) internal {\\n if (inboxL2L1MessageStatus[\\_messageHash] != INBOX\\_STATUS\\_RECEIVED) {\\n revert MessageAlreadyClaimed();\\n }\\n\\n delete inboxL2L1MessageStatus[\\_messageHash];\\n\\n emit L2L1MessageClaimed(\\_messageHash);\\n}\\n```\\n\\n```\\n function \\_updateL1L2MessageStatusToClaimed(bytes32 \\_messageHash) internal {\\n if (inboxL1L2MessageStatus[\\_messageHash] != INBOX\\_STATUS\\_RECEIVED) {\\n revert MessageAlreadyClaimed();\\n }\\n\\n inboxL1L2MessageStatus[\\_messageHash] = INBOX\\_STATUS\\_CLAIMED;\\n\\n emit L1L2MessageClaimed(\\_messageHash);\\n }\\n}\\n```\\nчAdd the missing status check and relevant revert reason for status `INBOX_STATUS_UNKNOWN`чч```\\nfunction \\_updateL2L1MessageStatusToClaimed(bytes32 \\_messageHash) internal {\\n if (inboxL2L1MessageStatus[\\_messageHash] != INBOX\\_STATUS\\_RECEIVED) {\\n revert MessageAlreadyClaimed();\\n }\\n\\n delete inboxL2L1MessageStatus[\\_messageHash];\\n\\n emit L2L1MessageClaimed(\\_messageHash);\\n}\\n```\\n
Events Which May Trigger False Alarmsчlowч1- `PauseManager` allows `PAUSE_MANAGER_ROLE` to pause/unpause a type as:\\n```\\nfunction pauseByType(bytes32 \\_pauseType) external onlyRole(PAUSE\\_MANAGER\\_ROLE) {\\n pauseTypeStatuses[\\_pauseType] = true;\\n emit Paused(\\_msgSender(), \\_pauseType);\\n}\\n```\\n\\n```\\nfunction unPauseByType(bytes32 \\_pauseType) external onlyRole(PAUSE\\_MANAGER\\_ROLE) {\\n pauseTypeStatuses[\\_pauseType] = false;\\n emit UnPaused(\\_msgSender(), \\_pauseType);\\n}\\n```\\n\\nHowever, the functions don't check whether the given `_pauseType` has already been paused/unpaused or not and emits an event every time called. This may trigger false alarms for off-chain monitoring tools and may cause unnecessary panic.\\n2 - `RateLimitter` allows resetting the limit and used amount as:\\n```\\nfunction resetRateLimitAmount(uint256 \\_amount) external onlyRole(RATE\\_LIMIT\\_SETTER\\_ROLE) {\\n bool amountUsedLoweredToLimit;\\n\\n if (\\_amount < currentPeriodAmountInWei) {\\n currentPeriodAmountInWei = \\_amount;\\n amountUsedLoweredToLimit = true;\\n }\\n\\n limitInWei = \\_amount;\\n\\n emit LimitAmountChange(\\_msgSender(), \\_amount, amountUsedLoweredToLimit);\\n}\\n```\\n\\n```\\nfunction resetAmountUsedInPeriod() external onlyRole(RATE\\_LIMIT\\_SETTER\\_ROLE) {\\n currentPeriodAmountInWei = 0;\\n\\n emit AmountUsedInPeriodReset(\\_msgSender());\\n}\\n```\\n\\nHowever, it doesn't account for the scenarios where the function can be called after the current period ends and before a new period gets started. As the `currentPeriodAmountInWei` will still be holding the used amount of the last period, if the `RATE_LIMIT_SETTER_ROLE` tries to reset the limit with the lower value than the used amount, the function will emit the same event `LimitAmountChange` with the flag `amountUsedLoweredToLimit`.\\nAdding to it, the function will make `currentPeriodAmountInWei` = `limitInWei`, which means no more amount can be added as the used amount until the used amount is manually reset to 0, which points out to the fact that the used amount should be automatically reset, once the current period ends. Although it is handled automatically in function `_addUsedAmount`, however, if the new period has not yet started, it is supposed to be done in a 2-step approach i.e., first, reset the used amount and then the limit. It can be simplified by checking for the current period in the `resetRateLimitAmount` function itself.\\nThe same goes for the scenario where the used amount is reset after the current period ends. It will emit the same event as `AmountUsedInPeriodReset`\\nThese can create unnecessary confusion, as the events emitted don't consider the abovementioned scenarios.чConsider adding checks to make sure already paused/unpaused types don't emit respective events.\\nConsider emitting different events, or adding a flag in the events, that makes it easy to differentiate whether the limit and used amount are reset in the current period or after it has ended.\\nReset `currentPeriodAmountInWei` in function `resetRateLimitAmount` itself if the current period has ended.чч```\\nfunction pauseByType(bytes32 \\_pauseType) external onlyRole(PAUSE\\_MANAGER\\_ROLE) {\\n pauseTypeStatuses[\\_pauseType] = true;\\n emit Paused(\\_msgSender(), \\_pauseType);\\n}\\n```\\n
No Proper Trusted Setup  AcknowledgedчhighчLinea uses Plonk proof system, which needs a preprocessed CRS (Common Reference String) for proving and verification, the Plonk system security is based on the existence of a trusted setup ceremony to compute the CRS, the current verifier uses a CRS created by one single party, which requires fully trust of the party to delete the toxic waste (trapdoor) which can be used to generate forged proof, undermining the security of the entire system\\n```\\nuint256 constant g2\\_srs\\_0\\_x\\_0 = 11559732032986387107991004021392285783925812861821192530917403151452391805634;\\nuint256 constant g2\\_srs\\_0\\_x\\_1 = 10857046999023057135944570762232829481370756359578518086990519993285655852781;\\nuint256 constant g2\\_srs\\_0\\_y\\_0 = 4082367875863433681332203403145435568316851327593401208105741076214120093531;\\nuint256 constant g2\\_srs\\_0\\_y\\_1 = 8495653923123431417604973247489272438418190587263600148770280649306958101930;\\n\\nuint256 constant g2\\_srs\\_1\\_x\\_0 = 18469474764091300207969441002824674761417641526767908873143851616926597782709;\\nuint256 constant g2\\_srs\\_1\\_x\\_1 = 17691709543839494245591259280773972507311536864513996659348773884770927133474;\\nuint256 constant g2\\_srs\\_1\\_y\\_0 = 2799122126101651639961126614695310298819570600001757598712033559848160757380;\\nuint256 constant g2\\_srs\\_1\\_y\\_1 = 3054480525781015242495808388429905877188466478626784485318957932446534030175;\\n```\\nчConduct a proper MPC to generate CRS like the Powers of Tau MPC or use a trustworthy CRS generated by an exisiting audited trusted setup like Aztec's ignitionчч```\\nuint256 constant g2\\_srs\\_0\\_x\\_0 = 11559732032986387107991004021392285783925812861821192530917403151452391805634;\\nuint256 constant g2\\_srs\\_0\\_x\\_1 = 10857046999023057135944570762232829481370756359578518086990519993285655852781;\\nuint256 constant g2\\_srs\\_0\\_y\\_0 = 4082367875863433681332203403145435568316851327593401208105741076214120093531;\\nuint256 constant g2\\_srs\\_0\\_y\\_1 = 8495653923123431417604973247489272438418190587263600148770280649306958101930;\\n\\nuint256 constant g2\\_srs\\_1\\_x\\_0 = 18469474764091300207969441002824674761417641526767908873143851616926597782709;\\nuint256 constant g2\\_srs\\_1\\_x\\_1 = 17691709543839494245591259280773972507311536864513996659348773884770927133474;\\nuint256 constant g2\\_srs\\_1\\_y\\_0 = 2799122126101651639961126614695310298819570600001757598712033559848160757380;\\nuint256 constant g2\\_srs\\_1\\_y\\_1 = 3054480525781015242495808388429905877188466478626784485318957932446534030175;\\n```\\n
Missing Verifying Paring Check ResultчhighчIn function `batch_verify_multi_points`, the SNARK paring check is done by calling paring pre-compile `let l_success := staticcall(sub(gas(), 2000),8,mPtr,0x180,0x00,0x20)` and the only the execution status is stored in the final success state (state_success), but the the paring check result which is stored in 0x00 is not stored and checked, which means if the paring check result is 0 (pairing check failed), the proof would still pass verification, e.g. invalid proof with incorrect proof element `proof_openings_selector_commit_api_at_zeta` would pass the paring check. As a result it breaks the SNARK paring verification.\\n```\\nlet l\\_success := staticcall(sub(gas(), 2000),8,mPtr,0x180,0x00,0x20)\\n// l\\_success := true\\nmstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n```\\n\\nAnother example is, if either of the following is sent as a point at infinity or (0,0) as (x,y) co-ordinate:\\ncommitment to the opening proof polynomial Wz\\ncommitment to the opening proof polynomial Wzw\\nThe proof will still work, since the pairing result is not being checked.чVerify paring check result and store it in the final success state after calling the paring pre-compileчч```\\nlet l\\_success := staticcall(sub(gas(), 2000),8,mPtr,0x180,0x00,0x20)\\n// l\\_success := true\\nmstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n```\\n
Gas Greifing and Missing Return Status Check for staticcall(s), May Lead to Unexpected Outcomes  Partially AddressedчhighчThe gas supplied to the staticcall(s), is calculated by subtracting `2000` from the remaining gas at this point in time. However, if not provided enough gas, the staticcall(s) may fail and there will be no return data, and the execution will continue with the stale data that was previously there at the memory location specified by the return offset with the staticcall(s).\\n1- Predictable Derivation of Challenges\\nThe function `derive_gamma_beta_alpha_zeta` is used to derive the challenge values `gamma`, `beta`, `alpha`, `zeta`. These values are derived from the prover's transcript by hashing defined parameters and are supposed to be unpredictable by either the prover or the verifier. The hash is collected with the help of SHA2-256 precompile. The values are considered unpredictable, due to the assumption that SHA2-256 acts as a random oracle and it would be computationally infeasible for an attacker to find the pre-image of `gamma`. However, the assumption might be wrong.\\n```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1b), size, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1c), 0x24, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1b), 0x65, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1c), 0xe4, mPtr, 0x20))\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr,start\\_input), size\\_input, add(state, state\\_gamma\\_kzg), 0x20))\\n```\\n\\nIf the staticcall(s) fails, it will make the challenge values to be predictable and may help the prover in forging proofs and launching other adversarial attacks.\\n2- Incorrect Exponentiation\\nFunctions `compute_ith_lagrange_at_z`, `compute_pi`, and `verify` compute modular exponentiation by making a `staticcall` to the precompile `modexp` as:\\n```\\npop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,0x00,0x20))\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,mPtr,0x20))\\n```\\n\\n```\\npop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,mPtr,0x20))\\n```\\n\\nHowever, if not supplied enough gas, the staticcall(s) will fail, thus returning no result and the execution will continue with the stale data.\\n3. Incorrect Point Addition and Scalar Multiplication\\n```\\npop(staticcall(sub(gas(), 2000),7,folded\\_evals\\_commit,0x60,folded\\_evals\\_commit,0x40))\\n```\\n\\n```\\nlet l\\_success := staticcall(sub(gas(), 2000),6,mPtr,0x80,dst,0x40)\\n```\\n\\n```\\nlet l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,dst,0x40)\\n```\\n\\n```\\nlet l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,mPtr,0x40)\\n```\\n\\n```\\nl\\_success := and(l\\_success, staticcall(sub(gas(), 2000),6,mPtr,0x80,dst, 0x40))\\n```\\n\\nFor the same reason, `point_add`, `point_mul`, and `point_acc_mul` will return incorrect results. Matter of fact, `point_acc_mul` will not revert even if the scalar multiplication fails in the first step. Because, the memory location specified for the return offset, will still be containing the old (x,y) coordinates of `src`, which are points on the curve. Hence, it will proceed by incorrectly adding (x,y) coordinates of `dst` with it.\\nHowever, it will not be practically possible to conduct a gas griefing attack for staticcall(s) at the start of the top-level transaction. As it will require an attacker to pass a very low amount of gas to make the `staticcall` fail, but at the same time, that would not be enough to make the top-level transaction execute entirely and not run out of gas. But, this can still be conducted for the staticcall(s) that are executed at the near end of the top-level transaction.чCheck the returned status of the staticcall and revert if any of the staticcall's return status has been 0.\\nAlso fix the comments mentioned for every staticcall, for instance: the function `derive_beta` says `0x1b -> 000..\"gamma\"` while the memory pointer holds the ASCII value of string `beta`чч```\\npop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1b), size, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\\n```\\n
Missing Scalar Field Range Check in Scalar MultiplicationчhighчThere is no field element range check on scalar field proof elements e.g. `proof_l_at_zeta, proof_r_at_zeta, proof_o_at_zeta, proof_s1_at_zeta,proof_s2_at_zeta, proof_grand_product_at_zeta_omega` as mentioned in the step 2 of the verifier's algorithm in the Plonk paper. The scalar multiplication functions `point_mul` and `point_acc_mul` call precompile ECMUL, according to EIP-169 , which would verify the point P is on curve and P.x and P.y is less than the base field modulus, however it doesn't check the scalar `s` is less than scalar field modulus, if `s` is greater than scalar field modulus `r_mod`, it would cause unintended behavior of the contract, specifically if the scalar field proof element `e` are replaced by `e + r_mod`, the proof would still pass verification. Although in Plonk's case, there is few attacker vectors could exists be based on this kind of proof malleability.\\n```\\nfunction point\\_mul(dst,src,s, mPtr) {\\n // let mPtr := add(mload(0x40), state\\_last\\_mem)\\n let state := mload(0x40)\\n mstore(mPtr,mload(src))\\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\\n mstore(add(mPtr,0x40),s)\\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,dst,0x40)\\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n}\\n\\n// dst <- dst + [s]src (Elliptic curve)\\nfunction point\\_acc\\_mul(dst,src,s, mPtr) {\\n let state := mload(0x40)\\n mstore(mPtr,mload(src))\\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\\n mstore(add(mPtr,0x40),s)\\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,mPtr,0x40)\\n mstore(add(mPtr,0x40),mload(dst))\\n mstore(add(mPtr,0x60),mload(add(dst,0x20)))\\n l\\_success := and(l\\_success, staticcall(sub(gas(), 2000),6,mPtr,0x80,dst, 0x40))\\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n}\\n```\\nчAdd scalar field range check on scalar multiplication functions `point_mul` and `point_acc_mul` or the scalar field proof elements.чч```\\nfunction point\\_mul(dst,src,s, mPtr) {\\n // let mPtr := add(mload(0x40), state\\_last\\_mem)\\n let state := mload(0x40)\\n mstore(mPtr,mload(src))\\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\\n mstore(add(mPtr,0x40),s)\\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,dst,0x40)\\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n}\\n\\n// dst <- dst + [s]src (Elliptic curve)\\nfunction point\\_acc\\_mul(dst,src,s, mPtr) {\\n let state := mload(0x40)\\n mstore(mPtr,mload(src))\\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\\n mstore(add(mPtr,0x40),s)\\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,mPtr,0x40)\\n mstore(add(mPtr,0x40),mload(dst))\\n mstore(add(mPtr,0x60),mload(add(dst,0x20)))\\n l\\_success := and(l\\_success, staticcall(sub(gas(), 2000),6,mPtr,0x80,dst, 0x40))\\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\\n}\\n```\\n
Missing Public Inputs Range CheckчhighчThe public input is an array of `uint256` numbers, there is no check if each public input is less than SNARK scalar field modulus `r_mod`, as mentioned in the step 3 of the verifier's algorithm in the Plonk paper. Since public inputs are involved computation of `Pi` in the plonk gate which is in the SNARK scalar field, without the check, it might cause scalar field overflow and the verification contract would fail and revert. To prevent overflow and other unintended behavior there should be a range check for the public inputs.\\n```\\nfunction Verify(bytes memory proof, uint256[] memory public\\_inputs)\\n```\\n\\n```\\nsum\\_pi\\_wo\\_api\\_commit(add(public\\_inputs,0x20), mload(public\\_inputs), zeta)\\npi := mload(mload(0x40))\\n\\nfunction sum\\_pi\\_wo\\_api\\_commit(ins, n, z) {\\n let li := mload(0x40)\\n batch\\_compute\\_lagranges\\_at\\_z(z, n, li)\\n let res := 0\\n let tmp := 0\\n for {let i:=0} lt(i,n) {i:=add(i,1)}\\n {\\n tmp := mulmod(mload(li), mload(ins), r\\_mod)\\n res := addmod(res, tmp, r\\_mod)\\n li := add(li, 0x20)\\n ins := add(ins, 0x20)\\n }\\n mstore(mload(0x40), res)\\n}\\n```\\nчAdd range check for the public inputs `require(input[i] < r_mod, \"public inputs greater than snark scalar field\");`чч```\\nfunction Verify(bytes memory proof, uint256[] memory public\\_inputs)\\n```\\n
Loading Arbitrary Data as Wire Commitments  AcknowledgedчmediumчFunction `load_wire_commitments_commit_api` as the name suggests, loads wire commitments from the proof into the memory array `wire_commitments`. The array is made to hold 2 values per commitment or the size of the array is 2 * `vk_nb_commitments_commit_api`, which makes sense as these 2 values are the x & y co-ordinates of the commitments.\\n```\\nuint256[] memory wire\\_committed\\_commitments = new uint256[](2\\*vk\\_nb\\_commitments\\_commit\\_api);\\nload\\_wire\\_commitments\\_commit\\_api(wire\\_committed\\_commitments, proof);\\n```\\n\\nComing back to the functionload_wire_commitments_commit_api, it extracts both the x & y coordinates of a commitment in a single iteration. However, the loop runs `2 * vk_nb_commitments_commit_api`, or in other words, twice as many of the required iterations. For instance, if there is 1 commitment, it will run two times. The first iteration will pick up the actual coordinates and the second one can pick any arbitrary data from the proof(if passed) and load it into memory. Although, this data which has been loaded in an extra iteration seems harmless but still adds an overhead for the processing.\\n```\\nfor {let i:=0} lt(i, mul(vk\\_nb\\_commitments\\_commit\\_api,2)) {i:=add(i,1)}\\n```\\nчThe number of iterations should be equal to the size of commitments, i.e., `vk_nb_commitments_commit_api`. So consider switching from:\\n```\\nfor {let i:=0} lt(i, mul(vk_nb_commitments_commit_api,2)) {i:=add(i,1)}\\n```\\n\\nto:\\n```\\nfor {let i:=0} lt(i, vk_nb_commitments_commit_api) {i:=add(i,1)}\\n```\\nчч```\\nuint256[] memory wire\\_committed\\_commitments = new uint256[](2\\*vk\\_nb\\_commitments\\_commit\\_api);\\nload\\_wire\\_commitments\\_commit\\_api(wire\\_committed\\_commitments, proof);\\n```\\n
Makefile: Target OrderчlowчThe target `all` in the Makefile ostensibly wants to run the targets `clean` and `solc` in that order.\\n```\\nall: clean solc\\n```\\n\\nHowever prerequisites in GNU Make are not ordered, and they might even run in parallel. In this case, this could cause spurious behavior like overwrite errors or files being deleted just after being created.чThe Make way to ensure that targets run one after the other is\\n```\\nall: clean\\n $(MAKE) solc\\n```\\n\\nAlso `all` should be listed in the PHONY targets.чч```\\nall: clean solc\\n```\\n
addPremium – A back runner may cause an insurance holder to lose their refunds by calling addPremium right after the original callчhighч`addPremium` is a public function that can be called by anyone and that distributes the weekly premium payments to the pool manager and the rest of the pool share holders. If the collateral deposited is not enough to cover the total coverage offered to insurance holders for a given week, refunds are allocated pro rata for all insurance holders of that particular week and policy. However, in the current implementation, attackers can call `addPremium` right after the original call to `addPremium` but before the call to refund; this will cause the insurance holders to lose their refunds, which will be effectively locked forever in the contract (unless the contract is upgraded).\\n```\\nrefundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\\n allCovered.sub(maximumToCover)).div(allCovered);\\n```\\nч`addPremium` should contain a validation check in the beginning of the function that reverts for the case of `incomeMap[policyIndex_][week] = 0`.чч```\\nrefundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\\n allCovered.sub(maximumToCover)).div(allCovered);\\n```\\n
refund – attacker can lock insurance holder's refunds by calling refund before a refund was allocatedчhighч`addPremium` is used to determine the `refund` amount that an insurance holder is eligible to claim. The amount is stored in the `refundMap` mapping and can then later be claimed by anyone on behalf of an insurance holder by calling `refund`. The `refund` function can't be called more than once for a given combination of `policyIndex_`, `week_`, and `who_`, as it would revert with an “Already refunded” error. This gives an attacker the opportunity to call `refund` on behalf of any insurance holder with value 0 inside the `refundMap`, causing any future `refund` allocated for that holder in a given week and for a given policy to be locked forever in the contract (unless the contract is upgraded).\\n```\\nfunction refund(\\n uint256 policyIndex\\_,\\n uint256 week\\_,\\n address who\\_\\n) external noReenter {\\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\\n\\n require(!coverage.refunded, \"Already refunded\");\\n\\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\\n coverage.amount).div(allCovered);\\n coverage.amount = coverage.amount.mul(\\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\\n coverage.refunded = true;\\n\\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\\n\\n if (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).refund(\\n policyIndex\\_,\\n week\\_,\\n who\\_,\\n amountToRefund\\n );\\n }\\n}\\n```\\nчThere should be a validation check at the beginning of the function that reverts if `refundMap[policyIndex_][week_] == 0`.чч```\\nfunction refund(\\n uint256 policyIndex\\_,\\n uint256 week\\_,\\n address who\\_\\n) external noReenter {\\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\\n\\n require(!coverage.refunded, \"Already refunded\");\\n\\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\\n coverage.amount).div(allCovered);\\n coverage.amount = coverage.amount.mul(\\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\\n coverage.refunded = true;\\n\\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\\n\\n if (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).refund(\\n policyIndex\\_,\\n week\\_,\\n who\\_,\\n amountToRefund\\n );\\n }\\n}\\n```\\n
addTidal, _updateUserTidal, withdrawTidal – wrong arithmetic calculationsчhighчTo further incentivize sellers, anyone – although it will usually be the pool manager – can send an arbitrary amount of the Tidal token to a pool, which is then supposed to be distributed proportionally among the share owners. There are several flaws in the calculations that implement this mechanism:\\nA. addTidal:\\n```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\\n```\\n\\nThis should be:\\n```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS).div(poolInfo.totalShare));\\n```\\n\\nNote the different parenthesization. Without SafeMath:\\n```\\npoolInfo.accTidalPerShare += amount\\_ \\* SHARE\\_UNITS / poolInfo.totalShare;\\n```\\n\\nB. _updateUserTidal:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.add(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nThis should be:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.mul(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nNote that `add` has been replaced with `mul`. Without SafeMath:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\\n```\\n\\nC. withdrawTidal:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.add(userInfo.share);\\n```\\n\\nAs in B, this should be:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.mul(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nNote that `add` has been replaced with `mul` and that a division by `SHARE_UNITS` has been appended. Without SafeMath:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\\n```\\n\\nAs an additional minor point, the division in `addTidal` will revert with a panic (0x12) if the number of shares in the pool is zero. This case could be handled more gracefully.чImplement the fixes described above. The versions without `SafeMath` are easier to read and should be preferred; see https://github.com/ConsensysDiligence/tidal-audit-2023-04/issues/20.чч```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\\n```\\n
claim – Incomplete and lenient implementationчhighчIn the current version of the code, the `claim` function is lacking crucial input validation logic as well as required state changes. Most of the process is implemented in other contracts or off-chain at the moment and is therefore out of scope for this audit, but there might still be issues caused by potential errors in the process. Moreover, pool manager and committee together have unlimited ownership of the deposits and can essentially withdraw all collateral to any desired address.\\n```\\nfunction claim(\\n uint256 policyIndex\\_,\\n uint256 amount\\_,\\n address receipient\\_\\n) external onlyPoolManager {\\n```\\nчTo ensure a more secure claiming process, we propose adding the following logic to the `claim` function:\\n`refund` should be called at the beginning of the `claim` flow, so that the recipient's true coverage amount will be used.\\n`policyIndex` should be added as a parameter to this function, so that `coverageMap` can be used to validate that the amount claimed on behalf of a recipient is covered.\\nThe payout amount should be subtracted in the `coveredMap` and `coverageMap` mappings.чч```\\nfunction claim(\\n uint256 policyIndex\\_,\\n uint256 amount\\_,\\n address receipient\\_\\n) external onlyPoolManager {\\n```\\n
buy – insurance buyers trying to increase their coverage amount will lose their previous coverageчhighчWhen a user is willing to `buy` insurance, he is required to specify the desired amount (denoted as amount_) and to pay the entire premium upfront. In return, he receives the ownership over an entry inside the `coverageMap` mapping. If a user calls the `buy` function more than once for the same policy and time frame, his entry in the `coverageMap` will not represent the accumulated amount that he paid for but only the last coverage amount, which means previous coverage will be lost forever (unless the contract is upgraded).\\n```\\nfor (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\\n incomeMap[policyIndex\\_][w] =\\n incomeMap[policyIndex\\_][w].add(premium);\\n coveredMap[policyIndex\\_][w] =\\n coveredMap[policyIndex\\_][w].add(amount\\_);\\n\\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\\n \"Not enough to buy\");\\n\\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\\n amount: amount\\_,\\n premium: premium,\\n refunded: false\\n });\\n}\\n```\\nчThe coverage entry that represents the user's coverage should not be overwritten but should hold the accumulated amount of coverage instead.чч```\\nfor (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\\n incomeMap[policyIndex\\_][w] =\\n incomeMap[policyIndex\\_][w].add(premium);\\n coveredMap[policyIndex\\_][w] =\\n coveredMap[policyIndex\\_][w].add(amount\\_);\\n\\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\\n \"Not enough to buy\");\\n\\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\\n amount: amount\\_,\\n premium: premium,\\n refunded: false\\n });\\n}\\n```\\n
Several issues related to upgradeability of contractsчmediumчWe did not find a proxy contract or factory in the repository, but the README contains the following information:\\ncode/README.md:L11\\n```\\nEvery Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin's Proxy Upgrade Pattern.\\n```\\n\\ncode/README.md:L56\\n```\\nAnd there will be multiple proxies and one implementation of the Pools, and one proxy and one implementation of EventAggregator.\\n```\\n\\nThere are several issues related to upgradeability or, generally, using the contracts as implementations for proxies. All recommendations in this report assume that it is not necessary to remain compatible with an existing deployment.\\nB. If upgradeability is supposed to work with inheritance, there should be dummy variables at the end of each contract in the inheritance hierarchy. Some of these have to be removed when “real” state variables are added. More precisely, it is conventional to use a fixed-size `uint256` array `__gap`, such that the consecutively occupied slots at the beginning (for the “real” state variables) add up to 50 with the size of the array. If state variables are added later, the gap's size has to be reduced accordingly to maintain this invariant. Currently, the contracts do not declare such a `__gap` variable.\\nC. Implementation contracts should not remain uninitalized. To prevent initialization by an attacker – which, in some cases, can have an impact on the proxy – the implementation contract's constructor should call `_disableInitializers`.чRefamiliarize yourself with the subtleties and pitfalls of upgradeable `contracts`, in particular regarding state variables and the storage gap. A lot of useful information can be found here.\\nOnly import from `contracts-upgradeable`, not from `contracts`.\\nAdd appropriately-sized storage gaps at least to `PoolModel`, `NonReentrancy`, and `EventAggregator`. (Note that adding a storage gap to `NonReentrancy` will break compatibility with existing deployments.) Ideally, add comments and warnings to each file that state variables may only be added at the end, that the storage gap's size has to be reduced accordingly, and that state variables must not be removed, rearranged, or in any way altered (e.g., type, `constant`, immutable). No state variables should ever be added to the `Pool` contract, and a comment should make that clear.\\nAdd a constructor to `Pool` and `EventAggregator` that calls `_disableInitializers`.чч```\\nEvery Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin's Proxy Upgrade Pattern.\\n```\\n
initialize – Committee members array can contain duplicatesчmediumчThe initial committee members are given as array argument to the pool's `initialize` function. When the array is processed, there is no check for duplicates, and duplicates may also end up in the storage array `committeeArray`.\\n```\\nfor (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\\n address member = committeeMembers\\_[i];\\n committeeArray.push(member);\\n committeeIndexPlusOne[member] = committeeArray.length;\\n}\\n```\\n\\nDuplicates will result in a discrepancy between the length of the array – which is later interpreted as the number of committee members – and the actual number of (different) committee members. This could lead to more problems, such as an insufficient committee size to reach the threshold.чThe `initialize` function should verify in the loop that `member` hasn't been added before. Note that `_executeAddToCommittee` refuses to add someone who is already in the committee, and the same technique can be employed here.чч```\\nfor (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\\n address member = committeeMembers\\_[i];\\n committeeArray.push(member);\\n committeeIndexPlusOne[member] = committeeArray.length;\\n}\\n```\\n
Pool.buy– Users may end up paying more than intended due to changes in policy.weeklyPremiumчmediumчThe price that an insurance buyer has to pay for insurance is determined by the duration of the coverage and the `weeklyPremium`. The price increases as the `weeklyPremium` increases. If a `buy` transaction is waiting in the mempool but eventually front-run by another transaction that increases `weeklyPremium`, the user will end up paying more than they anticipated for the same insurance coverage (assuming their allowance to the `Pool` contract is unlimited or at least higher than what they expected to pay).\\n```\\nuint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\\n```\\nчConsider adding a parameter for the maximum amount to pay, and make sure that the transaction will revert if `allPremium` is greater than this maximum value.чч```\\nuint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\\n```\\n
Missing validation checks in executeчmediumчThe `Pool` contract implements a threshold voting mechanism for some changes in the contract state, where either the pool manager or a committee member can propose a change by calling `claim`, `changePoolManager`, `addToCommittee`, `removeFromCommittee`, or `changeCommitteeThreshold`, and then the committee has a time period for voting. If the threshold is reached during this period, then anyone can call `execute` to `execute` the state change.\\nWhile some validation checks are implemented in the proposal phase, this is not enough to ensure that business logic rules around these changes are completely enforced.\\n`_executeRemoveFromCommittee` – While the `removeFromCommittee` function makes sure that `committeeArray.length > committeeThreshold`, i.e., that there should always be enough committee members to reach the threshold, the same validation check is not enforced in `_executeRemoveFromCommittee`. To better illustrate the issue, let's consider the following example: `committeeArray.length = 5`, `committeeThreshold = 4`, and now `removeFromCommittee` is called two times in a row, where the second call is made before the first call reaches the threshold. In this case, both requests will be executed successfully, and we end up with `committeeArray.length = 3` and `committeeThreshold = 4`, which is clearly not desired.\\n`_executeChangeCommitteeThreshold` – Applying the same concept here, this function lacks the validation check of `threshold_ <= committeeArray.length`, leading to the same issue as above. Let's consider the following example: `committeeArray.length = 3`, `committeeThreshold = 2`, and now changeCommitteeThresholdis called with `threshold_ = 3`, but before this request is executed, `removeFromCommittee` is called. After both requests have been executed successfully, we will end up with `committeeThreshold = 3` and `committeeArray.length = 2`, which is clearly not desired.\\n```\\nfunction \\_executeRemoveFromCommittee(address who\\_) private {\\n```\\n\\n```\\nfunction \\_executeChangeCommitteeThreshold(uint256 threshold\\_) private {\\n```\\nчApply the same validation checks in the functions that execute the state change.чч```\\nfunction \\_executeRemoveFromCommittee(address who\\_) private {\\n```\\n
Hard-coded minimum deposit amountчlowчResolution\\nFixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor's recommendation.\\nThe `deposit` function specifies a minimum amount of 1e12 units of the base token for a deposit:\\n```\\nuint256 constant AMOUNT\\_PER\\_SHARE = 1e18;\\n```\\n\\n```\\n// Anyone can be a seller, and deposit baseToken (e.g. USDC or WETH)\\n// to the pool.\\nfunction deposit(\\n uint256 amount\\_\\n) external noReenter {\\n require(enabled, \"Not enabled\");\\n\\n require(amount\\_ >= AMOUNT\\_PER\\_SHARE / 1000000, \"Less than minimum\");\\n```\\n\\nWhether that's an appropriate minimum amount or not depends on the base token. Note that the two example tokens listed above are USDC and WETH. With current ETH prices, 1e12 Wei cost an affordable 0.2 US Cent. USDC, on the other hand, has 6 decimals, so 1e12 units are worth 1 million USD, which is … steep.чThe minimum deposit amount should be configurable.чч```\\nuint256 constant AMOUNT\\_PER\\_SHARE = 1e18;\\n```\\n
Outdated Solidity versionчlowчThe source files' version pragmas either specify that they need compiler version exactly 0.8.10 or at least 0.8.10:\\n```\\npragma solidity 0.8.10;\\n```\\n\\n```\\npragma solidity ^0.8.10;\\n```\\n\\nSolidity v0.8.10 is a fairly dated version that has known security issues. We generally recommend using the latest version of the compiler (at the time of writing, this is v0.8.20), and we also discourage the use of floating pragmas to make sure that the source files are actually compiled and deployed with the same compiler version they have been tested with.чResolution\\nFixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor's recommendation.\\nUse the Solidity compiler v0.8.20, and change the version pragma in all Solidity source files to `pragma solidity 0.8.20;`.чч```\\npragma solidity 0.8.10;\\n```\\n
Code used for testing purposes should be removed before deploymentчlowчVariables and logic have been added to the code whose only purpose is to make it easier to test. This might cause unexpected behavior if deployed in production. For instance, `onlyTest` and `setTimeExtra` should be removed from the code before deployment, as well as `timeExtra` in `getCurrentWeek` and `getNow`.\\n```\\nmodifier onlyTest() {\\n```\\n\\n```\\nfunction setTimeExtra(uint256 timeExtra\\_) external onlyTest {\\n```\\n\\n```\\nfunction getCurrentWeek() public view returns(uint256) {\\n return (block.timestamp + TIME\\_OFFSET + timeExtra) / (7 days);\\n}\\n```\\n\\n```\\nfunction getNow() public view returns(uint256) {\\n return block.timestamp + timeExtra;\\n}\\n```\\nчFor the long term, consider mimicking this behavior by using features offered by your testing framework.чч```\\nmodifier onlyTest() {\\n```\\n
Missing eventsчlowчSome state-changing functions do not emit an event at all or omit relevant information.\\nA. `Pool.setEventAggregator` should emit an event with the value of `eventAggregator_` so that off-chain services will be notified and can automatically adjust.\\n```\\nfunction setEventAggregator(address eventAggregator\\_) external onlyPoolManager {\\n eventAggregator = eventAggregator\\_;\\n}\\n```\\n\\nB. `Pool.enablePool` should emit an event when the pool is dis- or enabled.\\n```\\nfunction enablePool(bool enabled\\_) external onlyPoolManager {\\n enabled = enabled\\_;\\n}\\n```\\n\\nC. `Pool.execute` only logs the `requestIndex_` while it should also include the `operation` and `data` to better reflect the state change in the transaction.\\n```\\nif (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).execute(\\n requestIndex\\_\\n );\\n}\\n```\\nчState-changing functions should emit an event to have an audit trail and enable monitoring of smart contract usage.чч```\\nfunction setEventAggregator(address eventAggregator\\_) external onlyPoolManager {\\n eventAggregator = eventAggregator\\_;\\n}\\n```\\n
addPremium – A Back Runner May Cause an Insurance Holder to Lose Their Refunds by Calling addPremium Right After the Original Callчhighч`addPremium` is a public function that can be called by anyone and that distributes the weekly premium payments to the pool manager and the rest of the pool share holders. If the collateral deposited is not enough to cover the total coverage offered to insurance holders for a given week, refunds are allocated pro rata for all insurance holders of that particular week and policy. However, in the current implementation, attackers can call `addPremium` right after the original call to `addPremium` but before the call to refund; this will cause the insurance holders to lose their refunds, which will be effectively locked forever in the contract (unless the contract is upgraded).\\n```\\nrefundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\\n allCovered.sub(maximumToCover)).div(allCovered);\\n```\\nч`addPremium` should contain a validation check in the beginning of the function that reverts for the case of `incomeMap[policyIndex_][week] = 0`.чч```\\nrefundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\\n allCovered.sub(maximumToCover)).div(allCovered);\\n```\\n
refund – Attacker Can Lock Insurance Holder's Refunds by Calling refund Before a Refund Was Allocatedчhighч`addPremium` is used to determine the `refund` amount that an insurance holder is eligible to claim. The amount is stored in the `refundMap` mapping and can then later be claimed by anyone on behalf of an insurance holder by calling `refund`. The `refund` function can't be called more than once for a given combination of `policyIndex_`, `week_`, and `who_`, as it would revert with an “Already refunded” error. This gives an attacker the opportunity to call `refund` on behalf of any insurance holder with value 0 inside the `refundMap`, causing any future `refund` allocated for that holder in a given week and for a given policy to be locked forever in the contract (unless the contract is upgraded).\\n```\\nfunction refund(\\n uint256 policyIndex\\_,\\n uint256 week\\_,\\n address who\\_\\n) external noReenter {\\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\\n\\n require(!coverage.refunded, \"Already refunded\");\\n\\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\\n coverage.amount).div(allCovered);\\n coverage.amount = coverage.amount.mul(\\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\\n coverage.refunded = true;\\n\\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\\n\\n if (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).refund(\\n policyIndex\\_,\\n week\\_,\\n who\\_,\\n amountToRefund\\n );\\n }\\n}\\n```\\nчThere should be a validation check at the beginning of the function that reverts if `refundMap[policyIndex_][week_] == 0`.чч```\\nfunction refund(\\n uint256 policyIndex\\_,\\n uint256 week\\_,\\n address who\\_\\n) external noReenter {\\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\\n\\n require(!coverage.refunded, \"Already refunded\");\\n\\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\\n coverage.amount).div(allCovered);\\n coverage.amount = coverage.amount.mul(\\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\\n coverage.refunded = true;\\n\\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\\n\\n if (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).refund(\\n policyIndex\\_,\\n week\\_,\\n who\\_,\\n amountToRefund\\n );\\n }\\n}\\n```\\n
addTidal, _updateUserTidal, withdrawTidal – Wrong Arithmetic CalculationsчhighчTo further incentivize sellers, anyone – although it will usually be the pool manager – can send an arbitrary amount of the Tidal token to a pool, which is then supposed to be distributed proportionally among the share owners. There are several flaws in the calculations that implement this mechanism:\\nA. addTidal:\\n```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\\n```\\n\\nThis should be:\\n```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS).div(poolInfo.totalShare));\\n```\\n\\nNote the different parenthesization. Without SafeMath:\\n```\\npoolInfo.accTidalPerShare += amount\\_ \\* SHARE\\_UNITS / poolInfo.totalShare;\\n```\\n\\nB. _updateUserTidal:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.add(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nThis should be:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.mul(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nNote that `add` has been replaced with `mul`. Without SafeMath:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\\n```\\n\\nC. withdrawTidal:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.add(userInfo.share);\\n```\\n\\nAs in B, this should be:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare.mul(\\n userInfo.share).div(SHARE\\_UNITS);\\n```\\n\\nNote that `add` has been replaced with `mul` and that a division by `SHARE_UNITS` has been appended. Without SafeMath:\\n```\\nuint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\\n```\\n\\nAs an additional minor point, the division in `addTidal` will revert with a panic (0x12) if the number of shares in the pool is zero. This case could be handled more gracefully.чImplement the fixes described above. The versions without `SafeMath` are easier to read and should be preferred; see issue 3.13.чч```\\npoolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\\n```\\n
claim – Incomplete and Lenient ImplementationчhighчIn the current version of the code, the `claim` function is lacking crucial input validation logic as well as required state changes. Most of the process is implemented in other contracts or off-chain at the moment and is therefore out of scope for this audit, but there might still be issues caused by potential errors in the process. Moreover, pool manager and committee together have unlimited ownership of the deposits and can essentially withdraw all collateral to any desired address.\\n```\\nfunction claim(\\n uint256 policyIndex\\_,\\n uint256 amount\\_,\\n address receipient\\_\\n) external onlyPoolManager {\\n```\\nчTo ensure a more secure claiming process, we propose adding the following logic to the `claim` function:\\n`refund` should be called at the beginning of the `claim` flow, so that the recipient's true coverage amount will be used.\\n`policyIndex` should be added as a parameter to this function, so that `coverageMap` can be used to validate that the amount claimed on behalf of a recipient is covered.\\nThe payout amount should be subtracted in the `coveredMap` and `coverageMap` mappings.чч```\\nfunction claim(\\n uint256 policyIndex\\_,\\n uint256 amount\\_,\\n address receipient\\_\\n) external onlyPoolManager {\\n```\\n
buy – Insurance Buyers Trying to Increase Their Coverage Amount Will Lose Their Previous CoverageчhighчWhen a user is willing to `buy` insurance, he is required to specify the desired amount (denoted as amount_) and to pay the entire premium upfront. In return, he receives the ownership over an entry inside the `coverageMap` mapping. If a user calls the `buy` function more than once for the same policy and time frame, his entry in the `coverageMap` will not represent the accumulated amount that he paid for but only the last coverage amount, which means previous coverage will be lost forever (unless the contract is upgraded).\\n```\\nfor (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\\n incomeMap[policyIndex\\_][w] =\\n incomeMap[policyIndex\\_][w].add(premium);\\n coveredMap[policyIndex\\_][w] =\\n coveredMap[policyIndex\\_][w].add(amount\\_);\\n\\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\\n \"Not enough to buy\");\\n\\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\\n amount: amount\\_,\\n premium: premium,\\n refunded: false\\n });\\n}\\n```\\nчThe coverage entry that represents the user's coverage should not be overwritten but should hold the accumulated amount of coverage instead.чч```\\nfor (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\\n incomeMap[policyIndex\\_][w] =\\n incomeMap[policyIndex\\_][w].add(premium);\\n coveredMap[policyIndex\\_][w] =\\n coveredMap[policyIndex\\_][w].add(amount\\_);\\n\\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\\n \"Not enough to buy\");\\n\\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\\n amount: amount\\_,\\n premium: premium,\\n refunded: false\\n });\\n}\\n```\\n
Several Issues Related to Upgradeability of ContractsчmediumчWe did not find a proxy contract or factory in the repository, but the README contains the following information:\\nREADME.md:L11\\n```\\nEvery Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin's Proxy Upgrade Pattern.\\n```\\n\\nREADME.md:L56\\n```\\nAnd there will be multiple proxies and one implementation of the Pools, and one proxy and one implementation of EventAggregator.\\n```\\n\\nThere are several issues related to upgradeability or, generally, using the contracts as implementations for proxies. All recommendations in this report assume that it is not necessary to remain compatible with an existing deployment.\\nB. If upgradeability is supposed to work with inheritance, there should be dummy variables at the end of each contract in the inheritance hierarchy. Some of these have to be removed when “real” state variables are added. More precisely, it is conventional to use a fixed-size `uint256` array `__gap`, such that the consecutively occupied slots at the beginning (for the “real” state variables) add up to 50 with the size of the array. If state variables are added later, the gap's size has to be reduced accordingly to maintain this invariant. Currently, the contracts do not declare such a `__gap` variable.\\nC. Implementation contracts should not remain uninitalized. To prevent initialization by an attacker – which, in some cases, can have an impact on the proxy – the implementation contract's constructor should call `_disableInitializers`.чRefamiliarize yourself with the subtleties and pitfalls of upgradeable `contracts`, in particular regarding state variables and the storage gap. A lot of useful information can be found here.\\nOnly import from `contracts-upgradeable`, not from `contracts`.\\nAdd appropriately-sized storage gaps at least to `PoolModel`, `NonReentrancy`, and `EventAggregator`. (Note that adding a storage gap to `NonReentrancy` will break compatibility with existing deployments.) Ideally, add comments and warnings to each file that state variables may only be added at the end, that the storage gap's size has to be reduced accordingly, and that state variables must not be removed, rearranged, or in any way altered (e.g., type, `constant`, immutable). No state variables should ever be added to the `Pool` contract, and a comment should make that clear.\\nAdd a constructor to `Pool` and `EventAggregator` that calls `_disableInitializers`.чч```\\nEvery Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin's Proxy Upgrade Pattern.\\n```\\n
initialize – Committee Members Array Can Contain DuplicatesчmediumчThe initial committee members are given as array argument to the pool's `initialize` function. When the array is processed, there is no check for duplicates, and duplicates may also end up in the storage array `committeeArray`.\\n```\\nfor (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\\n address member = committeeMembers\\_[i];\\n committeeArray.push(member);\\n committeeIndexPlusOne[member] = committeeArray.length;\\n}\\n```\\n\\nDuplicates will result in a discrepancy between the length of the array – which is later interpreted as the number of committee members – and the actual number of (different) committee members. This could lead to more problems, such as an insufficient committee size to reach the threshold.чThe `initialize` function should verify in the loop that `member` hasn't been added before. Note that `_executeAddToCommittee` refuses to add someone who is already in the committee, and the same technique can be employed here.чч```\\nfor (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\\n address member = committeeMembers\\_[i];\\n committeeArray.push(member);\\n committeeIndexPlusOne[member] = committeeArray.length;\\n}\\n```\\n
Pool.buy– Users May End Up Paying More Than Intended Due to Changes in policy.weeklyPremiumчmediumчThe price that an insurance buyer has to pay for insurance is determined by the duration of the coverage and the `weeklyPremium`. The price increases as the `weeklyPremium` increases. If a `buy` transaction is waiting in the mempool but eventually front-run by another transaction that increases `weeklyPremium`, the user will end up paying more than they anticipated for the same insurance coverage (assuming their allowance to the `Pool` contract is unlimited or at least higher than what they expected to pay).\\n```\\nuint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\\n```\\nчConsider adding a parameter for the maximum amount to pay, and make sure that the transaction will revert if `allPremium` is greater than this maximum value.чч```\\nuint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\\n```\\n
Missing Validation Checks in executeчmediumчThe `Pool` contract implements a threshold voting mechanism for some changes in the contract state, where either the pool manager or a committee member can propose a change by calling `claim`, `changePoolManager`, `addToCommittee`, `removeFromCommittee`, or `changeCommitteeThreshold`, and then the committee has a time period for voting. If the threshold is reached during this period, then anyone can call `execute` to `execute` the state change.\\nWhile some validation checks are implemented in the proposal phase, this is not enough to ensure that business logic rules around these changes are completely enforced.\\n`_executeRemoveFromCommittee` – While the `removeFromCommittee` function makes sure that `committeeArray.length > committeeThreshold`, i.e., that there should always be enough committee members to reach the threshold, the same validation check is not enforced in `_executeRemoveFromCommittee`. To better illustrate the issue, let's consider the following example: `committeeArray.length = 5`, `committeeThreshold = 4`, and now `removeFromCommittee` is called two times in a row, where the second call is made before the first call reaches the threshold. In this case, both requests will be executed successfully, and we end up with `committeeArray.length = 3` and `committeeThreshold = 4`, which is clearly not desired.\\n`_executeChangeCommitteeThreshold` – Applying the same concept here, this function lacks the validation check of `threshold_ <= committeeArray.length`, leading to the same issue as above. Let's consider the following example: `committeeArray.length = 3`, `committeeThreshold = 2`, and now changeCommitteeThresholdis called with `threshold_ = 3`, but before this request is executed, `removeFromCommittee` is called. After both requests have been executed successfully, we will end up with `committeeThreshold = 3` and `committeeArray.length = 2`, which is clearly not desired.\\n```\\nfunction \\_executeRemoveFromCommittee(address who\\_) private {\\n```\\n\\n```\\nfunction \\_executeChangeCommitteeThreshold(uint256 threshold\\_) private {\\n```\\nчApply the same validation checks in the functions that execute the state change.чч```\\nfunction \\_executeRemoveFromCommittee(address who\\_) private {\\n```\\n
Hard-Coded Minimum Deposit AmountчlowчResolution\\nFixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor's recommendation.\\nThe `deposit` function specifies a minimum amount of 1e12 units of the base token for a deposit:\\n```\\nuint256 constant AMOUNT\\_PER\\_SHARE = 1e18;\\n```\\n\\n```\\n// Anyone can be a seller, and deposit baseToken (e.g. USDC or WETH)\\n// to the pool.\\nfunction deposit(\\n uint256 amount\\_\\n) external noReenter {\\n require(enabled, \"Not enabled\");\\n\\n require(amount\\_ >= AMOUNT\\_PER\\_SHARE / 1000000, \"Less than minimum\");\\n```\\n\\nWhether that's an appropriate minimum amount or not depends on the base token. Note that the two example tokens listed above are USDC and WETH. With current ETH prices, 1e12 Wei cost an affordable 0.2 US Cent. USDC, on the other hand, has 6 decimals, so 1e12 units are worth 1 million USD, which is … steep.чThe minimum deposit amount should be configurable.чч```\\nuint256 constant AMOUNT\\_PER\\_SHARE = 1e18;\\n```\\n
Outdated Solidity VersionчlowчThe source files' version pragmas either specify that they need compiler version exactly 0.8.10 or at least 0.8.10:\\n```\\npragma solidity 0.8.10;\\n```\\n\\n```\\npragma solidity ^0.8.10;\\n```\\n\\nSolidity v0.8.10 is a fairly dated version that has known security issues. We generally recommend using the latest version of the compiler (at the time of writing, this is v0.8.20), and we also discourage the use of floating pragmas to make sure that the source files are actually compiled and deployed with the same compiler version they have been tested with.чResolution\\nFixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor's recommendation.\\nUse the Solidity compiler v0.8.20, and change the version pragma in all Solidity source files to `pragma solidity 0.8.20;`.чч```\\npragma solidity 0.8.10;\\n```\\n
Code Used for Testing Purposes Should Be Removed Before DeploymentчlowчVariables and logic have been added to the code whose only purpose is to make it easier to test. This might cause unexpected behavior if deployed in production. For instance, `onlyTest` and `setTimeExtra` should be removed from the code before deployment, as well as `timeExtra` in `getCurrentWeek` and `getNow`.\\n```\\nmodifier onlyTest() {\\n```\\n\\n```\\nfunction setTimeExtra(uint256 timeExtra\\_) external onlyTest {\\n```\\n\\n```\\nfunction getCurrentWeek() public view returns(uint256) {\\n return (block.timestamp + TIME\\_OFFSET + timeExtra) / (7 days);\\n}\\n```\\n\\n```\\nfunction getNow() public view returns(uint256) {\\n return block.timestamp + timeExtra;\\n}\\n```\\nчFor the long term, consider mimicking this behavior by using features offered by your testing framework.чч```\\nmodifier onlyTest() {\\n```\\n
Missing EventsчlowчSome state-changing functions do not emit an event at all or omit relevant information.\\nA. `Pool.setEventAggregator` should emit an event with the value of `eventAggregator_` so that off-chain services will be notified and can automatically adjust.\\n```\\nfunction setEventAggregator(address eventAggregator\\_) external onlyPoolManager {\\n eventAggregator = eventAggregator\\_;\\n}\\n```\\n\\nB. `Pool.enablePool` should emit an event when the pool is dis- or enabled.\\n```\\nfunction enablePool(bool enabled\\_) external onlyPoolManager {\\n enabled = enabled\\_;\\n}\\n```\\n\\nC. `Pool.execute` only logs the `requestIndex_` while it should also include the `operation` and `data` to better reflect the state change in the transaction.\\n```\\nif (eventAggregator != address(0)) {\\n IEventAggregator(eventAggregator).execute(\\n requestIndex\\_\\n );\\n}\\n```\\nчState-changing functions should emit an event to have an audit trail and enable monitoring of smart contract usage.чч```\\nfunction setEventAggregator(address eventAggregator\\_) external onlyPoolManager {\\n eventAggregator = eventAggregator\\_;\\n}\\n```\\n
InfinityPool contract authorization bypass attackчhighчAn attacker could create their own credential and set the `Agent` ID to `0`, which would bypass the `subjectIsAgentCaller` modifier. The attacker could use this attack to `borrow` funds from the pool, draining any available liquidity. For example, only an `Agent` should be able to `borrow` funds from the pool and call the `borrow` function:\\n```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n\\nThe following modifier checks that the caller is an Agent:\\n```\\nmodifier subjectIsAgentCaller(VerifiableCredential memory vc) {\\n if (\\n GetRoute.agentFactory(router).agents(msg.sender) != vc.subject\\n ) revert Unauthorized();\\n \\_;\\n}\\n```\\n\\nBut if the caller is not an `Agent`, the `GetRoute.agentFactory(router).agents(msg.sender)` will return `0`. And if the `vc.subject` is also zero, the check will be successful with any `msg.sender`. The attacker can also pass an arbitrary `vc.value` as the parameter and steal all the funds from the pool.чEnsure only an `Agent` can call `borrow` and pass the `subjectIsAgentCaller` modifier.чч```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n
Wrong accounting for totalBorrowed in the InfinityPool.writeOff functionчhighчHere is a part of the `InfinityPool.writeOff` function:\\n```\\n// transfer the assets into the pool\\n// whatever we couldn't pay back\\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\\n\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n```\\n\\nThe `totalBorrowed` is decreased by the `lostAmt` value. Instead, it should be decreased by the original `account.principal` value to acknowledge the loss.чResolution\\nFixed.чч```\\n// transfer the assets into the pool\\n// whatever we couldn't pay back\\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\\n\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n```\\n
The beneficiaryWithdrawable function can be called by anyoneчhighчThe `beneficiaryWithdrawable` function is supposed to be called by the Agent when a beneficiary is trying to withdraw funds:\\n```\\nfunction beneficiaryWithdrawable(\\n address recipient,\\n address sender,\\n uint256 agentID,\\n uint256 proposedAmount\\n) external returns (\\n uint256 amount\\n) {\\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\\n address benneficiaryAddress = beneficiary.active.beneficiary;\\n // If the sender is not the owner of the Agent or the beneficiary, revert\\n if(\\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\\n revert Unauthorized();\\n }\\n (\\n beneficiary,\\n amount\\n ) = beneficiary.withdraw(proposedAmount);\\n // update the beneficiary in storage\\n \\_agentBeneficiaries[agentID] = beneficiary;\\n}\\n```\\n\\nThis function reduces the quota that is supposed to be transferred during the `withdraw` call:\\n```\\n sendAmount = agentPolice.beneficiaryWithdrawable(receiver, msg.sender, id, sendAmount);\\n}\\nelse if (msg.sender != owner()) {\\n revert Unauthorized();\\n}\\n\\n// unwrap any wfil needed to withdraw\\n\\_poolFundsInFIL(sendAmount);\\n// transfer funds\\npayable(receiver).sendValue(sendAmount);\\n```\\n\\nThe issue is that anyone can call this function directly, and the quota will be reduced without funds being transferred.чEnsure only the Agent can call this function.чч```\\nfunction beneficiaryWithdrawable(\\n address recipient,\\n address sender,\\n uint256 agentID,\\n uint256 proposedAmount\\n) external returns (\\n uint256 amount\\n) {\\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\\n address benneficiaryAddress = beneficiary.active.beneficiary;\\n // If the sender is not the owner of the Agent or the beneficiary, revert\\n if(\\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\\n revert Unauthorized();\\n }\\n (\\n beneficiary,\\n amount\\n ) = beneficiary.withdraw(proposedAmount);\\n // update the beneficiary in storage\\n \\_agentBeneficiaries[agentID] = beneficiary;\\n}\\n```\\n
An Agent can borrow even with existing debt in interest paymentsчmediumчTo `borrow` funds, an `Agent` has to call the `borrow` function of the pool:\\n```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n\\nLet's assume that the `Agent` already had some funds borrowed. During this function execution, the current debt status is not checked. The principal debt increases after borrowing, but `account.epochsPaid` remains the same. So the pending debt will instantly increase as if the borrowing happened on `account.epochsPaid`.чEnsure the debt is paid when borrowing more funds.чч```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n
The AgentPolice.distributeLiquidatedFunds() function can have undistributed residual fundsчmediumчWhen an Agent is liquidated, the liquidator (owner of the protocol) is supposed to try to redeem as many funds as possible and re-distribute them to the pools:\\n```\\nfunction distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\\n if (!liquidated[agentID]) revert Unauthorized();\\n\\n // transfer the assets into the pool\\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\\n \\_writeOffPools(agentID, amount);\\n}\\n```\\n\\nThe problem is that in the pool, it's accounted that the amount of funds can be larger than the debt. In that case, the pool won't transfer more funds than the pool needs:\\n```\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n\\nemit WriteOff(agentID, recoveredFunds, lostAmt, interestPaid);\\n```\\n\\nIf that happens, the remaining funds will be stuck in the `AgentPolice` contract.чReturn the residual funds to the Agent's owner or process them in some way so they are not lost.чч```\\nfunction distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\\n if (!liquidated[agentID]) revert Unauthorized();\\n\\n // transfer the assets into the pool\\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\\n \\_writeOffPools(agentID, amount);\\n}\\n```\\n
An Agent can be upgraded even if there is no new implementationчmediumчAgents can be upgraded to a new implementation, and only the Agent's owner can call the upgrade function:\\n```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n\\nThe issue is that the owner can trigger the upgrade even if no new implementation exists. Multiple possible problems derive from it.\\nUpgrading to the current implementation of the Agent will break the logic because the current version is not calling the `migrateMiner` function, so all the miners will stay with the old Agent, and their funds will be lost.\\nThe owner can accidentally trigger multiple upgrades simultaneously, leading to a loss of funds (https://github.com/ConsenSysDiligence/glif-audit-2023-04/issues/2).\\nThe owner also has no control over the new version of the Agent. To increase decentralization, it's better to pass the deployer's address as a parameter additionally.чEnsure the upgrades can only happen when there is a new version of an Agent, and the owner controls this version.чч```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n
Potential re-entrancy issues when upgrading the contractsчlowчThe protocol doesn't have any built-in re-entrancy protection mechanisms. That mainly explains by using the `wFIL` token, which is not supposed to give that opportunity. And also by carefully using `FIL` transfers.\\nHowever, there are some places in the code where things may go wrong in the future. For example, when upgrading an Agent:\\n```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n\\nHere, we see the `oldAgent.decommissionAgent(newAgent);` call happens before the `oldAgent` is deleted. Inside this function, we see:\\n```\\nfunction decommissionAgent(address \\_newAgent) external {\\n // only the agent factory can decommission an agent\\n AuthController.onlyAgentFactory(router, msg.sender);\\n // if the newAgent has a mismatching ID, revert\\n if(IAgent(\\_newAgent).id() != id) revert Unauthorized();\\n // set the newAgent in storage, which marks the upgrade process as starting\\n newAgent = \\_newAgent;\\n uint256 \\_liquidAssets = liquidAssets();\\n // Withdraw all liquid funds from the Agent to the newAgent\\n \\_poolFundsInFIL(\\_liquidAssets);\\n // transfer funds to new agent\\n payable(\\_newAgent).sendValue(\\_liquidAssets);\\n}\\n```\\n\\nHere, the FIL is transferred to a new contract which is currently unimplemented and unknown. Potentially, the fallback function of this contract could trigger a re-entrancy attack. If that's the case, during the execution of this function, there will be two contracts that are active agents with the same ID, and the attacker can try to use that maliciously.чBe very cautious with further implementations of agents and pools. Also, consider using reentrancy protection in public functions.чч```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n
InfinityPool is subject to a donation with inflation attack if emtied.чlowчSince `InfinityPool` is an implementation of the ERC4626 vault, it is too susceptible to inflation attacks. An attacker could front-run the first deposit and inflate the share price to an extent where the following deposit will be less than the value of 1 wei of share resulting in 0 shares minted. The attacker could conduct the inflation by means of self-destructing of another contract. In the case of GLIF this attack is less likely on the first pool since GLIF team accepts predeposits so some amount of shares was already minted. We do suggest fixing this issue before the next pool is deployed and no pre-stake is generated.\\n```\\n/\\*//////////////////////////////////////////////////////////////\\n 4626 LOGIC\\n//////////////////////////////////////////////////////////////\\*/\\n\\n/\\*\\*\\n \\* @dev Converts `assets` to shares\\n \\* @param assets The amount of assets to convert\\n \\* @return shares - The amount of shares converted from assets\\n \\*/\\nfunction convertToShares(uint256 assets) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? assets : assets \\* supply / totalAssets();\\n}\\n\\n/\\*\\*\\n \\* @dev Converts `shares` to assets\\n \\* @param shares The amount of shares to convert\\n \\* @return assets - The amount of assets converted from shares\\n \\*/\\nfunction convertToAssets(uint256 shares) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? shares : shares \\* totalAssets() / supply;\\n}\\n```\\nчSince the pool does not need to accept donations, the easiest way to handle this case is to use virtual price, where the balance of the contract is duplicated in a separate variable.чч```\\n/\\*//////////////////////////////////////////////////////////////\\n 4626 LOGIC\\n//////////////////////////////////////////////////////////////\\*/\\n\\n/\\*\\*\\n \\* @dev Converts `assets` to shares\\n \\* @param assets The amount of assets to convert\\n \\* @return shares - The amount of shares converted from assets\\n \\*/\\nfunction convertToShares(uint256 assets) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? assets : assets \\* supply / totalAssets();\\n}\\n\\n/\\*\\*\\n \\* @dev Converts `shares` to assets\\n \\* @param shares The amount of shares to convert\\n \\* @return assets - The amount of assets converted from shares\\n \\*/\\nfunction convertToAssets(uint256 shares) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? shares : shares \\* totalAssets() / supply;\\n}\\n```\\n
MaxWithdraw should potentially account for the funds available in the ramp.чlowчSince `InfinityPool` is ERC4626 it should also support the `MaxWithdraw` method. According to the EIP it should include any withdrawal limitation that the participant could encounter. At the moment the `MaxWithdraw` function returns the maximum amount of IOU tokens rather than WFIL. Since IOU token is not the `asset` token of the vault, this behavior is not ideal.\\n```\\nfunction maxWithdraw(address owner) public view returns (uint256) {\\n return convertToAssets(liquidStakingToken.balanceOf(owner));\\n}\\n```\\nчWe suggest considering returning the maximum amount of WFIL withdrawal which should account for Ramp balance.чч```\\nfunction maxWithdraw(address owner) public view returns (uint256) {\\n return convertToAssets(liquidStakingToken.balanceOf(owner));\\n}\\n```\\n
The upgradeability of MinerRegistry, AgentPolice, and Agent is overcomplicated and has a hight chance of errors.  AcknowledgedчlowчDuring the engagement, we have identified a few places that signify that the `Agent`, `MinerRegistry` and `AgentPolice` can be upgraded, for example:\\nAbility to migrate the miner from one version of the Agent to another inside the `migrateMiner`.\\nAbility to `refreshRoutes` that would update the `AgentPolice` and `MinerRegistry` addresses for a given Agent.\\nAbility to `decommission` pool. We believe that this functionality is present it is not very well thought through. For example, both `MinerRegistry` and `AgentPolice` are not upgradable but have mappings inside of them.\\n```\\nmapping(uint256 => bool) public liquidated;\\n\\n/// @notice `\\_poolIDs` maps agentID to the pools they have actively borrowed from\\nmapping(uint256 => uint256[]) private \\_poolIDs;\\n\\n/// @notice `\\_credentialUseBlock` maps signature bytes to when a credential was used\\nmapping(bytes32 => uint256) private \\_credentialUseBlock;\\n\\n/// @notice `\\_agentBeneficiaries` maps an Agent ID to its Beneficiary struct\\nmapping(uint256 => AgentBeneficiary) private \\_agentBeneficiaries;\\n```\\n\\n```\\nmapping(bytes32 => bool) private \\_minerRegistered;\\n\\nmapping(uint256 => uint64[]) private \\_minersByAgent;\\n```\\n\\nThat means that any time these contracts would need to be upgraded, the contents of those mappings will need to be somehow recreated in the new contract. That is not trivial since it is not easy to obtain all values of a mapping. This will also require an additional protocol-controlled setter ala kickstart mapping functions that are not ideal.\\nIn the case of `Agent` if the contract was upgradable there would be no need for a process of migrating miners that can be tedious and opens possibilities for errors. Since protocol has a lot of centralization and trust assumptions already, having upgradability will not contribute to it a lot.\\nWe also believe that during the upgrade of the pool, the PoolToken will stay the same in the new pool. That means that the minting and burning permissions of the share tokens have to be carefully updated or checked in a manner that does not require the address of the pool to be constant. Since we did not have access to this file, we can not check if that is done correctly.чConsider using upgradable contracts or have a solid upgrade plan that is well-tested before an emergency situation occurs.чч```\\nmapping(uint256 => bool) public liquidated;\\n\\n/// @notice `\\_poolIDs` maps agentID to the pools they have actively borrowed from\\nmapping(uint256 => uint256[]) private \\_poolIDs;\\n\\n/// @notice `\\_credentialUseBlock` maps signature bytes to when a credential was used\\nmapping(bytes32 => uint256) private \\_credentialUseBlock;\\n\\n/// @notice `\\_agentBeneficiaries` maps an Agent ID to its Beneficiary struct\\nmapping(uint256 => AgentBeneficiary) private \\_agentBeneficiaries;\\n```\\n
Mint function in the Infinity pool will emit the incorrect value.чlowчIn the `InifinityPool` file the `mint` function recomputes the amount of the assets before emitting the event. While this is fine in a lot of cases, that will not always be true. The result of `previewMint` and `convertToAssets` will only be equal while the `totalAssets` and `totalSupply` are equal. For example, this assumption will break after the first liquidation.\\n```\\nfunction mint(uint256 shares, address receiver) public isOpen returns (uint256 assets) {\\n if(shares == 0) revert InvalidParams();\\n // These transfers need to happen before the mint, and this is forcing a higher degree of coupling than is ideal\\n assets = previewMint(shares);\\n asset.transferFrom(msg.sender, address(this), assets);\\n liquidStakingToken.mint(receiver, shares);\\n assets = convertToAssets(shares);\\n emit Deposit(msg.sender, receiver, assets, shares);\\n}\\n```\\nчUse the `assets` value computed by the `previewMint` when emitting the event.чч```\\nfunction mint(uint256 shares, address receiver) public isOpen returns (uint256 assets) {\\n if(shares == 0) revert InvalidParams();\\n // These transfers need to happen before the mint, and this is forcing a higher degree of coupling than is ideal\\n assets = previewMint(shares);\\n asset.transferFrom(msg.sender, address(this), assets);\\n liquidStakingToken.mint(receiver, shares);\\n assets = convertToAssets(shares);\\n emit Deposit(msg.sender, receiver, assets, shares);\\n}\\n```\\n
Potential overpayment due to rounding imprecision  Won't FixчlowчInside the `InifintyPool` the `pay` function might accept unaccounted files. Imagine a situation where an Agent is trying to repay only the fees portion of the debt. In that case, the following branch will be executed:\\n```\\nif (vc.value <= interestOwed) {\\n // compute the amount of epochs this payment covers\\n // vc.value is not WAD yet, so divWadDown cancels the extra WAD in interestPerEpoch\\n uint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n // update the account's `epochsPaid` cursor\\n account.epochsPaid += epochsForward;\\n // since the entire payment is interest, the entire payment is used to compute the fee (principal payments are fee-free)\\n feeBasis = vc.value;\\n} else {\\n```\\n\\nThe issue is if the `value` does not divide by the `interestPerEpoch` exactly, any remainder will remain in the InfinityPool.\\n```\\nuint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n```\\nчSince the remainder will most likely not be too large this is not critical, but ideally, those remaining funds would be included in the `refund` variable.чч```\\nif (vc.value <= interestOwed) {\\n // compute the amount of epochs this payment covers\\n // vc.value is not WAD yet, so divWadDown cancels the extra WAD in interestPerEpoch\\n uint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n // update the account's `epochsPaid` cursor\\n account.epochsPaid += epochsForward;\\n // since the entire payment is interest, the entire payment is used to compute the fee (principal payments are fee-free)\\n feeBasis = vc.value;\\n} else {\\n```\\n
jumpStartAccount should be subject to the same approval checks as regular borrow.чlowч`InfinityPool` contract has the ability to kick start an account that will have a debt position in this pool.\\n```\\nfunction jumpStartAccount(address receiver, uint256 agentID, uint256 accountPrincipal) external onlyOwner {\\n Account memory account = \\_getAccount(agentID);\\n // if the account is already initialized, revert\\n if (account.principal != 0) revert InvalidState();\\n // create the account\\n account.principal = accountPrincipal;\\n account.startEpoch = block.number;\\n account.epochsPaid = block.number;\\n // save the account\\n account.save(router, agentID, id);\\n // add the pool to the agent's list of borrowed pools\\n GetRoute.agentPolice(router).addPoolToList(agentID, id);\\n // mint the iFIL to the receiver, using principal as the deposit amount\\n liquidStakingToken.mint(receiver, convertToShares(accountPrincipal));\\n // account for the new principal in the total borrowed of the pool\\n totalBorrowed += accountPrincipal;\\n}\\n```\\nчWe suggest that this action is subject to the same rules as the standard borrow action. Thus checks on DTE, LTV and DTI should be done if possible.чч```\\nfunction jumpStartAccount(address receiver, uint256 agentID, uint256 accountPrincipal) external onlyOwner {\\n Account memory account = \\_getAccount(agentID);\\n // if the account is already initialized, revert\\n if (account.principal != 0) revert InvalidState();\\n // create the account\\n account.principal = accountPrincipal;\\n account.startEpoch = block.number;\\n account.epochsPaid = block.number;\\n // save the account\\n account.save(router, agentID, id);\\n // add the pool to the agent's list of borrowed pools\\n GetRoute.agentPolice(router).addPoolToList(agentID, id);\\n // mint the iFIL to the receiver, using principal as the deposit amount\\n liquidStakingToken.mint(receiver, convertToShares(accountPrincipal));\\n // account for the new principal in the total borrowed of the pool\\n totalBorrowed += accountPrincipal;\\n}\\n```\\n
InfinityPool Contract Authorization Bypass AttackчhighчAn attacker could create their own credential and set the `Agent` ID to `0`, which would bypass the `subjectIsAgentCaller` modifier. The attacker could use this attack to `borrow` funds from the pool, draining any available liquidity. For example, only an `Agent` should be able to `borrow` funds from the pool and call the `borrow` function:\\n```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n\\nThe following modifier checks that the caller is an Agent:\\n```\\nmodifier subjectIsAgentCaller(VerifiableCredential memory vc) {\\n if (\\n GetRoute.agentFactory(router).agents(msg.sender) != vc.subject\\n ) revert Unauthorized();\\n \\_;\\n}\\n```\\n\\nBut if the caller is not an `Agent`, the `GetRoute.agentFactory(router).agents(msg.sender)` will return `0`. And if the `vc.subject` is also zero, the check will be successful with any `msg.sender`. The attacker can also pass an arbitrary `vc.value` as the parameter and steal all the funds from the pool.чEnsure only an `Agent` can call `borrow` and pass the `subjectIsAgentCaller` modifier.чч```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n
Wrong Accounting for totalBorrowed in the InfinityPool.writeOff FunctionчhighчHere is a part of the `InfinityPool.writeOff` function:\\n```\\n// transfer the assets into the pool\\n// whatever we couldn't pay back\\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\\n\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n```\\n\\nThe `totalBorrowed` is decreased by the `lostAmt` value. Instead, it should be decreased by the original `account.principal` value to acknowledge the loss.чResolution\\nFixed.чч```\\n// transfer the assets into the pool\\n// whatever we couldn't pay back\\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\\n\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n```\\n
The beneficiaryWithdrawable Function Can Be Called by AnyoneчhighчThe `beneficiaryWithdrawable` function is supposed to be called by the Agent when a beneficiary is trying to withdraw funds:\\n```\\nfunction beneficiaryWithdrawable(\\n address recipient,\\n address sender,\\n uint256 agentID,\\n uint256 proposedAmount\\n) external returns (\\n uint256 amount\\n) {\\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\\n address benneficiaryAddress = beneficiary.active.beneficiary;\\n // If the sender is not the owner of the Agent or the beneficiary, revert\\n if(\\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\\n revert Unauthorized();\\n }\\n (\\n beneficiary,\\n amount\\n ) = beneficiary.withdraw(proposedAmount);\\n // update the beneficiary in storage\\n \\_agentBeneficiaries[agentID] = beneficiary;\\n}\\n```\\n\\nThis function reduces the quota that is supposed to be transferred during the `withdraw` call:\\n```\\n sendAmount = agentPolice.beneficiaryWithdrawable(receiver, msg.sender, id, sendAmount);\\n}\\nelse if (msg.sender != owner()) {\\n revert Unauthorized();\\n}\\n\\n// unwrap any wfil needed to withdraw\\n\\_poolFundsInFIL(sendAmount);\\n// transfer funds\\npayable(receiver).sendValue(sendAmount);\\n```\\n\\nThe issue is that anyone can call this function directly, and the quota will be reduced without funds being transferred.чEnsure only the Agent can call this function.чч```\\nfunction beneficiaryWithdrawable(\\n address recipient,\\n address sender,\\n uint256 agentID,\\n uint256 proposedAmount\\n) external returns (\\n uint256 amount\\n) {\\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\\n address benneficiaryAddress = beneficiary.active.beneficiary;\\n // If the sender is not the owner of the Agent or the beneficiary, revert\\n if(\\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\\n revert Unauthorized();\\n }\\n (\\n beneficiary,\\n amount\\n ) = beneficiary.withdraw(proposedAmount);\\n // update the beneficiary in storage\\n \\_agentBeneficiaries[agentID] = beneficiary;\\n}\\n```\\n
An Agent Can Borrow Even With Existing Debt in Interest PaymentsчmediumчTo `borrow` funds, an `Agent` has to call the `borrow` function of the pool:\\n```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n\\nLet's assume that the `Agent` already had some funds borrowed. During this function execution, the current debt status is not checked. The principal debt increases after borrowing, but `account.epochsPaid` remains the same. So the pending debt will instantly increase as if the borrowing happened on `account.epochsPaid`.чEnsure the debt is paid when borrowing more funds.чч```\\nfunction borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\\n if (vc.value < WAD) revert InvalidParams();\\n // can't borrow more than the pool has\\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\\n Account memory account = \\_getAccount(vc.subject);\\n // fresh account, set start epoch and epochsPaid to beginning of current window\\n if (account.principal == 0) {\\n uint256 currentEpoch = block.number;\\n account.startEpoch = currentEpoch;\\n account.epochsPaid = currentEpoch;\\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\\n }\\n\\n account.principal += vc.value;\\n account.save(router, vc.subject, id);\\n\\n totalBorrowed += vc.value;\\n\\n emit Borrow(vc.subject, vc.value);\\n\\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\\n asset.transfer(msg.sender, vc.value);\\n}\\n```\\n
The AgentPolice.distributeLiquidatedFunds() Function Can Have Undistributed Residual FundsчmediumчWhen an Agent is liquidated, the liquidator (owner of the protocol) is supposed to try to redeem as many funds as possible and re-distribute them to the pools:\\n```\\nfunction distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\\n if (!liquidated[agentID]) revert Unauthorized();\\n\\n // transfer the assets into the pool\\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\\n \\_writeOffPools(agentID, amount);\\n}\\n```\\n\\nThe problem is that in the pool, it's accounted that the amount of funds can be larger than the debt. In that case, the pool won't transfer more funds than the pool needs:\\n```\\nuint256 totalOwed = interestPaid + principalOwed;\\n\\nasset.transferFrom(\\n msg.sender,\\n address(this),\\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\\n);\\n// write off only what we lost\\ntotalBorrowed -= lostAmt;\\n// set the account with the funds the pool lost\\naccount.principal = lostAmt;\\n\\naccount.save(router, agentID, id);\\n\\nemit WriteOff(agentID, recoveredFunds, lostAmt, interestPaid);\\n```\\n\\nIf that happens, the remaining funds will be stuck in the `AgentPolice` contract.чReturn the residual funds to the Agent's owner or process them in some way so they are not lost.чч```\\nfunction distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\\n if (!liquidated[agentID]) revert Unauthorized();\\n\\n // transfer the assets into the pool\\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\\n \\_writeOffPools(agentID, amount);\\n}\\n```\\n
An Agent Can Be Upgraded Even if There Is No New ImplementationчmediumчAgents can be upgraded to a new implementation, and only the Agent's owner can call the upgrade function:\\n```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n\\nThe issue is that the owner can trigger the upgrade even if no new implementation exists. Multiple possible problems derive from it.\\nUpgrading to the current implementation of the Agent will break the logic because the current version is not calling the `migrateMiner` function, so all the miners will stay with the old Agent, and their funds will be lost.\\nThe owner can accidentally trigger multiple upgrades simultaneously, leading to a loss of funds (https://github.com/ConsenSysDiligence/glif-audit-2023-04/issues/2).\\nThe owner also has no control over the new version of the Agent. To increase decentralization, it's better to pass the deployer's address as a parameter additionally.чEnsure the upgrades can only happen when there is a new version of an Agent, and the owner controls this version.чч```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n
Potential Re-Entrancy Issues When Upgrading the ContractsчlowчThe protocol doesn't have any built-in re-entrancy protection mechanisms. That mainly explains by using the `wFIL` token, which is not supposed to give that opportunity. And also by carefully using `FIL` transfers.\\nHowever, there are some places in the code where things may go wrong in the future. For example, when upgrading an Agent:\\n```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n\\nHere, we see the `oldAgent.decommissionAgent(newAgent);` call happens before the `oldAgent` is deleted. Inside this function, we see:\\n```\\nfunction decommissionAgent(address \\_newAgent) external {\\n // only the agent factory can decommission an agent\\n AuthController.onlyAgentFactory(router, msg.sender);\\n // if the newAgent has a mismatching ID, revert\\n if(IAgent(\\_newAgent).id() != id) revert Unauthorized();\\n // set the newAgent in storage, which marks the upgrade process as starting\\n newAgent = \\_newAgent;\\n uint256 \\_liquidAssets = liquidAssets();\\n // Withdraw all liquid funds from the Agent to the newAgent\\n \\_poolFundsInFIL(\\_liquidAssets);\\n // transfer funds to new agent\\n payable(\\_newAgent).sendValue(\\_liquidAssets);\\n}\\n```\\n\\nHere, the FIL is transferred to a new contract which is currently unimplemented and unknown. Potentially, the fallback function of this contract could trigger a re-entrancy attack. If that's the case, during the execution of this function, there will be two contracts that are active agents with the same ID, and the attacker can try to use that maliciously.чBe very cautious with further implementations of agents and pools. Also, consider using reentrancy protection in public functions.чч```\\nfunction upgradeAgent(\\n address agent\\n) external returns (address newAgent) {\\n IAgent oldAgent = IAgent(agent);\\n address owner = IAuth(address(oldAgent)).owner();\\n uint256 agentId = agents[agent];\\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\\n // deploy a new instance of Agent with the same ID and auth\\n newAgent = GetRoute.agentDeployer(router).deploy(\\n router,\\n agentId,\\n owner,\\n IAuth(address(oldAgent)).operator()\\n );\\n // Register the new agent and unregister the old agent\\n agents[newAgent] = agentId;\\n // transfer funds from old agent to new agent and mark old agent as decommissioning\\n oldAgent.decommissionAgent(newAgent);\\n // delete the old agent from the registry\\n agents[agent] = 0;\\n}\\n```\\n
InfinityPool Is Subject to a Donation With Inflation Attack if Emtied.чlowчSince `InfinityPool` is an implementation of the ERC4626 vault, it is too susceptible to inflation attacks. An attacker could front-run the first deposit and inflate the share price to an extent where the following deposit will be less than the value of 1 wei of share resulting in 0 shares minted. The attacker could conduct the inflation by means of self-destructing of another contract. In the case of GLIF this attack is less likely on the first pool since GLIF team accepts predeposits so some amount of shares was already minted. We do suggest fixing this issue before the next pool is deployed and no pre-stake is generated.\\n```\\n/\\*//////////////////////////////////////////////////////////////\\n 4626 LOGIC\\n//////////////////////////////////////////////////////////////\\*/\\n\\n/\\*\\*\\n \\* @dev Converts `assets` to shares\\n \\* @param assets The amount of assets to convert\\n \\* @return shares - The amount of shares converted from assets\\n \\*/\\nfunction convertToShares(uint256 assets) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? assets : assets \\* supply / totalAssets();\\n}\\n\\n/\\*\\*\\n \\* @dev Converts `shares` to assets\\n \\* @param shares The amount of shares to convert\\n \\* @return assets - The amount of assets converted from shares\\n \\*/\\nfunction convertToAssets(uint256 shares) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? shares : shares \\* totalAssets() / supply;\\n}\\n```\\nчSince the pool does not need to accept donations, the easiest way to handle this case is to use virtual price, where the balance of the contract is duplicated in a separate variable.чч```\\n/\\*//////////////////////////////////////////////////////////////\\n 4626 LOGIC\\n//////////////////////////////////////////////////////////////\\*/\\n\\n/\\*\\*\\n \\* @dev Converts `assets` to shares\\n \\* @param assets The amount of assets to convert\\n \\* @return shares - The amount of shares converted from assets\\n \\*/\\nfunction convertToShares(uint256 assets) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? assets : assets \\* supply / totalAssets();\\n}\\n\\n/\\*\\*\\n \\* @dev Converts `shares` to assets\\n \\* @param shares The amount of shares to convert\\n \\* @return assets - The amount of assets converted from shares\\n \\*/\\nfunction convertToAssets(uint256 shares) public view returns (uint256) {\\n uint256 supply = liquidStakingToken.totalSupply(); // Saves an extra SLOAD if totalSupply is non-zero.\\n\\n return supply == 0 ? shares : shares \\* totalAssets() / supply;\\n}\\n```\\n
MaxWithdraw Should Potentially Account for the Funds Available in the Ramp.чlowчSince `InfinityPool` is ERC4626 it should also support the `MaxWithdraw` method. According to the EIP it should include any withdrawal limitation that the participant could encounter. At the moment the `MaxWithdraw` function returns the maximum amount of IOU tokens rather than WFIL. Since IOU token is not the `asset` token of the vault, this behavior is not ideal.\\n```\\nfunction maxWithdraw(address owner) public view returns (uint256) {\\n return convertToAssets(liquidStakingToken.balanceOf(owner));\\n}\\n```\\nчWe suggest considering returning the maximum amount of WFIL withdrawal which should account for Ramp balance.чч```\\nfunction maxWithdraw(address owner) public view returns (uint256) {\\n return convertToAssets(liquidStakingToken.balanceOf(owner));\\n}\\n```\\n
The Upgradeability of MinerRegistry, AgentPolice, and Agent Is Overcomplicated and Has a Hight Chance of Errors.  AcknowledgedчlowчDuring the engagement, we have identified a few places that signify that the `Agent`, `MinerRegistry` and `AgentPolice` can be upgraded, for example:\\nAbility to migrate the miner from one version of the Agent to another inside the `migrateMiner`.\\nAbility to `refreshRoutes` that would update the `AgentPolice` and `MinerRegistry` addresses for a given Agent.\\nAbility to `decommission` pool. We believe that this functionality is present it is not very well thought through. For example, both `MinerRegistry` and `AgentPolice` are not upgradable but have mappings inside of them.\\n```\\nmapping(uint256 => bool) public liquidated;\\n\\n/// @notice `\\_poolIDs` maps agentID to the pools they have actively borrowed from\\nmapping(uint256 => uint256[]) private \\_poolIDs;\\n\\n/// @notice `\\_credentialUseBlock` maps signature bytes to when a credential was used\\nmapping(bytes32 => uint256) private \\_credentialUseBlock;\\n\\n/// @notice `\\_agentBeneficiaries` maps an Agent ID to its Beneficiary struct\\nmapping(uint256 => AgentBeneficiary) private \\_agentBeneficiaries;\\n```\\n\\n```\\nmapping(bytes32 => bool) private \\_minerRegistered;\\n\\nmapping(uint256 => uint64[]) private \\_minersByAgent;\\n```\\n\\nThat means that any time these contracts would need to be upgraded, the contents of those mappings will need to be somehow recreated in the new contract. That is not trivial since it is not easy to obtain all values of a mapping. This will also require an additional protocol-controlled setter ala kickstart mapping functions that are not ideal.\\nIn the case of `Agent` if the contract was upgradable there would be no need for a process of migrating miners that can be tedious and opens possibilities for errors. Since protocol has a lot of centralization and trust assumptions already, having upgradability will not contribute to it a lot.\\nWe also believe that during the upgrade of the pool, the PoolToken will stay the same in the new pool. That means that the minting and burning permissions of the share tokens have to be carefully updated or checked in a manner that does not require the address of the pool to be constant. Since we did not have access to this file, we can not check if that is done correctly.чConsider using upgradable contracts or have a solid upgrade plan that is well-tested before an emergency situation occurs.чч```\\nmapping(uint256 => bool) public liquidated;\\n\\n/// @notice `\\_poolIDs` maps agentID to the pools they have actively borrowed from\\nmapping(uint256 => uint256[]) private \\_poolIDs;\\n\\n/// @notice `\\_credentialUseBlock` maps signature bytes to when a credential was used\\nmapping(bytes32 => uint256) private \\_credentialUseBlock;\\n\\n/// @notice `\\_agentBeneficiaries` maps an Agent ID to its Beneficiary struct\\nmapping(uint256 => AgentBeneficiary) private \\_agentBeneficiaries;\\n```\\n
Mint Function in the Infinity Pool Will Emit the Incorrect Value.чlowчIn the `InifinityPool` file the `mint` function recomputes the amount of the assets before emitting the event. While this is fine in a lot of cases, that will not always be true. The result of `previewMint` and `convertToAssets` will only be equal while the `totalAssets` and `totalSupply` are equal. For example, this assumption will break after the first liquidation.\\n```\\nfunction mint(uint256 shares, address receiver) public isOpen returns (uint256 assets) {\\n if(shares == 0) revert InvalidParams();\\n // These transfers need to happen before the mint, and this is forcing a higher degree of coupling than is ideal\\n assets = previewMint(shares);\\n asset.transferFrom(msg.sender, address(this), assets);\\n liquidStakingToken.mint(receiver, shares);\\n assets = convertToAssets(shares);\\n emit Deposit(msg.sender, receiver, assets, shares);\\n}\\n```\\nчUse the `assets` value computed by the `previewMint` when emitting the event.чч```\\nfunction mint(uint256 shares, address receiver) public isOpen returns (uint256 assets) {\\n if(shares == 0) revert InvalidParams();\\n // These transfers need to happen before the mint, and this is forcing a higher degree of coupling than is ideal\\n assets = previewMint(shares);\\n asset.transferFrom(msg.sender, address(this), assets);\\n liquidStakingToken.mint(receiver, shares);\\n assets = convertToAssets(shares);\\n emit Deposit(msg.sender, receiver, assets, shares);\\n}\\n```\\n
Potential Overpayment Due to Rounding Imprecision  Won't FixчlowчInside the `InifintyPool` the `pay` function might accept unaccounted files. Imagine a situation where an Agent is trying to repay only the fees portion of the debt. In that case, the following branch will be executed:\\n```\\nif (vc.value <= interestOwed) {\\n // compute the amount of epochs this payment covers\\n // vc.value is not WAD yet, so divWadDown cancels the extra WAD in interestPerEpoch\\n uint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n // update the account's `epochsPaid` cursor\\n account.epochsPaid += epochsForward;\\n // since the entire payment is interest, the entire payment is used to compute the fee (principal payments are fee-free)\\n feeBasis = vc.value;\\n} else {\\n```\\n\\nThe issue is if the `value` does not divide by the `interestPerEpoch` exactly, any remainder will remain in the InfinityPool.\\n```\\nuint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n```\\nчSince the remainder will most likely not be too large this is not critical, but ideally, those remaining funds would be included in the `refund` variable.чч```\\nif (vc.value <= interestOwed) {\\n // compute the amount of epochs this payment covers\\n // vc.value is not WAD yet, so divWadDown cancels the extra WAD in interestPerEpoch\\n uint256 epochsForward = vc.value.divWadDown(interestPerEpoch);\\n // update the account's `epochsPaid` cursor\\n account.epochsPaid += epochsForward;\\n // since the entire payment is interest, the entire payment is used to compute the fee (principal payments are fee-free)\\n feeBasis = vc.value;\\n} else {\\n```\\n
jumpStartAccount Should Be Subject to the Same Approval Checks as Regular Borrow.чlowч`InfinityPool` contract has the ability to kick start an account that will have a debt position in this pool.\\n```\\nfunction jumpStartAccount(address receiver, uint256 agentID, uint256 accountPrincipal) external onlyOwner {\\n Account memory account = \\_getAccount(agentID);\\n // if the account is already initialized, revert\\n if (account.principal != 0) revert InvalidState();\\n // create the account\\n account.principal = accountPrincipal;\\n account.startEpoch = block.number;\\n account.epochsPaid = block.number;\\n // save the account\\n account.save(router, agentID, id);\\n // add the pool to the agent's list of borrowed pools\\n GetRoute.agentPolice(router).addPoolToList(agentID, id);\\n // mint the iFIL to the receiver, using principal as the deposit amount\\n liquidStakingToken.mint(receiver, convertToShares(accountPrincipal));\\n // account for the new principal in the total borrowed of the pool\\n totalBorrowed += accountPrincipal;\\n}\\n```\\nчWe suggest that this action is subject to the same rules as the standard borrow action. Thus checks on DTE, LTV and DTI should be done if possible.чч```\\nfunction jumpStartAccount(address receiver, uint256 agentID, uint256 accountPrincipal) external onlyOwner {\\n Account memory account = \\_getAccount(agentID);\\n // if the account is already initialized, revert\\n if (account.principal != 0) revert InvalidState();\\n // create the account\\n account.principal = accountPrincipal;\\n account.startEpoch = block.number;\\n account.epochsPaid = block.number;\\n // save the account\\n account.save(router, agentID, id);\\n // add the pool to the agent's list of borrowed pools\\n GetRoute.agentPolice(router).addPoolToList(agentID, id);\\n // mint the iFIL to the receiver, using principal as the deposit amount\\n liquidStakingToken.mint(receiver, convertToShares(accountPrincipal));\\n // account for the new principal in the total borrowed of the pool\\n totalBorrowed += accountPrincipal;\\n}\\n```\\n
Potential Reentrancy Into StrategiesчmediumчThe `StrategyManager` contract is the entry point for deposits into and withdrawals from strategies. More specifically, to `deposit` into a strategy, a staker calls `depositIntoStrategy` (or anyone calls `depositIntoStrategyWithSignature` with the staker's signature) then the asset is transferred from the staker to the strategy contract. After that, the strategy's `deposit` function is called, followed by some bookkeeping in the `StrategyManager`. For withdrawals (and slashing), the `StrategyManager` calls the strategy's `withdraw` function, which transfers the given amount of the asset to the given recipient. Both token transfers are a potential source of reentrancy if the token allows it.\\nThe `StrategyManager` uses OpenZeppelin's `ReentrancyGuardUpgradeable` as reentrancy protection, and the relevant functions have a `nonReentrant` modifier. The `StrategyBase` contract – from which concrete strategies should be derived – does not have reentrancy protection. However, the functions `deposit` and `withdraw` can only be called from the `StrategyManager`, so reentering these is impossible.\\nNevertheless, other functions could be reentered, for example, `sharesToUnderlyingView` and `underlyingToSharesView`, as well as their (supposedly) non-view counterparts.\\nLet's look at the `withdraw` function in `StrategyBase`. First, the `amountShares` shares are burnt, and at the end of the function, the equivalent amount of `token` is transferred to the depositor:\\n```\\nfunction withdraw(address depositor, IERC20 token, uint256 amountShares)\\n    external\\n    virtual\\n    override\\n    onlyWhenNotPaused(PAUSED\\_WITHDRAWALS)\\n    onlyStrategyManager\\n{\\n    require(token == underlyingToken, \"StrategyBase.withdraw: Can only withdraw the strategy token\");\\n    // copy `totalShares` value to memory, prior to any decrease\\n    uint256 priorTotalShares = totalShares;\\n    require(\\n        amountShares <= priorTotalShares,\\n        \"StrategyBase.withdraw: amountShares must be less than or equal to totalShares\"\\n    );\\n\\n    // Calculate the value that `totalShares` will decrease to as a result of the withdrawal\\n    uint256 updatedTotalShares = priorTotalShares - amountShares;\\n    // check to avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\\n    require(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES || updatedTotalShares == 0,\\n        \"StrategyBase.withdraw: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n    // Actually decrease the `totalShares` value\\n    totalShares = updatedTotalShares;\\n\\n    /\\*\\*\\n \\* @notice calculation of amountToSend \\*mirrors\\* `sharesToUnderlying(amountShares)`, but is different since the `totalShares` has already\\n \\* been decremented. Specifically, notice how we use `priorTotalShares` here instead of `totalShares`.\\n \\*/\\n    uint256 amountToSend;\\n    if (priorTotalShares == amountShares) {\\n        amountToSend = \\_tokenBalance();\\n    } else {\\n        amountToSend = (\\_tokenBalance() \\* amountShares) / priorTotalShares;\\n    }\\n\\n    underlyingToken.safeTransfer(depositor, amountToSend);\\n}\\n```\\n\\nIf we assume that the `token` contract has a callback to the recipient of the transfer before the actual balance changes take place, then the recipient could reenter the strategy contract, for example, in sharesToUnderlyingView:\\n```\\nfunction sharesToUnderlyingView(uint256 amountShares) public view virtual override returns (uint256) {\\n    if (totalShares == 0) {\\n        return amountShares;\\n    } else {\\n        return (\\_tokenBalance() \\* amountShares) / totalShares;\\n    }\\n}\\n```\\n\\nThe crucial point is: If the callback is executed before the actual balance change, then `sharesToUnderlyingView` will report a bad result because the shares have already been burnt. Still, the token balance has not been updated yet.\\nFor deposits, the token transfer to the strategy happens first, and the shares are minted after that:\\n```\\nfunction \\_depositIntoStrategy(address depositor, IStrategy strategy, IERC20 token, uint256 amount)\\n    internal\\n    onlyStrategiesWhitelistedForDeposit(strategy)\\n    returns (uint256 shares)\\n{\\n    // transfer tokens from the sender to the strategy\\n    token.safeTransferFrom(msg.sender, address(strategy), amount);\\n\\n    // deposit the assets into the specified strategy and get the equivalent amount of shares in that strategy\\n    shares = strategy.deposit(token, amount);\\n```\\n\\n```\\nfunction deposit(IERC20 token, uint256 amount)\\n    external\\n    virtual\\n    override\\n    onlyWhenNotPaused(PAUSED\\_DEPOSITS)\\n    onlyStrategyManager\\n    returns (uint256 newShares)\\n{\\n    require(token == underlyingToken, \"StrategyBase.deposit: Can only deposit underlyingToken\");\\n\\n    /\\*\\*\\n \\* @notice calculation of newShares \\*mirrors\\* `underlyingToShares(amount)`, but is different since the balance of `underlyingToken`\\n \\* has already been increased due to the `strategyManager` transferring tokens to this strategy prior to calling this function\\n \\*/\\n    uint256 priorTokenBalance = \\_tokenBalance() - amount;\\n    if (priorTokenBalance == 0 || totalShares == 0) {\\n        newShares = amount;\\n    } else {\\n        newShares = (amount \\* totalShares) / priorTokenBalance;\\n    }\\n\\n    // checks to ensure correctness / avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\\n    require(newShares != 0, \"StrategyBase.deposit: newShares cannot be zero\");\\n    uint256 updatedTotalShares = totalShares + newShares;\\n    require(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES,\\n        \"StrategyBase.deposit: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n\\n    // update total share amount\\n    totalShares = updatedTotalShares;\\n    return newShares;\\n}\\n```\\n\\nThat means if there is a callback in the token's `transferFrom` function and it is executed after the balance change, a reentering call to `sharesToUnderlyingView` (for example) will again return a wrong result because shares and token balances are not “in sync.”\\nIn addition to the reversed order of token transfer and shares update, there's another vital difference between `withdraw` and deposit: For withdrawals, the call to the token contract originates in the strategy, while for deposits, it is the strategy manager that initiates the call to the token contract (before calling into the strategy). That's a technicality that has consequences for reentrancy protection: Note that for withdrawals, it is the strategy contract that is reentered, while for deposits, there is not a single contract that is reentered; instead, it is the contract system that is in an inconsistent state when the reentrancy happens. Hence, reentrancy protection on the level of individual contracts is not sufficient.\\nFinally, we want to discuss though which functions in the strategy contract the system could be reentered. As mentioned, `deposit` and `withdraw` can only be called by the strategy manager, so these two can be ruled out. For the examples above, we considered `sharesToUnderlyingView`, which (as the name suggests) is a `view` function. As such, it can't change the state of the contract, so reentrancy through a `view` function can only be a problem for other contracts that use this function and rely on its return value. However, there is also a potentially state-changing variant, `sharesToUnderlying`, and similar potentially state-changing functions, such as `underlyingToShares` and `userUnderlying`. Currently, these functions are not actually state-changing, but the idea is that they could be and, in some concrete strategy implementations that inherit from `StrategyBase`, will be. In such cases, these functions could make wrong state changes due to state inconsistency during reentrancy.\\nThe examples above assume that the token contract allows reentrancy through its `transfer` function before the balance change has been made or in its `transferFrom` function after. It might be tempting to argue that tokens which don't fall into this category are safe to use. While the examples discussed above are the most interesting attack vectors we found, there might still be others: To illustrate this point, assume a token contract that allows reentrancy through `transferFrom` only before any state change in the token takes place. The token `transfer` is the first thing that happens in `StrategyManager._depositIntoStrategy`, and the state changes (user shares) and calling the strategy's `deposit` function occur later, this might look safe. However, if the `deposit` happens via `StrategyManager.depositIntoStrategyWithSignature`, then it can be seen, for example, that the staker's nonce is updated before the internal `_depositIntoStrategy` function is called:\\n```\\nfunction depositIntoStrategyWithSignature(\\n    IStrategy strategy,\\n    IERC20 token,\\n    uint256 amount,\\n    address staker,\\n    uint256 expiry,\\n    bytes memory signature\\n)\\n    external\\n    onlyWhenNotPaused(PAUSED\\_DEPOSITS)\\n    onlyNotFrozen(staker)\\n    nonReentrant\\n    returns (uint256 shares)\\n{\\n    require(\\n        expiry >= block.timestamp,\\n        \"StrategyManager.depositIntoStrategyWithSignature: signature expired\"\\n    );\\n    // calculate struct hash, then increment `staker`'s nonce\\n    uint256 nonce = nonces[staker];\\n    bytes32 structHash = keccak256(abi.encode(DEPOSIT\\_TYPEHASH, strategy, token, amount, nonce, expiry));\\n    unchecked {\\n        nonces[staker] = nonce + 1;\\n    }\\n    bytes32 digestHash = keccak256(abi.encodePacked(\"\\x19\\x01\", DOMAIN\\_SEPARATOR, structHash));\\n\\n\\n    /\\*\\*\\n \\* check validity of signature:\\n \\* 1) if `staker` is an EOA, then `signature` must be a valid ECSDA signature from `staker`,\\n \\* indicating their intention for this action\\n \\* 2) if `staker` is a contract, then `signature` must will be checked according to EIP-1271\\n \\*/\\n    if (Address.isContract(staker)) {\\n        require(IERC1271(staker).isValidSignature(digestHash, signature) == ERC1271\\_MAGICVALUE,\\n            \"StrategyManager.depositIntoStrategyWithSignature: ERC1271 signature verification failed\");\\n    } else {\\n        require(ECDSA.recover(digestHash, signature) == staker,\\n            \"StrategyManager.depositIntoStrategyWithSignature: signature not from staker\");\\n    }\\n\\n    shares = \\_depositIntoStrategy(staker, strategy, token, amount);\\n}\\n```\\n\\nHence, querying the staker's nonce in reentrancy would still give a result based on an “incomplete state change.” It is, for example, conceivable that the staker still has zero shares, and yet their nonce is already 1. This particular situation is most likely not an issue, but the example shows that reentrancy can be subtle.чThis is fine if the token doesn't allow reentrancy in the first place. As discussed above, among the tokens that do allow reentrancy, some variants of when reentrancy can happen in relation to state changes in the token seem more dangerous than others, but we have also argued that this kind of reasoning can be dangerous and error-prone. Hence, we recommend employing comprehensive and defensive reentrancy protection based on reentrancy guards such as OpenZeppelin's ReentrancyGuardUpgradeable, which is already used in the `StrategyManager`.\\nUnfortunately, securing a multi-contract system against reentrancy can be challenging, but we hope the preceding discussion and the following pointers will prove helpful:\\nExternal functions in strategies that should only be callable by the strategy manager (such as `deposit` and withdraw) should have the `onlyStrategyManager` modifier. This is already the case in the current codebase and is listed here only for completeness.\\nExternal functions in strategies for which item 1 doesn't apply (such as `sharesToUnderlying` and underlyingToShares) should query the strategy manager's reentrancy lock and revert if it is set.\\nIn principle, the restrictions above also apply to `public` functions, but if a `public` function is also used internally, checks against reentrancy can cause problems (if used in an `internal` context) or at least be redundant. In the context of reentrancy protection, it is often easier to split `public` functions into an `internal` and an `external` one.\\nIf `view` functions are supposed to give reliable results (either internally – which is typically the case – or for other contracts), they have to be protected too.\\nThe previous item also applies to the StrategyManager: `view` functions that provide correct results should query the reentrancy lock and revert if it is set.\\nSolidity automatically generates getters for `public` state variables. Again, if these (external view) functions must deliver correct results, the same measures must be taken for explicit `view` functions. In practice, the state variable has to become `internal` or `private`, and the getter function must be hand-written.\\nThe `StrategyBase` contract provides some basic functionality. Concrete strategy implementations can inherit from this contract, meaning that some functions may be overridden (and might or might not call the overridden version via super), and new functions might be added. While the guidelines above should be helpful, derived contracts must be reviewed and assessed separately on a case-by-case basis. As mentioned before, reentrancy protection can be challenging, especially in a multi-contract system.чч```\\nfunction withdraw(address depositor, IERC20 token, uint256 amountShares)\\n    external\\n    virtual\\n    override\\n    onlyWhenNotPaused(PAUSED\\_WITHDRAWALS)\\n    onlyStrategyManager\\n{\\n    require(token == underlyingToken, \"StrategyBase.withdraw: Can only withdraw the strategy token\");\\n    // copy `totalShares` value to memory, prior to any decrease\\n    uint256 priorTotalShares = totalShares;\\n    require(\\n        amountShares <= priorTotalShares,\\n        \"StrategyBase.withdraw: amountShares must be less than or equal to totalShares\"\\n    );\\n\\n    // Calculate the value that `totalShares` will decrease to as a result of the withdrawal\\n    uint256 updatedTotalShares = priorTotalShares - amountShares;\\n    // check to avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\\n    require(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES || updatedTotalShares == 0,\\n        \"StrategyBase.withdraw: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n    // Actually decrease the `totalShares` value\\n    totalShares = updatedTotalShares;\\n\\n    /\\*\\*\\n \\* @notice calculation of amountToSend \\*mirrors\\* `sharesToUnderlying(amountShares)`, but is different since the `totalShares` has already\\n \\* been decremented. Specifically, notice how we use `priorTotalShares` here instead of `totalShares`.\\n \\*/\\n    uint256 amountToSend;\\n    if (priorTotalShares == amountShares) {\\n        amountToSend = \\_tokenBalance();\\n    } else {\\n        amountToSend = (\\_tokenBalance() \\* amountShares) / priorTotalShares;\\n    }\\n\\n    underlyingToken.safeTransfer(depositor, amountToSend);\\n}\\n```\\n
StrategyBase – Inflation Attack Prevention Can Lead to Stuck FundsчlowчAs a defense against what has come to be known as inflation or donation attack in the context of ERC-4626, the `StrategyBase` contract – from which concrete strategy implementations are supposed to inherit – enforces that the amount of shares in existence for a particular strategy is always either 0 or at least a certain minimum amount that is set to 10^9. This mitigates inflation attacks, which require a small total supply of shares to be effective.\\n```\\nuint256 updatedTotalShares = totalShares + newShares;\\nrequire(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES,\\n    \"StrategyBase.deposit: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n```\\n\\n```\\n// Calculate the value that `totalShares` will decrease to as a result of the withdrawal\\nuint256 updatedTotalShares = priorTotalShares - amountShares;\\n// check to avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\\nrequire(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES || updatedTotalShares == 0,\\n    \"StrategyBase.withdraw: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n```\\n\\nThis particular approach has the downside that, in the worst case, a user may be unable to withdraw the underlying asset for up to 10^9 - 1 shares. While the extreme circumstances under which this can happen might be unlikely to occur in a realistic setting and, in many cases, the value of 10^9 - 1 shares may be negligible, this is not ideal.чIt isn't easy to give a good general recommendation. None of the suggested mitigations are without a downside, and what's the best choice may also depend on the specific situation. We do, however, feel that alternative approaches that can't lead to stuck funds might be worth considering, especially for a default implementation.\\nOne option is internal accounting, i.e., the strategy keeps track of the number of underlying tokens it owns. It uses this number for conversion rate calculation instead of its balance in the token contract. This avoids the donation attack because sending tokens directly to the strategy will not affect the conversion rate. Moreover, this technique helps prevent reentrancy issues when the EigenLayer state is out of sync with the token contract's state. The downside is higher gas costs and that donating by just sending tokens to the contract is impossible; more specifically, if it happens accidentally, the funds are lost unless there's some special mechanism to recover them.\\nAn alternative approach with virtual shares and assets is presented here, and the document lists pointers to more discussions and proposed solutions.чч```\\nuint256 updatedTotalShares = totalShares + newShares;\\nrequire(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES,\\n    \"StrategyBase.deposit: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\\n```\\n
StrategyWrapper – Functions Shouldn't Be virtual (Out of Scope)чlowчThe `StrategyWrapper` contract is a straightforward strategy implementation and – as its NatSpec documentation explicitly states – is not designed to be inherited from:\\n```\\n/\\*\\*\\n \\* @title Extremely simple implementation of `IStrategy` interface.\\n \\* @author Layr Labs, Inc.\\n \\* @notice Simple, basic, \"do-nothing\" Strategy that holds a single underlying token and returns it on withdrawals.\\n \\* Assumes shares are always 1-to-1 with the underlyingToken.\\n \\* @dev Unlike `StrategyBase`, this contract is \\*not\\* designed to be inherited from.\\n \\* @dev This contract is expressly \\*not\\* intended for use with 'fee-on-transfer'-type tokens.\\n \\* Setting the `underlyingToken` to be a fee-on-transfer token may result in improper accounting.\\n \\*/\\ncontract StrategyWrapper is IStrategy {\\n```\\n\\nHowever, all functions in this contract are `virtual`, which only makes sense if inheriting from `StrategyWrapper` is possible.чAssuming the NatSpec documentation is correct, and no contract should inherit from `StrategyWrapper`, remove the `virtual` keyword from all function definitions. Otherwise, fix the documentation.\\nRemark\\nThis contract is out of scope, and this finding is only included because we noticed it accidentally. This does not mean we have reviewed the contract or other out-of-scope files.чч```\\n/\\*\\*\\n \\* @title Extremely simple implementation of `IStrategy` interface.\\n \\* @author Layr Labs, Inc.\\n \\* @notice Simple, basic, \"do-nothing\" Strategy that holds a single underlying token and returns it on withdrawals.\\n \\* Assumes shares are always 1-to-1 with the underlyingToken.\\n \\* @dev Unlike `StrategyBase`, this contract is \\*not\\* designed to be inherited from.\\n \\* @dev This contract is expressly \\*not\\* intended for use with 'fee-on-transfer'-type tokens.\\n \\* Setting the `underlyingToken` to be a fee-on-transfer token may result in improper accounting.\\n \\*/\\ncontract StrategyWrapper is IStrategy {\\n```\\n
StrategyBase – Inheritance-Related IssuesчlowчA. The `StrategyBase` contract defines `view` functions that, given an amount of shares, return the equivalent amount of tokens (sharesToUnderlyingView) and vice versa (underlyingToSharesView). These two functions also have non-view counterparts: `sharesToUnderlying` and `underlyingToShares`, and their NatSpec documentation explicitly states that they should be allowed to make state changes. Given the scope of this engagement, it is unclear if these non-view versions are needed, but assuming they are, this does currently not work as intended.\\nFirst, the interface `IStrategy` declares `underlyingToShares` as `view` (unlike sharesToUnderlying). This means overriding this function in derived contracts is impossible without the `view` modifier. Hence, in `StrategyBase` – which implements the `IStrategy` interface – this (virtual) function is (and has to be) `view`. The same applies to overridden versions of this function in contracts inherited from `StrategyBase`.\\n```\\n/\\*\\*\\n \\* @notice Used to convert an amount of underlying tokens to the equivalent amount of shares in this strategy.\\n \\* @notice In contrast to `underlyingToSharesView`, this function \\*\\*may\\*\\* make state modifications\\n \\* @param amountUnderlying is the amount of `underlyingToken` to calculate its conversion into strategy shares\\n \\* @dev Implementation for these functions in particular may vary signifcantly for different strategies\\n \\*/\\nfunction underlyingToShares(uint256 amountUnderlying) external view returns (uint256);\\n```\\n\\n```\\n/\\*\\*\\n \\* @notice Used to convert an amount of underlying tokens to the equivalent amount of shares in this strategy.\\n \\* @notice In contrast to `underlyingToSharesView`, this function \\*\\*may\\*\\* make state modifications\\n \\* @param amountUnderlying is the amount of `underlyingToken` to calculate its conversion into strategy shares\\n \\* @dev Implementation for these functions in particular may vary signifcantly for different strategies\\n \\*/\\nfunction underlyingToShares(uint256 amountUnderlying) external view virtual returns (uint256) {\\n    return underlyingToSharesView(amountUnderlying);\\n}\\n```\\n\\nAs mentioned above, the `sharesToUnderlying` function does not have the `view` modifier in the interface `IStrategy`. However, the overridden (and virtual) version in `StrategyBase` does, which means again that overriding this function in contracts inherited from `StrategyBase` is impossible without the `view` modifier.\\n```\\n/\\*\\*\\n \\* @notice Used to convert a number of shares to the equivalent amount of underlying tokens for this strategy.\\n \\* @notice In contrast to `sharesToUnderlyingView`, this function \\*\\*may\\*\\* make state modifications\\n \\* @param amountShares is the amount of shares to calculate its conversion into the underlying token\\n \\* @dev Implementation for these functions in particular may vary signifcantly for different strategies\\n \\*/\\nfunction sharesToUnderlying(uint256 amountShares) public view virtual override returns (uint256) {\\n    return sharesToUnderlyingView(amountShares);\\n}\\n```\\n\\nB. The `initialize` function in the `StrategyBase` contract is not virtual, which means the name will not be available in derived contracts (unless with different parameter types). It also has the `initializer` modifier, which is unavailable in concrete strategies inherited from `StrategyBase`.чA. If state-changing versions of the conversion functions are needed, the `view` modifier has to be removed from `IStrategy.underlyingToShares`, `StrategyBase.underlyingToShares`, and `StrategyBase.sharesToUnderlying`. They should be removed entirely from the interface and base contract if they're not needed.\\nB. Consider making the `StrategyBase` contract `abstract`, maybe give the `initialize` function a more specific name such as `_initializeStrategyBase`, change its visibility to `internal`, and use the `onlyInitializing` modifier instead of `initializer`.чч```\\n/\\*\\*\\n \\* @notice Used to convert an amount of underlying tokens to the equivalent amount of shares in this strategy.\\n \\* @notice In contrast to `underlyingToSharesView`, this function \\*\\*may\\*\\* make state modifications\\n \\* @param amountUnderlying is the amount of `underlyingToken` to calculate its conversion into strategy shares\\n \\* @dev Implementation for these functions in particular may vary signifcantly for different strategies\\n \\*/\\nfunction underlyingToShares(uint256 amountUnderlying) external view returns (uint256);\\n```\\n
StrategyManager - Cross-Chain Replay Attacks After Chain Split Due to Hard-Coded DOMAIN_SEPARATORчlowчA. The `StrategyManager` contract allows stakers to deposit into and withdraw from strategies. A staker can either deposit themself or have someone else do it on their behalf, where the latter requires an EIP-712-compliant signature. The EIP-712 domain separator is computed in the `initialize` function and stored in a state variable for later retrieval:\\n```\\n/// @notice EIP-712 Domain separator\\nbytes32 public DOMAIN\\_SEPARATOR;\\n```\\n\\n```\\nfunction initialize(address initialOwner, address initialStrategyWhitelister, IPauserRegistry \\_pauserRegistry, uint256 initialPausedStatus, uint256 \\_withdrawalDelayBlocks)\\n    external\\n    initializer\\n{\\n    DOMAIN\\_SEPARATOR = keccak256(abi.encode(DOMAIN\\_TYPEHASH, bytes(\"EigenLayer\"), block.chainid, address(this)));\\n```\\n\\nOnce set in the `initialize` function, the value can't be changed anymore. In particular, the chain ID is “baked into” the `DOMAIN_SEPARATOR` during initialization. However, it is not necessarily constant: In the event of a chain split, only one of the resulting chains gets to keep the original chain ID, and the other should use a new one. With the current approach to compute the `DOMAIN_SEPARATOR` during initialization, store it, and then use the stored value for signature verification, a signature will be valid on both chains after a split – but it should not be valid on the chain with the new ID. Hence, the domain separator should be computed dynamically.\\nB. The `name` in the `EIP712Domain` is of type string:\\n```\\nbytes32 public constant DOMAIN\\_TYPEHASH =\\n    keccak256(\"EIP712Domain(string name,uint256 chainId,address verifyingContract)\");\\n```\\n\\nWhat's encoded when the domain separator is computed is bytes(\"EigenLayer\"):\\n```\\nDOMAIN\\_SEPARATOR = keccak256(abi.encode(DOMAIN\\_TYPEHASH, bytes(\"EigenLayer\"), block.chainid, address(this)));\\n```\\n\\nAccording to EIP-712,\\nThe dynamic values `bytes` and `string` are encoded as a `keccak256` hash of their contents.\\nHence, `bytes(\"EigenLayer\")` should be replaced with `keccak256(bytes(\"EigenLayer\"))`.\\nC. The `EIP712Domain` does not include a version string:\\n```\\nbytes32 public constant DOMAIN\\_TYPEHASH =\\n    keccak256(\"EIP712Domain(string name,uint256 chainId,address verifyingContract)\");\\n```\\n\\nThat is allowed according to the specification. However, given that most, if not all, projects, as well as OpenZeppelin's EIP-712 implementation, do include a version string in their `EIP712Domain`, it might be a pragmatic choice to do the same, perhaps to avoid potential incompatibilities.чIndividual recommendations have been given above. Alternatively, you might want to utilize OpenZeppelin's `EIP712Upgradeable` library, which will take care of these issues. Note that some of these changes will break existing signatures.чч```\\n/// @notice EIP-712 Domain separator\\nbytes32 public DOMAIN\\_SEPARATOR;\\n```\\n
StrategyManagerStorage – Miscalculated Gap SizeчlowчUpgradeable contracts should have a “gap” of unused storage slots at the end to allow for adding state variables when the contract is upgraded. The convention is to have a gap whose size adds up to 50 with the used slots at the beginning of the contract's storage.\\nIn `StrategyManagerStorage`, the number of consecutively used storage slots is 10:\\n`DOMAIN_SEPARATOR`\\n`nonces`\\n`strategyWhitelister`\\n`withdrawalDelayBlocks`\\n`stakerStrategyShares`\\n`stakerStrategyList`\\n`withdrawalRootPending`\\n`numWithdrawalsQueued`\\n`strategyIsWhitelistedForDeposit`\\n`beaconChainETHSharesToDecrementOnWithdrawal`\\nHowever, the gap size in the storage contract is 41:\\n```\\nuint256[41] private \\_\\_gap;\\n```\\nчIf you don't have to maintain compatibility with an existing deployment, we recommend reducing the storage gap size to 40. Otherwise, we recommend adding a comment explaining that, in this particular case, the gap size and the used storage slots should add up to 51 instead of 50 and that this invariant has to be maintained in future versions of this contract.чч```\\nuint256[41] private \\_\\_gap;\\n```\\n
Funds Refunded From Celer Bridge Might Be Stolenчhighч```\\nif (!router.withdraws(transferId)) {\\n    router.withdraw(\\_request, \\_sigs, \\_signers, \\_powers);\\n}\\n```\\n\\nFrom the point of view of the Celer bridge, the initial depositor of the tokens is the `SocketGateway`. As a consequence, the Celer contract transfers the tokens to be refunded to the gateway. The gateway is then in charge of forwarding the tokens to the initial depositor. To achieve this, it keeps a mapping of unique transfer IDs to depositor addresses. Once a refund is processed, the corresponding address in the mapping is reset to the zero address.\\nLooking at the `withdraw` function of the Celer pool, we see that for some tokens, it is possible that the reimbursement will not be processed directly, but only after some delay. From the gateway point of view, the reimbursement will be marked as successful, and the address of the original sender corresponding to this transfer ID will be reset to address(0).\\n```\\nif (delayThreshold > 0 && wdmsg.amount > delayThreshold) {\\n     _addDelayedTransfer(wdId, wdmsg.receiver, wdmsg.token, wdmsg. // <--- here\\n} else {\\n      _sendToken(wdmsg.receiver, wdmsg.token, wdmsg.\\n}\\n```\\n\\nIt is then the responsibility of the user, once the locking delay has passed, to call another function to claim the tokens. Unfortunately, in our case, this means that the funds will be sent back to the gateway contract and not to the original sender. Because the gateway implements `rescueEther`, and `rescueFunds` functions, the admin might be able to send the funds back to the user. However, this requires manual intervention and breaks the trustlessness assumptions of the system. Also, in that case, there is no easy way to trace back the original address of the sender, that corresponds to this refund.\\nHowever, there is an additional issue that might allow an attacker to steal some funds from the gateway. Indeed, when claiming the refund, if it is in ETH, the gateway will have some balance when the transaction completes. Any user can then call any function that consumes the gateway balance, such as the `swapAndBridge` from `CelerImpl`, to steal the refunded ETH. That is possible as the function relies on a user-provided amount as an input, and not on `msg.value`. Additionally, if the refund is an ERC-20, an attacker can steal the funds by calling `bridgeAfterSwap` or `swapAndBridge` from the `Stargate` or `Celer` routes with the right parameters.\\n```\\nfunction bridgeAfterSwap(\\n    uint256 amount,\\n    bytes calldata bridgeData\\n) external payable override {\\n    CelerBridgeData memory celerBridgeData = abi.decode(\\n        bridgeData,\\n        (CelerBridgeData)\\n    );\\n```\\n\\n```\\nfunction swapAndBridge(\\n    uint32 swapId,\\n    bytes calldata swapData,\\n    StargateBridgeDataNoToken calldata stargateBridgeData\\n```\\n\\nNote that this violates the security assumption: “The contracts are not supposed to hold any funds post-tx execution.”чMake sure that `CelerImpl` supports also the delayed withdrawals functionality and that withdrawal requests are deleted only if the receiver has received the withdrawal in a single transaction.чч```\\nif (!router.withdraws(transferId)) {\\n    router.withdraw(\\_request, \\_sigs, \\_signers, \\_powers);\\n}\\n```\\n
Calls Made to Non-Existent/Removed Routes or Controllers Will Not Result in FailureчhighчThis issue was found in commit hash `a8d0ad1c280a699d88dc280d9648eacaf215fb41`.\\nIn the Ethereum Virtual Machine (EVM), `delegatecall` will succeed for calls to externally owned accounts and more specifically to the zero address, which presents a potential security risk. We have identified multiple instances of `delegatecall` being used to invoke smart contract functions.\\nThis, combined with the fact that routes can be removed from the system by the owner of the `SocketGateway` contract using the `disableRoute` function, makes it possible for the user's funds to be lost in case of an `executeRoute` transaction (for instance) that's waiting in the mempool is eventually being front-ran by a call to `disableRoute`.\\n```\\n(bool success, bytes memory result) = addressAt(routeId).delegatecall(\\n```\\n\\n```\\n.delegatecall(swapData);\\n```\\n\\n```\\n.delegatecall(swapData);\\n```\\n\\n```\\n.delegatecall(swapData);\\n```\\n\\n```\\n.delegatecall(data);\\n```\\n\\nEven after the upgrade to commit hash `d0841a3e96b54a9d837d2dba471aa0946c3c8e7b`, the following bug is still present:\\nTo optimize gas usage, the `addressAt` function in `socketGateway` uses a binary search in a hard-coded table to resolve a `routeID` (routeID <= 512) to a contract address. This is made possible thanks to the factory using the `CREATE2` pattern. This allows to pre-compute future addresses of contracts before they are deployed. In case the `routeID` is strictly greater than 512, `addressAt` falls back to fetching the address from a state mapping (routes).\\nThe new commit hash adds a check to make sure that the call to the `addressAt` function reverts in case a `routeID` is not present in the `routes` mapping. This prevents delegate-calling to non-existent addresses in various places of the code. However, this does not solve the issue for the hard-coded route addresses (i.e., `routeID` <= 512). In that case, the `addressAt` function still returns a valid route contract address, despite the contract not being deployed yet. This will result in a successful `delegatecall` later in the code and might lead to various side-effects.\\n```\\nfunction addressAt(uint32 routeId) public view returns (address) {\\n    if (routeId < 513) {\\n        if (routeId < 257) {\\n            if (routeId < 129) {\\n                if (routeId < 65) {\\n                    if (routeId < 33) {\\n                        if (routeId < 17) {\\n                            if (routeId < 9) {\\n                                if (routeId < 5) {\\n                                    if (routeId < 3) {\\n                                        if (routeId == 1) {\\n                                            return\\n                                                0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;\\n                                        } else {\\n                                            return\\n                                                0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;\\n                                        }\\n                                    } else {\\n```\\n\\n```\\nif (routes[routeId] == address(0)) revert ZeroAddressNotAllowed();\\nreturn routes[routeId];\\n```\\nчConsider adding a check to validate that the callee of a `delegatecall` is indeed a contract, you may refer to the Address library by OZ.чч```\\n(bool success, bytes memory result) = addressAt(routeId).delegatecall(\\n```\\n
Owner Can Add Arbitrary Code to Be Executed From the SocketGateway ContractчmediumчThe Socket system is managed by the `SocketGateway` contract that maintains all routes and controller addresses within its state. There, the address with the `Owner` role of the `SocketGateway` contract can add new routes and controllers that would have a `delegatecall()` executed upon them from the `SocketGateway` so user transactions can go through the logic required for the bridge, swap, or any other solution integrated with Socket. These routes and controllers would then have arbitrary code that is entirely up to the `Owner`, though users are not required to go through any specific routes and can decide which routes to pick.\\nSince these routes are called via `delegatecall()`, they don't hold any storage variables that would be used in the Socket systems. However, as Socket aggregates more solutions, unexpected complexities may arise that could require storing and accessing variables through additional contracts. Those contracts would be access control protected to only have the `SocketGateway` contract have the privileges to modify its variables.\\nThis together with the `Owner` of the `SocketGateway` being able to add routes with arbitrary code creates an attack vector where a compromised address with `Owner` privileges may add a route that would contain code that exploits the special privileges assigned to the `SocketGateway` contract for their benefit.\\nFor example, the Celer bridge needs extra logic to account for its refund mechanism, so there is an additional `CelerStorageWrapper` contract that maintains a mapping between individual bridge transfer transactions and their associated msg.sender:\\n```\\ncelerStorageWrapper.setAddressForTransferId(transferId, msg.sender);\\n```\\n\\n```\\n/\\*\\*\\n \\* @title CelerStorageWrapper\\n \\* @notice handle storageMappings used while bridging ERC20 and native on CelerBridge\\n \\* @dev all functions ehich mutate the storage are restricted to Owner of SocketGateway\\n \\* @author Socket dot tech.\\n \\*/\\ncontract CelerStorageWrapper {\\n```\\n\\nConsequently, this contract has access-protected functions that may only be called by the SocketGateway to set and delete the transfer IDs:\\n```\\nfunction setAddressForTransferId(\\n```\\n\\n```\\nfunction deleteTransferId(bytes32 transferId) external {\\n```\\n\\nA compromised `Owner` of SocketGateway could then create a route that calls into the `CelerStorageWrapper` contract and updates the transfer IDs associated addresses to be under their control via `deleteTransferId()` and `setAddressForTransferId()` functions. This could create a significant drain of user funds, though, it depends on a compromised privileged `Owner` address.чAlthough it may indeed be unlikely, for aggregating solutions it is especially important to try and minimize compromised access issues. As future solutions require more complexity, consider architecting their integrations in such a way that they require as few administrative and SocketGateway-initiated transactions as possible. Through conversations with the Socket team, it appears that solutions such as timelocks on adding new routes are being considered as well, which would help catch the problem before it appears as well.чч```\\ncelerStorageWrapper.setAddressForTransferId(transferId, msg.sender);\\n```\\n
Dependency on Third-Party APIs to Create the Right PayloadчmediumчThe Socket system of routes and controllers integrates swaps, bridges, and potentially other solutions that are vastly different from each other. The function arguments that are required to execute them may often seem like a black box of a payload for a typical end user. In fact, even when users explicitly provide a destination `token` with an associated `amount` for a swap, these arguments themselves might not even be fully (or at all) used in the route itself. Instead, often the routes and controllers accept a `bytes` payload that contains all the necessary data for its action. These data payloads are generated off-chain, often via centralized APIs provided by the integrated systems themselves, which is understandable in isolation as they have to be generated somewhere at some point. However, the provided `bytes` do not get checked for their correctness or matching with the other arguments that the user explicitly provided. Even the events that get emitted refer to the individual arguments of functions as opposed to what actually was being used to execute the logic.\\nFor example, the implementation route for the 1inch swaps explicitly asks the user to provide `fromToken`, `toToken`, `amount`, and `receiverAddress`, however only `fromToken` and `amount` are used meaningfully to transfer the `amount` to the SocketGateway and approve the `fromToken` to be spent by the 1inch contract. Everything else is dictated by `swapExtraData`, including even the true `amount` that is getting swapped. A mishap in the API providing this data payload could cause much less of a token `amount` to be swapped, a wrong address to receive the swap, and even the wrong destination token to return.\\n```\\n// additional data is generated in off-chain using the OneInch API which takes in\\n// fromTokenAddress, toTokenAddress, amount, fromAddress, slippage, destReceiver, disableEstimate\\n(bool success, bytes memory result) = ONEINCH\\_AGGREGATOR.call(\\n    swapExtraData\\n);\\n```\\n\\nEven the event at the end of the transaction partially refers to the explicitly provided arguments instead of those that actually facilitated the execution of logic\\n```\\nemit SocketSwapTokens(\\n    fromToken,\\n    toToken,\\n    returnAmount,\\n    amount,\\n    OneInchIdentifier,\\n    receiverAddress\\n);\\n```\\n\\nAs Socket aggregates other solutions, it naturally incurs the trust assumptions and risks associated with its integrations. In some ways, they even stack on top of each other, especially in those Socket functions that batch several routes together – all of them and their associated API calls need to return the correct payloads. So, there is an opportunity to minimize these risks by introducing additional checks into the contracts that would verify the correctness of the payloads that are passed over to the routes and controllers. In fact, creating these payloads within the contracts would allow other systems to integrate Socket more simpler as they could just call the functions with primary logical arguments such as the source token, destination token, and amount.чConsider allocating additional checks within the route implementations that ensure that the explicitly passed arguments match what is being sent for execution to the integrated solutions, like in the above example with the 1inch implementation.чч```\\n// additional data is generated in off-chain using the OneInch API which takes in\\n// fromTokenAddress, toTokenAddress, amount, fromAddress, slippage, destReceiver, disableEstimate\\n(bool success, bytes memory result) = ONEINCH\\_AGGREGATOR.call(\\n    swapExtraData\\n);\\n```\\n
NativeOptimismImpl - Events Will Not Be Emitted in Case of Non-Native Tokens BridgingчmediumчIn the case of the usage of non-native tokens by users, the `SocketBridge` event will not be emitted since the code will return early.\\n```\\nfunction bridgeAfterSwap(\\n```\\n\\n```\\nfunction swapAndBridge(\\n```\\n\\n```\\nfunction bridgeERC20To(\\n```\\nчMake sure that the `SocketBridge` event is emitted for non-native tokens as well.чч```\\nfunction bridgeAfterSwap(\\n```\\n
Inconsistent CommentsчlowчSome of the contracts in the code have incorrect developer comments annotated for them. This could create confusion for future readers of this code that may be trying to maintain, audit, update, fork, integrate it, and so on.\\n```\\n/\\*\\*\\n \\* @notice function to bridge tokens after swap. This is used after swap function call\\n \\* @notice This method is payable because the caller is doing token transfer and briding operation\\n \\* @dev for usage, refer to controller implementations\\n \\* encodedData for bridge should follow the sequence of properties in Stargate-BridgeData struct\\n \\* @param swapId routeId for the swapImpl\\n \\* @param swapData encoded data for swap\\n \\* @param stargateBridgeData encoded data for StargateBridgeData\\n \\*/\\nfunction swapAndBridge(\\n```\\n\\nThis is the same comment as `bridgeAfterSwap`, whereas it instead does swapping and bridging together\\n```\\n/\\*\\*\\n \\* @notice function to store the transferId and message-sender of a bridging activity\\n \\* @notice This method is payable because the caller is doing token transfer and briding operation\\n \\* @dev for usage, refer to controller implementations\\n \\* encodedData for bridge should follow the sequence of properties in CelerBridgeData struct\\n \\* @param transferId transferId generated during the bridging of ERC20 or native on CelerBridge\\n \\* @param transferIdAddress message sender who is making the bridging on CelerBridge\\n \\*/\\nfunction setAddressForTransferId(\\n```\\n\\nThis comment refers to a payable property of this function when it isn't.\\n```\\n/\\*\\*\\n \\* @notice function to store the transferId and message-sender of a bridging activity\\n \\* @notice This method is payable because the caller is doing token transfer and briding operation\\n \\* @dev for usage, refer to controller implementations\\n \\* encodedData for bridge should follow the sequence of properties in CelerBridgeData struct\\n \\* @param transferId transferId generated during the bridging of ERC20 or native on CelerBridge\\n \\*/\\nfunction deleteTransferId(bytes32 transferId) external {\\n```\\n\\nThis comment is copied from the above function when it does the opposite of storing - it deletes the `transferId`чAdjust comments so they reflect what the functions are actually doing.чч```\\n/\\*\\*\\n \\* @notice function to bridge tokens after swap. This is used after swap function call\\n \\* @notice This method is payable because the caller is doing token transfer and briding operation\\n \\* @dev for usage, refer to controller implementations\\n \\* encodedData for bridge should follow the sequence of properties in Stargate-BridgeData struct\\n \\* @param swapId routeId for the swapImpl\\n \\* @param swapData encoded data for swap\\n \\* @param stargateBridgeData encoded data for StargateBridgeData\\n \\*/\\nfunction swapAndBridge(\\n```\\n
Unused Error Codes.чlowч`error RouteAlreadyExist();`\\n`error ContractContainsNoCode();`\\n`error ControllerAlreadyExist();`\\n`error ControllerAddressIsZero();`\\nIt seems that they were created as errors that may have been expected to occur during the early stages of development, but the resulting architecture doesn't seem to have a place for them currently.\\n```\\nerror RouteAlreadyExist();\\nerror SwapFailed();\\nerror UnsupportedInterfaceId();\\nerror ContractContainsNoCode();\\nerror InvalidCelerRefund();\\nerror CelerAlreadyRefunded();\\nerror ControllerAlreadyExist();\\nerror ControllerAddressIsZero();\\n```\\nчResolution\\nRemediated as per the client team in SocketDotTech/socket-ll-contracts#148.\\nConsider revisiting these errors and identifying whether they need to remain or can be removed.чч```\\nerror RouteAlreadyExist();\\nerror SwapFailed();\\nerror UnsupportedInterfaceId();\\nerror ContractContainsNoCode();\\nerror InvalidCelerRefund();\\nerror CelerAlreadyRefunded();\\nerror ControllerAlreadyExist();\\nerror ControllerAddressIsZero();\\n```\\n
Inaccurate Interface.чlowч`ISocketGateway` implies a `bridge(uint32 routeId, bytes memory data)` function, but there is no socket contract with a function like that, including the `SocketGateway` contract.\\n```\\nfunction bridge(\\n    uint32 routeId,\\n    bytes memory data\\n) external payable returns (bytes memory);\\n```\\nчAdjust the interface.чч```\\nfunction bridge(\\n    uint32 routeId,\\n    bytes memory data\\n) external payable returns (bytes memory);\\n```\\n
Validate Array Length Matching Before Execution to Avoid RevertsчlowчThe Socket system not only aggregates different solutions via its routes and controllers but also allows to batch calls between them into one transaction. For example, a user may call swaps between several DEXs and then perform a bridge transfer.\\nAs a result, the `SocketGateway` contract has many functions that accept multiple arrays that contain the necessary data for execution in their respective routes. However, these arrays need to be of the same length because individual elements in the arrays are intended to be matched at the same indices:\\n```\\nfunction executeRoutes(\\n    uint32[] calldata routeIds,\\n    bytes[] calldata dataItems,\\n    bytes[] calldata eventDataItems\\n) external payable {\\n    uint256 routeIdslength = routeIds.length;\\n    for (uint256 index = 0; index < routeIdslength; ) {\\n        (bool success, bytes memory result) = addressAt(routeIds[index])\\n            .delegatecall(dataItems[index]);\\n\\n        if (!success) {\\n            assembly {\\n                revert(add(result, 32), mload(result))\\n            }\\n        }\\n\\n        emit SocketRouteExecuted(routeIds[index], eventDataItems[index]);\\n\\n        unchecked {\\n            ++index;\\n        }\\n    }\\n}\\n```\\n\\nNote that in the above example function, all 3 different calldata arrays `routeIds`, `dataItems`, and `eventDataItems` were utilizing the same `index` to retrieve the correct element. A common practice in such cases is to confirm that the sizes of the arrays match before continuing with the execution of the rest of the transaction to avoid costly reverts that could happen due to “Index out of bounds” error.\\nDue to the aggregating and batching nature of the Socket system that may have its users rely on 3rd party offchain APIs to construct these array payloads, such as from APIs of the systems that Socket is integrating, a mishap in just any one of them could cause this issue.чImplement a check on the array lengths so they match.чч```\\nfunction executeRoutes(\\n    uint32[] calldata routeIds,\\n    bytes[] calldata dataItems,\\n    bytes[] calldata eventDataItems\\n) external payable {\\n    uint256 routeIdslength = routeIds.length;\\n    for (uint256 index = 0; index < routeIdslength; ) {\\n        (bool success, bytes memory result) = addressAt(routeIds[index])\\n            .delegatecall(dataItems[index]);\\n\\n        if (!success) {\\n            assembly {\\n                revert(add(result, 32), mload(result))\\n            }\\n        }\\n\\n        emit SocketRouteExecuted(routeIds[index], eventDataItems[index]);\\n\\n        unchecked {\\n            ++index;\\n        }\\n    }\\n}\\n```\\n
Destroyed Routes Eth Balances Will Be Left Locked in SocketDeployFactoryчlowч`SocketDeployFactory.destroy` calls the `killme` function which in turn self-destructs the route and sends back any eth to the factory contract. However, these funds can not be claimed from the `SocketDeployFactory` contract.\\n```\\nfunction destroy(uint256 routeId) external onlyDisabler {\\n```\\nчMake sure that these funds can be claimed.чч```\\nfunction destroy(uint256 routeId) external onlyDisabler {\\n```\\n
RocketNodeDistributorDelegate - Reentrancy in distribute() allows node owner to drain distributor fundsчhighчThe `distribute()` function distributes the contract's balance between the node operator and the user. The node operator is returned their initial collateral, including a fee. The rest is returned to the RETH token contract as user collateral.\\nAfter determining the node owner's share, the contract transfers `ETH` to the node withdrawal address, which can be the configured withdrawal address or the node address. Both addresses may potentially be a malicious contract that recursively calls back into the `distribute()` function to retrieve the node share multiple times until all funds are drained from the contract. The `distribute()` function is not protected against reentrancy:\\n```\\n/// @notice Distributes the balance of this contract to its owners\\nfunction distribute() override external {\\n    // Calculate node share\\n    uint256 nodeShare = getNodeShare();\\n    // Transfer node share\\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    (bool success,) = withdrawalAddress.call{value : nodeShare}(\"\");\\n    require(success);\\n    // Transfer user share\\n    uint256 userShare = address(this).balance;\\n    address rocketTokenRETH = rocketStorage.getAddress(rocketTokenRETHKey);\\n    payable(rocketTokenRETH).transfer(userShare);\\n    // Emit event\\n    emit FeesDistributed(nodeAddress, userShare, nodeShare, block.timestamp);\\n}\\n```\\n\\nWe also noticed that any address could set a withdrawal address as there is no check for the caller to be a registered node. In fact, the caller can be the withdrawal address or node operator.\\n```\\n// Set a node's withdrawal address\\nfunction setWithdrawalAddress(address \\_nodeAddress, address \\_newWithdrawalAddress, bool \\_confirm) external override {\\n    // Check new withdrawal address\\n    require(\\_newWithdrawalAddress != address(0x0), \"Invalid withdrawal address\");\\n    // Confirm the transaction is from the node's current withdrawal address\\n    address withdrawalAddress = getNodeWithdrawalAddress(\\_nodeAddress);\\n    require(withdrawalAddress == msg.sender, \"Only a tx from a node's withdrawal address can update it\");\\n    // Update immediately if confirmed\\n    if (\\_confirm) {\\n        updateWithdrawalAddress(\\_nodeAddress, \\_newWithdrawalAddress);\\n    }\\n    // Set pending withdrawal address if not confirmed\\n    else {\\n        pendingWithdrawalAddresses[\\_nodeAddress] = \\_newWithdrawalAddress;\\n    }\\n}\\n```\\nчResolution\\nFixed in https://github.com/rocket-pool/rocketpool/tree/77d7cca65b7c0557cfda078a4fc45f9ac0cc6cc6 by implementing a custom reentrancy guard via a new state variable `lock` that is appended to the end of the storage layout. The reentrancy guard is functionally equivalent to the OpenZeppelin implementation. The method was not refactored to give user funds priority over the node share. Additionally, the client provided the following statement:\\nWe acknowledge this as a critical issue and have solved with a reentrancy guard.\\nWe followed OpenZeppelin's design for a reentrancy guard. We were unable to use it directly as it is hardcoded to use storage slot 0 and because we already have deployment of this delegate in the wild already using storage slot 0 for another purpose, we had to append it to the end of the existing storage layout.\\nAdd a reentrancy guard to functions that interact with untrusted contracts. Adhere to the checks-effects pattern and send user funds to the ‘trusted' RETH contract first. Only then send funds to the node's withdrawal address.чч```\\n/// @notice Distributes the balance of this contract to its owners\\nfunction distribute() override external {\\n    // Calculate node share\\n    uint256 nodeShare = getNodeShare();\\n    // Transfer node share\\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    (bool success,) = withdrawalAddress.call{value : nodeShare}(\"\");\\n    require(success);\\n    // Transfer user share\\n    uint256 userShare = address(this).balance;\\n    address rocketTokenRETH = rocketStorage.getAddress(rocketTokenRETHKey);\\n    payable(rocketTokenRETH).transfer(userShare);\\n    // Emit event\\n    emit FeesDistributed(nodeAddress, userShare, nodeShare, block.timestamp);\\n}\\n```\\n
RocketMinipoolDelegateOld - Node operator may reenter finalise() to manipulate accountingчhighчIn the old Minipool delegate contract, a node operator may call the `finalise()` function to finalize a Minipool. As part of this process, a call to `_refund()` may be performed if there is a node refund balance to be transferred. This will send an amount of `nodeRefundBalance` in ETH to the `nodeWithdrawalAddress` via a low-level call, handing over control flow to an - in terms of the system - untrusted external account that this node operator controls. The node operator, therefore, is granted to opportunity to call back into `finalise()`, which is not protected against reentrancy and violates the checks-effects-interactions pattern (finalised = true is only set at the very end), to manipulate the following system settings:\\nnode.minipools.finalised.count<NodeAddress>: NodeAddress finalised count increased twice instead\\nminipools.finalised.count: global finalised count increased twice\\n`eth.matched.node.amount<NodeAddress>` - NodeAddress eth matched amount potentially reduced too many times; has an impact on `getNodeETHCollateralisationRatio -> GetNodeShare`, `getNodeETHProvided -> getNodeEffectiveRPLStake` and `getNodeETHProvided->getNodeMaximumRPLStake->withdrawRPL` and is the limiting factor when withdrawing RPL to ensure the pools stay collateralized.\\nNote: `RocketMinipoolDelegateOld` is assumed to be the currently deployed MiniPool implementation. Users may upgrade from this delegate to the new version and can roll back at any time and re-upgrade, even within the same transaction (see issue 5.3 ).\\nThe following is an annotated call stack from a node operator calling `minipool.finalise()` reentering `finalise()` once more on their Minipool:\\n```\\nfinalise() --> \\n  status == MinipoolStatus.Withdrawable  //<-- true\\n  withdrawalBlock > 0  //<-- true\\n  _finalise() -->\\n     !finalised  //<-- true\\n        _refund()\\n            nodeRefundBalance = 0  //<-- reset refund balance\\n              ---> extCall: nodeWithdrawalAddress\\n                     ---> reenter: finalise()\\n                        status == MinipoolStatus.Withdrawable  //<-- true\\n                        withdrawalBlock > 0  //<-- true\\n                        _finalise() -->\\n                             !finalised  //<-- true\\n                             nodeRefundBalance > 0  //<-- false; no refund()\\n                             address(this).balance to RETH\\n                             RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral()\\n                             rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress)  //<-- 1st time\\n                             eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress); \\n                             finalised = true;\\n                   <--- return from reentrant call\\n        <--- return from _refund()\\n     address(this).balance to RETH  //<-- NOP as balance was sent to RETH already\\n     RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral();   //<-- does not revert\\n     rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress);  //<-- no revert, increases\\n     'node.minipools.finalised.count', 'minipools.finalised.count', reduces 'eth.matched.node.amount' one to\\n     many times\\n     eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress);  //<-- manipulates\\n     'member.validator.unbonded.count' by +1\\n     finalised = true;  //<-- is already 'true', gracefully continues\\n<--- returns      \\n```\\n\\n```\\n// Called by node operator to finalise the pool and unlock their RPL stake\\nfunction finalise() external override onlyInitialised onlyMinipoolOwnerOrWithdrawalAddress(msg.sender) {\\n    // Can only call if withdrawable and can only be called once\\n    require(status == MinipoolStatus.Withdrawable, \"Minipool must be withdrawable\");\\n    // Node operator cannot finalise the pool unless distributeBalance has been called\\n    require(withdrawalBlock > 0, \"Minipool balance must have been distributed at least once\");\\n    // Finalise the pool\\n    \\_finalise();\\n}\\n```\\n\\n`_refund()` handing over control flow to `nodeWithdrawalAddress`\\n```\\n// Perform any slashings, refunds, and unlock NO's stake\\nfunction \\_finalise() private {\\n    // Get contracts\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    // Can only finalise the pool once\\n    require(!finalised, \"Minipool has already been finalised\");\\n    // If slash is required then perform it\\n    if (nodeSlashBalance > 0) {\\n        \\_slash();\\n    }\\n    // Refund node operator if required\\n    if (nodeRefundBalance > 0) {\\n        \\_refund();\\n    }\\n    // Send any left over ETH to rETH contract\\n    if (address(this).balance > 0) {\\n        // Send user amount to rETH contract\\n        payable(rocketTokenRETH).transfer(address(this).balance);\\n    }\\n    // Trigger a deposit of excess collateral from rETH contract to deposit pool\\n    RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral();\\n    // Unlock node operator's RPL\\n    rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress);\\n    // Update unbonded validator count if minipool is unbonded\\n    if (depositType == MinipoolDeposit.Empty) {\\n        RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\n        rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress);\\n    }\\n    // Set finalised flag\\n    finalised = true;\\n}\\n```\\n\\n```\\nfunction \\_refund() private {\\n    // Update refund balance\\n    uint256 refundAmount = nodeRefundBalance;\\n    nodeRefundBalance = 0;\\n    // Get node withdrawal address\\n    address nodeWithdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    // Transfer refund amount\\n    (bool success,) = nodeWithdrawalAddress.call{value : refundAmount}(\"\");\\n    require(success, \"ETH refund amount was not successfully transferred to node operator\");\\n    // Emit ether withdrawn event\\n    emit EtherWithdrawn(nodeWithdrawalAddress, refundAmount, block.timestamp);\\n}\\n```\\n\\nMethods adjusting system settings called twice:\\n```\\n// Increments \\_nodeAddress' number of minipools that have been finalised\\nfunction incrementNodeFinalisedMinipoolCount(address \\_nodeAddress) override external onlyLatestContract(\"rocketMinipoolManager\", address(this)) onlyRegisteredMinipool(msg.sender) {\\n    // Update the node specific count\\n    addUint(keccak256(abi.encodePacked(\"node.minipools.finalised.count\", \\_nodeAddress)), 1);\\n    // Update the total count\\n    addUint(keccak256(bytes(\"minipools.finalised.count\")), 1);\\n}\\n```\\n\\n```\\n}\\nfunction decrementMemberUnbondedValidatorCount(address \\_nodeAddress) override external onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) onlyRegisteredMinipool(msg.sender) {\\n    subUint(keccak256(abi.encodePacked(daoNameSpace, \"member.validator.unbonded.count\", \\_nodeAddress)), 1);\\n}\\n```\\nчWe recommend setting the `finalised = true` flag immediately after checking for it. Additionally, the function flow should adhere to the checks-effects-interactions pattern whenever possible. We recommend adding generic reentrancy protection whenever the control flow is handed to an untrusted entity.чч```\\nfinalise() --> \\n  status == MinipoolStatus.Withdrawable  //<-- true\\n  withdrawalBlock > 0  //<-- true\\n  _finalise() -->\\n     !finalised  //<-- true\\n        _refund()\\n            nodeRefundBalance = 0  //<-- reset refund balance\\n              ---> extCall: nodeWithdrawalAddress\\n                     ---> reenter: finalise()\\n                        status == MinipoolStatus.Withdrawable  //<-- true\\n                        withdrawalBlock > 0  //<-- true\\n                        _finalise() -->\\n                             !finalised  //<-- true\\n                             nodeRefundBalance > 0  //<-- false; no refund()\\n                             address(this).balance to RETH\\n                             RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral()\\n                             rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress)  //<-- 1st time\\n                             eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress); \\n                             finalised = true;\\n                   <--- return from reentrant call\\n        <--- return from _refund()\\n     address(this).balance to RETH  //<-- NOP as balance was sent to RETH already\\n     RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral();   //<-- does not revert\\n     rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress);  //<-- no revert, increases\\n     'node.minipools.finalised.count', 'minipools.finalised.count', reduces 'eth.matched.node.amount' one to\\n     many times\\n     eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress);  //<-- manipulates\\n     'member.validator.unbonded.count' by +1\\n     finalised = true;  //<-- is already 'true', gracefully continues\\n<--- returns      \\n```\\n
RocketMinipoolDelegate - Sandwiching of Minipool calls can have unintended side effectsчhighчThe `RocketMinipoolBase` contract exposes the functions `delegateUpgrade` and `delegateRollback`, allowing the minipool owner to switch between delegate implementations. While giving the minipool owner a chance to roll back potentially malfunctioning upgrades, the fact that upgrades and rollback are instantaneous also gives them a chance to alternate between executing old and new code (e.g. by utilizing callbacks) and sandwich user calls to the minipool.\\nAssuming the latest minipool delegate implementation, any user can call `RocketMinipoolDelegate.slash`, which slashes the node operator's RPL balance if a slashing has been recorded on their validator. To mark the minipool as having been `slashed`, the `slashed` contract variable is set to `true`. A minipool owner can avoid this flag from being set By sandwiching the user calls:\\nIn detail, the new slash implementation:\\n```\\nfunction \\_slash() private {\\n    // Get contracts\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    // Slash required amount and reset storage value\\n    uint256 slashAmount = nodeSlashBalance;\\n    nodeSlashBalance = 0;\\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\\n    // Record slashing\\n    slashed = true;\\n}\\n```\\n\\nCompared to the old slash implementation:\\n```\\nfunction \\_slash() private {\\n    // Get contracts\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    // Slash required amount and reset storage value\\n    uint256 slashAmount = nodeSlashBalance;\\n    nodeSlashBalance = 0;\\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\\n}\\n```\\n\\nWhile the bypass of `slashed` being set is a benign example, the effects of this issue, in general, could result in a significant disruption of minipool operations and potentially affect the system's funds. The impact highly depends on the changes introduced by future minipool upgrades.чWe recommend limiting upgrades and rollbacks to prevent minipool owners from switching implementations with an immediate effect. A time lock can fulfill this purpose when a minipool owner announces an upgrade to be done at a specific block. A warning can precede user-made calls that an upgrade is pending, and their interaction can have unintended side effects.чч```\\nfunction \\_slash() private {\\n    // Get contracts\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    // Slash required amount and reset storage value\\n    uint256 slashAmount = nodeSlashBalance;\\n    nodeSlashBalance = 0;\\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\\n    // Record slashing\\n    slashed = true;\\n}\\n```\\n
RocketDAONodeTrustedActions - No way to access ETH provided by non-member votes  AcknowledgedчhighчDAO members can challenge nodes to prove liveliness for free. Non-DAO members must provide `members.challenge.cost = 1 eth` to start a challenge. However, the provided challenge cost is locked within the contract instead of being returned or recycled as system collateral.\\n```\\n// In the event that the majority/all of members go offline permanently and no more proposals could be passed, a current member or a regular node can 'challenge' a DAO members node to respond\\n// If it does not respond in the given window, it can be removed as a member. The one who removes the member after the challenge isn't met, must be another node other than the proposer to provide some oversight\\n// This should only be used in an emergency situation to recover the DAO. Members that need removing when consensus is still viable, should be done via the 'kick' method.\\nfunction actionChallengeMake(address \\_nodeAddress) override external onlyTrustedNode(\\_nodeAddress) onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrustedActions\", address(this)) payable {\\n    // Load contracts\\n    RocketDAONodeTrustedInterface rocketDAONode = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\n    RocketDAONodeTrustedSettingsMembersInterface rocketDAONodeTrustedSettingsMembers = RocketDAONodeTrustedSettingsMembersInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMembers\"));\\n    // Members can challenge other members for free, but for a regular bonded node to challenge a DAO member, requires non-refundable payment to prevent spamming\\n    if(rocketDAONode.getMemberIsValid(msg.sender) != true) require(msg.value == rocketDAONodeTrustedSettingsMembers.getChallengeCost(), \"Non DAO members must pay ETH to challenge a members node\");\\n    // Can't challenge yourself duh\\n    require(msg.sender != \\_nodeAddress, \"You cannot challenge yourself\");\\n    // Is this member already being challenged?\\n```\\nчWe recommend locking the ETH inside the contract during the challenge process. If a challenge is refuted, we recommend feeding the locked value back into the system as protocol collateral. If the challenge succeeds and the node is kicked, it is assumed that the challenger will be repaid the amount they had to lock up to prove non-liveliness.чч```\\n// In the event that the majority/all of members go offline permanently and no more proposals could be passed, a current member or a regular node can 'challenge' a DAO members node to respond\\n// If it does not respond in the given window, it can be removed as a member. The one who removes the member after the challenge isn't met, must be another node other than the proposer to provide some oversight\\n// This should only be used in an emergency situation to recover the DAO. Members that need removing when consensus is still viable, should be done via the 'kick' method.\\nfunction actionChallengeMake(address \\_nodeAddress) override external onlyTrustedNode(\\_nodeAddress) onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrustedActions\", address(this)) payable {\\n    // Load contracts\\n    RocketDAONodeTrustedInterface rocketDAONode = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\n    RocketDAONodeTrustedSettingsMembersInterface rocketDAONodeTrustedSettingsMembers = RocketDAONodeTrustedSettingsMembersInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMembers\"));\\n    // Members can challenge other members for free, but for a regular bonded node to challenge a DAO member, requires non-refundable payment to prevent spamming\\n    if(rocketDAONode.getMemberIsValid(msg.sender) != true) require(msg.value == rocketDAONodeTrustedSettingsMembers.getChallengeCost(), \"Non DAO members must pay ETH to challenge a members node\");\\n    // Can't challenge yourself duh\\n    require(msg.sender != \\_nodeAddress, \"You cannot challenge yourself\");\\n    // Is this member already being challenged?\\n```\\n
Multiple checks-effects violationsчhighчThroughout the system, there are various violations of the checks-effects-interactions pattern where the contract state is updated after an external call. Since large parts of the Rocket Pool system's smart contracts are not guarded against reentrancy, the external call's recipient may reenter and potentially perform malicious actions that can impact the overall accounting and, thus, system funds.\\n`distributeToOwner()` sends the contract's balance to the node or the withdrawal address before clearing the internal accounting:\\n```\\n/// @notice Withdraw node balances from the minipool and close it. Only accepts calls from the owner\\nfunction close() override external onlyMinipoolOwner(msg.sender) onlyInitialised {\\n    // Check current status\\n    require(status == MinipoolStatus.Dissolved, \"The minipool can only be closed while dissolved\");\\n    // Distribute funds to owner\\n    distributeToOwner();\\n    // Destroy minipool\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    require(rocketMinipoolManager.getMinipoolExists(address(this)), \"Minipool already closed\");\\n    rocketMinipoolManager.destroyMinipool();\\n    // Clear state\\n    nodeDepositBalance = 0;\\n    nodeRefundBalance = 0;\\n    userDepositBalance = 0;\\n    userDepositBalanceLegacy = 0;\\n    userDepositAssignedTime = 0;\\n}\\n```\\n\\nThe withdrawal block should be set before any other contracts are called:\\n```\\n// Save block to prevent multiple withdrawals within a few blocks\\nwithdrawalBlock = block.number;\\n```\\n\\nThe `slashed` state should be set before any external calls are made:\\n```\\n/// @dev Slash node operator's RPL balance based on nodeSlashBalance\\nfunction \\_slash() private {\\n    // Get contracts\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    // Slash required amount and reset storage value\\n    uint256 slashAmount = nodeSlashBalance;\\n    nodeSlashBalance = 0;\\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\\n    // Record slashing\\n    slashed = true;\\n}\\n```\\n\\nIn the bond reducer, the accounting values should be cleared before any external calls are made:\\n```\\n// Get desired to amount\\nuint256 newBondAmount = getUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.value\", msg.sender)));\\nrequire(rocketNodeDeposit.isValidDepositAmount(newBondAmount), \"Invalid bond amount\");\\n// Calculate difference\\nuint256 existingBondAmount = minipool.getNodeDepositBalance();\\nuint256 delta = existingBondAmount.sub(newBondAmount);\\n// Get node address\\naddress nodeAddress = minipool.getNodeAddress();\\n// Increase ETH matched or revert if exceeds limit based on current RPL stake\\nrocketNodeDeposit.increaseEthMatched(nodeAddress, delta);\\n// Increase node operator's deposit credit\\nrocketNodeDeposit.increaseDepositCreditBalance(nodeAddress, delta);\\n// Clean up state\\ndeleteUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.time\", msg.sender)));\\ndeleteUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.value\", msg.sender)));\\n```\\n\\nThe counter for reward snapshot execution should be incremented before RPL gets minted:\\n```\\n// Execute inflation if required\\nrplContract.inflationMintTokens();\\n// Increment the reward index and update the claim interval timestamp\\nincrementRewardIndex();\\n```\\nчWe recommend following the checks-effects-interactions pattern and adjusting any contract state variables before making external calls. With the upgradeable nature of the system, we also recommend strictly adhering to this practice when all external calls are being made to trusted network contracts.чч```\\n/// @notice Withdraw node balances from the minipool and close it. Only accepts calls from the owner\\nfunction close() override external onlyMinipoolOwner(msg.sender) onlyInitialised {\\n    // Check current status\\n    require(status == MinipoolStatus.Dissolved, \"The minipool can only be closed while dissolved\");\\n    // Distribute funds to owner\\n    distributeToOwner();\\n    // Destroy minipool\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    require(rocketMinipoolManager.getMinipoolExists(address(this)), \"Minipool already closed\");\\n    rocketMinipoolManager.destroyMinipool();\\n    // Clear state\\n    nodeDepositBalance = 0;\\n    nodeRefundBalance = 0;\\n    userDepositBalance = 0;\\n    userDepositBalanceLegacy = 0;\\n    userDepositAssignedTime = 0;\\n}\\n```\\n
RocketMinipoolDelegate - Redundant refund() call on forced finalizationчmediumчThe `RocketMinipoolDelegate.refund` function will force finalization if a user previously distributed the pool. However, `_finalise` already calls `_refund()` if there is a node refund balance to transfer, making the additional call to `_refund()` in `refund()` obsolete.\\n```\\nfunction refund() override external onlyMinipoolOwnerOrWithdrawalAddress(msg.sender) onlyInitialised {\\n    // Check refund balance\\n    require(nodeRefundBalance > 0, \"No amount of the node deposit is available for refund\");\\n    // If this minipool was distributed by a user, force finalisation on the node operator\\n    if (!finalised && userDistributed) {\\n        \\_finalise();\\n    }\\n    // Refund node\\n    \\_refund();\\n}\\n```\\n\\n```\\nfunction \\_finalise() private {\\n    // Get contracts\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    // Can only finalise the pool once\\n    require(!finalised, \"Minipool has already been finalised\");\\n    // Set finalised flag\\n    finalised = true;\\n    // If slash is required then perform it\\n    if (nodeSlashBalance > 0) {\\n        \\_slash();\\n    }\\n    // Refund node operator if required\\n    if (nodeRefundBalance > 0) {\\n        \\_refund();\\n    }\\n```\\nчResolution\\nFixed in https://github.com/rocket-pool/rocketpool/tree/77d7cca65b7c0557cfda078a4fc45f9ac0cc6cc6 by refactoring `refund()` to avoid a double invocation of `_refund()` in the `_finalise()` codepath.\\nFixed per the recommendation. Thanks.\\nWe recommend refactoring the if condition to contain `_refund()` in the else branch.чч```\\nfunction refund() override external onlyMinipoolOwnerOrWithdrawalAddress(msg.sender) onlyInitialised {\\n    // Check refund balance\\n    require(nodeRefundBalance > 0, \"No amount of the node deposit is available for refund\");\\n    // If this minipool was distributed by a user, force finalisation on the node operator\\n    if (!finalised && userDistributed) {\\n        \\_finalise();\\n    }\\n    // Refund node\\n    \\_refund();\\n}\\n```\\n
Sparse documentation and accounting complexity  AcknowledgedчmediumчThroughout the project, inline documentation is either sparse or missing altogether. Furthermore, few technical documents about the system's design rationale are available. The recent releases' increased complexity makes it significantly harder to trace the flow of funds through the system as components change semantics, are split into separate contracts, etc.\\nIt is essential that documentation not only outlines what is being done but also why and what a function's role in the system's “bigger picture” is. Many comments in the code base fail to fulfill this requirement and are thus redundant, e.g.\\n```\\n// Sanity check that refund balance is zero\\nrequire(nodeRefundBalance == 0, \"Refund balance not zero\");\\n```\\n\\n```\\n// Remove from vacant set\\nrocketMinipoolManager.removeVacantMinipool();\\n```\\n\\n```\\nif (ownerCalling) {\\n    // Finalise the minipool if the owner is calling\\n    \\_finalise();\\n```\\n\\nThe increased complexity and lack of documentation can increase the likelihood of developer error. Furthermore, the time spent maintaining the code and introducing new developers to the code base will drastically increase. This effect can be especially problematic in the system's accounting of funds as the various stages of a Minipool imply different flows of funds and interactions with external dependencies. Documentation should explain the rationale behind specific hardcoded values, such as the magic `8 ether` boundary for withdrawal detection. An example of a lack of documentation and distribution across components is the calculation and influence of `ethMatched` as it plays a role in:\\nthe minipool bond reducer,\\nthe node deposit contract,\\nthe node manager, and\\nthe node staking contract.чAs the Rocketpool system grows in complexity, we highly recommend significantly increasing the number of inline comments and general technical documentation and exploring ways to centralize the system's accounting further to provide a clear picture of which funds move where and at what point in time. Where the flow of funds is obscured because multiple components or multi-step processes are involved, we recommend adding extensive inline documentation to give context.чч```\\n// Sanity check that refund balance is zero\\nrequire(nodeRefundBalance == 0, \"Refund balance not zero\");\\n```\\n
RocketNodeDistributor - Missing extcodesize check in dynamic proxy  Won't Fixчmediumч`RocketNodeDistributor` dynamically retrieves the currently set delegate from the centralized `RocketStorage` contract. The target contract (delegate) is resolved inside the fallback function. It may return `address(0)`. `rocketStorage.getAddress()` does not enforce that the requested settings key exists, which may lead to `RocketNodeDistributor` delegate-calling into `address(0)`, which returns no error. This might stay undetected when calling `RocketNodeDistributorDelegate.distribute()` as the method does not return a value, which is consistent with calling a target address with no code.\\n```\\nfallback() external payable {\\n    address \\_target = rocketStorage.getAddress(distributorStorageKey);\\n    assembly {\\n        calldatacopy(0x0, 0x0, calldatasize())\\n        let result := delegatecall(gas(), \\_target, 0x0, calldatasize(), 0x0, 0)\\n        returndatacopy(0x0, 0x0, returndatasize())\\n        switch result case 0 {revert(0, returndatasize())} default {return (0, returndatasize())}\\n    }\\n}\\n```\\n\\n```\\nfunction getAddress(bytes32 \\_key) override external view returns (address r) {\\n    return addressStorage[\\_key];\\n}\\n```\\nчBefore delegate-calling into the target contract, check if it exists.\\n```\\nassembly {\\n    codeSize := extcodesize(\\_target)\\n}\\nrequire(codeSize > 0);\\n```\\nчч```\\nfallback() external payable {\\n    address \\_target = rocketStorage.getAddress(distributorStorageKey);\\n    assembly {\\n        calldatacopy(0x0, 0x0, calldatasize())\\n        let result := delegatecall(gas(), \\_target, 0x0, calldatasize(), 0x0, 0)\\n        returndatacopy(0x0, 0x0, returndatasize())\\n        switch result case 0 {revert(0, returndatasize())} default {return (0, returndatasize())}\\n    }\\n}\\n```\\n
Kicked oDAO members' votes taken into account  AcknowledgedчmediumчoDAO members can vote on proposals or submit external data to the system, acting as an oracle. Data submission is based on a vote by itself, and multiple oDAO members must submit the same data until a configurable threshold (51% by default) is reached for the data to be confirmed.\\nWhen a member gets kicked or leaves the oDAO after voting, their vote is still accounted for while the total number of oDAO members decreases.\\nA (group of) malicious oDAO actors may exploit this fact to artificially lower the consensus threshold by voting for a proposal and then leaving the oDAO. This will leave excess votes with the proposal while the total member count decreases.\\nFor example, let's assume there are 17 oDAO members. 9 members must vote for the proposal for it to pass (52.9%). Let's assume 8 members voted for, and the rest abstained and is against the proposal (47%, threshold not met). The proposal is unlikely to pass unless two malicious oDAO members leave the DAO, lowering the member count to 15 in an attempt to manipulate the vote, suddenly inflating vote power from 8/17 (47%; rejected) to 8/15 (53.3%; passed).\\nThe crux is that the votes of ex-oDAO members still count, while the quorum is based on the current oDAO member number.\\nHere are some examples, however, this is a general pattern used for oDAO votes in the system.\\nExample: RocketNetworkPrices\\nMembers submit votes via `submitPrices()`. If the threshold is reached, the proposal is executed. Quorum is based on the current oDAO member count, votes of ex-oDAO members are still accounted for. If a proposal is a near miss, malicious actors can force execute it by leaving the oDAO, lowering the threshold, and then calling `executeUpdatePrices()` to execute it.\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    // Update the price\\n    updatePrices(\\_block, \\_rplPrice);\\n}\\n```\\n\\n```\\nfunction executeUpdatePrices(uint256 \\_block, uint256 \\_rplPrice) override external onlyLatestContract(\"rocketNetworkPrices\", address(this)) {\\n    // Check settings\\n```\\n\\nRocketMinipoolBondReducer\\nThe `RocketMinipoolBondReducer` contract's `voteCancelReduction` function takes old votes of previously kicked oDAO members into account. This results in the vote being significantly higher and increases the potential for malicious actors, even after their removal, to sway the vote. Note that a canceled bond reduction cannot be undone.\\n```\\nRocketDAONodeTrustedSettingsMinipoolInterface rocketDAONodeTrustedSettingsMinipool = RocketDAONodeTrustedSettingsMinipoolInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMinipool\"));\\nuint256 quorum = rocketDAONode.getMemberCount().mul(rocketDAONodeTrustedSettingsMinipool.getCancelBondReductionQuorum()).div(calcBase);\\nbytes32 totalCancelVotesKey = keccak256(abi.encodePacked(\"minipool.bond.reduction.vote.count\", \\_minipoolAddress));\\nuint256 totalCancelVotes = getUint(totalCancelVotesKey).add(1);\\nif (totalCancelVotes > quorum) {\\n```\\n\\nRocketNetworkPenalties\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodePenaltyThreshold()) {\\n    setBool(executedKey, true);\\n    incrementMinipoolPenaltyCount(\\_minipoolAddress);\\n}\\n```\\n\\n```\\n// Executes incrementMinipoolPenaltyCount if consensus threshold is reached\\nfunction executeUpdatePenalty(address \\_minipoolAddress, uint256 \\_block) override external onlyLatestContract(\"rocketNetworkPenalties\", address(this)) {\\n    // Get contracts\\n    RocketDAOProtocolSettingsNetworkInterface rocketDAOProtocolSettingsNetwork = RocketDAOProtocolSettingsNetworkInterface(getContractAddress(\"rocketDAOProtocolSettingsNetwork\"));\\n    // Get submission keys\\n```\\nчTrack oDAO members' votes and remove them from the tally when the removal from the oDAO is executed.чч```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    // Update the price\\n    updatePrices(\\_block, \\_rplPrice);\\n}\\n```\\n
RocketDAOProtocolSettingsRewards - settings key collission  AcknowledgedчmediumчA malicious user may craft a DAO protocol proposal to set a rewards claimer for a specific contract, thus overwriting another contract's settings. This issue arises due to lax requirements when choosing safe settings keys.\\n```\\nfunction setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\\n    // Get the total perc set, can't be more than 100\\n    uint256 percTotal = getRewardsClaimersPercTotal();\\n    // If this group already exists, it will update the perc\\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\\n    // Can't be more than a total claim amount of 100%\\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\\n    // Update the total\\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\\n    // Update/Add the claimer amount\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\\n    // Set the time it was updated at\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\\n}\\n```\\n\\nThe method updates the rewards claimer for a specific contract by writing to the following two setting keys:\\n`settingNameSpace.rewards.claimsgroup.amount<_contractName>`\\n`settingNameSpace.rewards.claimsgroup.amount.updated.time<_contractName>`\\nDue to the way the settings hierarchy was chosen in this case, a malicious proposal might define a `<_contractName> = .updated.time<targetContract>` that overwrites the settings of a different contract with an invalid value.\\nNote that the issue of delimiter consistency is also discussed in issue 5.12.\\nThe severity rating is based on the fact that this should be detectable by DAO members. However, following a defense-in-depth approach means that such collisions should be avoided wherever possible.чWe recommend enforcing a unique prefix and delimiter when concatenating user-provided input to setting keys. In this specific case, the settings could be renamed as follows:\\n`settingNameSpace.rewards.claimsgroup.amount.value<_contractName>`\\n`settingNameSpace.rewards.claimsgroup.amount.updated.time<_contractName>`чч```\\nfunction setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\\n    // Get the total perc set, can't be more than 100\\n    uint256 percTotal = getRewardsClaimersPercTotal();\\n    // If this group already exists, it will update the perc\\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\\n    // Can't be more than a total claim amount of 100%\\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\\n    // Update the total\\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\\n    // Update/Add the claimer amount\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\\n    // Set the time it was updated at\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\\n}\\n```\\n
RocketDAOProtocolSettingsRewards - missing setting delimiters  AcknowledgedчmediumчSettings in the Rocket Pool system are hierarchical, and namespaces are prefixed using dot delimiters.\\nCalling `abi.encodePacked(<string>, <string>)` on strings performs a simple concatenation. According to the settings' naming scheme, it is suggested that the following example writes to a key named: `<settingNameSpace>.rewards.claims.group.amount.<_contractName>`. However, due to missing delimiters, the actual key written to is: `<settingNameSpace>.rewards.claimsgroup.amount<_contractName>`.\\nNote that there is no delimiter between `claims|group` and `amount|<_contractName>`.\\n```\\nfunction setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\\n    // Get the total perc set, can't be more than 100\\n    uint256 percTotal = getRewardsClaimersPercTotal();\\n    // If this group already exists, it will update the perc\\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\\n    // Can't be more than a total claim amount of 100%\\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\\n    // Update the total\\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\\n    // Update/Add the claimer amount\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\\n    // Set the time it was updated at\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\\n}\\n```\\nчWe recommend adding the missing intermediate delimiters. The system should enforce delimiters after the last setting key before user input is concatenated to reduce the risk of accidental namespace collisions.чч```\\nfunction setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\\n    // Get the total perc set, can't be more than 100\\n    uint256 percTotal = getRewardsClaimersPercTotal();\\n    // If this group already exists, it will update the perc\\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\\n    // Can't be more than a total claim amount of 100%\\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\\n    // Update the total\\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\\n    // Update/Add the claimer amount\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\\n    // Set the time it was updated at\\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\\n}\\n```\\n
Use of address instead of specific contract types  AcknowledgedчlowчRather than using a low-level `address` type and then casting to the safer contract type, it's better to use the best type available by default so the compiler can eventually check for type safety and contract existence and only downcast to less secure low-level types (address) when necessary.\\n`RocketStorageInterface _rocketStorage` should be declared in the arguments, removing the need to cast the address explicitly.\\n```\\n/// @notice Sets up starting delegate contract and then delegates initialisation to it\\nfunction initialise(address \\_rocketStorage, address \\_nodeAddress) external override notSelf {\\n    // Check input\\n    require(\\_nodeAddress != address(0), \"Invalid node address\");\\n    require(storageState == StorageState.Undefined, \"Already initialised\");\\n    // Set storage state to uninitialised\\n    storageState = StorageState.Uninitialised;\\n    // Set rocketStorage\\n    rocketStorage = RocketStorageInterface(\\_rocketStorage);\\n```\\n\\n`RocketMinipoolInterface _minipoolAddress` should be declared in the arguments, removing the need to cast the address explicitly. Downcast to low-level address if needed. The event can be redeclared with the contract type.\\n```\\nfunction beginReduceBondAmount(address \\_minipoolAddress, uint256 \\_newBondAmount) override external onlyLatestContract(\"rocketMinipoolBondReducer\", address(this)) {\\n    RocketMinipoolInterface minipool = RocketMinipoolInterface(\\_minipoolAddress);\\n```\\n\\n```\\n/// @notice Returns whether owner of given minipool can reduce bond amount given the waiting period constraint\\n/// @param \\_minipoolAddress Address of the minipool\\nfunction canReduceBondAmount(address \\_minipoolAddress) override public view returns (bool) {\\n    RocketMinipoolInterface minipool = RocketMinipoolInterface(\\_minipoolAddress);\\n    RocketDAONodeTrustedSettingsMinipoolInterface rocketDAONodeTrustedSettingsMinipool = RocketDAONodeTrustedSettingsMinipoolInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMinipool\"));\\n    uint256 reduceBondTime = getUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.time\", \\_minipoolAddress)));\\n    return rocketDAONodeTrustedSettingsMinipool.isWithinBondReductionWindow(block.timestamp.sub(reduceBondTime));\\n}\\n```\\n\\n```\\nfunction voteCancelReduction(address \\_minipoolAddress) override external onlyTrustedNode(msg.sender) onlyLatestContract(\"rocketMinipoolBondReducer\", address(this)) {\\n    // Prevent calling if consensus has already been reached\\n    require(!getReduceBondCancelled(\\_minipoolAddress), \"Already cancelled\");\\n    // Get contracts\\n    RocketMinipoolInterface minipool = RocketMinipoolInterface(\\_minipoolAddress);\\n```\\n\\nNote that `abi.encode*(contractType)` assumes `address` for contract types by default. An explicit downcast is not required.\\n```\\n »  Test example = Test(0x5B38Da6a701c568545dCfcB03FcB875f56beddC4)\\n »  abi.encodePacked(\"hi\", example)\\n0x68695b38da6a701c568545dcfcb03fcb875f56beddc4\\n »  abi.encodePacked(\"hi\", address(example))\\n0x68695b38da6a701c568545dcfcb03fcb875f56beddc4\\n```\\n\\nMore examples of `address _minipool` declarations:\\n```\\n/// @dev Internal logic to set a minipool's pubkey\\n/// @param \\_pubkey The pubkey to set for the calling minipool\\nfunction \\_setMinipoolPubkey(address \\_minipool, bytes calldata \\_pubkey) private {\\n    // Load contracts\\n    AddressSetStorageInterface addressSetStorage = AddressSetStorageInterface(getContractAddress(\"addressSetStorage\"));\\n    // Initialize minipool & get properties\\n    RocketMinipoolInterface minipool = RocketMinipoolInterface(\\_minipool);\\n```\\n\\n```\\nfunction getMinipoolDetails(address \\_minipoolAddress) override external view returns (MinipoolDetails memory) {\\n    // Get contracts\\n    RocketMinipoolInterface minipoolInterface = RocketMinipoolInterface(\\_minipoolAddress);\\n    RocketMinipoolBase minipool = RocketMinipoolBase(payable(\\_minipoolAddress));\\n    RocketNetworkPenaltiesInterface rocketNetworkPenalties = RocketNetworkPenaltiesInterface(getContractAddress(\"rocketNetworkPenalties\"));\\n```\\n\\nMore examples of `RocketStorageInterface _rocketStorage` casts:\\n```\\ncontract RocketNodeDistributor is RocketNodeDistributorStorageLayout {\\n    bytes32 immutable distributorStorageKey;\\n\\n    constructor(address \\_nodeAddress, address \\_rocketStorage) {\\n        rocketStorage = RocketStorageInterface(\\_rocketStorage);\\n        nodeAddress = \\_nodeAddress;\\n```\\nчWe recommend using more specific types instead of `address` where possible. Downcast if necessary. This goes for parameter types as well as state variable types.чч```\\n/// @notice Sets up starting delegate contract and then delegates initialisation to it\\nfunction initialise(address \\_rocketStorage, address \\_nodeAddress) external override notSelf {\\n    // Check input\\n    require(\\_nodeAddress != address(0), \"Invalid node address\");\\n    require(storageState == StorageState.Undefined, \"Already initialised\");\\n    // Set storage state to uninitialised\\n    storageState = StorageState.Uninitialised;\\n    // Set rocketStorage\\n    rocketStorage = RocketStorageInterface(\\_rocketStorage);\\n```\\n
Redundant double casts  Acknowledgedчlowч`_rocketStorageAddress` is already of contract type `RocketStorageInterface`.\\n```\\n/// @dev Set the main Rocket Storage address\\nconstructor(RocketStorageInterface \\_rocketStorageAddress) {\\n    // Update the contract address\\n    rocketStorage = RocketStorageInterface(\\_rocketStorageAddress);\\n}\\n```\\n\\n`_tokenAddress` is already of contract type `ERC20Burnable`.\\n```\\nfunction burnToken(ERC20Burnable \\_tokenAddress, uint256 \\_amount) override external onlyLatestNetworkContract {\\n    // Get contract key\\n    bytes32 contractKey = keccak256(abi.encodePacked(getContractName(msg.sender), \\_tokenAddress));\\n    // Update balances\\n    tokenBalances[contractKey] = tokenBalances[contractKey].sub(\\_amount);\\n    // Get the token ERC20 instance\\n    ERC20Burnable tokenContract = ERC20Burnable(\\_tokenAddress);\\n```\\n\\n`_rocketTokenRPLFixedSupplyAddress` is already of contract type `IERC20`.\\n```\\nconstructor(RocketStorageInterface \\_rocketStorageAddress, IERC20 \\_rocketTokenRPLFixedSupplyAddress) RocketBase(\\_rocketStorageAddress) ERC20(\"Rocket Pool Protocol\", \"RPL\") {\\n    // Version\\n    version = 1;\\n    // Set the mainnet RPL fixed supply token address\\n    rplFixedSupplyContract = IERC20(\\_rocketTokenRPLFixedSupplyAddress);\\n```\\nчWe recommend removing the unnecessary double casts and copies of local variables.чч```\\n/// @dev Set the main Rocket Storage address\\nconstructor(RocketStorageInterface \\_rocketStorageAddress) {\\n    // Update the contract address\\n    rocketStorage = RocketStorageInterface(\\_rocketStorageAddress);\\n}\\n```\\n
RocketMinipoolDelegate - Missing event in prepareVacancyчlowчThe function `prepareVacancy` updates multiple contract state variables and should therefore emit an event.\\n```\\n/// @dev Sets the bond value and vacancy flag on this minipool\\n/// @param \\_bondAmount The bond amount selected by the node operator\\n/// @param \\_currentBalance The current balance of the validator on the beaconchain (will be checked by oDAO and scrubbed if not correct)\\nfunction prepareVacancy(uint256 \\_bondAmount, uint256 \\_currentBalance) override external onlyLatestContract(\"rocketMinipoolManager\", msg.sender) onlyInitialised {\\n    // Check status\\n    require(status == MinipoolStatus.Initialised, \"Must be in initialised status\");\\n    // Sanity check that refund balance is zero\\n    require(nodeRefundBalance == 0, \"Refund balance not zero\");\\n    // Check balance\\n    RocketDAOProtocolSettingsMinipoolInterface rocketDAOProtocolSettingsMinipool = RocketDAOProtocolSettingsMinipoolInterface(getContractAddress(\"rocketDAOProtocolSettingsMinipool\"));\\n    uint256 launchAmount = rocketDAOProtocolSettingsMinipool.getLaunchBalance();\\n    require(\\_currentBalance >= launchAmount, \"Balance is too low\");\\n    // Store bond amount\\n    nodeDepositBalance = \\_bondAmount;\\n    // Calculate user amount from launch amount\\n    userDepositBalance = launchAmount.sub(nodeDepositBalance);\\n    // Flag as vacant\\n    vacant = true;\\n    preMigrationBalance = \\_currentBalance;\\n    // Refund the node whatever rewards they have accrued prior to becoming a RP validator\\n    nodeRefundBalance = \\_currentBalance.sub(launchAmount);\\n    // Set status to preLaunch\\n    setStatus(MinipoolStatus.Prelaunch);\\n}\\n```\\nчEmit the missing event.чч```\\n/// @dev Sets the bond value and vacancy flag on this minipool\\n/// @param \\_bondAmount The bond amount selected by the node operator\\n/// @param \\_currentBalance The current balance of the validator on the beaconchain (will be checked by oDAO and scrubbed if not correct)\\nfunction prepareVacancy(uint256 \\_bondAmount, uint256 \\_currentBalance) override external onlyLatestContract(\"rocketMinipoolManager\", msg.sender) onlyInitialised {\\n    // Check status\\n    require(status == MinipoolStatus.Initialised, \"Must be in initialised status\");\\n    // Sanity check that refund balance is zero\\n    require(nodeRefundBalance == 0, \"Refund balance not zero\");\\n    // Check balance\\n    RocketDAOProtocolSettingsMinipoolInterface rocketDAOProtocolSettingsMinipool = RocketDAOProtocolSettingsMinipoolInterface(getContractAddress(\"rocketDAOProtocolSettingsMinipool\"));\\n    uint256 launchAmount = rocketDAOProtocolSettingsMinipool.getLaunchBalance();\\n    require(\\_currentBalance >= launchAmount, \"Balance is too low\");\\n    // Store bond amount\\n    nodeDepositBalance = \\_bondAmount;\\n    // Calculate user amount from launch amount\\n    userDepositBalance = launchAmount.sub(nodeDepositBalance);\\n    // Flag as vacant\\n    vacant = true;\\n    preMigrationBalance = \\_currentBalance;\\n    // Refund the node whatever rewards they have accrued prior to becoming a RP validator\\n    nodeRefundBalance = \\_currentBalance.sub(launchAmount);\\n    // Set status to preLaunch\\n    setStatus(MinipoolStatus.Prelaunch);\\n}\\n```\\n
RocketMinipool - Inconsistent access control modifier declaration onlyMinipoolOwner  AcknowledgedчlowчThe access control modifier `onlyMinipoolOwner` should be renamed to `onlyMinipoolOwnerOrWithdrawalAddress` to be consistent with the actual check permitting the owner or the withdrawal address to interact with the function. This would also be consistent with other declarations in the codebase.\\nExample\\nThe `onlyMinipoolOwner` modifier in `RocketMinipoolBase` is the same as `onlyMinipoolOwnerOrWithdrawalAddress` in other modules.\\n```\\n/// @dev Only allow access from the owning node address\\nmodifier onlyMinipoolOwner() {\\n    // Only the node operator can upgrade\\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    require(msg.sender == nodeAddress || msg.sender == withdrawalAddress, \"Only the node operator can access this method\");\\n    \\_;\\n}\\n```\\n\\n```\\n// Only allow access from the owning node address\\nmodifier onlyMinipoolOwner() {\\n    // Only the node operator can upgrade\\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    require(msg.sender == nodeAddress || msg.sender == withdrawalAddress, \"Only the node operator can access this method\");\\n    \\_;\\n}\\n```\\n\\nOther declarations:\\n```\\n/// @dev Only allow access from the owning node address\\nmodifier onlyMinipoolOwner(address \\_nodeAddress) {\\n    require(\\_nodeAddress == nodeAddress, \"Invalid minipool owner\");\\n    \\_;\\n}\\n\\n/// @dev Only allow access from the owning node address or their withdrawal address\\nmodifier onlyMinipoolOwnerOrWithdrawalAddress(address \\_nodeAddress) {\\n    require(\\_nodeAddress == nodeAddress || \\_nodeAddress == rocketStorage.getNodeWithdrawalAddress(nodeAddress), \"Invalid minipool owner\");\\n    \\_;\\n}\\n```\\n\\n```\\n// Only allow access from the owning node address\\nmodifier onlyMinipoolOwner(address \\_nodeAddress) {\\n    require(\\_nodeAddress == nodeAddress, \"Invalid minipool owner\");\\n    \\_;\\n}\\n\\n// Only allow access from the owning node address or their withdrawal address\\nmodifier onlyMinipoolOwnerOrWithdrawalAddress(address \\_nodeAddress) {\\n    require(\\_nodeAddress == nodeAddress || \\_nodeAddress == rocketStorage.getNodeWithdrawalAddress(nodeAddress), \"Invalid minipool owner\");\\n    \\_;\\n}\\n```\\nчResolution\\nAcknowledged by the client. Not addressed within rocket-pool/[email protected]77d7cca\\nAgreed. This would change a lot of contracts just for a minor improvement in readbility.\\nWe recommend renaming `RocketMinipoolBase.onlyMinipoolOwner` to `RocketMinipoolBase.onlyMinipoolOwnerOrWithdrawalAddress`.чч```\\n/// @dev Only allow access from the owning node address\\nmodifier onlyMinipoolOwner() {\\n    // Only the node operator can upgrade\\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\\n    require(msg.sender == nodeAddress || msg.sender == withdrawalAddress, \"Only the node operator can access this method\");\\n    \\_;\\n}\\n```\\n
RocketDAO*Settings - settingNameSpace should be immutable  AcknowledgedчlowчThe `settingNameSpace` in the abstract contract `RocketDAONodeTrustedSettings` is only set on contract deployment. Hence, the fields should be declared immutable to make clear that the settings namespace cannot change after construction.\\n`RocketDAONodeTrustedSettings`\\n```\\n// The namespace for a particular group of settings\\nbytes32 settingNameSpace;\\n```\\n\\n```\\n// Construct\\nconstructor(RocketStorageInterface \\_rocketStorageAddress, string memory \\_settingNameSpace) RocketBase(\\_rocketStorageAddress) {\\n    // Apply the setting namespace\\n    settingNameSpace = keccak256(abi.encodePacked(\"dao.trustednodes.setting.\", \\_settingNameSpace));\\n}\\n```\\n\\n`RocketDAOProtocolSettings`\\n```\\n// The namespace for a particular group of settings\\nbytes32 settingNameSpace;\\n```\\n\\n```\\n// Construct\\nconstructor(RocketStorageInterface \\_rocketStorageAddress, string memory \\_settingNameSpace) RocketBase(\\_rocketStorageAddress) {\\n    // Apply the setting namespace\\n    settingNameSpace = keccak256(abi.encodePacked(\"dao.protocol.setting.\", \\_settingNameSpace));\\n}\\n```\\n\\n```\\nconstructor(RocketStorageInterface \\_rocketStorageAddress) RocketDAOProtocolSettings(\\_rocketStorageAddress, \"auction\") {\\n    // Set version\\n    version = 1;\\n```\\nчWe recommend using the `immutable` annotation in Solidity (see Immutable).чч```\\n// The namespace for a particular group of settings\\nbytes32 settingNameSpace;\\n```\\n
Kicked oDAO members' votes taken into account  AcknowledgedчmediumчoDAO members can vote on proposals or submit external data to the system, acting as an oracle. Data submission is based on a vote by itself, and multiple oDAO members must submit the same data until a configurable threshold (51% by default) is reached for the data to be confirmed.\\nWhen a member gets kicked or leaves the oDAO after voting, their vote is still accounted for while the total number of oDAO members decreases.\\nA (group of) malicious oDAO actors may exploit this fact to artificially lower the consensus threshold by voting for a proposal and then leaving the oDAO. This will leave excess votes with the proposal while the total member count decreases.\\nFor example, let's assume there are 17 oDAO members. 9 members must vote for the proposal for it to pass (52.9%). Let's assume 8 members voted for, and the rest abstained and is against the proposal (47%, threshold not met). The proposal is unlikely to pass unless two malicious oDAO members leave the DAO, lowering the member count to 15 in an attempt to manipulate the vote, suddenly inflating vote power from 8/17 (47%; rejected) to 8/15 (53.3%; passed).\\nThe crux is that the votes of ex-oDAO members still count, while the quorum is based on the current oDAO member number.\\nHere are some examples, however, this is a general pattern used for oDAO votes in the system.\\nExample: RocketNetworkPrices\\nMembers submit votes via `submitPrices()`. If the threshold is reached, the proposal is executed. Quorum is based on the current oDAO member count, votes of ex-oDAO members are still accounted for. If a proposal is a near miss, malicious actors can force execute it by leaving the oDAO, lowering the threshold, and then calling `executeUpdatePrices()` to execute it.\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n // Update the price\\n updatePrices(\\_block, \\_rplPrice);\\n}\\n```\\n\\n```\\nfunction executeUpdatePrices(uint256 \\_block, uint256 \\_rplPrice) override external onlyLatestContract(\"rocketNetworkPrices\", address(this)) {\\n // Check settings\\n```\\n\\nRocketMinipoolBondReducer\\nThe `RocketMinipoolBondReducer` contract's `voteCancelReduction` function takes old votes of previously kicked oDAO members into account. This results in the vote being significantly higher and increases the potential for malicious actors, even after their removal, to sway the vote. Note that a canceled bond reduction cannot be undone.\\n```\\nRocketDAONodeTrustedSettingsMinipoolInterface rocketDAONodeTrustedSettingsMinipool = RocketDAONodeTrustedSettingsMinipoolInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMinipool\"));\\nuint256 quorum = rocketDAONode.getMemberCount().mul(rocketDAONodeTrustedSettingsMinipool.getCancelBondReductionQuorum()).div(calcBase);\\nbytes32 totalCancelVotesKey = keccak256(abi.encodePacked(\"minipool.bond.reduction.vote.count\", \\_minipoolAddress));\\nuint256 totalCancelVotes = getUint(totalCancelVotesKey).add(1);\\nif (totalCancelVotes > quorum) {\\n```\\n\\nRocketNetworkPenalties\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodePenaltyThreshold()) {\\n setBool(executedKey, true);\\n incrementMinipoolPenaltyCount(\\_minipoolAddress);\\n}\\n```\\n\\n```\\n// Executes incrementMinipoolPenaltyCount if consensus threshold is reached\\nfunction executeUpdatePenalty(address \\_minipoolAddress, uint256 \\_block) override external onlyLatestContract(\"rocketNetworkPenalties\", address(this)) {\\n // Get contracts\\n RocketDAOProtocolSettingsNetworkInterface rocketDAOProtocolSettingsNetwork = RocketDAOProtocolSettingsNetworkInterface(getContractAddress(\"rocketDAOProtocolSettingsNetwork\"));\\n // Get submission keys\\n```\\nчTrack oDAO members' votes and remove them from the tally when the removal from the oDAO is executed.чч```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n // Update the price\\n updatePrices(\\_block, \\_rplPrice);\\n}\\n```\\n
didTransferShares function has no access control modifierчhighчThe staked tokens (shares) in Forta are meant to be transferable. Similarly, the rewards allocation for these shares for delegated staking is meant to be transferable as well. This allocation for the shares' owner is tracked in the `StakeAllocator`. To enable this, the Forta staking contract `FortaStaking` implements a `_beforeTokenTransfer()` function that calls `_allocator.didTransferShares()` when it is appropriate to transfer the underlying allocation.\\n```\\nfunction \\_beforeTokenTransfer(\\n    address operator,\\n    address from,\\n    address to,\\n    uint256[] memory ids,\\n    uint256[] memory amounts,\\n    bytes memory data\\n) internal virtual override {\\n    for (uint256 i = 0; i < ids.length; i++) {\\n        if (FortaStakingUtils.isActive(ids[i])) {\\n            uint8 subjectType = FortaStakingUtils.subjectTypeOfShares(ids[i]);\\n            if (subjectType == DELEGATOR\\_NODE\\_RUNNER\\_SUBJECT && to != address(0) && from != address(0)) {\\n                \\_allocator.didTransferShares(ids[i], subjectType, from, to, amounts[i]);\\n            }\\n```\\n\\nDue to this, the `StakeAllocator.didTransferShares()` has an `external` visibility so it can be called from the `FortaStaking` contract to perform transfers. However, there is no access control modifier to allow only the staking contract to call this. Therefore, anyone can call this function with whatever parameters they want.\\n```\\nfunction didTransferShares(\\n    uint256 sharesId,\\n    uint8 subjectType,\\n    address from,\\n    address to,\\n    uint256 sharesAmount\\n) external {\\n    \\_rewardsDistributor.didTransferShares(sharesId, subjectType, from, to, sharesAmount);\\n}\\n```\\n\\nSince the allocation isn't represented as a token standard and is tracked directly in the `StakeAllocator` and `RewardsDistributor`, it lacks many standard checks that would prevent abuse of the function. For example, this function does not have a check for allowance or `msg.sender==from`, so any user could call `didTransferShares()` with `to` being their address and `from` being any address they want `to` transfer allocation `from`, and the call would succeed.чApply access control modifiers as appropriate for this contract, for example `onlyRole()`.чч```\\nfunction \\_beforeTokenTransfer(\\n    address operator,\\n    address from,\\n    address to,\\n    uint256[] memory ids,\\n    uint256[] memory amounts,\\n    bytes memory data\\n) internal virtual override {\\n    for (uint256 i = 0; i < ids.length; i++) {\\n        if (FortaStakingUtils.isActive(ids[i])) {\\n            uint8 subjectType = FortaStakingUtils.subjectTypeOfShares(ids[i]);\\n            if (subjectType == DELEGATOR\\_NODE\\_RUNNER\\_SUBJECT && to != address(0) && from != address(0)) {\\n                \\_allocator.didTransferShares(ids[i], subjectType, from, to, amounts[i]);\\n            }\\n```\\n
Incorrect reward epoch start date calculationчhighчThe Forta rewards system is based on epochs. A privileged address with the role `REWARDER_ROLE` calls the `reward()` function with a parameter for a specific `epochNumber` that consequently distributes the rewards for that epoch. Additionally, as users stake and delegate their stake, accounts in the Forta system accrue weight that is based on the active stake to distribute these rewards. Since accounts can modify their stake as well as delegate or un-delegate it, the rewards weight for each account can be modified, as seen, for example, in the `didAllocate()` function. In turn, this modifies the `DelegatedAccRewards` storage struct that stores the accumulated rewards for each share id. To keep track of changes done to the accumulated rewards, epochs with checkpoints are used to manage the accumulated rate of rewards, their value at the checkpoint, and the timestamp of the checkpoint.\\nFor example, in the `didAllocate()` function the `addRate()` function is being called to modify the accumulated rewards.\\n```\\nfunction didAllocate(\\n    uint8 subjectType,\\n    uint256 subject,\\n    uint256 stakeAmount,\\n    uint256 sharesAmount,\\n    address staker\\n) external onlyRole(ALLOCATOR\\_CONTRACT\\_ROLE) {\\n    bool delegated = getSubjectTypeAgency(subjectType) == SubjectStakeAgency.DELEGATED;\\n    if (delegated) {\\n        uint8 delegatorType = getDelegatorSubjectType(subjectType);\\n        uint256 shareId = FortaStakingUtils.subjectToActive(delegatorType, subject);\\n        DelegatedAccRewards storage s = \\_rewardsAccumulators[shareId];\\n        s.delegated.addRate(stakeAmount);\\n```\\n\\nThen the function flow goes into `setRate()` that checks the existing accumulated rewards storage and modifies it based on the current timestamp.\\n```\\nfunction addRate(Accumulator storage acc, uint256 rate) internal {\\n    setRate(acc, latest(acc).rate + rate);\\n}\\n```\\n\\n```\\nfunction setRate(Accumulator storage acc, uint256 rate) internal {\\n    EpochCheckpoint memory ckpt = EpochCheckpoint({ timestamp: SafeCast.toUint32(block.timestamp), rate: SafeCast.toUint224(rate), value: getValue(acc) });\\n    uint256 length = acc.checkpoints.length;\\n    if (length > 0 && isCurrentEpoch(acc.checkpoints[length - 1].timestamp)) {\\n        acc.checkpoints[length - 1] = ckpt;\\n    } else {\\n        acc.checkpoints.push(ckpt);\\n    }\\n}\\n```\\n\\nNamely, it pushes epoch checkpoints to the list of account checkpoints based on its timestamp. If the last checkpoint's timestamp is during the current epoch, then the last checkpoint is replaced with the new one altogether. If the last checkpoint's timestamp is different from the current epoch, a new checkpoint is added to the list. However, the `isCurrentEpoch()` function calls a function `getCurrentEpochTimestamp()` that incorrectly determines the start date of the current epoch. In particular, it doesn't take the offset into account when calculating how many epochs have already passed.\\n```\\nfunction getCurrentEpochTimestamp() internal view returns (uint256) {\\n    return ((block.timestamp / EPOCH\\_LENGTH) \\* EPOCH\\_LENGTH) + TIMESTAMP\\_OFFSET;\\n}\\n\\nfunction isCurrentEpoch(uint256 timestamp) internal view returns (bool) {\\n    uint256 currentEpochStart = getCurrentEpochTimestamp();\\n    return timestamp > currentEpochStart;\\n}\\n```\\n\\nInstead of `((block.timestamp / EPOCH_LENGTH) * EPOCH_LENGTH) + TIMESTAMP_OFFSET`, it should be `(((block.timestamp - TIMESTAMP_OFFSET) / EPOCH_LENGTH) * EPOCH_LENGTH) + TIMESTAMP_OFFSET`. In fact, it should simply call the `getEpochNumber()` function that correctly provides the epoch number for any timestamp.\\n```\\nfunction getEpochNumber(uint256 timestamp) internal pure returns (uint32) {\\n    return SafeCast.toUint32((timestamp - TIMESTAMP\\_OFFSET) / EPOCH\\_LENGTH);\\n}\\n```\\n\\nIn other words, the resulting function would look something like the following:\\n```\\n    function getCurrentEpochTimestamp() public view returns (uint256) {\\n        return (getEpochNumber(block.timestamp) * EPOCH_LENGTH) + TIMESTAMP_OFFSET;\\n    }\\n```\\n\\nOtherwise, if `block.timestamp` is such that `(block.timestamp - TIMESTAMP_OFFSET) / EPOCH_LENGTH = n` and `block.timestamp / EPOCH_LENGTH = n+1`, which would happen on roughly 4 out of 7 days of the week since `EPOCH_LENGTH = 1 weeks` and `TIMESTAMP_OFFSET = 4 days`, this would cause the `getCurrentEpochTimestamp()` function to return the end timestamp of the epoch (which is in the future) instead of the start. Therefore, if a checkpoint with such a timestamp is committed to the account's accumulated rewards checkpoints list, it will always fail the below check in the epoch it got submitted, and any checkpoint committed afterwards but during the same epoch with a similar type of `block.timestamp` (i.e. satisfying the condition at the beginning of this paragraph), would be pushed to the top of the list instead of replacing the previous checkpoint.\\n```\\nif (length > 0 && isCurrentEpoch(acc.checkpoints[length - 1].timestamp)) {\\n    acc.checkpoints[length - 1] = ckpt;\\n} else {\\n    acc.checkpoints.push(ckpt);\\n```\\n\\nThis causes several checkpoints to be stored for the same epoch, which would cause issues in functions such as `getAtEpoch()`, that feeds into `getValueAtEpoch()` function that provides data for the rewards' share calculation. In the end, this would cause issues in the accounting for the rewards calculation resulting in incorrect distributions.\\nDuring the discussion with the Forta Foundation team, it was additionally discovered that there are edge cases around the limits of epochs. Specifically, epoch's end time and the subsequent epoch's start time are exactly the same, although it should be that it is only the start of the next epoch. Similarly, that start time isn't recognized as part of the epoch due to `>` sign instead of `>=`. In particular, the following changes need to be made:\\n```\\n    function getEpochEndTimestamp(uint256 epochNumber) public pure returns (uint256) {\\n        return ((epochNumber + 1) * EPOCH_LENGTH) + TIMESTAMP_OFFSET - 1; <---- so it is 23:59:59 instead of next day 00:00:00\\n    }\\n\\n    function isCurrentEpoch(uint256 timestamp) public view returns (bool) {\\n        uint256 currentEpochStart = getCurrentEpochTimestamp();\\n        return timestamp >= currentEpochStart; <--- for the first second on Monday\\n    }\\n```\\nчA refactor of the epoch timestamp calculation functions is recommended to account for:\\nThe correct epoch number to calculate the start and end timestamps of epochs.\\nThe boundaries of epochs coinciding.\\nClarity in functions' intent. For example, adding a function just to calculate any epoch's start time and renaming `getCurrentEpochTimestamp()` to `getCurrentEpochStartTimestamp()`.чч```\\nfunction didAllocate(\\n    uint8 subjectType,\\n    uint256 subject,\\n    uint256 stakeAmount,\\n    uint256 sharesAmount,\\n    address staker\\n) external onlyRole(ALLOCATOR\\_CONTRACT\\_ROLE) {\\n    bool delegated = getSubjectTypeAgency(subjectType) == SubjectStakeAgency.DELEGATED;\\n    if (delegated) {\\n        uint8 delegatorType = getDelegatorSubjectType(subjectType);\\n        uint256 shareId = FortaStakingUtils.subjectToActive(delegatorType, subject);\\n        DelegatedAccRewards storage s = \\_rewardsAccumulators[shareId];\\n        s.delegated.addRate(stakeAmount);\\n```\\n
A single unfreeze dismisses all other slashing proposal freezesчhighчIn order to retaliate against malicious actors, the Forta staking system allows users to submit slashing proposals that are guarded by submitting along a deposit with a slashing reason. These proposals immediately freeze the proposal's subject's stake, blocking them from withdrawing that stake.\\nAt the same time, there can be multiple proposals submitted against the same subject, which works out with freezing – the subject remains frozen with each proposal submitted. However, once any one of the active proposals against the subject gets to the end of its lifecycle, be it `REJECTED`, `DISMISSED`, `EXECUTED`, or `REVERTED`, the subject gets unfrozen altogether. The other proposals might still be active, but the stake is no longer frozen, allowing the subject to withdraw it if they would like.\\nIn terms of impact, this allows bad actors to avoid punishment intended by the slashes and freezes. A malicious actor could, for example, submit a faulty proposal against themselves in the hopes that it will get quickly rejected or dismissed while the existing, legitimate proposals against them are still being considered. This would allow them to get unfrozen quickly and withdraw their stake. Similarly, in the event a bad staker has several proposals against them, they could withdraw right after a single slashing proposal goes through.\\n```\\nfunction dismissSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external onlyRole(SLASHING\\_ARBITER\\_ROLE) {\\n    \\_transition(\\_proposalId, DISMISSED);\\n    \\_submitEvidence(\\_proposalId, DISMISSED, \\_evidence);\\n    \\_returnDeposit(\\_proposalId);\\n    \\_unfreeze(\\_proposalId);\\n}\\n```\\n\\n```\\nfunction rejectSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external onlyRole(SLASHING\\_ARBITER\\_ROLE) {\\n    \\_transition(\\_proposalId, REJECTED);\\n    \\_submitEvidence(\\_proposalId, REJECTED, \\_evidence);\\n    \\_slashDeposit(\\_proposalId);\\n    \\_unfreeze(\\_proposalId);\\n}\\n```\\n\\n```\\nfunction reviewSlashProposalParameters(\\n    uint256 \\_proposalId,\\n    uint8 \\_subjectType,\\n    uint256 \\_subjectId,\\n    bytes32 \\_penaltyId,\\n    string[] calldata \\_evidence\\n) external onlyRole(SLASHING\\_ARBITER\\_ROLE) onlyInState(\\_proposalId, IN\\_REVIEW) onlyValidSlashPenaltyId(\\_penaltyId) onlyValidSubjectType(\\_subjectType) notAgencyType(\\_subjectType, SubjectStakeAgency.DELEGATOR) {\\n    // No need to check for proposal existence, onlyInState will revert if \\_proposalId is in undefined state\\n    if (!subjectGateway.isRegistered(\\_subjectType, \\_subjectId)) revert NonRegisteredSubject(\\_subjectType, \\_subjectId);\\n\\n    \\_submitEvidence(\\_proposalId, IN\\_REVIEW, \\_evidence);\\n    if (\\_subjectType != proposals[\\_proposalId].subjectType || \\_subjectId != proposals[\\_proposalId].subjectId) {\\n        \\_unfreeze(\\_proposalId);\\n        \\_freeze(\\_subjectType, \\_subjectId);\\n    }\\n```\\n\\n```\\nfunction revertSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external {\\n    \\_authorizeRevertSlashProposal(\\_proposalId);\\n    \\_transition(\\_proposalId, REVERTED);\\n    \\_submitEvidence(\\_proposalId, REVERTED, \\_evidence);\\n    \\_unfreeze(\\_proposalId);\\n}\\n```\\n\\n```\\nfunction executeSlashProposal(uint256 \\_proposalId) external onlyRole(SLASHER\\_ROLE) {\\n    \\_transition(\\_proposalId, EXECUTED);\\n    Proposal memory proposal = proposals[\\_proposalId];\\n    slashingExecutor.slash(proposal.subjectType, proposal.subjectId, getSlashedStakeValue(\\_proposalId), proposal.proposer, slashPercentToProposer);\\n    slashingExecutor.freeze(proposal.subjectType, proposal.subjectId, false);\\n}\\n```\\n\\n```\\nfunction \\_unfreeze(uint256 \\_proposalId) private {\\n    slashingExecutor.freeze(proposals[\\_proposalId].subjectType, proposals[\\_proposalId].subjectId, false);\\n}\\n```\\nчIntroduce a check in the unfreezing mechanics to first ensure there are no other active proposals for that subject.чч```\\nfunction dismissSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external onlyRole(SLASHING\\_ARBITER\\_ROLE) {\\n    \\_transition(\\_proposalId, DISMISSED);\\n    \\_submitEvidence(\\_proposalId, DISMISSED, \\_evidence);\\n    \\_returnDeposit(\\_proposalId);\\n    \\_unfreeze(\\_proposalId);\\n}\\n```\\n
Storage gap variables slightly off from the intended sizeчmediumчThe Forta staking system is using upgradeable proxies for its deployment strategy. To avoid storage collisions between contract versions during upgrades, uint256[] private `__gap` array variables are introduced that create a storage buffer. Together with contract state variables, the storage slots should sum up to 50. For example, the `__gap` variable is present in the `BaseComponentUpgradeable` component, which is the base of most Forta contracts, and there is a helpful comment in `AgentRegistryCore` that describes how its relevant `__gap` variable size was calculated:\\n```\\nuint256[50] private \\_\\_gap;\\n```\\n\\n```\\nuint256[41] private \\_\\_gap; // 50 - 1 (frontRunningDelay) - 3 (\\_stakeThreshold) - 5 StakeSubjectUpgradeable\\n```\\n\\nHowever, there are a few places where the `__gap` size was not computed correctly to get the storage slots up to 50. Some of these are:\\n```\\nuint256[49] private \\_\\_gap;\\n```\\n\\n```\\nuint256[47] private \\_\\_gap;\\n```\\n\\n```\\nuint256[44] private \\_\\_gap;\\n```\\n\\nWhile these still provide large storage buffers, it is best if the `__gap` variables are calculated to hold the same buffer within contracts of similar types as per the initial intentions to avoid confusion.\\nDuring conversations with the Forta Foundation team, it appears that some contracts like `ScannerRegistry` and `AgentRegistry` should instead add up to 45 with their `__gap` variable due to the `StakeSubject` contracts they inherit from adding 5 from themselves. This is something to note and be careful with as well for future upgrades.чProvide appropriate sizes for the `__gap` variables to have a consistent storage layout approach that would help avoid storage issues with future versions of the system.чч```\\nuint256[50] private \\_\\_gap;\\n```\\n
AgentRegistryCore - Agent Creation DoSчmediumчAgentRegistryCore allows anyone to mint an `agentID` for the desired owner address. However, in some cases, it may fall prey to DoS, either deliberately or unintentionally.\\nFor instance, let's assume the Front Running Protection is disabled or the `frontRunningDelay` is 0. It means anyone can directly create an agent without any prior commitment. Thus, anyone can observe pending transactions and try to front run them to mint an `agentID` prior to the victim's restricting it to mint a desired `agentID`.\\nAlso, it may be possible that a malicious actor succeeds in frontrunning a transaction with manipulated data/chainIDs but with the same owner address and `agentID`. There is a good chance that victim still accepts the attacker's transaction as valid, even though its own transaction reverted, due to the fact that the victim is still seeing itself as the owner of that ID.\\nTaking an instance where let's assume the frontrunning protection is enabled. Still, there is a good chance that two users vouch for the same `agentIDs` and commits in the same block, thus getting the same frontrunning delay. Then, it will be a game of luck, whoever creates that agent first will get the ID minted to its address, and the other user's transaction will be reverted wasting the time they have spent on the delay.\\nAs the `agentIDs` can be picked by users, the chances of collisions with an already minted ID will increase over time causing unnecessary reverts for others.\\nAdding to the fact that there is no restriction for owner address, anyone can spam mint any `agentID` to any address for any profitable reason.\\n```\\nfunction createAgent(uint256 agentId, address owner, string calldata metadata, uint256[] calldata chainIds)\\npublic\\n    onlySorted(chainIds)\\n    frontrunProtected(keccak256(abi.encodePacked(agentId, owner, metadata, chainIds)), frontRunningDelay)\\n{\\n    \\_mint(owner, agentId);\\n    \\_beforeAgentUpdate(agentId, metadata, chainIds);\\n    \\_agentUpdate(agentId, metadata, chainIds);\\n    \\_afterAgentUpdate(agentId, metadata, chainIds);\\n}\\n```\\nчModify function `prepareAgent` to not commit an already registered `agentID`.\\nA better approach could be to allow sequential minting of `agentIDs` using some counters.\\nOnly allow users to mint an `agentID`, either for themselves or for someone they are approved to.чч```\\nfunction createAgent(uint256 agentId, address owner, string calldata metadata, uint256[] calldata chainIds)\\npublic\\n    onlySorted(chainIds)\\n    frontrunProtected(keccak256(abi.encodePacked(agentId, owner, metadata, chainIds)), frontRunningDelay)\\n{\\n    \\_mint(owner, agentId);\\n    \\_beforeAgentUpdate(agentId, metadata, chainIds);\\n    \\_agentUpdate(agentId, metadata, chainIds);\\n    \\_afterAgentUpdate(agentId, metadata, chainIds);\\n}\\n```\\n
Lack of checks for rewarding an epoch that has already been rewardedчmediumчTo give rewards to the participating stakers, the Forta system utilizes reward epochs for each `shareId`, i.e. a delegated staking share. Each epoch gets their own reward distribution, and then `StakeAllocator` and `RewardsDistributor` contracts along with the Forta staking shares determine how much the users get.\\nTo actually allocate these rewards, a privileged account with the role `REWARDER_ROLE` calls the `RewardsDistributor.reward()` function with appropriate parameters to store the `amount` a `shareId` gets for that specific `epochNumber`, and then adds the `amount` to the `totalRewardsDistributed` contract variable for tracking. However, there is no check that the `shareId` already received rewards for that `epoch`. The new reward `amount` simply replaces the old reward `amount`, and `totalRewardsDistributed` gets the new `amount` added to it anyway. This causes inconsistencies with accounting in the `totalRewardsDistributed` variable.\\nAlthough `totalRewardsDistributed` is essentially isolated to the `sweep()` function to allow transferring out the reward tokens without taking away those tokens reserved for the reward distribution, this still creates an inconsistency, albeit a minor one in the context of the current system.\\nSimilarly, the `sweep()` function deducts the `totalRewardsDistributed` amount instead of the amount of pending rewards only. In other words, either there should be a different variable that tracks only pending rewards, or the `totalRewardsDistributed` should have token amounts deducted from it when users execute the `claimRewards()` function. Otherwise, after a few epochs there will be a really large `totalRewardsDistributed` amount that might not reflect the real amount of pending reward tokens left on the contract, and the `sweep()` function for the reward token is likely to fail for any amount being transferred out.\\n```\\nfunction reward(\\n    uint8 subjectType,\\n    uint256 subjectId,\\n    uint256 amount,\\n    uint256 epochNumber\\n) external onlyRole(REWARDER\\_ROLE) {\\n    if (subjectType != NODE\\_RUNNER\\_SUBJECT) revert InvalidSubjectType(subjectType);\\n    if (!\\_subjectGateway.isRegistered(subjectType, subjectId)) revert RewardingNonRegisteredSubject(subjectType, subjectId);\\n    uint256 shareId = FortaStakingUtils.subjectToActive(getDelegatorSubjectType(subjectType), subjectId);\\n    \\_rewardsPerEpoch[shareId][epochNumber] = amount;\\n    totalRewardsDistributed += amount;\\n    emit Rewarded(subjectType, subjectId, amount, epochNumber);\\n}\\n```\\nчImplement checks as appropriate to the `reward()` function to ensure correct behavior of `totalRewardsDistributed` tracking. Also, implement necessary changes to the tracking of pending rewards, if necessary.чч```\\nfunction reward(\\n    uint8 subjectType,\\n    uint256 subjectId,\\n    uint256 amount,\\n    uint256 epochNumber\\n) external onlyRole(REWARDER\\_ROLE) {\\n    if (subjectType != NODE\\_RUNNER\\_SUBJECT) revert InvalidSubjectType(subjectType);\\n    if (!\\_subjectGateway.isRegistered(subjectType, subjectId)) revert RewardingNonRegisteredSubject(subjectType, subjectId);\\n    uint256 shareId = FortaStakingUtils.subjectToActive(getDelegatorSubjectType(subjectType), subjectId);\\n    \\_rewardsPerEpoch[shareId][epochNumber] = amount;\\n    totalRewardsDistributed += amount;\\n    emit Rewarded(subjectType, subjectId, amount, epochNumber);\\n}\\n```\\n
Reentrancy in FortaStaking during ERC1155 mintsчmediumчIn the Forta staking system, the staking shares (both “active” and “inactive”) are represented as tokens implemented according to the `ERC1155` standard. The specific implementation that is being used utilizes a smart contract acceptance check `_doSafeTransferAcceptanceCheck()` upon mints to the recipient.\\n```\\ncontract FortaStaking is BaseComponentUpgradeable, ERC1155SupplyUpgradeable, SubjectTypeValidator, ISlashingExecutor, IStakeMigrator {\\n```\\n\\nThe specific implementation for `ERC1155SupplyUpgradeable` contracts can be found here, and the smart contract check can be found here.\\nThis opens up reentrancy into the system's flow. In fact, the reentrancy occurs on all mints that happen in the below functions, and it happens before a call to another Forta contract for allocation is made via either `_allocator.depositAllocation` or _allocator.withdrawAllocation:\\n```\\nfunction deposit(\\n    uint8 subjectType,\\n    uint256 subject,\\n    uint256 stakeValue\\n) external onlyValidSubjectType(subjectType) notAgencyType(subjectType, SubjectStakeAgency.MANAGED) returns (uint256) {\\n    if (address(subjectGateway) == address(0)) revert ZeroAddress(\"subjectGateway\");\\n    if (!subjectGateway.isStakeActivatedFor(subjectType, subject)) revert StakeInactiveOrSubjectNotFound();\\n    address staker = \\_msgSender();\\n    uint256 activeSharesId = FortaStakingUtils.subjectToActive(subjectType, subject);\\n    bool reachedMax;\\n    (stakeValue, reachedMax) = \\_getInboundStake(subjectType, subject, stakeValue);\\n    if (reachedMax) {\\n        emit MaxStakeReached(subjectType, subject);\\n    }\\n    uint256 sharesValue = stakeToActiveShares(activeSharesId, stakeValue);\\n    SafeERC20.safeTransferFrom(stakedToken, staker, address(this), stakeValue);\\n\\n    \\_activeStake.mint(activeSharesId, stakeValue);\\n    \\_mint(staker, activeSharesId, sharesValue, new bytes(0));\\n    emit StakeDeposited(subjectType, subject, staker, stakeValue);\\n    \\_allocator.depositAllocation(activeSharesId, subjectType, subject, staker, stakeValue, sharesValue);\\n    return sharesValue;\\n}\\n```\\n\\n```\\nfunction migrate(\\n    uint8 oldSubjectType,\\n    uint256 oldSubject,\\n    uint8 newSubjectType,\\n    uint256 newSubject,\\n    address staker\\n) external onlyRole(SCANNER\\_2\\_NODE\\_RUNNER\\_MIGRATOR\\_ROLE) {\\n    if (oldSubjectType != SCANNER\\_SUBJECT) revert InvalidSubjectType(oldSubjectType);\\n    if (newSubjectType != NODE\\_RUNNER\\_SUBJECT) revert InvalidSubjectType(newSubjectType); \\n    if (isFrozen(oldSubjectType, oldSubject)) revert FrozenSubject();\\n\\n    uint256 oldSharesId = FortaStakingUtils.subjectToActive(oldSubjectType, oldSubject);\\n    uint256 oldShares = balanceOf(staker, oldSharesId);\\n    uint256 stake = activeSharesToStake(oldSharesId, oldShares);\\n    uint256 newSharesId = FortaStakingUtils.subjectToActive(newSubjectType, newSubject);\\n    uint256 newShares = stakeToActiveShares(newSharesId, stake);\\n\\n    \\_activeStake.burn(oldSharesId, stake);\\n    \\_activeStake.mint(newSharesId, stake);\\n    \\_burn(staker, oldSharesId, oldShares);\\n    \\_mint(staker, newSharesId, newShares, new bytes(0));\\n    emit StakeDeposited(newSubjectType, newSubject, staker, stake);\\n    \\_allocator.depositAllocation(newSharesId, newSubjectType, newSubject, staker, stake, newShares);\\n}\\n```\\n\\n```\\nfunction initiateWithdrawal(\\n    uint8 subjectType,\\n    uint256 subject,\\n    uint256 sharesValue\\n) external onlyValidSubjectType(subjectType) returns (uint64) {\\n    address staker = \\_msgSender();\\n    uint256 activeSharesId = FortaStakingUtils.subjectToActive(subjectType, subject);\\n    if (balanceOf(staker, activeSharesId) == 0) revert NoActiveShares();\\n    uint64 deadline = SafeCast.toUint64(block.timestamp) + \\_withdrawalDelay;\\n\\n    \\_lockingDelay[activeSharesId][staker].setDeadline(deadline);\\n\\n    uint256 activeShares = Math.min(sharesValue, balanceOf(staker, activeSharesId));\\n    uint256 stakeValue = activeSharesToStake(activeSharesId, activeShares);\\n    uint256 inactiveShares = stakeToInactiveShares(FortaStakingUtils.activeToInactive(activeSharesId), stakeValue);\\n    SubjectStakeAgency agency = getSubjectTypeAgency(subjectType);\\n    \\_activeStake.burn(activeSharesId, stakeValue);\\n    \\_inactiveStake.mint(FortaStakingUtils.activeToInactive(activeSharesId), stakeValue);\\n    \\_burn(staker, activeSharesId, activeShares);\\n    \\_mint(staker, FortaStakingUtils.activeToInactive(activeSharesId), inactiveShares, new bytes(0));\\n    if (agency == SubjectStakeAgency.DELEGATED || agency == SubjectStakeAgency.DELEGATOR) {\\n        \\_allocator.withdrawAllocation(activeSharesId, subjectType, subject, staker, stakeValue, activeShares);\\n    }\\n```\\n\\nAlthough this doesn't seem to be an issue in the current Forta system of contracts since the allocator's logic doesn't seem to be manipulable, this could still be dangerous as it opens up an external execution flow.чConsider introducing a reentrancy check or emphasize this behavior in the documentation, so that both other projects using this system later and future upgrades along with maintenance work on the Forta staking system itself are implemented safely.чч```\\ncontract FortaStaking is BaseComponentUpgradeable, ERC1155SupplyUpgradeable, SubjectTypeValidator, ISlashingExecutor, IStakeMigrator {\\n```\\n
Unnecessary code blocks that check the same conditionчlowчIn the `RewardsDistributor` there is a function that allows to set delegation fees for a `NodeRunner`. It adjusts the `fees[]` array for that node as appropriate. However, during its checks, it performs the same check twice in a row.\\n```\\nif (fees[1].sinceEpoch != 0) {\\n    if (Accumulators.getCurrentEpochNumber() < fees[1].sinceEpoch + delegationParamsEpochDelay) revert SetDelegationFeeNotReady();\\n}\\nif (fees[1].sinceEpoch != 0) {\\n    fees[0] = fees[1];\\n}\\n```\\nчConsider refactoring this under a single code block.чч```\\nif (fees[1].sinceEpoch != 0) {\\n    if (Accumulators.getCurrentEpochNumber() < fees[1].sinceEpoch + delegationParamsEpochDelay) revert SetDelegationFeeNotReady();\\n}\\nif (fees[1].sinceEpoch != 0) {\\n    fees[0] = fees[1];\\n}\\n```\\n
Event spam in RewardsDistributor.claimRewardsчlowчThe `RewardsDistributor` contract allows users to claim their rewards through the `claimRewards()` function. It does check to see whether or not the user has already claimed the rewards for a specific epoch that they are claiming for, but it does not check to see if the user has any associated rewards at all. This could lead to event `ClaimedRewards` being spammed by malicious users, especially on low gas chains.\\n```\\nfor (uint256 i = 0; i < epochNumbers.length; i++) {\\n    if (\\_claimedRewardsPerEpoch[shareId][epochNumbers[i]][\\_msgSender()]) revert AlreadyClaimed();\\n    \\_claimedRewardsPerEpoch[shareId][epochNumbers[i]][\\_msgSender()] = true;\\n    uint256 epochRewards = \\_availableReward(shareId, isDelegator, epochNumbers[i], \\_msgSender());\\n    SafeERC20.safeTransfer(rewardsToken, \\_msgSender(), epochRewards);\\n    emit ClaimedRewards(subjectType, subjectId, \\_msgSender(), epochNumbers[i], epochRewards);\\n```\\nчAdd a check for rewards amounts being greater than 0.чч```\\nfor (uint256 i = 0; i < epochNumbers.length; i++) {\\n    if (\\_claimedRewardsPerEpoch[shareId][epochNumbers[i]][\\_msgSender()]) revert AlreadyClaimed();\\n    \\_claimedRewardsPerEpoch[shareId][epochNumbers[i]][\\_msgSender()] = true;\\n    uint256 epochRewards = \\_availableReward(shareId, isDelegator, epochNumbers[i], \\_msgSender());\\n    SafeERC20.safeTransfer(rewardsToken, \\_msgSender(), epochRewards);\\n    emit ClaimedRewards(subjectType, subjectId, \\_msgSender(), epochNumbers[i], epochRewards);\\n```\\n
Lack of a check for the subject's stake for reviewSlashProposalParametersчlowчIn the `SlashingController` contract, the address with the `SLASHING_ARBITER_ROLE` may call the `reviewSlashProposalParameters()` function to adjust the slashing proposal to a new `_subjectId` and `_subjectType`. However, unlike in the `proposeSlash()` function, there is no check for that subject having any stake at all.\\nWhile it may be assumed that the review function will be called by a privileged and knowledgeable actor, this additional check may avoid accidental mistakes.\\n```\\nif (subjectGateway.totalStakeFor(\\_subjectType, \\_subjectId) == 0) revert ZeroAmount(\"subject stake\");\\n```\\n\\n```\\nif (\\_subjectType != proposals[\\_proposalId].subjectType || \\_subjectId != proposals[\\_proposalId].subjectId) {\\n    \\_unfreeze(\\_proposalId);\\n    \\_freeze(\\_subjectType, \\_subjectId);\\n}\\n```\\nчAdd a check for the new subject having stake to slash.чч```\\nif (subjectGateway.totalStakeFor(\\_subjectType, \\_subjectId) == 0) revert ZeroAmount(\"subject stake\");\\n```\\n
Comment and code inconsistenciesчlowчDuring the audit a few inconsistencies were found between what the comments say and what the implemented code actually did.\\nSubject Type Agency for Scanner Subjects\\nIn the `SubjectTypeValidator`, the comment says that the `SCANNER_SUBJECT` is of type `DIRECT` agency type, i.e. it can be directly staked on by multiple different stakers. However, we found a difference in the implementation, where the concerned subject is defined as type `MANAGED` agency type, which says that it cannot be staked on directly; instead it's a delegated type and the allocation is supposed to be managed by its manager.\\n```\\n\\* - SCANNER\\_SUBJECT --> DIRECT\\n```\\n\\n```\\n} else if (subjectType == SCANNER\\_SUBJECT) {\\n    return SubjectStakeAgency.MANAGED;\\n```\\n\\nDispatch refers to ERC721 tokens as ERC1155\\nOne of the comments describing the functionality to `link` and `unlink` agents and scanners refers to them as ERC1155 tokens, when in reality they are ERC721.\\n```\\n/\\*\\*\\n \\* @notice Assigns the job of running an agent to a scanner.\\n \\* @dev currently only allowed for DISPATCHER\\_ROLE (Assigner software).\\n \\* @dev emits Link(agentId, scannerId, true) event.\\n \\* @param agentId ERC1155 token id of the agent.\\n \\* @param scannerId ERC1155 token id of the scanner.\\n \\*/\\n```\\n\\nNodeRunnerRegistryCore comment that implies the reverse of what happens\\nA comment describing a helper function that returns address for a given scanner ID describes the opposite behavior. It is the same comment for the function just above that actually does what the comment says.\\n```\\n/// Converts scanner address to uint256 for FortaStaking Token Id.\\nfunction scannerIdToAddress(uint256 scannerId) public pure returns (address) {\\n    return address(uint160(scannerId));\\n}\\n```\\n\\nScannerToNodeRunnerMigration comment that says that no NodeRunner tokens must be owned\\nFor the migration from Scanners to NodeRunners, a comment in the beginning of the file implies that for the system to work correctly, there must be no NodeRunner tokens owned prior to migration. After a conversation with the Forta Foundation team, it appears that this was an early design choice that is no longer relevant.\\n```\\n\\* @param nodeRunnerId If set as 0, a new NodeRunnerRegistry ERC721 will be minted to nodeRunner (but it must not own any prior),\\n```\\n\\n```\\n\\* @param nodeRunnerId If set as 0, a new NodeRunnerRegistry ERC721 will be minted to nodeRunner (but it must not own any prior),\\n```\\nчVerify the operational logic and fix either the concerned comments or defined logic as per the need.чч```\\n\\* - SCANNER\\_SUBJECT --> DIRECT\\n```\\n
Oracle's _sanityCheck for prices will not work with slashingчhighчThe `_sanityCheck` is verifying that the new price didn't change significantly:\\n```\\nuint256 maxPrice = curPrice +\\n ((curPrice \\*\\n self.PERIOD\\_PRICE\\_INCREASE\\_LIMIT \\*\\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\\n\\nuint256 minPrice = curPrice -\\n ((curPrice \\*\\n self.PERIOD\\_PRICE\\_DECREASE\\_LIMIT \\*\\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\\n\\nrequire(\\n \\_newPrice >= minPrice && \\_newPrice <= maxPrice,\\n \"OracleUtils: price is insane\"\\n```\\n\\nWhile the rewards of staking can be reasonably predicted, the balances may also be changed due to slashing. So any slashing event should reduce the price, and if enough ETH is slashed, the price will drop heavily. The oracle will not be updated because of a sanity check. After that, there will be an arbitrage opportunity, and everyone will be incentivized to withdraw as soon as possible. That process will inevitably devaluate gETH to zero. The severity of this issue is also amplified by the fact that operators have no skin in the game and won't lose anything from slashing.чMake sure that slashing can be adequately processed when updating the price.чч```\\nuint256 maxPrice = curPrice +\\n ((curPrice \\*\\n self.PERIOD\\_PRICE\\_INCREASE\\_LIMIT \\*\\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\\n\\nuint256 minPrice = curPrice -\\n ((curPrice \\*\\n self.PERIOD\\_PRICE\\_DECREASE\\_LIMIT \\*\\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\\n\\nrequire(\\n \\_newPrice >= minPrice && \\_newPrice <= maxPrice,\\n \"OracleUtils: price is insane\"\\n```\\n
MiniGovernance - fetchUpgradeProposal will always revertчhighчIn the function `fetchUpgradeProposal()`, `newProposal()` is called with a hard coded `duration` of 4 weeks. This means the function will always revert since `newProposal()` checks that the proposal `duration` is not more than the constant `MAX_PROPOSAL_DURATION` of 2 weeks. Effectively, this leaves MiniGovernance non-upgradeable.\\n```\\nGEM.newProposal(proposal.CONTROLLER, 2, proposal.NAME, 4 weeks);\\n```\\n\\n```\\nrequire(\\n duration <= MAX\\_PROPOSAL\\_DURATION,\\n \"GeodeUtils: duration exceeds MAX\\_PROPOSAL\\_DURATION\"\\n);\\n```\\nчSwitch the hard coded proposal duration to 2 weeks.чч```\\nGEM.newProposal(proposal.CONTROLLER, 2, proposal.NAME, 4 weeks);\\n```\\n
Updating interfaces of derivatives is done in a dangerous and unpredictable manner.чmediumчGeode Finance codebase provides planet maintainers with the ability to enable or disable different contracts to act as the main token contract. In fact, multiple separate contracts can be used at the same time if decided so by the planet maintainer. Those contracts will have shared balances but will not share the allowances as you can see below:\\n```\\nmapping(uint256 => mapping(address => uint256)) private \\_balances;\\n```\\n\\n```\\nmapping(address => mapping(address => uint256)) private \\_allowances;\\n```\\n\\nUnfortunately, this approach comes with some implications that are very hard to predict as they involve interactions with other systems, but is possible to say that the consequences of those implications will most always be negative. We will not be able to outline all the implications of this issue, but we can try and outline the pattern that they all would follow.\\nThere are really two ways to update an interface: set the new one and immediately unset the old one, or have them both run in parallel for some time. Let's look at them one by one.\\nin the first case, the old interface is disabled immediately. Given that interfaces share balances that will lead to some very serious consequences. Imagine the following sequence:\\nAlice deposits her derivatives into the DWP contract for liquidity mining.\\nPlanet maintainer updates the interface and immediately disables the old one.\\nDWP contract now has the old tokens and the new ones. But only the new ones are accounted for in the storage and thus can be withdrawn. Unfortunately, the old tokens are disabled meaning that now both old and new tokens are lost.\\nThis can happen in pretty much any contract and not just the DWP token. Unless the holders had enough time to withdraw the derivatives back to their wallets all the funds deposited into contracts could be lost.\\nThis leads us to the second case where the two interfaces are active in parallel. This would solve the issue above by allowing Alice to withdraw the old tokens from the DWP and make the new tokens follow. Unfortunately, there is an issue in that case as well.\\nSome DeFi contracts allow their owners to withdraw any tokens that are not accounted for by the internal accounting. DWP allows the withdrawal of admin fees if the contract has more tokens than `balances[]` store. Some contracts even allow to withdraw funds that were accidentally sent to the contract by people. Either to recover them or just as a part of dust collection. Let's call such contracts “dangerous contracts” for our purposes.\\nAlice deposits her derivatives into the dangerous contract.\\nPlanet maintainer sets a new interface.\\nOwner of the dangerous contract sees that some odd and unaccounted tokens landed in the contract. He learns those are real and are part of Geode ecosystem. So he takes them.\\nOld tokens will follow the new tokens. That means Alice now has no claim to them and the contract that they just left has broken accounting since numbers there are not backed by tokens anymore.\\nOne other issue we would like to highlight here is that despite the contracts being expected to have separate allowances, if the old contract has the allowance set, the initial 0 value of the new one will be ignored. Here is an example:\\nAlice approves Bob for 100 derivatives.\\nPlanet maintainer sets a new interface. The new interface has no allowance from Alice to Bob.\\nBob still can transfer new tokens from Alice to himself by transferring the old tokens for which he still has the allowance. New token balances will be updated accordingly.\\nAlice could also give Bob an allowance of 100 tokens in the new contract since that was her original intent, but this would mean that Bob now has 200 token allowance.\\nThis is extremely convoluted and will most likely result in errors made by the planet maintainers when updating the interfaces.чThe safest option is to only allow a list of whitelisted interfaces to be used that are well-documented and audited. Planet maintainers could then choose the once that they see fit.чч```\\nmapping(uint256 => mapping(address => uint256)) private \\_balances;\\n```\\n
Only the GOVERNANCE can initialize the PortalчmediumчIn the Portal's `initialize` function, the `_GOVERNANCE` is passed as a parameter:\\n```\\nfunction initialize(\\n address \\_GOVERNANCE,\\n address \\_gETH,\\n address \\_ORACLE\\_POSITION,\\n address \\_DEFAULT\\_gETH\\_INTERFACE,\\n address \\_DEFAULT\\_DWP,\\n address \\_DEFAULT\\_LP\\_TOKEN,\\n address \\_MINI\\_GOVERNANCE\\_POSITION,\\n uint256 \\_GOVERNANCE\\_TAX,\\n uint256 \\_COMET\\_TAX,\\n uint256 \\_MAX\\_MAINTAINER\\_FEE,\\n uint256 \\_BOOSTRAP\\_PERIOD\\n) public virtual override initializer {\\n \\_\\_ReentrancyGuard\\_init();\\n \\_\\_Pausable\\_init();\\n \\_\\_ERC1155Holder\\_init();\\n \\_\\_UUPSUpgradeable\\_init();\\n\\n GEODE.SENATE = \\_GOVERNANCE;\\n GEODE.GOVERNANCE = \\_GOVERNANCE;\\n GEODE.GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\\n GEODE.MAX\\_GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\\n GEODE.SENATE\\_EXPIRY = type(uint256).max;\\n\\n STAKEPOOL.GOVERNANCE = \\_GOVERNANCE;\\n STAKEPOOL.gETH = IgETH(\\_gETH);\\n STAKEPOOL.TELESCOPE.gETH = IgETH(\\_gETH);\\n STAKEPOOL.TELESCOPE.ORACLE\\_POSITION = \\_ORACLE\\_POSITION;\\n STAKEPOOL.TELESCOPE.MONOPOLY\\_THRESHOLD = 20000;\\n\\n updateStakingParams(\\n \\_DEFAULT\\_gETH\\_INTERFACE,\\n \\_DEFAULT\\_DWP,\\n \\_DEFAULT\\_LP\\_TOKEN,\\n \\_MAX\\_MAINTAINER\\_FEE,\\n \\_BOOSTRAP\\_PERIOD,\\n type(uint256).max,\\n type(uint256).max,\\n \\_COMET\\_TAX,\\n 3 days\\n );\\n```\\n\\nBut then it calls the `updateStakingParams` function, which requires the `msg.sender` to be the governance:\\n```\\nfunction updateStakingParams(\\n address \\_DEFAULT\\_gETH\\_INTERFACE,\\n address \\_DEFAULT\\_DWP,\\n address \\_DEFAULT\\_LP\\_TOKEN,\\n uint256 \\_MAX\\_MAINTAINER\\_FEE,\\n uint256 \\_BOOSTRAP\\_PERIOD,\\n uint256 \\_PERIOD\\_PRICE\\_INCREASE\\_LIMIT,\\n uint256 \\_PERIOD\\_PRICE\\_DECREASE\\_LIMIT,\\n uint256 \\_COMET\\_TAX,\\n uint256 \\_BOOST\\_SWITCH\\_LATENCY\\n) public virtual override {\\n require(\\n msg.sender == GEODE.GOVERNANCE,\\n \"Portal: sender not GOVERNANCE\"\\n );\\n```\\n\\nSo only the future governance can initialize the `Portal`. In the case of the Geode protocol, the governance will be represented by a token contract, making it hard to initialize promptly. Initialization should be done by an actor that is more flexible than governance.чSplit the `updateStakingParams` function into public and private ones and use them accordingly.чч```\\nfunction initialize(\\n address \\_GOVERNANCE,\\n address \\_gETH,\\n address \\_ORACLE\\_POSITION,\\n address \\_DEFAULT\\_gETH\\_INTERFACE,\\n address \\_DEFAULT\\_DWP,\\n address \\_DEFAULT\\_LP\\_TOKEN,\\n address \\_MINI\\_GOVERNANCE\\_POSITION,\\n uint256 \\_GOVERNANCE\\_TAX,\\n uint256 \\_COMET\\_TAX,\\n uint256 \\_MAX\\_MAINTAINER\\_FEE,\\n uint256 \\_BOOSTRAP\\_PERIOD\\n) public virtual override initializer {\\n \\_\\_ReentrancyGuard\\_init();\\n \\_\\_Pausable\\_init();\\n \\_\\_ERC1155Holder\\_init();\\n \\_\\_UUPSUpgradeable\\_init();\\n\\n GEODE.SENATE = \\_GOVERNANCE;\\n GEODE.GOVERNANCE = \\_GOVERNANCE;\\n GEODE.GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\\n GEODE.MAX\\_GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\\n GEODE.SENATE\\_EXPIRY = type(uint256).max;\\n\\n STAKEPOOL.GOVERNANCE = \\_GOVERNANCE;\\n STAKEPOOL.gETH = IgETH(\\_gETH);\\n STAKEPOOL.TELESCOPE.gETH = IgETH(\\_gETH);\\n STAKEPOOL.TELESCOPE.ORACLE\\_POSITION = \\_ORACLE\\_POSITION;\\n STAKEPOOL.TELESCOPE.MONOPOLY\\_THRESHOLD = 20000;\\n\\n updateStakingParams(\\n \\_DEFAULT\\_gETH\\_INTERFACE,\\n \\_DEFAULT\\_DWP,\\n \\_DEFAULT\\_LP\\_TOKEN,\\n \\_MAX\\_MAINTAINER\\_FEE,\\n \\_BOOSTRAP\\_PERIOD,\\n type(uint256).max,\\n type(uint256).max,\\n \\_COMET\\_TAX,\\n 3 days\\n );\\n```\\n
The maintainer of the MiniGovernance can block the changeMaintainer functionчmediumчEvery entity with an ID has a controller and a maintainer. The controller tends to have more control, and the maintainer is mostly used for operational purposes. So the controller should be able to change the maintainer if that is required. Indeed we see that it is possible in the MiniGovernance too:\\n```\\nfunction changeMaintainer(\\n bytes calldata password,\\n bytes32 newPasswordHash,\\n address newMaintainer\\n)\\n external\\n virtual\\n override\\n onlyPortal\\n whenNotPaused\\n returns (bool success)\\n{\\n require(\\n SELF.PASSWORD\\_HASH == bytes32(0) ||\\n SELF.PASSWORD\\_HASH ==\\n keccak256(abi.encodePacked(SELF.ID, password))\\n );\\n SELF.PASSWORD\\_HASH = newPasswordHash;\\n\\n \\_refreshSenate(newMaintainer);\\n\\n success = true;\\n}\\n```\\n\\nHere the `changeMaintainer` function can only be called by the Portal, and only the controller can initiate that call. But the maintainer can pause the MiniGovernance, which will make this call revert because the `_refreshSenate` function has the `whenNotPaused` modifier. Thus maintainer could intentionally prevent the controller from replacing it by another maintainer.чMake sure that the controller can always change the malicious maintainer.чч```\\nfunction changeMaintainer(\\n bytes calldata password,\\n bytes32 newPasswordHash,\\n address newMaintainer\\n)\\n external\\n virtual\\n override\\n onlyPortal\\n whenNotPaused\\n returns (bool success)\\n{\\n require(\\n SELF.PASSWORD\\_HASH == bytes32(0) ||\\n SELF.PASSWORD\\_HASH ==\\n keccak256(abi.encodePacked(SELF.ID, password))\\n );\\n SELF.PASSWORD\\_HASH = newPasswordHash;\\n\\n \\_refreshSenate(newMaintainer);\\n\\n success = true;\\n}\\n```\\n
Entities are not required to be initiatedчmediumчEvery entity (Planet, Comet, Operator) has a 3-step creation process:\\nCreation of the proposal.\\nApproval of the proposal.\\nInitiation of the entity.\\nThe last step is crucial, but it is never explicitly checked that the entity is initialized. The initiation always includes the `initiator` modifier that works with the `\"initiated\"` slot on DATASTORE:\\n```\\nmodifier initiator(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 \\_TYPE,\\n uint256 \\_id,\\n address \\_maintainer\\n) {\\n require(\\n msg.sender == DATASTORE.readAddressForId(\\_id, \"CONTROLLER\"),\\n \"MaintainerUtils: sender NOT CONTROLLER\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"TYPE\") == \\_TYPE,\\n \"MaintainerUtils: id NOT correct TYPE\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"initiated\") == 0,\\n \"MaintainerUtils: already initiated\"\\n );\\n\\n DATASTORE.writeAddressForId(\\_id, \"maintainer\", \\_maintainer);\\n\\n \\_;\\n\\n DATASTORE.writeUintForId(\\_id, \"initiated\", block.timestamp);\\n\\n emit IdInitiated(\\_id, \\_TYPE);\\n}\\n```\\n\\nBut this slot is never actually checked when the entities are used. While we did not find any profitable attack vector using uninitiated entities, the code will be upgraded, which may allow for possible attack vectors related to this issue.чMake sure the entities are initiated before they are used.чч```\\nmodifier initiator(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 \\_TYPE,\\n uint256 \\_id,\\n address \\_maintainer\\n) {\\n require(\\n msg.sender == DATASTORE.readAddressForId(\\_id, \"CONTROLLER\"),\\n \"MaintainerUtils: sender NOT CONTROLLER\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"TYPE\") == \\_TYPE,\\n \"MaintainerUtils: id NOT correct TYPE\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"initiated\") == 0,\\n \"MaintainerUtils: already initiated\"\\n );\\n\\n DATASTORE.writeAddressForId(\\_id, \"maintainer\", \\_maintainer);\\n\\n \\_;\\n\\n DATASTORE.writeUintForId(\\_id, \"initiated\", block.timestamp);\\n\\n emit IdInitiated(\\_id, \\_TYPE);\\n}\\n```\\n
The blameOperator can be called for an alienated validatorчmediumчThe `blameOperator` function is designed to be called by anyone. If some operator did not signal to exit in time, anyone can blame and imprison this operator.\\n```\\n/\\*\\*\\n \\* @notice allows improsening an Operator if the validator have not been exited until expectedExit\\n \\* @dev anyone can call this function\\n \\* @dev if operator has given enough allowence, they can rotate the validators to avoid being prisoned\\n \\*/\\nfunction blameOperator(\\n StakePool storage self,\\n DataStoreUtils.DataStore storage DATASTORE,\\n bytes calldata pk\\n) external {\\n if (\\n block.timestamp > self.TELESCOPE.\\_validators[pk].expectedExit &&\\n self.TELESCOPE.\\_validators[pk].state != 3\\n ) {\\n OracleUtils.imprison(\\n DATASTORE,\\n self.TELESCOPE.\\_validators[pk].operatorId\\n );\\n }\\n}\\n```\\n\\nThe problem is that it can be called for any state that is not `3` (self.TELESCOPE._validators[pk].state != 3). But it should only be called for active validators whose state equals `2`. So the `blameOperator` can be called an infinite amount of time for alienated or not approved validators. These types of validators cannot switch to state `3`.\\nThe severity of the issue is mitigated by the fact that this function is currently unavailable for users to call. But it is intended to be external once the withdrawal process is in place.чMake sure that you can only blame the operator of an active validator.чч```\\n/\\*\\*\\n \\* @notice allows improsening an Operator if the validator have not been exited until expectedExit\\n \\* @dev anyone can call this function\\n \\* @dev if operator has given enough allowence, they can rotate the validators to avoid being prisoned\\n \\*/\\nfunction blameOperator(\\n StakePool storage self,\\n DataStoreUtils.DataStore storage DATASTORE,\\n bytes calldata pk\\n) external {\\n if (\\n block.timestamp > self.TELESCOPE.\\_validators[pk].expectedExit &&\\n self.TELESCOPE.\\_validators[pk].state != 3\\n ) {\\n OracleUtils.imprison(\\n DATASTORE,\\n self.TELESCOPE.\\_validators[pk].operatorId\\n );\\n }\\n}\\n```\\n
Latency timelocks on certain functions can be bypassedчmediumчThe functions `switchMaintainerFee()` and `switchWithdrawalBoost()` add a latency of typically three days to the current timestamp at which the new value is meant to be valid. However, they don't limit the number of times this value can be changed within the latency period. This allows a malicious maintainer to set their desired value twice and effectively make the change immediately. Let's take the first function as an example. The first call to it sets a value as the `newFee`, moving the old value to `priorFee`, which is effectively the fee in use until the time lock is up. A follow-up call to the function with the same value as a parameter would mean the “new” value overwrites the old `priorFee` while remaining in the queue for the switch.\\n```\\nfunction switchMaintainerFee(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 id,\\n uint256 newFee\\n) external {\\n DATASTORE.writeUintForId(\\n id,\\n \"priorFee\",\\n DATASTORE.readUintForId(id, \"fee\")\\n );\\n DATASTORE.writeUintForId(\\n id,\\n \"feeSwitch\",\\n block.timestamp + FEE\\_SWITCH\\_LATENCY\\n );\\n DATASTORE.writeUintForId(id, \"fee\", newFee);\\n\\n emit MaintainerFeeSwitched(\\n id,\\n newFee,\\n block.timestamp + FEE\\_SWITCH\\_LATENCY\\n );\\n}\\n```\\n\\n```\\nfunction getMaintainerFee(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 id\\n) internal view returns (uint256 fee) {\\n if (DATASTORE.readUintForId(id, \"feeSwitch\") > block.timestamp) {\\n return DATASTORE.readUintForId(id, \"priorFee\");\\n }\\n return DATASTORE.readUintForId(id, \"fee\");\\n}\\n```\\nчAdd a check to make sure only one value can be set between time lock periods.чч```\\nfunction switchMaintainerFee(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 id,\\n uint256 newFee\\n) external {\\n DATASTORE.writeUintForId(\\n id,\\n \"priorFee\",\\n DATASTORE.readUintForId(id, \"fee\")\\n );\\n DATASTORE.writeUintForId(\\n id,\\n \"feeSwitch\",\\n block.timestamp + FEE\\_SWITCH\\_LATENCY\\n );\\n DATASTORE.writeUintForId(id, \"fee\", newFee);\\n\\n emit MaintainerFeeSwitched(\\n id,\\n newFee,\\n block.timestamp + FEE\\_SWITCH\\_LATENCY\\n );\\n}\\n```\\n
MiniGovernance's senate has almost unlimited validityчmediumчA new senate for the MiniGovernance contract is set in the following line:\\n```\\nGEM.\\_setSenate(newSenate, block.timestamp + SENATE\\_VALIDITY);\\n```\\n\\nThe validity period argument should not include `block.timestamp`, because it is going to be added a bit later in the code:\\n```\\nself.SENATE\\_EXPIRY = block.timestamp + \\_senatePeriod;\\n```\\n\\nSo currently, every senate of MiniGovernance will have much longer validity than it is supposed to.чPass onlySENATE_VALIDITY in the `_refreshSenate` function.чч```\\nGEM.\\_setSenate(newSenate, block.timestamp + SENATE\\_VALIDITY);\\n```\\n
Proposed validators not accounted for in the monopoly check.чmediumчThe Geode team introduced a check that makes sure that node operators do not initiate more validators than a threshold called `MONOPOLY_THRESHOLD` allows. It is used on call to `proposeStake(...)` which the operator would call in order to propose new validators. It is worth mentioning that onboarding new validator nodes requires 2 steps: a proposal from the node operator and approval from the planet maintainer. After the first step validators get a status of `proposed`. After the second step validators get the status of `active` and all eth accounting is done. The issue we found is that the `proposed` validators step performs the monopoly check but does not account for previously `proposed` but not `active` validators.\\nAssume that `MONOPOLY_THRESHOLD` is set to 5. The node operator could propose 4 new validators and pass the monopoly check and label those validators as `proposed`. The node operator could then suggest 4 more validators in a separate transaction and since the monopoly check does not check for the `proposed` validators, that would pass as well. Then in `beaconStake` or the step of maintainer approval, there is no monopoly check at all, so 8 validators could be activated at once.\\n```\\nrequire(\\n (DATASTORE.readUintForId(operatorId, \"totalActiveValidators\") +\\n pubkeys.length) <= self.TELESCOPE.MONOPOLY\\_THRESHOLD,\\n \"StakeUtils: IceBear does NOT like monopolies\"\\n);\\n```\\nчInclude the `(DATASTORE.readUintForId(poolId,DataStoreUtils.getKey(operatorId, \"proposedValidators\"))` into the require statement, just like in the check for the node operator allowance check.\\n```\\nrequire(\\n (DATASTORE.readUintForId(\\n poolId,\\n DataStoreUtils.getKey(operatorId, \"proposedValidators\")\\n ) +\\n DATASTORE.readUintForId(\\n poolId,\\n DataStoreUtils.getKey(operatorId, \"activeValidators\")\\n ) +\\n pubkeys.length) <=\\n operatorAllowance(DATASTORE, poolId, operatorId),\\n \"StakeUtils: NOT enough allowance\"\\n);\\n```\\nчч```\\nrequire(\\n (DATASTORE.readUintForId(operatorId, \"totalActiveValidators\") +\\n pubkeys.length) <= self.TELESCOPE.MONOPOLY\\_THRESHOLD,\\n \"StakeUtils: IceBear does NOT like monopolies\"\\n);\\n```\\n
Comparison operator used instead of assignment operatorчmediumч```\\nself.\\_validators[\\_pk].state == 2;\\n```\\n\\n```\\nself.\\_validators[\\_pk].state == 3;\\n```\\nчReplace `==` with `=`.чч```\\nself.\\_validators[\\_pk].state == 2;\\n```\\n
initiator modifier will not work in the context of one transactionчlowчEach planet, comet or operator must be initialized after the onboarding proposal is approved. In order to make sure that these entities are not initialized more than once `initiateOperator`, `initiateComet` and `initiatePlanet` have the `initiator` modifier.\\n```\\nfunction initiatePlanet(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256[3] memory uintSpecs,\\n address[5] memory addressSpecs,\\n string[2] calldata interfaceSpecs\\n)\\n external\\n initiator(DATASTORE, 5, uintSpecs[0], addressSpecs[1])\\n returns (\\n address miniGovernance,\\n address gInterface,\\n address withdrawalPool\\n )\\n```\\n\\n```\\nfunction initiateComet(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 id,\\n uint256 fee,\\n address maintainer\\n) external initiator(DATASTORE, 6, id, maintainer) {\\n```\\n\\n```\\nfunction initiateOperator(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 id,\\n uint256 fee,\\n address maintainer\\n) external initiator(DATASTORE, 4, id, maintainer) {\\n```\\n\\nInside that modifier, we check that the `initiated` flag is 0 and if so we proceed to initialization. We later update it to the current timestamp.\\n```\\nmodifier initiator(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256 \\_TYPE,\\n uint256 \\_id,\\n address \\_maintainer\\n) {\\n require(\\n msg.sender == DATASTORE.readAddressForId(\\_id, \"CONTROLLER\"),\\n \"MaintainerUtils: sender NOT CONTROLLER\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"TYPE\") == \\_TYPE,\\n \"MaintainerUtils: id NOT correct TYPE\"\\n );\\n require(\\n DATASTORE.readUintForId(\\_id, \"initiated\") == 0,\\n \"MaintainerUtils: already initiated\"\\n );\\n\\n DATASTORE.writeAddressForId(\\_id, \"maintainer\", \\_maintainer);\\n\\n \\_;\\n\\n DATASTORE.writeUintForId(\\_id, \"initiated\", block.timestamp);\\n\\n emit IdInitiated(\\_id, \\_TYPE);\\n}\\n```\\n\\nUnfortunately, this does not follow the checks-effects-interractions pattern. If one for example would call `initiatePlanet` again from the body of the modifier, this check will still pass making it susceptible to a reentrancy attack. While we could not find a way to exploit this in the current engagement, given that system is designed to be upgradable this could become a risk in the future. For example, if during the initialization of the planet the maintainer will be allowed to pass a custom interface that could potentially allow reentering.чBring the line that updated the `initiated` flag to the current timestamp before the `_;`.\\n```\\nDATASTORE.writeUintForId(\\_id, \"initiated\", block.timestamp);\\n```\\nчч```\\nfunction initiatePlanet(\\n DataStoreUtils.DataStore storage DATASTORE,\\n uint256[3] memory uintSpecs,\\n address[5] memory addressSpecs,\\n string[2] calldata interfaceSpecs\\n)\\n external\\n initiator(DATASTORE, 5, uintSpecs[0], addressSpecs[1])\\n returns (\\n address miniGovernance,\\n address gInterface,\\n address withdrawalPool\\n )\\n```\\n
Incorrect accounting for the burned gEthчlowчGeode Portal records the amount of minted and burned gETH on any given day during the active period of the oracle. One case where some gETH is burned is when the users redeem gETH for ETH. In the burn function we burn the `spentGeth - gEthDonation` but in the accounting code we do not account for `gEthDonation` so the code records more assets burned than was really burned.\\n```\\nDATASTORE.subUintForId(poolId, \"surplus\", spentSurplus);\\nself.gETH.burn(address(this), poolId, spentGeth - gEthDonation);\\n\\nif (self.TELESCOPE.\\_isOracleActive()) {\\n bytes32 dailyBufferKey = DataStoreUtils.getKey(\\n block.timestamp - (block.timestamp % OracleUtils.ORACLE\\_PERIOD),\\n \"burnBuffer\"\\n );\\n DATASTORE.addUintForId(poolId, dailyBufferKey, spentGeth);\\n}\\n```\\nчRecord the `spentGeth` - gEthDonation instead of just `spentGeth` in the burn buffer.\\n```\\nDATASTORE.addUintForId(poolId, dailyBufferKey, spentGeth);\\n```\\nчч```\\nDATASTORE.subUintForId(poolId, \"surplus\", spentSurplus);\\nself.gETH.burn(address(this), poolId, spentGeth - gEthDonation);\\n\\nif (self.TELESCOPE.\\_isOracleActive()) {\\n bytes32 dailyBufferKey = DataStoreUtils.getKey(\\n block.timestamp - (block.timestamp % OracleUtils.ORACLE\\_PERIOD),\\n \"burnBuffer\"\\n );\\n DATASTORE.addUintForId(poolId, dailyBufferKey, spentGeth);\\n}\\n```\\n
Boost calculation on fetchUnstake should not be using the cumBalance when it is larger than debt.чlowчThe Geode team implemented the 2-step withdrawal mechanism for the staked ETH. First, node operators signal their intent to withdraw the stake, and then the oracle will trigger all of the accounting of rewards, balances, and buybacks if necessary. Buybacks are what we are interested in at this time. Buybacks are performed by checking if the derivative asset is off peg in the Dynamic Withdrawal Pool contract. Once the debt is larger than some ignorable threshold an arbitrage buyback will be executed. A portion of the arbitrage profit will go to the node operator. The issue here is that when simulating the arbitrage swap in the `calculateSwap` call we use the cumulative un-stake balance rather than ETH debt preset in the DWP. In the case where the withdrawal cumulative balance is higher than the debt node operator will receive a higher reward than intended.\\n```\\nuint256 arb = withdrawalPoolById(DATASTORE, poolId)\\n .calculateSwap(0, 1, cumBal);\\n```\\nчUse the `debt` amount of ETH in the boost reward calculation when the cumulative balance is larger than the `debt`.чч```\\nuint256 arb = withdrawalPoolById(DATASTORE, poolId)\\n .calculateSwap(0, 1, cumBal);\\n```\\n
DataStore struct not having the _gap for upgrades.чlowч```\\nDataStoreUtils.DataStore private DATASTORE;\\nGeodeUtils.Universe private GEODE;\\nStakeUtils.StakePool private STAKEPOOL;\\n```\\n\\nIt is worth mentioning that Geode contracts are meant to support the upgradability pattern. Given that information, one should be careful not to overwrite the storage variables by reordering the old ones or adding the new once not at the end of the list of variables when upgrading. The issue comes with the fact that structs seem to give a false sense of security making it feel like they are an isolated set of storage variables that will not override anything else. In reality, struts are just tuples that are expanded in storage sequentially just like all the other storage variables. For that reason, if you have two struct storage variables listed back to back like in the code above, you either need to make sure not to change the order or the number of variables in the structs other than the last one between upgrades or you need to add a `uint256[N] _gap` array of fixed size to reserve some storage slots for the future at the end of each struct. The Geode Finance team is missing the gap in the `DataStrore` struct making it non-upgradable.\\n```\\nstruct DataStore {\\n mapping(uint256 => uint256[]) allIdsByType;\\n mapping(bytes32 => uint256) uintData;\\n mapping(bytes32 => bytes) bytesData;\\n mapping(bytes32 => address) addressData;\\n}\\n```\\nчWe suggest that gap is used in DataStore as well. Since it was used for all the other structs we consider it just a typo.чч```\\nDataStoreUtils.DataStore private DATASTORE;\\nGeodeUtils.Universe private GEODE;\\nStakeUtils.StakePool private STAKEPOOL;\\n```\\n
Handle division by 0чmediumчThere are a few places in the code where division by zero may occur but isn't handled.\\nIf the vault settles at exactly 0 value with 0 remaining strategy token value, there may be an unhandled division by zero trying to divide claims on the settled assets:\\n```\\nint256 settledVaultValue = settlementRate.convertToUnderlying(residualAssetCashBalance)\\n    .add(totalStrategyTokenValueAtSettlement);\\n\\n// If the vault is insolvent (meaning residualAssetCashBalance < 0), it is necessarily\\n// true that totalStrategyTokens == 0 (meaning all tokens were sold in an attempt to\\n// repay the debt). That means settledVaultValue == residualAssetCashBalance, strategyTokenClaim == 0\\n// and assetCashClaim == totalAccountValue. Accounts that are still solvent will be paid from the\\n// reserve, accounts that are insolvent will have a totalAccountValue == 0.\\nstrategyTokenClaim = totalAccountValue.mul(vaultState.totalStrategyTokens.toInt())\\n    .div(settledVaultValue).toUint();\\n\\nassetCashClaim = totalAccountValue.mul(residualAssetCashBalance)\\n    .div(settledVaultValue);\\n```\\n\\nIf a vault account is entirely insolvent and its `vaultShareValue` is zero, there will be an unhandled division by zero during liquidation:\\n```\\nuint256 vaultSharesToLiquidator;\\n{\\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\\n        .mul(vaultConfig.liquidationRate.toUint())\\n        .mul(vaultAccount.vaultShares)\\n        .div(vaultShareValue.toUint())\\n        .div(uint256(Constants.RATE\\_PRECISION));\\n}\\n```\\n\\nIf a vault account's secondary debt is being repaid when there is none, there will be an unhandled division by zero:\\n```\\nVaultSecondaryBorrowStorage storage balance =\\n    LibStorage.getVaultSecondaryBorrow()[vaultConfig.vault][maturity][currencyId];\\nuint256 totalfCashBorrowed = balance.totalfCashBorrowed;\\nuint256 totalAccountDebtShares = balance.totalAccountDebtShares;\\n\\nfCashToLend = debtSharesToRepay.mul(totalfCashBorrowed).div(totalAccountDebtShares).toInt();\\n```\\n\\nWhile these cases may be unlikely today, this code could be reutilized in other circumstances later that could cause reverts and even disrupt operations more frequently.чHandle the cases where the denominator could be zero appropriately.чч```\\nint256 settledVaultValue = settlementRate.convertToUnderlying(residualAssetCashBalance)\\n    .add(totalStrategyTokenValueAtSettlement);\\n\\n// If the vault is insolvent (meaning residualAssetCashBalance < 0), it is necessarily\\n// true that totalStrategyTokens == 0 (meaning all tokens were sold in an attempt to\\n// repay the debt). That means settledVaultValue == residualAssetCashBalance, strategyTokenClaim == 0\\n// and assetCashClaim == totalAccountValue. Accounts that are still solvent will be paid from the\\n// reserve, accounts that are insolvent will have a totalAccountValue == 0.\\nstrategyTokenClaim = totalAccountValue.mul(vaultState.totalStrategyTokens.toInt())\\n    .div(settledVaultValue).toUint();\\n\\nassetCashClaim = totalAccountValue.mul(residualAssetCashBalance)\\n    .div(settledVaultValue);\\n```\\n
Increasing a leveraged position in a vault with secondary borrow currency will revertчlowчFrom the client's specifications for the strategy vaults, we know that accounts should be able to increase their leveraged positions before maturity. This property will not hold for the vaults that require borrowing a secondary currency to enter a position. When an account opens its position in such vault for the first time, the `VaultAccountSecondaryDebtShareStorage.maturity` is set to the maturity an account has entered. When the account is trying to increase the debt position, an accounts current maturity will be checked, and since it is not set to 0, as in the case where an account enters the vault for the first time, nor it is smaller than the new maturity passed by an account as in case of a rollover, the code will revert.\\n```\\nif (accountMaturity != 0) {\\n    // Cannot roll to a shorter term maturity\\n    require(accountMaturity < maturity);\\n```\\nчIn order to fix this issue, we recommend that `<` is replaced with `<=` so that account can enter the vault maturity the account is already in as well as the future once.чч```\\nif (accountMaturity != 0) {\\n    // Cannot roll to a shorter term maturity\\n    require(accountMaturity < maturity);\\n```\\n
Secondary Currency debt is not managed by the Notional ControllerчlowчSome of the Notional Strategy Vaults may allow for secondary currencies to be borrowed as part of the same strategy. For example, a strategy may allow for USDC to be its primary borrow currency as well as have ETH as its secondary borrow currency.\\nIn order to enter the vault, a user would have to deposit `depositAmountExternal` of the primary borrow currency when calling `VaultAccountAction.enterVault()`. This would allow the user to borrow with leverage, as long as the `vaultConfig.checkCollateralRatio()` check on that account succeeds, which is based on the initial deposit and borrow currency amounts. This collateral ratio check is then performed throughout that user account's lifecycle in that vault, such as when they try to roll their maturity, or when liquidators try to perform collateral checks to ensure there is no bad debt.\\nHowever, in the event that the vault has a secondary borrow currency as well, that additional secondary debt is not calculated as part of the `checkCollateralRatio()` check. The only debt that is being considered is the `vaultAccount.fCash` that corresponds to the primary borrow currency debt:\\n```\\nfunction checkCollateralRatio(\\n    VaultConfig memory vaultConfig,\\n    VaultState memory vaultState,\\n    VaultAccount memory vaultAccount\\n) internal view {\\n    (int256 collateralRatio, /\\* \\*/) = calculateCollateralRatio(\\n        vaultConfig, vaultState, vaultAccount.account, vaultAccount.vaultShares, vaultAccount.fCash\\n```\\n\\n```\\nfunction calculateCollateralRatio(\\n    VaultConfig memory vaultConfig,\\n    VaultState memory vaultState,\\n    address account,\\n    uint256 vaultShares,\\n    int256 fCash\\n) internal view returns (int256 collateralRatio, int256 vaultShareValue) {\\n    vaultShareValue = vaultState.getCashValueOfShare(vaultConfig, account, vaultShares);\\n\\n    // We do not discount fCash to present value so that we do not introduce interest\\n    // rate risk in this calculation. The economic benefit of discounting will be very\\n    // minor relative to the added complexity of accounting for interest rate risk.\\n\\n    // Convert fCash to a positive amount of asset cash\\n    int256 debtOutstanding = vaultConfig.assetRate.convertFromUnderlying(fCash.neg());\\n```\\n\\nWhereas the value of strategy tokens that belong to that user account are being calculated by calling `IStrategyVault(vault).convertStrategyToUnderlying()` on the associated strategy vault:\\n```\\nfunction getCashValueOfShare(\\n    VaultState memory vaultState,\\n    VaultConfig memory vaultConfig,\\n    address account,\\n    uint256 vaultShares\\n) internal view returns (int256 assetCashValue) {\\n    if (vaultShares == 0) return 0;\\n    (uint256 assetCash, uint256 strategyTokens) = getPoolShare(vaultState, vaultShares);\\n    int256 underlyingInternalStrategyTokenValue = \\_getStrategyTokenValueUnderlyingInternal(\\n        vaultConfig.borrowCurrencyId, vaultConfig.vault, account, strategyTokens, vaultState.maturity\\n    );\\n```\\n\\n```\\nfunction \\_getStrategyTokenValueUnderlyingInternal(\\n    uint16 currencyId,\\n    address vault,\\n    address account,\\n    uint256 strategyTokens,\\n    uint256 maturity\\n) private view returns (int256) {\\n    Token memory token = TokenHandler.getUnderlyingToken(currencyId);\\n    // This will be true if the the token is \"NonMintable\" meaning that it does not have\\n    // an underlying token, only an asset token\\n    if (token.decimals == 0) token = TokenHandler.getAssetToken(currencyId);\\n\\n    return token.convertToInternal(\\n        IStrategyVault(vault).convertStrategyToUnderlying(account, strategyTokens, maturity)\\n    );\\n}\\n```\\n\\nFrom conversations with the Notional team, it is assumed that this call returns the strategy token value subtracted against the secondary currencies debt, as is the case in the `Balancer2TokenVault` for example. In other words, when collateral ratio checks are performed, those strategy vaults that utilize secondary currency borrows would need to calculate the value of strategy tokens already accounting for any secondary debt. However, this is a dependency for a critical piece of the Notional controller's strategy vaults collateral checks.\\nTherefore, even though the strategy vaults' code and logic would be vetted before their whitelisting into the Notional system, they would still remain an external dependency with relatively arbitrary code responsible for the liquidation infrastructure that could lead to bad debt or incorrect liquidations if the vaults give inaccurate information, and thus potential loss of funds.чSpecific strategy vault implementations using secondary borrows were not in scope of this audit. However, since the core Notional Vault system was, and it includes secondary borrow currency functionality, from the point of view of the larger Notional system it is recommended to include secondary debt checks within the Notional controller contract to reduce external dependency on the strategy vaults' logic.чч```\\nfunction checkCollateralRatio(\\n    VaultConfig memory vaultConfig,\\n    VaultState memory vaultState,\\n    VaultAccount memory vaultAccount\\n) internal view {\\n    (int256 collateralRatio, /\\* \\*/) = calculateCollateralRatio(\\n        vaultConfig, vaultState, vaultAccount.account, vaultAccount.vaultShares, vaultAccount.fCash\\n```\\n
Vaults are unable to borrow single secondary currencyчlowчAs was previously mentioned some strategies `require` borrowing one or two secondary currencies. All secondary currencies have to be whitelisted in the `VaultConfig.secondaryBorrowCurrencies`. Borrow operation on secondary currencies is performed in the `borrowSecondaryCurrencyToVault(...)` function. Due to a `require` statement in that function, vaults will only be able to borrow secondary currencies if both of the currencies are whitelisted in `VaultConfig.secondaryBorrowCurrencies`. Considering that many strategies will have just one secondary currency, this will prevent those strategies from borrowing any secondary assets.\\n```\\nrequire(currencies[0] != 0 && currencies[1] != 0);\\n```\\nчWe suggest that the `&&` operator is replaced by the `||` operator. Ideally, an additional check will be performed that will ensure that values in argument arrays `fCashToBorrow`, `maxBorrowRate`, and `minRollLendRate` are passed under the same index as the whitelisted currencies in `VaultConfig.secondaryBorrowCurrencies`.\\n```\\nfunction borrowSecondaryCurrencyToVault(\\n    address account,\\n    uint256 maturity,\\n    uint256[2] calldata fCashToBorrow,\\n    uint32[2] calldata maxBorrowRate,\\n    uint32[2] calldata minRollLendRate\\n) external override returns (uint256[2] memory underlyingTokensTransferred) {\\n```\\nчч```\\nrequire(currencies[0] != 0 && currencies[1] != 0);\\n```\\n
An account roll may be impossible if the vault is already at the maximum borrow capacity.чlowчOne of the actions allowed in Notional Strategy Vaults is to roll an account's maturity to a later one by borrowing from a later maturity and repaying that into the debt of the earlier maturity.\\nHowever, this could cause an issue if the vault is at maximum capacity at the time of the roll. When an account performs this type of roll, the new borrow would have to be more than the existing debt simply because it has to at least cover the existing debt and pay for the borrow fees that get added on every new borrow. Since the whole vault was already at max borrow capacity before with the old, smaller borrow, this process would revert at the end after the new borrow as well once the process gets to `VaultAccount.updateAccountfCash` and VaultConfiguration.updateUsedBorrowCapacity:\\n```\\nfunction updateUsedBorrowCapacity(\\n    address vault,\\n    uint16 currencyId,\\n    int256 netfCash\\n) internal returns (int256 totalUsedBorrowCapacity) {\\n    VaultBorrowCapacityStorage storage cap = LibStorage.getVaultBorrowCapacity()[vault][currencyId];\\n\\n    // Update the total used borrow capacity, when borrowing this number will increase (netfCash < 0),\\n    // when lending this number will decrease (netfCash > 0).\\n    totalUsedBorrowCapacity = int256(uint256(cap.totalUsedBorrowCapacity)).sub(netfCash);\\n    if (netfCash < 0) {\\n        // Always allow lending to reduce the total used borrow capacity to satisfy the case when the max borrow\\n        // capacity has been reduced by governance below the totalUsedBorrowCapacity. When borrowing, it cannot\\n        // go past the limit.\\n        require(totalUsedBorrowCapacity <= int256(uint256(cap.maxBorrowCapacity)), \"Max Capacity\");\\n```\\n\\nThe result is that users won't able to roll while the vault is at max capacity. However, users may exit some part of their position to reduce their borrow, thereby reducing the overall vault borrow capacity, and then could execute the roll. A bigger problem would occur if the vault configuration got updated to massively reduce the borrow capacity, which would force users to exit their position more significantly with likely a much smaller chance at being able to roll.чDocument this case so that users can realise that rolling may not always be an option. Perhaps consider adding ways where users can pay a small deposit, like on `enterVault`, to offset the additional difference in borrows and pay for fees so they can remain with essentially the same size position within Notional.чч```\\nfunction updateUsedBorrowCapacity(\\n    address vault,\\n    uint16 currencyId,\\n    int256 netfCash\\n) internal returns (int256 totalUsedBorrowCapacity) {\\n    VaultBorrowCapacityStorage storage cap = LibStorage.getVaultBorrowCapacity()[vault][currencyId];\\n\\n    // Update the total used borrow capacity, when borrowing this number will increase (netfCash < 0),\\n    // when lending this number will decrease (netfCash > 0).\\n    totalUsedBorrowCapacity = int256(uint256(cap.totalUsedBorrowCapacity)).sub(netfCash);\\n    if (netfCash < 0) {\\n        // Always allow lending to reduce the total used borrow capacity to satisfy the case when the max borrow\\n        // capacity has been reduced by governance below the totalUsedBorrowCapacity. When borrowing, it cannot\\n        // go past the limit.\\n        require(totalUsedBorrowCapacity <= int256(uint256(cap.maxBorrowCapacity)), \"Max Capacity\");\\n```\\n
Rollover might introduce economically impractical deposits of dust into a strategyчlowчDuring the rollover of the strategy position into a longer maturity, several things happen:\\nFunds are borrowed from the longer maturity to pay off the debt and fees of the current maturity.\\nStrategy tokens that are associated with the current maturity are moved to the new maturity.\\nAny additional funds provided by the account are deposited into the strategy into a new longer maturity.\\nIn reality, due to the AMM nature of the protocol, the funds borrowed from the new maturity could exceed the debt the account has in the current maturity, resulting in a non-zero `vaultAccount.tempCashBalance`. In that case, those funds will be deposited into the strategy. That would happen even if there are no external funds supplied by the account for the deposit.\\nIt is possible that the dust in the temporary account balance will not cover the gas cost of triggering a full deposit call of the strategy.\\n```\\nuint256 strategyTokensMinted = vaultConfig.deposit(\\n    vaultAccount.account, vaultAccount.tempCashBalance, vaultState.maturity, additionalUnderlyingExternal, vaultData\\n);\\n```\\nчWe suggest that additional checks are introduced that would check that on rollover `vaultAccount.tempCashBalance + additionalUnderlyingExternal > 0` or larger than a certain threshold like `minAccountBorrowSize` for example.чч```\\nuint256 strategyTokensMinted = vaultConfig.deposit(\\n    vaultAccount.account, vaultAccount.tempCashBalance, vaultState.maturity, additionalUnderlyingExternal, vaultData\\n);\\n```\\n
Strategy vault swaps can be frontrunчlowчSome strategy vaults utilize borrowing one currency, swapping it for another, and then using the new currency somewhere to generate yield. For example, the CrossCurrencyfCash strategy vault could borrow USDC, swap it for DAI, and then deposit that DAI back into Notional if the DAI lending interest rates are greater than USDC borrowing interest rates. However, during vault settlement the assets would need to be swapped back into the original borrow currency.\\nSince these vaults control the borrowed assets that go only into white-listed strategies, the Notional system allows users to borrow multiples of their posted collateral and claim the yield from a much larger position. As a result, these strategy vaults would likely have significant funds being borrowed and managed into these strategies.\\nHowever, as mentioned above, these strategies usually utilize a trading mechanism to swap borrowed currencies into whatever is required by the strategy, and these trades may be quite large. In fact, the `BaseStrategyVault` implementation contains functions that interact with Notional's trading module to assist with those swaps:\\n```\\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\\n/// a trade.\\nfunction \\_executeTrade(\\n    uint16 dexId,\\n    Trade memory trade\\n) internal returns (uint256 amountSold, uint256 amountBought) {\\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\\n        .delegatecall(abi.encodeWithSelector(ITradingModule.executeTrade.selector, dexId, trade));\\n    require(success);\\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\\n}\\n\\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\\n/// a trade.\\nfunction \\_executeTradeWithDynamicSlippage(\\n    uint16 dexId,\\n    Trade memory trade,\\n    uint32 dynamicSlippageLimit\\n) internal returns (uint256 amountSold, uint256 amountBought) {\\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\\n        .delegatecall(abi.encodeWithSelector(\\n            ITradingModule.executeTradeWithDynamicSlippage.selector,\\n            dexId, trade, dynamicSlippageLimit\\n        )\\n    );\\n    require(success);\\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\\n}\\n```\\n\\nAlthough some strategies may manage stablecoin <-> stablecoin swaps that typically would incur low slippage, large size trades could still suffer from low on-chain liquidity and end up getting frontrun and “sandwiched” by MEV bots or other actors, thereby extracting maximum amount from the strategy vault swaps as slippage permits. This could be especially significant during vaults' settlements, that can be initiated by anyone, as lending currencies may be swapped in large batches and not do it on a per-account basis. For example with the CrossCurrencyfCash vault, it can only enter settlement if all strategy tokens (lending currency in this case) are gone and swapped back into the borrow currency:\\n```\\nif (vaultState.totalStrategyTokens == 0) {\\n    NOTIONAL.settleVault(address(this), maturity);\\n}\\n```\\n\\nAs a result, in addition to the risk of stablecoins' getting off-peg, unfavorable market liquidity conditions and arbitrage-seeking actors could eat into the profits generated by this strategy as per the maximum allowed slippage. However, during settlement the strategy vaults don't have the luxury of waiting for the right conditions to perform the trade as the borrows need to repaid at their maturities.\\nSo, the profitability of the vaults, and therefore users, could suffer due to potential low market liquidity allowing high slippage and risks of being frontrun with the chosen strategy vaults' currencies.чEnsure that the currencies chosen to generate yield in the strategy vaults have sufficient market liquidity on exchanges allowing for low slippage swaps.чч```\\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\\n/// a trade.\\nfunction \\_executeTrade(\\n    uint16 dexId,\\n    Trade memory trade\\n) internal returns (uint256 amountSold, uint256 amountBought) {\\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\\n        .delegatecall(abi.encodeWithSelector(ITradingModule.executeTrade.selector, dexId, trade));\\n    require(success);\\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\\n}\\n\\n/// @notice Can be used to delegate call to the TradingModule's implementation in order to execute\\n/// a trade.\\nfunction \\_executeTradeWithDynamicSlippage(\\n    uint16 dexId,\\n    Trade memory trade,\\n    uint32 dynamicSlippageLimit\\n) internal returns (uint256 amountSold, uint256 amountBought) {\\n    (bool success, bytes memory result) = nProxy(payable(address(TRADING\\_MODULE))).getImplementation()\\n        .delegatecall(abi.encodeWithSelector(\\n            ITradingModule.executeTradeWithDynamicSlippage.selector,\\n            dexId, trade, dynamicSlippageLimit\\n        )\\n    );\\n    require(success);\\n    (amountSold, amountBought) = abi.decode(result, (uint256, uint256));\\n}\\n```\\n
ConvexPositionHandler._claimRewards incorrectly calculates amount of LP tokens to unstakeчhighч`ConvexPositionHandler._claimRewards` is an internal function that harvests Convex reward tokens and takes the generated yield in ETH out of the Curve pool by calculating the difference in LP token price. To do so, it receives the current share price of the curve LP tokens and compares it to the last one stored in the contract during the last rewards claim. The difference in share price is then multiplied by the LP token balance to get the ETH yield via the `yieldEarned` variable:\\n```\\nuint256 currentSharePrice = ethStEthPool.get\\_virtual\\_price();\\nif (currentSharePrice > prevSharePrice) {\\n    // claim any gain on lp token yields\\n    uint256 contractLpTokenBalance = lpToken.balanceOf(address(this));\\n    uint256 totalLpBalance = contractLpTokenBalance +\\n        baseRewardPool.balanceOf(address(this));\\n    uint256 yieldEarned = (currentSharePrice - prevSharePrice) \\*\\n        totalLpBalance;\\n```\\n\\nHowever, to receive this ETH yield, LP tokens need to be unstaked from the Convex pool and then converted via the Curve pool. To do this, the contract introduces lpTokenEarned:\\n```\\nuint256 lpTokenEarned = yieldEarned / NORMALIZATION\\_FACTOR; // 18 decimal from virtual price\\n```\\n\\nThis calculation is incorrect. It uses yieldEarned which is denominated in ETH and simply divides it by the normalization factor to get the correct number of decimals, which still returns back an amount denominated in ETH, whereas an amount denominated in LP tokens should be returned instead.\\nThis could lead to significant accounting issues including losses in the “no-loss” parts of the vault's strategy as 1 LP token is almost always guaranteed to be worth more than 1 ETH. So, when the intention is to withdraw `X` ETH worth of an LP token, withdrawing `X` LP tokens will actually withdraw `Y` ETH worth of an LP token, where `Y>X`. As a result, less than expected ETH will remain in the Convex handler part of the vault, and the ETH yield will go to the Lyra options, which are much riskier. In the event Lyra options don't work out and there is more ETH withdrawn than expected, there is a possibility that this would result in a loss for the vault.чThe fix is straightforward and that is to calculate `lpTokenEarned` using the `currentSharePrice` already received from the Curve pool. That way, it is the amount of LP tokens that will be sent to be unwrapped and unstaked from the Convex and Curve pools. This will also take care of the normalization factor. uint256 `lpTokenEarned` = yieldEarned / currentSharePrice;чч```\\nuint256 currentSharePrice = ethStEthPool.get\\_virtual\\_price();\\nif (currentSharePrice > prevSharePrice) {\\n    // claim any gain on lp token yields\\n    uint256 contractLpTokenBalance = lpToken.balanceOf(address(this));\\n    uint256 totalLpBalance = contractLpTokenBalance +\\n        baseRewardPool.balanceOf(address(this));\\n    uint256 yieldEarned = (currentSharePrice - prevSharePrice) \\*\\n        totalLpBalance;\\n```\\n
The WETH tokens are not taken into account in the ConvexTradeExecutor.totalFunds functionчhighчThe `totalFunds` function of every executor should include all the funds that belong to the contract:\\n```\\nfunction totalFunds() public view override returns (uint256, uint256) {\\n    return ConvexPositionHandler.positionInWantToken();\\n}\\n```\\n\\nThe `ConvexTradeExecutor` uses this function for calculations:\\n```\\nfunction positionInWantToken()\\n    public\\n    view\\n    override\\n    returns (uint256, uint256)\\n{\\n    (\\n        uint256 stakedLpBalanceInETH,\\n        uint256 lpBalanceInETH,\\n        uint256 ethBalance\\n    ) = \\_getTotalBalancesInETH(true);\\n\\n    return (\\n        stakedLpBalanceInETH + lpBalanceInETH + ethBalance,\\n        block.number\\n    );\\n}\\n```\\n\\n```\\nfunction \\_getTotalBalancesInETH(bool useVirtualPrice)\\n    internal\\n    view\\n    returns (\\n        uint256 stakedLpBalance,\\n        uint256 lpTokenBalance,\\n        uint256 ethBalance\\n    )\\n{\\n    uint256 stakedLpBalanceRaw = baseRewardPool.balanceOf(address(this));\\n    uint256 lpTokenBalanceRaw = lpToken.balanceOf(address(this));\\n\\n    uint256 totalLpBalance = stakedLpBalanceRaw + lpTokenBalanceRaw;\\n\\n    // Here, in order to prevent price manipulation attacks via curve pools,\\n    // When getting total position value -> its calculated based on virtual price\\n    // During withdrawal -> calc\\_withdraw\\_one\\_coin() is used to get an actual estimate of ETH received if we were to remove liquidity\\n    // The following checks account for this\\n    uint256 totalLpBalanceInETH = useVirtualPrice\\n        ? \\_lpTokenValueInETHFromVirtualPrice(totalLpBalance)\\n        : \\_lpTokenValueInETH(totalLpBalance);\\n\\n    lpTokenBalance = useVirtualPrice\\n        ? \\_lpTokenValueInETHFromVirtualPrice(lpTokenBalanceRaw)\\n        : \\_lpTokenValueInETH(lpTokenBalanceRaw);\\n\\n    stakedLpBalance = totalLpBalanceInETH - lpTokenBalance;\\n    ethBalance = address(this).balance;\\n}\\n```\\n\\nThis function includes ETH balance, LP balance, and staked balance. But WETH balance is not included here. WETH tokens are initially transferred to the contract, and before the withdrawal, the contract also stores WETH.чInclude WETH balance into the `totalFunds`.чч```\\nfunction totalFunds() public view override returns (uint256, uint256) {\\n    return ConvexPositionHandler.positionInWantToken();\\n}\\n```\\n
LyraPositionHandlerL2 inaccurate modifier onlyAuthorized may lead to funds loss if keeper is compromisedчmediumчThe `LyraPositionHandlerL2` contract is operated either by the L2 keeper or by the L1 `LyraPositionHandler` via the `L2CrossDomainMessenger`. This is implemented through the `onlyAuthorized` modifier:\\n```\\nmodifier onlyAuthorized() {\\n    require(\\n        ((msg.sender == L2CrossDomainMessenger &&\\n            OptimismL2Wrapper.messageSender() == positionHandlerL1) ||\\n            msg.sender == keeper),\\n        \"ONLY\\_AUTHORIZED\"\\n    );\\n    \\_;\\n}\\n```\\n\\nThis is set on:\\n`withdraw()`\\n`openPosition()`\\n`closePosition()`\\n`setSlippage()`\\n`deposit()`\\n`sweep()`\\n`setSocketRegistry()`\\n`setKeeper()`\\nFunctions 1-3 have a corresponding implementation on the L1 `LyraPositionHandler`, so they could indeed be called by it with the right parameters. However, 4-8 do not have an implemented way to call them from L1, and this modifier creates an unnecessarily expanded list of authorised entities that can call them.\\nAdditionally, even if their implementation is provided, it needs to be done carefully because `msg.sender` in their case is going to end up being the `L2CrossDomainMessenger`. For example, the `sweep()` function sends any specified token to `msg.sender`, with the intention likely being that the recipient is under the team's or the governance's control – yet, it will be `L2CrossDomainMessenger` and the tokens will likely be lost forever instead.\\nOn the other hand, the `setKeeper()` function would need a way to be called by something other than the keeper because it is intended to change the keeper itself. In the event that the access to the L2 keeper is compromised, and the L1 `LyraPositionHandler` has no way to call `setKeeper()` on the `LyraPositionHandlerL2`, the whole contract and its funds will be compromised as well. So, there needs to be some way to at least call the `setKeeper()` by something other than the keeper to ensure security of the funds on L2.\\n```\\nfunction closePosition(bool toSettle) public override onlyAuthorized {\\n    LyraController.\\_closePosition(toSettle);\\n    UniswapV3Controller.\\_estimateAndSwap(\\n        false,\\n        LyraController.sUSD.balanceOf(address(this))\\n    );\\n}\\n\\n/\\*///////////////////////////////////////////////////////////////\\n MAINTAINANCE FUNCTIONS\\n//////////////////////////////////////////////////////////////\\*/\\n\\n/// @notice Sweep tokens\\n/// @param \\_token Address of the token to sweepr\\nfunction sweep(address \\_token) public override onlyAuthorized {\\n    IERC20(\\_token).transfer(\\n        msg.sender,\\n        IERC20(\\_token).balanceOf(address(this))\\n    );\\n}\\n\\n/// @notice socket registry setter\\n/// @param \\_socketRegistry new address of socket registry\\nfunction setSocketRegistry(address \\_socketRegistry) public onlyAuthorized {\\n    socketRegistry = \\_socketRegistry;\\n}\\n\\n/// @notice keeper setter\\n/// @param \\_keeper new keeper address\\nfunction setKeeper(address \\_keeper) public onlyAuthorized {\\n    keeper = \\_keeper;\\n}\\n```\\nчCreate an additional modifier for functions intended to be called just by the keeper (onlyKeeper) such as functions 4-7, and create an additional modifier `onlyGovernance` for the `setKeeper()` function. As an example, the L1 `Vault` contract also has a `setKeeper()` function that has a `onlyGovernance()` modifier. Please note that this will likely require implementing a function for the system's governance that can call `LyraPositionHandlerL2.setKeeper()` via the `L2CrossDomainMessenger`.чч```\\nmodifier onlyAuthorized() {\\n    require(\\n        ((msg.sender == L2CrossDomainMessenger &&\\n            OptimismL2Wrapper.messageSender() == positionHandlerL1) ||\\n            msg.sender == keeper),\\n        \"ONLY\\_AUTHORIZED\"\\n    );\\n    \\_;\\n}\\n```\\n
Harvester.harvest swaps have no slippage parametersчmediumчAs part of the vault strategy, all reward tokens for staking in the Convex ETH-stETH pool are claimed and swapped into ETH. The swaps for these tokens are done with no slippage at the moment, i.e. the expected output amount for all of them is given as 0.\\nIn particular, one reward token that is most susceptible to slippage is LDO, and its swap is implemented through the Uniswap router:\\n```\\nfunction \\_swapLidoForWETH(uint256 amountToSwap) internal {\\n    IUniswapSwapRouter.ExactInputSingleParams\\n        memory params = IUniswapSwapRouter.ExactInputSingleParams({\\n            tokenIn: address(ldo),\\n            tokenOut: address(weth),\\n            fee: UNISWAP\\_FEE,\\n            recipient: address(this),\\n            deadline: block.timestamp,\\n            amountIn: amountToSwap,\\n            amountOutMinimum: 0,\\n            sqrtPriceLimitX96: 0\\n        });\\n    uniswapRouter.exactInputSingle(params);\\n}\\n```\\n\\nThe swap is called with `amountOutMinimum: 0`, meaning that there is no slippage protection in this swap. This could result in a significant loss of yield from this reward as MEV bots could “sandwich” this swap by manipulating the price before this transaction and immediately reversing their action after the transaction, profiting at the expense of our swap. Moreover, the Uniswap pools seem to have low liquidity for the LDO token as opposed to Balancer or Sushiswap, further magnifying slippage issues and susceptibility to frontrunning.\\nThe other two tokens - CVX and CRV - are being swapped through their Curve pools, which have higher liquidity and are less susceptible to slippage. Nonetheless, MEV strategies have been getting more advanced and calling these swaps with 0 as expected output may place these transactions in danger of being frontrun and “sandwiched” as well.\\n```\\nif (cvxBalance > 0) {\\n    cvxeth.exchange(1, 0, cvxBalance, 0, false);\\n}\\n// swap CRV to WETH\\nif (crvBalance > 0) {\\n    crveth.exchange(1, 0, crvBalance, 0, false);\\n}\\n```\\n\\nIn these calls `.exchange` , the last `0` is the `min_dy` argument in the Curve pools swap functions that represents the minimum expected amount of tokens received after the swap, which is `0` in our case.чIntroduce some slippage parameters into the swaps.чч```\\nfunction \\_swapLidoForWETH(uint256 amountToSwap) internal {\\n    IUniswapSwapRouter.ExactInputSingleParams\\n        memory params = IUniswapSwapRouter.ExactInputSingleParams({\\n            tokenIn: address(ldo),\\n            tokenOut: address(weth),\\n            fee: UNISWAP\\_FEE,\\n            recipient: address(this),\\n            deadline: block.timestamp,\\n            amountIn: amountToSwap,\\n            amountOutMinimum: 0,\\n            sqrtPriceLimitX96: 0\\n        });\\n    uniswapRouter.exactInputSingle(params);\\n}\\n```\\n
Harvester.rewardTokens doesn't account for LDO tokensчmediumчAs part of the vault's strategy, the reward tokens for participating in Curve's ETH-stETH pool and Convex staking are claimed and swapped for ETH. This is done by having the `ConvexPositionHandler` contract call the reward claims API from Convex via `baseRewardPool.getReward()`, which transfers the reward tokens to the handler's address. Then, the tokens are iterated through and sent to the harvester to be swapped from `ConvexPositionHandler` by getting their list from `harvester.rewardTokens()` and calling `harvester.harvest()`\\n```\\n// get list of tokens to transfer to harvester\\naddress[] memory rewardTokens = harvester.rewardTokens();\\n//transfer them\\nuint256 balance;\\nfor (uint256 i = 0; i < rewardTokens.length; i++) {\\n    balance = IERC20(rewardTokens[i]).balanceOf(address(this));\\n\\n    if (balance > 0) {\\n        IERC20(rewardTokens[i]).safeTransfer(\\n            address(harvester),\\n            balance\\n        );\\n    }\\n}\\n\\n// convert all rewards to WETH\\nharvester.harvest();\\n```\\n\\nHowever, `harvester.rewardTokens()` doesn't have the LDO token's address in its list, so they will not be transferred to the harvester to be swapped.\\n```\\nfunction rewardTokens() external pure override returns (address[] memory) {\\n    address[] memory rewards = new address[](2);\\n    rewards[0] = address(crv);\\n    rewards[1] = address(cvx);\\n    return rewards;\\n}\\n```\\n\\nAs a result, `harvester.harvest()` will not be able to execute its `_swapLidoForWETH()` function since its `ldoBalance` will be 0. This results in missed rewards and therefore yield for the vault as part of its normal flow.\\nThere is a possible mitigation in the current state of the contract that would require governance to call `sweep()` on the LDO balance from the `BaseTradeExecutor` contract (that `ConvexPositionHandler` inherits) and then transferring those LDO tokens to the harvester contract to perform the swap at a later rewards claim. This, however, requires transactions separate from the intended flow of the system as well as governance intervention.чAdd the LDO token address to the `rewardTokens()` function by adding the following line `rewards[2] = address(ldo);`чч```\\n// get list of tokens to transfer to harvester\\naddress[] memory rewardTokens = harvester.rewardTokens();\\n//transfer them\\nuint256 balance;\\nfor (uint256 i = 0; i < rewardTokens.length; i++) {\\n    balance = IERC20(rewardTokens[i]).balanceOf(address(this));\\n\\n    if (balance > 0) {\\n        IERC20(rewardTokens[i]).safeTransfer(\\n            address(harvester),\\n            balance\\n        );\\n    }\\n}\\n\\n// convert all rewards to WETH\\nharvester.harvest();\\n```\\n
Keeper design complexityчmediumчThe current design of the protocol relies on the keeper being operated correctly in a complex manner. Since the offchain code for the keeper wasn't in scope of this audit, the following is a commentary on the complexity of the keeper operations in the context of the contracts. Keeper logic such as the order of operations and function argument parameters with log querying are some examples where if the keeper doesn't execute them correctly, there may be inconsistencies and issues with accounting of vault shares and vault funds resulting in unexpected behaviour. While it may represent little risk or issues to the current Brahma-fi team as the vault is recently live, the keeper logic and exact steps should be well documented so that public keepers (if and when they are enabled) can execute the logic securely and future iterations of the vault code can account for any intricacies of the keeper logic.\\n1. Order of operations: Convex rewards & new depositors profiting at the expense of old depositors' yielded reward tokens. As part of the vault's strategy, the depositors' ETH is provided to Curve and the LP tokens are staked in Convex, which yield rewards such as CRV, CVX, and LDO tokens. As new depositors provide their ETH, the vault shares minted for their deposits will be less compared to old deposits as they account for the increasing value of LP tokens staked in these pools. In other words, if the first depositor provides 1 ETH, then when a new depositor provides 1 ETH much later, the new depositor will get less shares back as the `totalVaultFunds()` will increase:\\n```\\nshares = totalSupply() > 0\\n    ? (totalSupply() \\* amountIn) / totalVaultFunds()\\n    : amountIn;\\n```\\n\\n```\\nfunction totalVaultFunds() public view returns (uint256) {\\n    return\\n        IERC20(wantToken).balanceOf(address(this)) + totalExecutorFunds();\\n}\\n```\\n\\n```\\nfunction totalFunds() public view override returns (uint256, uint256) {\\n    return ConvexPositionHandler.positionInWantToken();\\n}\\n```\\n\\n```\\nfunction positionInWantToken()\\n    public\\n    view\\n    override\\n    returns (uint256, uint256)\\n{\\n    (\\n        uint256 stakedLpBalanceInETH,\\n        uint256 lpBalanceInETH,\\n        uint256 ethBalance\\n    ) = \\_getTotalBalancesInETH(true);\\n\\n    return (\\n        stakedLpBalanceInETH + lpBalanceInETH + ethBalance,\\n        block.number\\n    );\\n}\\n```\\n\\nHowever, this does not account for the reward tokens yielded throughout that time. From the smart contract logic alone, there is no requirement to first execute the reward token harvest. It is up to the keeper to execute `ConvexTradeExecutor.claimRewards` in order to claim and swap their rewards into ETH, which only then will be included into the yield in the above `ConvexPositionHandler.positionInWantToken` function. If this is not done prior to processing new deposits and minting new shares, new depositors would unfairly benefit from the reward tokens' yield that was generated before they deposited but accounted for in the vault funds only after they deposited.\\n2. Order of operations: closing Lyra options before processing new deposits.\\nThe other part of the vault's strategy is utilising the yield from Convex to purchase options from Lyra on Optimism. While Lyra options are risky and can become worthless in the event of bad trades, only yield is used for them, therefore keeping user deposits' initial value safe. However, their value could also yield significant returns, increasing the overall funds of the vault. Just as with `ConvexTradeExecutor`, `LyraTradeExecutor` also has a `totalFunds()` function that feeds into the vault's `totalVaultFunds()` function. In Lyra's case, however, it is a manually set value by the keeper that is supposed to represent the value of Lyra L2 options:\\n```\\nfunction totalFunds()\\n    public\\n    view\\n    override\\n    returns (uint256 posValue, uint256 lastUpdatedBlock)\\n{\\n    return (\\n        positionInWantToken.posValue +\\n            IERC20(vaultWantToken()).balanceOf(address(this)),\\n        positionInWantToken.lastUpdatedBlock\\n    );\\n}\\n```\\n\\n```\\nfunction setPosValue(uint256 \\_posValue) public onlyKeeper {\\n    LyraPositionHandler.\\_setPosValue(\\_posValue);\\n}\\n```\\n\\n```\\nfunction \\_setPosValue(uint256 \\_posValue) internal {\\n    positionInWantToken.posValue = \\_posValue;\\n    positionInWantToken.lastUpdatedBlock = block.number;\\n}\\n```\\n\\nSolely from the smart contract logic, there is a possibility that a user deposits when Lyra options are valued high, meaning the total vault funds are high as well, thus decreasing the amount of shares the user would have received if it weren't for the Lyra options' value. Consequently, if after the deposit the Lyra options become worthless, decreasing the total vault funds, the user's newly minted shares will now represent less than what they have deposited.\\nWhile this is not currently mitigated by smart contract logic, it may be worked around by the keeper first settling and closing all Lyra options and transferring all their yielded value in ETH, if any, to the Convex trade executor. Only then the keeper would process new deposits and mint new shares. This order of operations is critical to maintain the vault's intended safe strategy of maintaining the user's deposited value, and is dependent entirely on the keeper offchain logic.\\n3. Order of operations: additional trade executors and their specific management Similarly to the above examples, as more trade executors and position handlers are added to the vault, the complexity for the keeper will go up significantly, requiring it to maintain all correct orders of operations not just to keep the shares and funds accounting intact, but simply for the trade executors to function normally. For example, in the case of Lyra, the keepers need to manually call `confirmDeposit` and `confirmWithdraw` to update their `depositStatus` and `withdrawalStatus` respectively to continue normal operations or otherwise new deposits and withdrawals wouldn't be processed. On the other hand, the Convex executor does it automatically. Due to the system design, there may be no single standard way to handle a trade executor. New executors may also require specific calls to be done manually, increasing overall complexity keeper logic to support the system.\\n4. Keeper calls & arguments: depositFunds/batchDeposit and initiateWithdrawal/batchWithdraw `userAddresses[]` array + gas overhead With the current gated approach and batching for deposits and withdrawals to and from the vault, users aren't able to directly mint and redeem their vault shares. Instead, they interact with the `Batcher` contract that then communicates with the `Vault` contract with the help of the keeper. However, while each user's deposit and withdrawal amounts are registered in the contract state variables such as `depositLedger[user]` and `withdrawLedger[user]`, and there is an event emitted with the user address and their action, to process them the keeper is required to keep track of all the user addresses in the batch they need to process. In particular, the keeper needs to provide `address[] memory users` for both `batchDeposit()` and `batchWithdraw()` functions that communicate with the vault. There is no stored list of users within the contract that could provide or verify the right users, so it is entirely up to the keeper's offchain logic to query the logs and retrieve the addresses required. Therefore, depending on the size of the `address[] memory users` array, the keepers may need to consider the transaction gas limit, possibly requiring splitting the array up and doing several transactions to process all of them. In addition, in the event of withdrawals, the keepers need to calculate how much of the `wantToken` (WETH in our case) will be required to process the withdrawals, and call `withdrawFromExecutor()` with that amount to provide enough assets to cover withdrawals from the vault.\\n5. Timing: 50 block radius for updates on trade executors that need to have their values updated via a call Some trade executors, like the Convex one, can retrieve their funds value at any time from Layer 1, thereby always being up to date with the current block. Others, like the Lyra trade executor, require the keeper to update their position value by initiating a call, which also updates their `positionInWantToken.lastUpdatedBlock` state variable. However, this variable is also called during during the vault.totalVaultFunds()call during deposits and withdrawals via `totalExecutorFunds()`, which eventually calls `areFundsUpdated(blockUpdated)`. This is a check to ensure that the current transaction's `block.number <= _blockUpdated + BLOCK_LIMIT`, where BLOCK_LIMIT=50 blocks, i.e. roughly 12-15 min. As a result, keepers need to make sure that all executors that require a call for this have their position values updated before and rather close to processing and deposits or withdrawals, or `areFundsUpdated()` will revert those calls.чDocument the exact order of operations, steps, necessary logs and parameters that keepers need to keep track of in order for the vault strategy to succeed.чч```\\nshares = totalSupply() > 0\\n    ? (totalSupply() \\* amountIn) / totalVaultFunds()\\n    : amountIn;\\n```\\n
Approving MAX_UINT amount of ERC20 tokensчlowчApproving the maximum value of uint256 is a known practice to save gas. However, this pattern was proven to increase the impact of an attack many times in the past, in case the approved contract gets hacked.\\n```\\nIERC20(vaultWantToken()).approve(vault, MAX\\_INT);\\n```\\n\\n```\\nIERC20(vaultInfo.tokenAddress).approve(vaultAddress, type(uint256).max);\\n```\\n\\n```\\nIERC20(LP\\_TOKEN).safeApprove(ETH\\_STETH\\_POOL, type(uint256).max);\\n\\n// Approve max LP tokens to convex booster\\nIERC20(LP\\_TOKEN).safeApprove(\\n    address(CONVEX\\_BOOSTER),\\n    type(uint256).max\\n);\\n```\\n\\n```\\ncrv.safeApprove(address(crveth), type(uint256).max);\\n// max approve CVX to CVX/ETH pool on curve\\ncvx.safeApprove(address(cvxeth), type(uint256).max);\\n// max approve LDO to uniswap swap router\\nldo.safeApprove(address(uniswapRouter), type(uint256).max);\\n```\\n\\n```\\nIERC20(wantTokenL2).safeApprove(\\n    address(UniswapV3Controller.uniswapRouter),\\n    type(uint256).max\\n);\\n// approve max susd balance to uniV3 router\\nLyraController.sUSD.safeApprove(\\n    address(UniswapV3Controller.uniswapRouter),\\n    type(uint256).max\\n);\\n```\\nчConsider approving the exact amount that's needed to be transferred, or alternatively, add an external function that allows the revocation of approvals.чч```\\nIERC20(vaultWantToken()).approve(vault, MAX\\_INT);\\n```\\n
Batcher.depositFunds may allow for more deposits than vaultInfo.maxAmountчlowчAs part of a gradual rollout strategy, the Brahma-fi system of contracts has a limit of how much can be deposited into the protocol. This is implemented through the `Batcher` contract that allows users to deposit into it and keep the amount they have deposited in the `depositLedger[recipient]` state variable. In order to cap how much is deposited, the user's input `amountIn` is evaluated within the following statement:\\n```\\nrequire(\\n    IERC20(vaultInfo.vaultAddress).totalSupply() +\\n        pendingDeposit -\\n        pendingWithdrawal +\\n        amountIn <=\\n        vaultInfo.maxAmount,\\n    \"MAX\\_LIMIT\\_EXCEEDED\"\\n);\\n```\\n\\nHowever, while `pendingDeposit`, `amountIn`, and `vaultInfo.maxAmount` are denominated in the vault asset token (WETH in our case), `IERC20(vaultInfo.vaultAddress).totalSupply()` and `pendingWithdrawal` represent vault shares tokens, creating potential mismatches in this evaluation.\\nAs the yield brings in more and more funds to the vault, the amount of share minted for each token deposited in decreases, so `totalSupply()` becomes less than the total deposited amount (not just vault funds) as the strategy succeeds over time. For example, at first `X` deposited tokens would mint `X` shares. After some time, this would create additional funds in the vault through yield, and another `X` deposit of tokens would mint less than `X` shares, say `X-Y`, where `Y` is some number greater than 0 representing the difference in the number of shares minted. So, while there were `2*X` deposited tokens, `totalSupply()=(2*X-Y)` shares would have been minted in total. However, at the time of the next deposit, a user's `amountIn` will be added with `totalSupply()=(2*X-Y)` number of shares instead of a greater `2*X` number of deposited tokens. So, this will undershoot the actual amount of tokens deposited after this user's deposit, thus potentially evaluating it less than `maxAmount`, and letting more user deposits get inside the vault than what was intended.чConsider either documenting this potential discrepancy or keeping track of all deposits in a state variable and using that inside the `require` statement..чч```\\nrequire(\\n    IERC20(vaultInfo.vaultAddress).totalSupply() +\\n        pendingDeposit -\\n        pendingWithdrawal +\\n        amountIn <=\\n        vaultInfo.maxAmount,\\n    \"MAX\\_LIMIT\\_EXCEEDED\"\\n);\\n```\\n
BaseTradeExecutor.confirmDeposit | confirmWithdraw - Violation of the “checks-effects-interactions” patternчlowчBoth `confirmDeposit, confirmWithdraw` might be re-entered by the keeper (in case it is a contract), in case the derived contract allows the execution of untrusted code.\\n```\\nfunction confirmDeposit() public override onlyKeeper {\\n    require(depositStatus.inProcess, \"DEPOSIT\\_COMPLETED\");\\n    \\_confirmDeposit();\\n    depositStatus.inProcess = false;\\n}\\n```\\n\\n```\\nfunction confirmWithdraw() public override onlyKeeper {\\n    require(withdrawalStatus.inProcess, \"WIHDRW\\_COMPLETED\");\\n    \\_confirmWithdraw();\\n    withdrawalStatus.inProcess = false;\\n}\\n```\\nчAlthough the impact is very limited, it is recommended to implement the “checks-effects-interactions” in both functions.чч```\\nfunction confirmDeposit() public override onlyKeeper {\\n    require(depositStatus.inProcess, \"DEPOSIT\\_COMPLETED\");\\n    \\_confirmDeposit();\\n    depositStatus.inProcess = false;\\n}\\n```\\n
Reactivated gauges can't queue up rewardsчhighчActive gauges as set in `ERC20Gauges.addGauge()` function by authorised users get their rewards queued up in the `FlywheelGaugeRewards._queueRewards()` function. As part of it, their associated struct `QueuedRewards` updates its `storedCycle` value to the cycle in which they get queued up:\\n```\\ngaugeQueuedRewards[gauge] = QueuedRewards({\\n    priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,\\n    cycleRewards: uint112(nextRewards),\\n    storedCycle: currentCycle\\n});\\n```\\n\\nHowever, these gauges may be deactivated in `ERC20Gauges.removeGauge()`, and they will now be ignored in either `FlywheelGaugeRewards.queueRewardsForCycle()` or `FlywheelGaugeRewards.queueRewardsForCyclePaginated()` because both use `gaugeToken.gauges()` to get the set of gauges for which to queue up rewards for the cycle, and that only gives active gauges. Therefore, any updates `FlywheelGaugeRewards` makes to its state will not be done to deactivated gauges' `QueuedRewards` structs. In particular, the `gaugeCycle` contract state variable will keep advancing throughout its cycles, while `QueuedRewards.storedCycle` will retain its previously set value, which is the cycle where it was queued and not 0.\\nOnce reactivated later with at least 1 full cycle being done without it, it will produce issues. It will now be returned by `gaugeToken.gauges()` to be processed in either FlywheelGaugeRewards.queueRewardsForCycle()or `FlywheelGaugeRewards.queueRewardsForCyclePaginated()`, but, once the reactivated gauge is passed to `_queueRewards()`, it will fail an assert:\\n```\\nassert(queuedRewards.storedCycle == 0 || queuedRewards.storedCycle >= lastCycle);\\n```\\n\\nThis is because it already has a set value from the cycle it was processed in previously (i.e. storedCycle>0), and, since that cycle is at least 1 full cycle behind the state contract, it will also not pass the second condition `queuedRewards.storedCycle >= lastCycle`.\\nThe result is that this gauge is locked out of queuing up for rewards because `queuedRewards.storedCycle` is only synchronised with the contract's cycle later in `_queueRewards()` which will now always fail for this gauge.чAccount for the reactivated gauges that previously went through the rewards queue process, such as introducing a separate flow for newly activated gauges. However, any changes such as removing the above mentioned `assert()` should be carefully validated for other downstream logic that may use the `QueuedRewards.storedCycle` value. Therefore, it is recommended to review the state transitions as opposed to only passing this specific check.чч```\\ngaugeQueuedRewards[gauge] = QueuedRewards({\\n    priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,\\n    cycleRewards: uint112(nextRewards),\\n    storedCycle: currentCycle\\n});\\n```\\n
Reactivated gauges have incorrect accounting for the last cycle's rewardsчmediumчAs described in https://github.com/ConsenSysDiligence/fei-labs-audit-2022-04/issues/3, reactivated gauges that previously had queued up rewards have a mismatch between their `storedCycle` and contract's `gaugeCycle` state variable.\\nDue to this mismatch, there is also a resulting issue with the accounting logic for its completed rewards:\\n```\\nuint112 completedRewards = queuedRewards.storedCycle == lastCycle ? queuedRewards.cycleRewards : 0;\\n```\\n\\nConsequently, this then produces an incorrect value for QueuedRewards.priorCycleRewards:\\n```\\npriorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,\\n```\\n\\nAs now `completedRewards` will be equal to 0 instead of the previous cycle's rewards for that gauge. This may cause a loss of rewards accounted for this gauge as this value is later used in `getAccruedRewards()`.чConsider changing the logic of the check so that `storedCycle` values further in the past than `lastCycle` may produce the right rewards return for this expression, such as using `<=` instead of `==` and adding an explicit check for `storedCycle` `==` 0 to account for the initial scenario.чч```\\nuint112 completedRewards = queuedRewards.storedCycle == lastCycle ? queuedRewards.cycleRewards : 0;\\n```\\n
Lack of input validation in delegateBySigчlowч```\\nfunction delegateBySig(\\n    address delegatee,\\n    uint256 nonce,\\n    uint256 expiry,\\n    uint8 v,\\n    bytes32 r,\\n    bytes32 s\\n) public {\\n    require(block.timestamp <= expiry, \"ERC20MultiVotes: signature expired\");\\n    address signer = ecrecover(\\n        keccak256(\\n            abi.encodePacked(\\n                \"\\x19\\x01\",\\n                DOMAIN\\_SEPARATOR(),\\n                keccak256(abi.encode(DELEGATION\\_TYPEHASH, delegatee, nonce, expiry))\\n            )\\n        ),\\n        v,\\n        r,\\n        s\\n    );\\n    require(nonce == nonces[signer]++, \"ERC20MultiVotes: invalid nonce\");\\n    \\_delegate(signer, delegatee);\\n}\\n```\\nчIntroduce a zero address check i.e `require signer!=address(0)` and check if the recovered signer is an expected address. Refer to ERC20's permit for inspiration.чч```\\nfunction delegateBySig(\\n    address delegatee,\\n    uint256 nonce,\\n    uint256 expiry,\\n    uint8 v,\\n    bytes32 r,\\n    bytes32 s\\n) public {\\n    require(block.timestamp <= expiry, \"ERC20MultiVotes: signature expired\");\\n    address signer = ecrecover(\\n        keccak256(\\n            abi.encodePacked(\\n                \"\\x19\\x01\",\\n                DOMAIN\\_SEPARATOR(),\\n                keccak256(abi.encode(DELEGATION\\_TYPEHASH, delegatee, nonce, expiry))\\n            )\\n        ),\\n        v,\\n        r,\\n        s\\n    );\\n    require(nonce == nonces[signer]++, \"ERC20MultiVotes: invalid nonce\");\\n    \\_delegate(signer, delegatee);\\n}\\n```\\n
Decreasing maxGauges does not account for users' previous gauge list size.чlowч`ERC20Gauges` contract has a `maxGauges` state variable meant to represent the maximum amount of gauges a user can allocate to. As per the natspec, it is meant to protect against gas DOS attacks upon token transfer to allow complicated transactions to fit in a block. There is also a function `setMaxGauges` for authorised users to decrease or increase this state variable.\\n```\\nfunction setMaxGauges(uint256 newMax) external requiresAuth {\\n    uint256 oldMax = maxGauges;\\n    maxGauges = newMax;\\n\\n    emit MaxGaugesUpdate(oldMax, newMax);\\n}\\n```\\n\\nHowever, if it is decreased and there are users that have already reached the previous maximum that was larger, there may be unexpected behavior. All of these users' gauges will remain active and manageable, such as have user gauge weights incremented or decremented. So it could be possible that for such a user address `user_address`, numUserGauges(user_address) > `maxGauges`. While in the current contract logic this does not cause issues, `maxGauges` is a public variable that may be used by other systems. If unaccounted for, this discrepancy between the contract's `maxGauges` and the users' actual number of gauges given by `numUserGauges()` could, for example, cause gauges to be skipped or fail loops bounded by `maxGauges` in other systems' logic that try and go through all user gauges.чEither document the potential discrepancy between the user gauges size and the `maxGauges` state variable, or limit `maxGauges` to be only called within the contract thereby forcing other contracts to retrieve user gauge list size through `numUserGauges()`.чч```\\nfunction setMaxGauges(uint256 newMax) external requiresAuth {\\n    uint256 oldMax = maxGauges;\\n    maxGauges = newMax;\\n\\n    emit MaxGaugesUpdate(oldMax, newMax);\\n}\\n```\\n
Decrementing a gauge by 0 that is not in the user gauge list will fail an assert.чlowч`ERC20Gauges._decrementGaugeWeight` has an edge case scenario where a user can attempt to decrement a `gauge` that is not in the user `gauge` list by 0 `weight`, which would trigger a failure in an assert.\\n```\\nfunction \\_decrementGaugeWeight(\\n    address user,\\n    address gauge,\\n    uint112 weight,\\n    uint32 cycle\\n) internal {\\n    uint112 oldWeight = getUserGaugeWeight[user][gauge];\\n\\n    getUserGaugeWeight[user][gauge] = oldWeight - weight;\\n    if (oldWeight == weight) {\\n        // If removing all weight, remove gauge from user list.\\n        assert(\\_userGauges[user].remove(gauge));\\n    }\\n```\\n\\nAs `_decrementGaugeWeight`, `decrementGauge`, or `decrementGauges` don't explicitly check that a `gauge` belongs to the user, the contract logic continues with its operations in `_decrementGaugeWeight` for any gauges passed to it. In general this is fine because if a user tries to decrement non-zero `weight` from a `gauge` they have no allocation to, thus getting `getUserGaugeWeight[user][gauge]=0`, there would be a revert due to a negative value being passed to `getUserGaugeWeight[user][gauge]`\\n```\\nuint112 oldWeight = getUserGaugeWeight[user][gauge];\\n\\ngetUserGaugeWeight[user][gauge] = oldWeight - weight;\\n```\\n\\nHowever, passing a `weight=0` parameter with a `gauge` that doesn't belong to the user, would successfully process that line. This would then be followed by an evaluation `if (oldWeight == weight)`, which would also succeed since both are 0, to finally reach an assert that will verify a remove of that `gauge` from the user `gauge` list. However, it will fail since it was never there in the first place.\\n```\\nassert(\\_userGauges[user].remove(gauge));\\n```\\n\\nAlthough an edge case with no effect on contract state's health, it may happen with front end bugs or incorrect user transactions, and it is best not to have asserts fail.чReplace `assert()` with a `require()` or verify that the gauge belongs to the user prior to performing any operations.чч```\\nfunction \\_decrementGaugeWeight(\\n    address user,\\n    address gauge,\\n    uint112 weight,\\n    uint32 cycle\\n) internal {\\n    uint112 oldWeight = getUserGaugeWeight[user][gauge];\\n\\n    getUserGaugeWeight[user][gauge] = oldWeight - weight;\\n    if (oldWeight == weight) {\\n        // If removing all weight, remove gauge from user list.\\n        assert(\\_userGauges[user].remove(gauge));\\n    }\\n```\\n
Undelegating 0 votes from an address who is not a delegate of a user will fail an assert.чlowчSimilar scenario with issue 5.5. `ERC20MultiVotes._undelegate` has an edge case scenario where a user can attempt to undelegate from a `delegatee` that is not in the user delegates list by 0 `amount`, which would trigger a failure in an assert.\\n```\\nfunction \\_undelegate(\\n    address delegator,\\n    address delegatee,\\n    uint256 amount\\n) internal virtual {\\n    uint256 newDelegates = \\_delegatesVotesCount[delegator][delegatee] - amount;\\n\\n    if (newDelegates == 0) {\\n        assert(\\_delegates[delegator].remove(delegatee)); // Should never fail.\\n    }\\n```\\n\\nAs `_undelegate`, or `undelegate` don't explicitly check that a `delegatee` belongs to the user, the contract logic continues with its operations in `_undelegate` for the `delegatee` passed to it. In general this is fine because if a user tries to `undelegate` non-zero `amount` from a `delegatee` they have no votes delegated to, thus getting `_delegatesVotesCount[delegator][delegatee]=0`, there would be a revert due to a negative value being passed to `uint256 newDelegates`\\n```\\nuint256 newDelegates = \\_delegatesVotesCount[delegator][delegatee] - amount;\\n```\\n\\nHowever, passing a `amount=0` parameter with a `delegatee` that doesn't belong to the user, would successfully process that line. This would then be followed by an evaluation `if (newDelegates == 0)`, which would succeed, to finally reach an assert that will verify a remove of that `delegatee` from the user delegates list. However, it will fail since it was never there in the first place.\\n```\\nassert(\\_delegates[delegator].remove(delegatee)); // Should never fail.\\n```\\n\\nAlthough an edge case with no effect on contract state's health, it may happen with front end bugs or incorrect user transactions, and it is best not to have asserts fail, as per the dev comment in that line “// Should never fail”.чReplace `assert()` with a `require()` or verify that the delegatee belongs to the user prior to performing any operations.чч```\\nfunction \\_undelegate(\\n    address delegator,\\n    address delegatee,\\n    uint256 amount\\n) internal virtual {\\n    uint256 newDelegates = \\_delegatesVotesCount[delegator][delegatee] - amount;\\n\\n    if (newDelegates == 0) {\\n        assert(\\_delegates[delegator].remove(delegatee)); // Should never fail.\\n    }\\n```\\n
xTRIBE.emitVotingBalances - DelegateVotesChanged event can be emitted by anyoneчmediumч`xTRIBE.emitVotingBalances` is an external function without authentication constraints. It means anyone can call it and emit `DelegateVotesChanged` which may impact other layers of code that rely on these events.\\n```\\nfunction emitVotingBalances(address[] calldata accounts) external {\\n    uint256 size = accounts.length;\\n\\n    for (uint256 i = 0; i < size; ) {\\n        emit DelegateVotesChanged(accounts[i], 0, getVotes(accounts[i]));\\n\\n        unchecked {\\n            i++;\\n        }\\n    }\\n}\\n```\\nчConsider restricting access to this function for allowed accounts only.чч```\\nfunction emitVotingBalances(address[] calldata accounts) external {\\n    uint256 size = accounts.length;\\n\\n    for (uint256 i = 0; i < size; ) {\\n        emit DelegateVotesChanged(accounts[i], 0, getVotes(accounts[i]));\\n\\n        unchecked {\\n            i++;\\n        }\\n    }\\n}\\n```\\n
Decreasing maxGauges does not account for users' previous gauge list size.чlowч`ERC20Gauges` contract has a `maxGauges` state variable meant to represent the maximum amount of gauges a user can allocate to. As per the natspec, it is meant to protect against gas DOS attacks upon token transfer to allow complicated transactions to fit in a block. There is also a function `setMaxGauges` for authorised users to decrease or increase this state variable.\\n```\\nfunction setMaxGauges(uint256 newMax) external requiresAuth {\\n uint256 oldMax = maxGauges;\\n maxGauges = newMax;\\n\\n emit MaxGaugesUpdate(oldMax, newMax);\\n}\\n```\\n\\nHowever, if it is decreased and there are users that have already reached the previous maximum that was larger, there may be unexpected behavior. All of these users' gauges will remain active and manageable, such as have user gauge weights incremented or decremented. So it could be possible that for such a user address `user_address`, numUserGauges(user_address) > `maxGauges`. While in the current contract logic this does not cause issues, `maxGauges` is a public variable that may be used by other systems. If unaccounted for, this discrepancy between the contract's `maxGauges` and the users' actual number of gauges given by `numUserGauges()` could, for example, cause gauges to be skipped or fail loops bounded by `maxGauges` in other systems' logic that try and go through all user gauges.чEither document the potential discrepancy between the user gauges size and the `maxGauges` state variable, or limit `maxGauges` to be only called within the contract thereby forcing other contracts to retrieve user gauge list size through `numUserGauges()`.чч```\\nfunction setMaxGauges(uint256 newMax) external requiresAuth {\\n uint256 oldMax = maxGauges;\\n maxGauges = newMax;\\n\\n emit MaxGaugesUpdate(oldMax, newMax);\\n}\\n```\\n
Accounts that claim incentives immediately before the migration will be stuckчmediumчFor accounts that existed before the migration to the new incentive calculation, the following happens when they claim incentives for the first time after the migration: First, the incentives that are still owed from before the migration are computed according to the old formula; the incentives since the migration are calculated according to the new logic, and the two values are added together. The first part – calculating the pre-migration incentives according to the old formula – happens in function MigrateIncentives.migrateAccountFromPreviousCalculation; the following lines are of particular interest in the current context:\\n```\\nuint256 timeSinceMigration = finalMigrationTime - lastClaimTime;\\n\\n// (timeSinceMigration \\* INTERNAL\\_TOKEN\\_PRECISION \\* finalEmissionRatePerYear) / YEAR\\nuint256 incentiveRate =\\n    timeSinceMigration\\n        .mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\\n        // Migration emission rate is stored as is, denominated in whole tokens\\n        .mul(finalEmissionRatePerYear).mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\\n        .div(Constants.YEAR);\\n\\n// Returns the average supply using the integral of the total supply.\\nuint256 avgTotalSupply = finalTotalIntegralSupply.sub(lastClaimIntegralSupply).div(timeSinceMigration);\\n```\\n\\nThe division in the last line will throw if `finalMigrationTime` and `lastClaimTime` are equal. This will happen if an account claims incentives immediately before the migration happens – where “immediately” means in the same block. In such a case, the account will be stuck as any attempt to claim incentives will revert.чThe function should return `0` if `finalMigrationTime` and `lastClaimTime` are equal. Moreover, the variable name `timeSinceMigration` is misleading, as the variable doesn't store the time since the migration but the time between the last incentive claim and the migration.чч```\\nuint256 timeSinceMigration = finalMigrationTime - lastClaimTime;\\n\\n// (timeSinceMigration \\* INTERNAL\\_TOKEN\\_PRECISION \\* finalEmissionRatePerYear) / YEAR\\nuint256 incentiveRate =\\n    timeSinceMigration\\n        .mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\\n        // Migration emission rate is stored as is, denominated in whole tokens\\n        .mul(finalEmissionRatePerYear).mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\\n        .div(Constants.YEAR);\\n\\n// Returns the average supply using the integral of the total supply.\\nuint256 avgTotalSupply = finalTotalIntegralSupply.sub(lastClaimIntegralSupply).div(timeSinceMigration);\\n```\\n
type(T).max is inclusiveчlowчThroughout the codebase, there are checks whether a number can be represented by a certain type.\\n```\\nrequire(accumulatedNOTEPerNToken < type(uint128).max); // dev: accumulated NOTE overflow\\n```\\n\\n```\\nrequire(blockTime < type(uint32).max); // dev: block time overflow\\n```\\n\\n```\\nrequire(totalSupply <= type(uint96).max);\\nrequire(blockTime <= type(uint32).max);\\n```\\n\\nSometimes these checks use `<=`, sometimes they use `<`.ч`type(T).max` is inclusive, i.e., it is the greatest number that can be represented with type `T`. Strictly speaking, it can and should therefore be used consistently with `<=` instead of `<`.чч```\\nrequire(accumulatedNOTEPerNToken < type(uint128).max); // dev: accumulated NOTE overflow\\n```\\n
FlasherFTM - Unsolicited invocation of the callback (CREAM auth bypass)чhighчTL;DR: Anyone can call `ICTokenFlashloan(crToken).flashLoan(address(FlasherFTM), address(FlasherFTM), info.amount, params)` directly and pass validation checks in `onFlashLoan()`. This call forces it to accept unsolicited flash loans and execute the actions provided under the attacker's `FlashLoan.Info`.\\n`receiver.onFlashLoan(initiator, token, amount, ...)` is called when receiving a flash loan. According to EIP-3156, the `initiator` is `msg.sender` so that one can use it to check if the call to `receiver.onFlashLoan()` was unsolicited or not.\\nThird-party Flash Loan provider contracts are often upgradeable.\\nFor example, the Geist lending contract configured with this system is upgradeable. Upgradeable contracts bear the risk that one cannot assume that the contract is always running the same code. In the worst case, for example, a malicious proxy admin (leaked keys, insider, …) could upgrade the contract and perform unsolicited calls with arbitrary data to Flash Loan consumers in an attempt to exploit them. It, therefore, is highly recommended to verify that flash loan callbacks in the system can only be called if the contract was calling out to the provider to provide a Flash Loan and that the conditions of the flash loan (returned data, amount) are correct.\\nNot all Flash Loan providers implement EIP-3156 correctly.\\nCream Finance, for example, allows users to set an arbitrary `initiator` when requesting a flash loan. This deviates from EIP-3156 and was reported to the Cream development team as a security issue. Hence, anyone can spoof that `initiator` and potentially bypass authentication checks in the consumers' `receiver.onFlashLoan()`. Depending on the third-party application consuming the flash loan is doing with the funds, the impact might range from medium to critical with funds at risk. For example, projects might assume that the flash loan always originates from their trusted components, e.g., because they use them to refinance switching funds between pools or protocols.\\nThe `FlasherFTM` contract assumes that flash loans for the Flasher can only be initiated by authorized callers (isAuthorized) - for a reason - because it is vital that the `FlashLoan.Info calldata info` parameter only contains trusted data:\\n```\\n/\\*\\*\\n \\* @dev Routing Function for Flashloan Provider\\n \\* @param info: struct information for flashLoan\\n \\* @param \\_flashnum: integer identifier of flashloan provider\\n \\*/\\nfunction initiateFlashloan(FlashLoan.Info calldata info, uint8 \\_flashnum) external isAuthorized override {\\n if (\\_flashnum == 0) {\\n \\_initiateGeistFlashLoan(info);\\n } else if (\\_flashnum == 2) {\\n \\_initiateCreamFlashLoan(info);\\n } else {\\n revert(Errors.VL\\_INVALID\\_FLASH\\_NUMBER);\\n }\\n}\\n```\\n\\n```\\nmodifier isAuthorized() {\\n require(\\n msg.sender == \\_fujiAdmin.getController() ||\\n msg.sender == \\_fujiAdmin.getFliquidator() ||\\n msg.sender == owner(),\\n Errors.VL\\_NOT\\_AUTHORIZED\\n );\\n \\_;\\n}\\n```\\n\\nThe Cream Flash Loan initiation code requests the flash loan via ICTokenFlashloan(crToken).flashLoan(receiver=address(this), initiator=address(this), ...):\\n```\\n/\\*\\*\\n \\* @dev Initiates an CreamFinance flashloan.\\n \\* @param info: data to be passed between functions executing flashloan logic\\n \\*/\\nfunction \\_initiateCreamFlashLoan(FlashLoan.Info calldata info) internal {\\n address crToken = info.asset == \\_FTM\\n ? 0xd528697008aC67A21818751A5e3c58C8daE54696\\n : \\_crMappings.addressMapping(info.asset);\\n\\n // Prepara data for flashloan execution\\n bytes memory params = abi.encode(info);\\n\\n // Initialize Instance of Cream crLendingContract\\n ICTokenFlashloan(crToken).flashLoan(address(this), address(this), info.amount, params);\\n}\\n```\\n\\nNote: The Cream implementation does not send `sender=msg.sender` to the `onFlashLoan()` callback - like any other flash loan provider does and EIP-3156 suggests - but uses the value that was passed in as `initiator` when requesting the callback. This detail completely undermines the authentication checks implemented in `onFlashLoan` as the `sender` value cannot be trusted.\\n```\\naddress initiator,\\n```\\n\\n```\\n \\*/\\nfunction onFlashLoan(\\n address sender,\\n address underlying,\\n uint256 amount,\\n uint256 fee,\\n bytes calldata params\\n) external override returns (bytes32) {\\n // Check Msg. Sender is crToken Lending Contract\\n // from IronBank because ETH on Cream cannot perform a flashloan\\n address crToken = underlying == \\_WFTM\\n ? 0xd528697008aC67A21818751A5e3c58C8daE54696\\n : \\_crMappings.addressMapping(underlying);\\n require(msg.sender == crToken && address(this) == sender, Errors.VL\\_NOT\\_AUTHORIZED);\\n```\\nчCream Finance\\nWe've reached out to the Cream developer team, who have confirmed the issue. They are planning to implement countermeasures. Our recommendation can be summarized as follows:\\nImplement the EIP-3156 compliant version of flashLoan() with initiator hardcoded to `msg.sender`.\\nFujiDAO (and other flash loan consumers)\\nWe recommend not assuming that `FlashLoan.Info` contains trusted or even validated data when a third-party flash loan provider provides it! Developers should ensure that the data received was provided when the flash loan was requested.\\nThe contract should reject unsolicited flash loans. In the scenario where a flash loan provider is exploited, the risk of an exploited trust relationship is less likely to spread to the rest of the system.\\nThe Cream `initiator` provided to the `onFlashLoan()` callback cannot be trusted until the Cream developers fix this issue. The `initiator` can easily be spoofed to perform unsolicited flash loans. We, therefore, suggest:\\nValidate that the `initiator` value is the `flashLoan()` caller. This conforms to the standard and is hopefully how the Cream team is fixing this, and\\nEnsure the implementation tracks its own calls to `flashLoan()` in a state-variable semaphore, i.e. store the flash loan data/hash in a temporary state-variable that is only set just before calling `flashLoan()` until being called back in `onFlashLoan()`. The received data can then be verified against the stored artifact. This is a safe way of authenticating and verifying callbacks.\\nValues received from untrusted third parties should always be validated with the utmost scrutiny.\\nSmart contract upgrades are risky, so we recommend implementing the means to pause certain flash loan providers.\\nEnsure that flash loan handler functions should never re-enter the system. This provides additional security guarantees in case a flash loan provider gets breached.\\nNote: The Fuji development team implemented a hotfix to prevent unsolicited calls from Cream by storing the `hash(FlashLoan.info)` in a state variable just before requesting the flash loan. Inside the `onFlashLoan` callback, this state is validated and cleared accordingly.\\nAn improvement to this hotfix would be, to check `_paramsHash` before any external calls are made and clear it right after validation at the beginning of the function. Additionally, `hash==0x0` should be explicitly disallowed. By doing so, the check also serves as a reentrancy guard and helps further reduce the risk of a potentially malicious flash loan re-entering the function.чч```\\n/\\*\\*\\n \\* @dev Routing Function for Flashloan Provider\\n \\* @param info: struct information for flashLoan\\n \\* @param \\_flashnum: integer identifier of flashloan provider\\n \\*/\\nfunction initiateFlashloan(FlashLoan.Info calldata info, uint8 \\_flashnum) external isAuthorized override {\\n if (\\_flashnum == 0) {\\n \\_initiateGeistFlashLoan(info);\\n } else if (\\_flashnum == 2) {\\n \\_initiateCreamFlashLoan(info);\\n } else {\\n revert(Errors.VL\\_INVALID\\_FLASH\\_NUMBER);\\n }\\n}\\n```\\n
Lack of reentrancy protection in token interactionsчhighчToken operations may potentially re-enter the system. For example, `univTransfer` may perform a low-level `to.call{value}()` and, depending on the token's specification (e.g. `ERC-20` extension or `ERC-20` compliant ERC-777), `token` may implement callbacks when being called as `token.safeTransfer(to, amount)` (or token.transfer*()).\\nTherefore, it is crucial to strictly adhere to the checks-effects pattern and safeguard affected methods using a mutex.\\n```\\nfunction univTransfer(\\n IERC20 token,\\n address payable to,\\n uint256 amount\\n) internal {\\n if (amount > 0) {\\n if (isFTM(token)) {\\n (bool sent, ) = to.call{ value: amount }(\"\");\\n require(sent, \"Failed to send Ether\");\\n } else {\\n token.safeTransfer(to, amount);\\n }\\n }\\n}\\n```\\n\\n`withdraw` is `nonReentrant` while `paybackAndWithdraw` is not, which appears to be inconsistent\\n```\\n/\\*\\*\\n \\* @dev Paybacks the underlying asset and withdraws collateral in a single function call from activeProvider\\n \\* @param \\_paybackAmount: amount of underlying asset to be payback, pass -1 to pay full amount\\n \\* @param \\_collateralAmount: amount of collateral to be withdrawn, pass -1 to withdraw maximum amount\\n \\*/\\nfunction paybackAndWithdraw(int256 \\_paybackAmount, int256 \\_collateralAmount) external payable {\\n updateF1155Balances();\\n \\_internalPayback(\\_paybackAmount);\\n \\_internalWithdraw(\\_collateralAmount);\\n}\\n```\\n\\n```\\n/\\*\\*\\n \\* @dev Paybacks Vault's type underlying to activeProvider - called by users\\n \\* @param \\_repayAmount: token amount of underlying to repay, or\\n \\* pass any 'negative number' to repay full ammount\\n \\* Emits a {Repay} event.\\n \\*/\\nfunction payback(int256 \\_repayAmount) public payable override {\\n updateF1155Balances();\\n \\_internalPayback(\\_repayAmount);\\n}\\n```\\n\\n`depositAndBorrow` is not `nonReentrant` while `borrow()` is which appears to be inconsistent\\n```\\n/\\*\\*\\n \\* @dev Deposits collateral and borrows underlying in a single function call from activeProvider\\n \\* @param \\_collateralAmount: amount to be deposited\\n \\* @param \\_borrowAmount: amount to be borrowed\\n \\*/\\nfunction depositAndBorrow(uint256 \\_collateralAmount, uint256 \\_borrowAmount) external payable {\\n updateF1155Balances();\\n \\_internalDeposit(\\_collateralAmount);\\n \\_internalBorrow(\\_borrowAmount);\\n}\\n```\\n\\n```\\n/\\*\\*\\n \\* @dev Borrows Vault's type underlying amount from activeProvider\\n \\* @param \\_borrowAmount: token amount of underlying to borrow\\n \\* Emits a {Borrow} event.\\n \\*/\\nfunction borrow(uint256 \\_borrowAmount) public override nonReentrant {\\n updateF1155Balances();\\n \\_internalBorrow(\\_borrowAmount);\\n}\\n```\\n\\nHere's an example call stack for `depositAndBorrow` that outlines how a reentrant `ERC20` token (e.g. ERC777) may call back into `depositAndBorrow` again, `updateBalances` twice in the beginning before tokens are even transferred and then continues to call `internalDeposit`, `internalBorrow`, `internalBorrow` without an update before the 2nd borrow. Note that both `internalDeposit` and `internalBorrow` read indexes that may now be outdated.\\n```\\ndepositAndBorrow\\n updateBalances\\n internalDeposit ->\\n ERC777(collateralAsset).safeTransferFrom() ---> calls back!\\n ---callback:beforeTokenTransfer---->\\n !! depositAndBorrow\\n updateBalances\\n internalDeposit\\n --> ERC777.safeTransferFrom()\\n <--\\n \\_deposit\\n mint\\n internalBorrow\\n mint\\n \\_borrow\\n ERC777(borrowAsset).univTransfer(msg.sender) --> might call back\\n\\n <-------------------------------\\n \\_deposit\\n mint\\n internalBorrow\\n mint\\n \\_borrow \\n --> ERC777(borrowAsset).univTransfer(msg.sender) --> might call back\\n <--\\n```\\nчConsider decorating methods that may call back to untrusted sources (i.e., native token transfers, callback token operations) as `nonReentrant` and strictly follow the checks-effects pattern for all contracts in the code-base.чч```\\nfunction univTransfer(\\n IERC20 token,\\n address payable to,\\n uint256 amount\\n) internal {\\n if (amount > 0) {\\n if (isFTM(token)) {\\n (bool sent, ) = to.call{ value: amount }(\"\");\\n require(sent, \"Failed to send Ether\");\\n } else {\\n token.safeTransfer(to, amount);\\n }\\n }\\n}\\n```\\n
Unchecked Return Values - ICErc20 repayBorrowчhighч`ICErc20.repayBorrow` returns a non-zero uint on error. Multiple providers do not check for this error condition and might return `success` even though `repayBorrow` failed, returning an error code.\\nThis can potentially allow a malicious user to call `paybackAndWithdraw()` while not repaying by causing an error in the sub-call to `Compound.repayBorrow()`, which ends up being silently ignored. Due to the missing success condition check, execution continues normally with `_internalWithdraw()`.\\nAlso, see issue 4.5.\\n```\\nfunction repayBorrow(uint256 repayAmount) external returns (uint256);\\n```\\n\\nThe method may return an error due to multiple reasons:\\n```\\nfunction repayBorrowInternal(uint repayAmount) internal nonReentrant returns (uint, uint) {\\n uint error = accrueInterest();\\n if (error != uint(Error.NO\\_ERROR)) {\\n // accrueInterest emits logs on errors, but we still want to log the fact that an attempted borrow failed\\n return (fail(Error(error), FailureInfo.REPAY\\_BORROW\\_ACCRUE\\_INTEREST\\_FAILED), 0);\\n }\\n // repayBorrowFresh emits repay-borrow-specific logs on errors, so we don't need to\\n return repayBorrowFresh(msg.sender, msg.sender, repayAmount);\\n}\\n```\\n\\n```\\nif (allowed != 0) {\\n return (failOpaque(Error.COMPTROLLER\\_REJECTION, FailureInfo.REPAY\\_BORROW\\_COMPTROLLER\\_REJECTION, allowed), 0);\\n}\\n\\n/\\* Verify market's block number equals current block number \\*/\\nif (accrualBlockNumber != getBlockNumber()) {\\n return (fail(Error.MARKET\\_NOT\\_FRESH, FailureInfo.REPAY\\_BORROW\\_FRESHNESS\\_CHECK), 0);\\n}\\n\\nRepayBorrowLocalVars memory vars;\\n\\n/\\* We remember the original borrowerIndex for verification purposes \\*/\\nvars.borrowerIndex = accountBorrows[borrower].interestIndex;\\n\\n/\\* We fetch the amount the borrower owes, with accumulated interest \\*/\\n(vars.mathErr, vars.accountBorrows) = borrowBalanceStoredInternal(borrower);\\nif (vars.mathErr != MathError.NO\\_ERROR) {\\n return (failOpaque(Error.MATH\\_ERROR, FailureInfo.REPAY\\_BORROW\\_ACCUMULATED\\_BALANCE\\_CALCULATION\\_FAILED, uint(vars.mathErr)), 0);\\n}\\n```\\n\\nMultiple providers, here are some examples:\\n```\\n // Check there is enough balance to pay\\n require(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\\n erc20token.univApprove(address(cyTokenAddr), \\_amount);\\n cyToken.repayBorrow(\\_amount);\\n}\\n```\\n\\n```\\nrequire(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\\nerc20token.univApprove(address(cyTokenAddr), \\_amount);\\ncyToken.repayBorrow(\\_amount);\\n```\\n\\n```\\nif (\\_isETH(\\_asset)) {\\n // Create a reference to the corresponding cToken contract\\n ICEth cToken = ICEth(cTokenAddr);\\n\\n cToken.repayBorrow{ value: msg.value }();\\n} else {\\n // Create reference to the ERC20 contract\\n IERC20 erc20token = IERC20(\\_asset);\\n\\n // Create a reference to the corresponding cToken contract\\n ICErc20 cToken = ICErc20(cTokenAddr);\\n\\n // Check there is enough balance to pay\\n require(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\\n erc20token.univApprove(address(cTokenAddr), \\_amount);\\n cToken.repayBorrow(\\_amount);\\n}\\n```\\nчCheck for `cyToken.repayBorrow(_amount) != 0` or `Error.NO_ERROR`.чч```\\nfunction repayBorrow(uint256 repayAmount) external returns (uint256);\\n```\\n
Unchecked Return Values - IComptroller exitMarket, enterMarketчhighч`IComptroller.exitMarket()`, `IComptroller.enterMarkets()` may return a non-zero uint on error but none of the Providers check for this error condition. Together with issue 4.10, this might suggest that unchecked return values may be a systemic problem.\\nHere's the upstream implementation:\\n```\\nif (amountOwed != 0) {\\n return fail(Error.NONZERO\\_BORROW\\_BALANCE, FailureInfo.EXIT\\_MARKET\\_BALANCE\\_OWED);\\n}\\n\\n/\\* Fail if the sender is not permitted to redeem all of their tokens \\*/\\nuint allowed = redeemAllowedInternal(cTokenAddress, msg.sender, tokensHeld);\\nif (allowed != 0) {\\n return failOpaque(Error.REJECTION, FailureInfo.EXIT\\_MARKET\\_REJECTION, allowed);\\n}\\n```\\n\\n```\\n /\\*\\*\\n \\* @notice Removes asset from sender's account liquidity calculation\\n \\* @dev Sender must not have an outstanding borrow balance in the asset,\\n \\* or be providing necessary collateral for an outstanding borrow.\\n \\* @param cTokenAddress The address of the asset to be removed\\n \\* @return Whether or not the account successfully exited the market\\n \\*/\\n function exitMarket(address cTokenAddress) external returns (uint) {\\n CToken cToken = CToken(cTokenAddress);\\n /\\* Get sender tokensHeld and amountOwed underlying from the cToken \\*/\\n (uint oErr, uint tokensHeld, uint amountOwed, ) = cToken.getAccountSnapshot(msg.sender);\\n require(oErr == 0, \"exitMarket: getAccountSnapshot failed\"); // semi-opaque error code\\n\\n /\\* Fail if the sender has a borrow balance \\*/\\n if (amountOwed != 0) {\\n return fail(Error.NONZERO\\_BORROW\\_BALANCE, FailureInfo.EXIT\\_MARKET\\_BALANCE\\_OWED);\\n }\\n\\n /\\* Fail if the sender is not permitted to redeem all of their tokens \\*/\\n uint allowed = redeemAllowedInternal(cTokenAddress, msg.sender, tokensHeld);\\n if (allowed != 0) {\\n return failOpaque(Error.REJECTION, FailureInfo.EXIT\\_MARKET\\_REJECTION, allowed);\\n }\\n```\\n\\nUnchecked return value `exitMarket`\\nAll Providers exhibit the same issue, probably due to code reuse. (also see https://github.com/ConsenSysDiligence/fuji-protocol-audit-2022-02/issues/19). Some examples:\\n```\\nfunction \\_exitCollatMarket(address \\_cyTokenAddress) internal {\\n // Create a reference to the corresponding network Comptroller\\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\\n\\n comptroller.exitMarket(\\_cyTokenAddress);\\n}\\n```\\n\\n```\\nfunction \\_exitCollatMarket(address \\_cyTokenAddress) internal {\\n // Create a reference to the corresponding network Comptroller\\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\\n\\n comptroller.exitMarket(\\_cyTokenAddress);\\n}\\n```\\n\\n```\\nfunction \\_exitCollatMarket(address \\_cTokenAddress) internal {\\n // Create a reference to the corresponding network Comptroller\\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\\n\\n comptroller.exitMarket(\\_cTokenAddress);\\n}\\n```\\n\\n```\\nfunction \\_exitCollatMarket(address \\_cyTokenAddress) internal {\\n // Create a reference to the corresponding network Comptroller\\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\\n\\n comptroller.exitMarket(\\_cyTokenAddress);\\n}\\n```\\n\\nUnchecked return value `enterMarkets` (Note that `IComptroller` returns `NO_ERROR` when already joined to `enterMarkets`.\\nAll Providers exhibit the same issue, probably due to code reuse. (also see https://github.com/ConsenSysDiligence/fuji-protocol-audit-2022-02/issues/19). For example:\\n```\\nfunction \\_enterCollatMarket(address \\_cyTokenAddress) internal {\\n // Create a reference to the corresponding network Comptroller\\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\\n\\n address[] memory cyTokenMarkets = new address[](1);\\n cyTokenMarkets[0] = \\_cyTokenAddress;\\n comptroller.enterMarkets(cyTokenMarkets);\\n}\\n```\\nчRequire that return value is `ERROR.NO_ERROR` or `0`.чч```\\nif (amountOwed != 0) {\\n return fail(Error.NONZERO\\_BORROW\\_BALANCE, FailureInfo.EXIT\\_MARKET\\_BALANCE\\_OWED);\\n}\\n\\n/\\* Fail if the sender is not permitted to redeem all of their tokens \\*/\\nuint allowed = redeemAllowedInternal(cTokenAddress, msg.sender, tokensHeld);\\nif (allowed != 0) {\\n return failOpaque(Error.REJECTION, FailureInfo.EXIT\\_MARKET\\_REJECTION, allowed);\\n}\\n```\\n
Fliquidator - excess funds of native tokens are not returnedчmediumч`FliquidatorFTM.batchLiquidate` accepts the `FTM` native token and checks if at least an amount of `debtTotal` was provided with the call. The function continues using the `debtTotal` value. If a caller provides msg.value > `debtTotal`, excess funds are not returned and remain in the contract. `FliquidatorFTM` is not upgradeable, and there is no way to recover the surplus funds.\\n```\\nif (vAssets.borrowAsset == FTM) {\\n require(msg.value >= debtTotal, Errors.VL\\_AMOUNT\\_ERROR);\\n} else {\\n```\\nчConsider returning excess funds. Consider making `_constructParams` public to allow the caller to pre-calculate the `debtTotal` that needs to be provided with the call.\\nConsider removing support for native token `FTM` entirely to reduce the overall code complexity. The wrapped equivalent can be used instead.чч```\\nif (vAssets.borrowAsset == FTM) {\\n require(msg.value >= debtTotal, Errors.VL\\_AMOUNT\\_ERROR);\\n} else {\\n```\\n
Unsafe arithmetic castsчmediumчThe reason for using signed integers in some situations appears to be to use negative values as an indicator to withdraw everything. Using a whole bit of uint256 for this is quite a lot when using `type(uint256).max` would equal or better serve as a flag to withdraw everything.\\nFurthermore, even though the code uses `solidity 0.8.x`, which safeguards arithmetic operations against under/overflows, arithmetic typecast is not protected.\\nAlso, see issue 4.9 for a related issue.\\n```\\n⇒ solidity-shell\\n\\n🚀 Entering interactive Solidity ^0.8.11 shell. '.help' and '.exit' are your friends.\\n » ℹ️ ganache-mgr: starting temp. ganache instance // rest of code\\n » uint(int(-100))\\n115792089237316195423570985008687907853269984665640564039457584007913129639836\\n » int256(uint(2\\*\\*256-100))\\n-100\\n```\\n\\n```\\n// Compute how much collateral needs to be swapt\\nuint256 collateralInPlay = \\_getCollateralInPlay(\\n vAssets.collateralAsset,\\n vAssets.borrowAsset,\\n debtTotal + bonus\\n);\\n\\n// Burn f1155\\n\\_burnMulti(addrs, borrowBals, vAssets, \\_vault, f1155);\\n\\n// Withdraw collateral\\nIVault(\\_vault).withdrawLiq(int256(collateralInPlay));\\n```\\n\\n```\\n// Compute how much collateral needs to be swapt for all liquidated users\\nuint256 collateralInPlay = \\_getCollateralInPlay(\\n vAssets.collateralAsset,\\n vAssets.borrowAsset,\\n \\_amount + \\_flashloanFee + bonus\\n);\\n\\n// Burn f1155\\n\\_burnMulti(\\_addrs, \\_borrowBals, vAssets, \\_vault, f1155);\\n\\n// Withdraw collateral\\nIVault(\\_vault).withdrawLiq(int256(collateralInPlay));\\n```\\n\\n```\\nuint256 amount = \\_amount < 0 ? debtTotal : uint256(\\_amount);\\n```\\n\\n```\\nfunction withdrawLiq(int256 \\_withdrawAmount) external override nonReentrant onlyFliquidator {\\n // Logic used when called by Fliquidator\\n \\_withdraw(uint256(\\_withdrawAmount), address(activeProvider));\\n IERC20Upgradeable(vAssets.collateralAsset).univTransfer(\\n payable(msg.sender),\\n uint256(\\_withdrawAmount)\\n );\\n}\\n```\\n\\npot. unsafe truncation (unlikely)\\n```\\nfunction updateState(uint256 \\_assetID, uint256 newBalance) external override onlyPermit {\\n uint256 total = totalSupply(\\_assetID);\\n if (newBalance > 0 && total > 0 && newBalance > total) {\\n uint256 newIndex = (indexes[\\_assetID] \\* newBalance) / total;\\n indexes[\\_assetID] = uint128(newIndex);\\n }\\n}\\n```\\nчIf negative values are only used as a flag to indicate that all funds should be used for an operation, use `type(uint256).max` instead. It is wasting less value-space for a simple flag than using the uint256 high-bit range. Avoid typecast where possible. Use `SafeCast` instead or verify that the casts are safe because the values they operate on cannot under- or overflow. Add inline code comments if that's the case.чч```\\n⇒ solidity-shell\\n\\n🚀 Entering interactive Solidity ^0.8.11 shell. '.help' and '.exit' are your friends.\\n » ℹ️ ganache-mgr: starting temp. ganache instance // rest of code\\n » uint(int(-100))\\n115792089237316195423570985008687907853269984665640564039457584007913129639836\\n » int256(uint(2\\*\\*256-100))\\n-100\\n```\\n
Missing input validation on flash close fee factorsчmediumчThe `FliquidatorFTM` contract allows authorized parties to set the flash close fee factor. The factor is provided as two integers denoting numerator and denominator. Due to a lack of boundary checks, it is possible to set unrealistically high factors, which go well above 1. This can have unexpected effects on internal accounting and the impact of flashloan balances.\\n```\\nfunction setFlashCloseFee(uint64 \\_newFactorA, uint64 \\_newFactorB) external isAuthorized {\\n flashCloseF.a = \\_newFactorA;\\n flashCloseF.b = \\_newFactorB;\\n```\\nчAdd a requirement making sure that `flashCloseF.a <= flashCloseF.b`.чч```\\nfunction setFlashCloseFee(uint64 \\_newFactorA, uint64 \\_newFactorB) external isAuthorized {\\n flashCloseF.a = \\_newFactorA;\\n flashCloseF.b = \\_newFactorB;\\n```\\n
Separation of concerns and consistency in vaultsчmediumчThe `FujiVaultFTM` contract contains multiple balance-changing functions. Most notably, `withdraw` is passed an `int256` denoted amount parameter. Negative values of this parameter are given to the `_internalWithdraw` function, where they trigger the withdrawal of all collateral. This approach can result in accounting mistakes in the future as beyond a certain point in the vault's accounting; amounts are expected to be only positive. Furthermore, the concerns of withdrawing and entirely withdrawing are not separated.\\nThe above issue applies analogously to the `payback` function and its dependency on `_internalPayback`.\\nFor consistency, `withdrawLiq` also takes an `int256` amount parameter. This function is only accessible to the `Fliquidator` contract and withdraws collateral from the active provider. However, all occurrences of the `_withdrawAmount` parameter are cast to `uint256`.\\nThe `withdraw` entry point:\\n```\\nfunction withdraw(int256 \\_withdrawAmount) public override nonReentrant {\\n updateF1155Balances();\\n \\_internalWithdraw(\\_withdrawAmount);\\n}\\n```\\n\\n_internalWithdraw's negative amount check:\\n```\\nuint256 amountToWithdraw = \\_withdrawAmount < 0\\n ? providedCollateral - neededCollateral\\n : uint256(\\_withdrawAmount);\\n```\\n\\nThe `withdrawLiq` entry point for the Fliquidator:\\n```\\nfunction withdrawLiq(int256 \\_withdrawAmount) external override nonReentrant onlyFliquidator {\\n // Logic used when called by Fliquidator\\n \\_withdraw(uint256(\\_withdrawAmount), address(activeProvider));\\n IERC20Upgradeable(vAssets.collateralAsset).univTransfer(\\n payable(msg.sender),\\n uint256(\\_withdrawAmount)\\n );\\n}\\n```\\nчWe recommend splitting the `withdraw(int256)` function into two: `withdraw(uint256)` and `withdrawAll()`. These will provide the same functionality while rendering the updated code of `_internalWithdraw` easier to read, maintain, and harder to manipulate. The recommendation applies to `payback` and `_internalPayback`.\\nSimilarly, withdrawLiq's parameter should be a `uint256` to prevent unnecessary casts.чч```\\nfunction withdraw(int256 \\_withdrawAmount) public override nonReentrant {\\n updateF1155Balances();\\n \\_internalWithdraw(\\_withdrawAmount);\\n}\\n```\\n
Aave/Geist Interface declaration mismatch and unchecked return valuesчmediumчThe two lending providers, Geist & Aave, do not seem to be directly affiliated even though one is a fork of the other. However, the interfaces may likely diverge in the future. Using the same interface declaration for both protocols might become problematic with future upgrades to either protocol. The interface declaration does not seem to come from the original upstream project. The interface `IAaveLendingPool` does not declare any return values while some of the functions called in Geist or Aave return them.\\nNote: that we have not verified all interfaces for correctness. However, we urge the client to only use official interface declarations from the upstream projects and verify that all other interfaces match.\\nThe `ILendingPool` configured in `ProviderAave` (0xB53C1a33016B2DC2fF3653530bfF1848a515c8c5 -> implementation: 0xc6845a5c768bf8d7681249f8927877efda425baf)\\n```\\nfunction \\_getAaveProvider() internal pure returns (IAaveLendingPoolProvider) {\\n return IAaveLendingPoolProvider(0xB53C1a33016B2DC2fF3653530bfF1848a515c8c5);\\n}\\n```\\n\\nThe `IAaveLendingPool` does not declare return values for any function, while upstream does.\\n```\\n// SPDX-License-Identifier: MIT\\n\\npragma solidity ^0.8.0;\\n\\ninterface IAaveLendingPool {\\n function flashLoan(\\n address receiverAddress,\\n address[] calldata assets,\\n uint256[] calldata amounts,\\n uint256[] calldata modes,\\n address onBehalfOf,\\n bytes calldata params,\\n uint16 referralCode\\n ) external;\\n\\n function deposit(\\n address \\_asset,\\n uint256 \\_amount,\\n address \\_onBehalfOf,\\n uint16 \\_referralCode\\n ) external;\\n\\n function withdraw(\\n address \\_asset,\\n uint256 \\_amount,\\n address \\_to\\n ) external;\\n\\n function borrow(\\n address \\_asset,\\n uint256 \\_amount,\\n uint256 \\_interestRateMode,\\n uint16 \\_referralCode,\\n address \\_onBehalfOf\\n ) external;\\n\\n function repay(\\n address \\_asset,\\n uint256 \\_amount,\\n uint256 \\_rateMode,\\n address \\_onBehalfOf\\n ) external;\\n\\n function setUserUseReserveAsCollateral(address \\_asset, bool \\_useAsCollateral) external;\\n}\\n```\\n\\nMethods: `withdraw()`, `repay()` return `uint256` in the original implementation for Aave, see:\\nhttps://etherscan.io/address/0xc6845a5c768bf8d7681249f8927877efda425baf#code\\nThe `ILendingPool` configured for Geist:\\nMethods `withdraw()`, `repay()` return `uint256` in the original implementation for Geist, see:\\nhttps://ftmscan.com/address/0x3104ad2aadb6fe9df166948a5e3a547004862f90#code\\nNote: that the actual `amount` withdrawn does not necessarily need to match the `amount` provided with the function argument. Here's an excerpt of the upstream LendingProvider.withdraw():\\n```\\n// rest of code\\n if (amount == type(uint256).max) {\\n amountToWithdraw = userBalance;\\n }\\n// rest of code\\n return amountToWithdraw;\\n```\\n\\nAnd here's the code in Fuji that calls that method. This will break the `withdrawAll` functionality of `LendingProvider` if token `isFTM`.\\n```\\nfunction withdraw(address \\_asset, uint256 \\_amount) external payable override {\\n IAaveLendingPool aave = IAaveLendingPool(\\_getAaveProvider().getLendingPool());\\n\\n bool isFtm = \\_asset == \\_getFtmAddr();\\n address \\_tokenAddr = isFtm ? \\_getWftmAddr() : \\_asset;\\n\\n aave.withdraw(\\_tokenAddr, \\_amount, address(this));\\n\\n // convert WFTM to FTM\\n if (isFtm) {\\n address unwrapper = \\_getUnwrapper();\\n IERC20(\\_tokenAddr).univTransfer(payable(unwrapper), \\_amount);\\n IUnwrapper(unwrapper).withdraw(\\_amount);\\n }\\n}\\n```\\n\\nSimilar for `repay()`, which returns the actual amount repaid.чAlways use the original interface unless only a minimal subset of functions is used.\\nUse the original upstream interfaces of the corresponding project (link via the respective npm packages if available).\\nAvoid omitting parts of the function declaration! Especially when it comes to return values.\\nCheck return values. Use the value returned from `withdraw()` AND `repay()`чч```\\nfunction \\_getAaveProvider() internal pure returns (IAaveLendingPoolProvider) {\\n return IAaveLendingPoolProvider(0xB53C1a33016B2DC2fF3653530bfF1848a515c8c5);\\n}\\n```\\n
Missing slippage protection for rewards swapчmediumчIn `FujiVaultFTM.harvestRewards` a swap transaction is generated using a call to `SwapperFTM.getSwapTransaction`. In all relevant scenarios, this call uses a minimum output amount of zero, which de-facto deactivates slippage checks. Most values from harvesting rewards can thus be siphoned off by sandwiching such calls.\\n`amountOutMin` is `0`, effectively disabling slippage control in the swap method.\\n```\\ntransaction.data = abi.encodeWithSelector(\\n IUniswapV2Router01.swapExactETHForTokens.selector,\\n 0,\\n path,\\n msg.sender,\\n type(uint256).max\\n);\\n```\\n\\nOnly success required\\n```\\n// Swap rewards -> collateralAsset\\n(success, ) = swapTransaction.to.call{ value: swapTransaction.value }(swapTransaction.data);\\nrequire(success, \"failed to swap rewards\");\\n```\\nчUse a slippage check such as for liquidator swaps:\\n```\\nrequire(\\n (priceDelta \\* SLIPPAGE\\_LIMIT\\_DENOMINATOR) / priceFromOracle < SLIPPAGE\\_LIMIT\\_NUMERATOR,\\n Errors.VL\\_SWAP\\_SLIPPAGE\\_LIMIT\\_EXCEED\\n);\\n```\\n\\nOr specify a non-zero `amountOutMin` argument in calls to `IUniswapV2Router01.swapExactETHForTokens`.чч```\\ntransaction.data = abi.encodeWithSelector(\\n IUniswapV2Router01.swapExactETHForTokens.selector,\\n 0,\\n path,\\n msg.sender,\\n type(uint256).max\\n);\\n```\\n
FujiOracle - _getUSDPrice does not detect stale oracle prices; General Oracle RisksчmediumчThe external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations. Oracle reliance has historically resulted in crippled on-chain systems, and complications that lead to these outcomes can arise from things as simple as network congestion.\\nThis is more extreme in lesser-known tokens with fewer ChainLink Price feeds to update the price frequently.\\nEnsuring that unexpected oracle return values are correctly handled will reduce reliance on off-chain components and increase the resiliency of the smart contract system that depends on them.\\nThe codebase, as is, relies on `chainLinkOracle.latestRoundData()` and does not check the `timestamp` or `answeredIn` round of the returned price.\\nHere's how the oracle is consumed, skipping any fields that would allow checking for stale data:\\n```\\n/\\*\\*\\n \\* @dev Calculates the USD price of asset.\\n \\* @param \\_asset: the asset address.\\n \\* Returns the USD price of the given asset\\n \\*/\\nfunction \\_getUSDPrice(address \\_asset) internal view returns (uint256 price) {\\n require(usdPriceFeeds[\\_asset] != address(0), Errors.ORACLE\\_NONE\\_PRICE\\_FEED);\\n\\n (, int256 latestPrice, , , ) = AggregatorV3Interface(usdPriceFeeds[\\_asset]).latestRoundData();\\n\\n price = uint256(latestPrice);\\n}\\n```\\n\\nHere's the implementation of the v0.6 FluxAggregator Chainlink feed with a note that timestamps should be checked.\\n```\\n\\* @return updatedAt is the timestamp when the round last was updated (i.e.\\n\\* answer was last computed)\\n```\\nчPerform sanity checks on the price returned by the oracle. If the price is older, not within configured limits, revert or handle in other means.\\nThe oracle does not provide any means to remove a potentially broken price-feed (e.g., by updating its address to `address(0)` or by pausing specific feeds or the complete oracle). The only way to pause an oracle right now is to deploy a new oracle contract. Therefore, consider adding minimally invasive functionality to pause the price-feeds if the oracle becomes unreliable.\\nMonitor the oracle data off-chain and intervene if it becomes unreliable.\\nOn-chain, realistically, both `answeredInRound` and `updatedAt` must be checked within acceptable bounds.\\n`answeredInRound == latestRound` - in this case, data may be assumed to be fresh while it might not be because the feed was entirely abandoned by nodes (no one starting a new round). Also, there's a good chance that many feeds won't always be super up-to-date (it might be acceptable to allow a threshold). A strict check might lead to transactions failing (race; e.g., round just timed out).\\n`roundId + threshold >= answeredInRound` - would allow a deviation of threshold rounds. This check alone might still result in stale data to be used if there are no more rounds. Therefore, this should be combined with `updatedAt + threshold >= block.timestamp`.чч```\\n/\\*\\*\\n \\* @dev Calculates the USD price of asset.\\n \\* @param \\_asset: the asset address.\\n \\* Returns the USD price of the given asset\\n \\*/\\nfunction \\_getUSDPrice(address \\_asset) internal view returns (uint256 price) {\\n require(usdPriceFeeds[\\_asset] != address(0), Errors.ORACLE\\_NONE\\_PRICE\\_FEED);\\n\\n (, int256 latestPrice, , , ) = AggregatorV3Interface(usdPriceFeeds[\\_asset]).latestRoundData();\\n\\n price = uint256(latestPrice);\\n}\\n```\\n
Unclaimed or front-runnable proxy implementationsчmediumчVarious smart contracts in the system require initialization functions to be called. The point when these calls happen is up to the deploying address. Deployment and initialization in one transaction are typically safe, but it can potentially be front-run if the initialization is done in a separate transaction.\\nA frontrunner can call these functions to silently take over the contracts and provide malicious parameters or plant a backdoor during the deployment.\\nLeaving proxy implementations uninitialized further aides potential phishing attacks where users might claim that - just because a contract address is listed in the official documentation/code-repo - a contract is a legitimate component of the system. At the same time, it is ‘only' a proxy implementation that an attacker claimed. For the end-user, it might be hard to distinguish whether this contract is part of the system or was a maliciously appropriated implementation.\\n```\\nfunction initialize(\\n address \\_fujiadmin,\\n address \\_oracle,\\n address \\_collateralAsset,\\n address \\_borrowAsset\\n) external initializer {\\n```\\n\\n`FujiVault` was initialized many days after deployment, and `FujiVault` inherits `VaultBaseUpgradeable`, which exposes a `delegatecall` that can be used to `selfdestruct` the contract's implementation.\\nAnother `FujiVault` was deployed by `deployer` initialized in a 2-step approach that can theoretically silently be front-run.\\ncode/artifacts/250-core.deploy:L2079-L2079\\n```\\n\"deployer\": \"0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148\",\\n```\\n\\nTransactions of deployer:\\nhttps://ftmscan.com/txs?a=0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148&p=2\\nThe specific contract was initialized 19 blocks after deployment.\\nhttps://ftmscan.com/address/0x8513c2db99df213887f63300b23c6dd31f1d14b0\\n\\n`FujiAdminFTM` (and others) don't seem to be initialized. (low prior; no risk other than pot. reputational damage)\\ncode/artifacts/250-core.deploy:L1-L7\\n```\\n{\\n \"FujiAdmin\": {\\n \"address\": \"0xaAb2AAfBFf7419Ff85181d3A846bA9045803dd67\",\\n \"deployer\": \"0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148\",\\n \"abi\": [\\n {\\n \"anonymous\": false,\\n```\\nчIt is recommended to use constructors wherever possible to immediately initialize proxy implementations during deploy-time. The code is only run when the implementation is deployed and affects the proxy initializations. If other initialization functions are used, we recommend enforcing deployer access restrictions or a standardized, top-level `initialized` boolean, set to `true` on the first deployment and used to prevent future initialization.\\nUsing constructors and locked-down initialization functions will significantly reduce potential developer errors and the possibility of attackers re-initializing vital system components.чч```\\nfunction initialize(\\n address \\_fujiadmin,\\n address \\_oracle,\\n address \\_collateralAsset,\\n address \\_borrowAsset\\n) external initializer {\\n```\\n
WFTM - Use of incorrect interface declarationsчlowчThe `WFTMUnwrapper` and various providers utilize the `IWETH` interface declaration for handling funds denoted in `WFTM`. However, the `WETH` and `WFTM` implementations are different. `WFTM` returns `uint256` values to indicate error conditions while the `WETH` contract does not.\\n```\\ncontract WFTMUnwrapper {\\n address constant wftm = 0x21be370D5312f44cB42ce377BC9b8a0cEF1A4C83;\\n\\n receive() external payable {}\\n\\n /\\*\\*\\n \\* @notice Convert WFTM to FTM and transfer to msg.sender\\n \\* @dev msg.sender needs to send WFTM before calling this withdraw\\n \\* @param \\_amount amount to withdraw.\\n \\*/\\n function withdraw(uint256 \\_amount) external {\\n IWETH(wftm).withdraw(\\_amount);\\n (bool sent, ) = msg.sender.call{ value: \\_amount }(\"\");\\n require(sent, \"Failed to send FTM\");\\n }\\n}\\n```\\n\\nThe `WFTM` contract on Fantom returns an error return value. The error return value cannot be checked when utilizing the `IWETH` interface for `WFTM`. The error return values are never checked throughout the system for `WFTM` operations. This might be intentional to allow `amount=0` on `WETH` to act as a NOOP similar to `WETH`.\\n```\\n// convert FTM to WFTM\\nif (isFtm) IWETH(\\_tokenAddr).deposit{ value: \\_amount }();\\n```\\n\\nAlso see issues: issue 4.4, issue 4.5, issue 4.10чWe recommend using the correct interfaces for all contracts instead of partial stubs. Do not modify the original function declarations, e.g., by omitting return value declarations. The codebase should also check return values where possible or explicitly state why values can safely be ignored in inline comments or the function's natspec documentation block.чч```\\ncontract WFTMUnwrapper {\\n address constant wftm = 0x21be370D5312f44cB42ce377BC9b8a0cEF1A4C83;\\n\\n receive() external payable {}\\n\\n /\\*\\*\\n \\* @notice Convert WFTM to FTM and transfer to msg.sender\\n \\* @dev msg.sender needs to send WFTM before calling this withdraw\\n \\* @param \\_amount amount to withdraw.\\n \\*/\\n function withdraw(uint256 \\_amount) external {\\n IWETH(wftm).withdraw(\\_amount);\\n (bool sent, ) = msg.sender.call{ value: \\_amount }(\"\");\\n require(sent, \"Failed to send FTM\");\\n }\\n}\\n```\\n
Inconsistent isFTM, isETH checksчlowч`LibUniversalERC20FTM.isFTM()` and `LibUniversalERC20.isETH()` identifies native assets by matching against two distinct addresses while some components only check for one.\\nThe same is true for `FTM`.\\n`Flasher` only identifies a native `asset` transfer by matching `asset` against `_ETH = 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE` while `univTransfer()` identifies it using `0x0 || 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE`\\n```\\nfunction callFunction(\\n address sender,\\n Account.Info calldata account,\\n bytes calldata data\\n) external override {\\n require(msg.sender == \\_dydxSoloMargin && sender == address(this), Errors.VL\\_NOT\\_AUTHORIZED);\\n account;\\n\\n FlashLoan.Info memory info = abi.decode(data, (FlashLoan.Info));\\n\\n uint256 \\_value;\\n if (info.asset == \\_ETH) {\\n // Convert WETH to ETH and assign amount to be set as msg.value\\n \\_convertWethToEth(info.amount);\\n \\_value = info.amount;\\n } else {\\n // Transfer to Vault the flashloan Amount\\n // \\_value is 0\\n IERC20(info.asset).univTransfer(payable(info.vault), info.amount);\\n }\\n```\\n\\n`LibUniversalERC20`\\n```\\nlibrary LibUniversalERC20 {\\n using SafeERC20 for IERC20;\\n\\n IERC20 private constant \\_ETH\\_ADDRESS = IERC20(0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE);\\n IERC20 private constant \\_ZERO\\_ADDRESS = IERC20(0x0000000000000000000000000000000000000000);\\n\\n function isETH(IERC20 token) internal pure returns (bool) {\\n return (token == \\_ZERO\\_ADDRESS || token == \\_ETH\\_ADDRESS);\\n }\\n```\\n\\n```\\nfunction univTransfer(\\n IERC20 token,\\n address payable to,\\n uint256 amount\\n) internal {\\n if (amount > 0) {\\n if (isETH(token)) {\\n (bool sent, ) = to.call{ value: amount }(\"\");\\n require(sent, \"Failed to send Ether\");\\n } else {\\n token.safeTransfer(to, amount);\\n }\\n }\\n}\\n```\\n\\nThere are multiple other instances of this\\n```\\nuint256 \\_value = vAssets.borrowAsset == ETH ? debtTotal : 0;\\n```\\nчConsider using a consistent way to identify native asset transfers (i.e. `ETH`, FTM) by using `LibUniversalERC20.isETH()`. Alternatively, the system can be greatly simplified by expecting WFTM and only working with it. This simplification will remove all special cases where the library must handle non-ERC20 interfaces.чч```\\nfunction callFunction(\\n address sender,\\n Account.Info calldata account,\\n bytes calldata data\\n) external override {\\n require(msg.sender == \\_dydxSoloMargin && sender == address(this), Errors.VL\\_NOT\\_AUTHORIZED);\\n account;\\n\\n FlashLoan.Info memory info = abi.decode(data, (FlashLoan.Info));\\n\\n uint256 \\_value;\\n if (info.asset == \\_ETH) {\\n // Convert WETH to ETH and assign amount to be set as msg.value\\n \\_convertWethToEth(info.amount);\\n \\_value = info.amount;\\n } else {\\n // Transfer to Vault the flashloan Amount\\n // \\_value is 0\\n IERC20(info.asset).univTransfer(payable(info.vault), info.amount);\\n }\\n```\\n
FujiOracle - setPriceFeed should check asset and priceFeed decimalsчlowч`getPriceOf()` assumes that all price feeds return prices with identical decimals, but `setPriceFeed` does not enforce this. Potential misconfigurations can have severe effects on the system's internal accounting.\\n```\\n/\\*\\*\\n \\* @dev Sets '\\_priceFeed' address for a '\\_asset'.\\n \\* Can only be called by the contract owner.\\n \\* Emits a {AssetPriceFeedChanged} event.\\n \\*/\\nfunction setPriceFeed(address \\_asset, address \\_priceFeed) public onlyOwner {\\n require(\\_priceFeed != address(0), Errors.VL\\_ZERO\\_ADDR);\\n usdPriceFeeds[\\_asset] = \\_priceFeed;\\n emit AssetPriceFeedChanged(\\_asset, \\_priceFeed);\\n}\\n```\\nчWe recommend adding additional checks to detect unexpected changes in assets' properties. Safeguard price feeds by enforcing `priceFeed` == address(0) || priceFeed.decimals() == `8`. This allows the owner to disable a `priceFeed` (setting it to zero) and otherwise ensure that the feed is compatible and indeed returns `8` decimals.чч```\\n/\\*\\*\\n \\* @dev Sets '\\_priceFeed' address for a '\\_asset'.\\n \\* Can only be called by the contract owner.\\n \\* Emits a {AssetPriceFeedChanged} event.\\n \\*/\\nfunction setPriceFeed(address \\_asset, address \\_priceFeed) public onlyOwner {\\n require(\\_priceFeed != address(0), Errors.VL\\_ZERO\\_ADDR);\\n usdPriceFeeds[\\_asset] = \\_priceFeed;\\n emit AssetPriceFeedChanged(\\_asset, \\_priceFeed);\\n}\\n```\\n
UniProxy.depositSwap - Tokens are not approved before calling Router.exactInputчhighчthe call to Router.exactInputrequires the sender to pre-approve the tokens. We could not find any reference for that, thus we assume that a call to `UniProxy.depositSwap` will always revert.\\n```\\nrouter = ISwapRouter(\\_router);\\nuint256 amountOut;\\nuint256 swap;\\nif(swapAmount < 0) {\\n    //swap token1 for token0\\n\\n    swap = uint256(swapAmount \\* -1);\\n    IHypervisor(pos).token1().transferFrom(msg.sender, address(this), deposit1+swap);\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit0\\n        )\\n    );\\n}\\nelse{\\n    //swap token1 for token0\\n    swap = uint256(swapAmount);\\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit1\\n        )\\n    );     \\n}\\n```\\nчResolution\\nFixed in GammaStrategies/[email protected]9a7a3dd by deleting the `depositSwap` function.\\nConsider approving the exact amount of input tokens before the swap.чч```\\nrouter = ISwapRouter(\\_router);\\nuint256 amountOut;\\nuint256 swap;\\nif(swapAmount < 0) {\\n    //swap token1 for token0\\n\\n    swap = uint256(swapAmount \\* -1);\\n    IHypervisor(pos).token1().transferFrom(msg.sender, address(this), deposit1+swap);\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit0\\n        )\\n    );\\n}\\nelse{\\n    //swap token1 for token0\\n    swap = uint256(swapAmount);\\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit1\\n        )\\n    );     \\n}\\n```\\n
Uniproxy.depositSwap - _router should not be determined by the callerчhighч`Uniproxy.depositSwap` uses `_router` that is determined by the caller, which in turn might inject a “fake” contract, and thus may steal funds stuck in the `UniProxy` contract.\\nThe `UniProxy` contract has certain trust assumptions regarding the router. The router is supposed to return not less than deposit1(or deposit0) amount of tokens but that fact is never checked.\\n```\\nfunction depositSwap(\\n  int256 swapAmount, // (-) token1, (+) token0 for token1; amount to swap\\n  uint256 deposit0,\\n  uint256 deposit1,\\n  address to,\\n  address from,\\n  bytes memory path,\\n  address pos,\\n  address \\_router\\n) external returns (uint256 shares) {\\n```\\nчConsider removing the `_router` parameter from the function, and instead, use a storage variable that will be initialized in the constructor.чч```\\nfunction depositSwap(\\n  int256 swapAmount, // (-) token1, (+) token0 for token1; amount to swap\\n  uint256 deposit0,\\n  uint256 deposit1,\\n  address to,\\n  address from,\\n  bytes memory path,\\n  address pos,\\n  address \\_router\\n) external returns (uint256 shares) {\\n```\\n
Re-entrancy + flash loan attack can invalidate price checkчhighчThe `UniProxy` contract has a price manipulation protection:\\n```\\nif (twapCheck || positions[pos].twapOverride) {\\n  // check twap\\n  checkPriceChange(\\n    pos,\\n    (positions[pos].twapOverride ? positions[pos].twapInterval : twapInterval),\\n    (positions[pos].twapOverride ? positions[pos].priceThreshold : priceThreshold)\\n  );\\n}\\n```\\n\\nBut after that, the tokens are transferred from the user, if the token transfer allows an attacker to hijack the call-flow of the transaction inside, the attacker can manipulate the Uniswap price there, after the check happened. The Hypervisor's `deposit` function itself is vulnerable to the flash-loan attack.чMake sure the price does not change before the `Hypervisor.deposit` call. For example, the token transfers can be made at the beginning of the `UniProxy.deposit` function.чч```\\nif (twapCheck || positions[pos].twapOverride) {\\n  // check twap\\n  checkPriceChange(\\n    pos,\\n    (positions[pos].twapOverride ? positions[pos].twapInterval : twapInterval),\\n    (positions[pos].twapOverride ? positions[pos].priceThreshold : priceThreshold)\\n  );\\n}\\n```\\n
UniProxy.properDepositRatio - Proper ratio will not prevent liquidity imbalance for all possible scenariosчhighч`UniProxy.properDepositRatio` purpose is to be used as a mechanism to prevent liquidity imbalance. The idea is to compare the deposit ratio with the `hypeRatio`, which is the ratio between the tokens held by the `Hypervisor` contract. In practice, however, this function will not prevent a skewed deposit ratio in many cases. `deposit1 / deposit0` might be a huge number, while `10^16 <= depositRatio <= 10^18`, and 10^16 <= `hypeRatio` <= 10^18. Let us consider the case where `hype1 / hype0 >= 10`, that means `hypeRatio` = 10^18, and now if `deposit1 / deposit0` = 10^200 for example, `depositRatio = 10^18`, and the transaction will pass, which is clearly not intended.\\n```\\nfunction properDepositRatio(\\n  address pos,\\n  uint256 deposit0,\\n  uint256 deposit1\\n) public view returns (bool) {\\n  (uint256 hype0, uint256 hype1) = IHypervisor(pos).getTotalAmounts();\\n  if (IHypervisor(pos).totalSupply() != 0) {\\n    uint256 depositRatio = deposit0 == 0 ? 10e18 : deposit1.mul(1e18).div(deposit0);\\n    depositRatio = depositRatio > 10e18 ? 10e18 : depositRatio;\\n    depositRatio = depositRatio < 10e16 ? 10e16 : depositRatio;\\n    uint256 hypeRatio = hype0 == 0 ? 10e18 : hype1.mul(1e18).div(hype0);\\n    hypeRatio = hypeRatio > 10e18 ? 10e18 : hypeRatio;\\n    hypeRatio = hypeRatio < 10e16 ? 10e16 : hypeRatio;\\n    return (FullMath.mulDiv(depositRatio, deltaScale, hypeRatio) < depositDelta &&\\n            FullMath.mulDiv(hypeRatio, deltaScale, depositRatio) < depositDelta);\\n  }\\n  return true;\\n}\\n```\\nчResolution\\nFixed in GammaStrategies/[email protected]9a7a3dd by deleting the `properDepositRatio` function.\\nConsider removing the cap of [0.1,10] both for `depositRatio` and for `hypeRatio`.чч```\\nfunction properDepositRatio(\\n  address pos,\\n  uint256 deposit0,\\n  uint256 deposit1\\n) public view returns (bool) {\\n  (uint256 hype0, uint256 hype1) = IHypervisor(pos).getTotalAmounts();\\n  if (IHypervisor(pos).totalSupply() != 0) {\\n    uint256 depositRatio = deposit0 == 0 ? 10e18 : deposit1.mul(1e18).div(deposit0);\\n    depositRatio = depositRatio > 10e18 ? 10e18 : depositRatio;\\n    depositRatio = depositRatio < 10e16 ? 10e16 : depositRatio;\\n    uint256 hypeRatio = hype0 == 0 ? 10e18 : hype1.mul(1e18).div(hype0);\\n    hypeRatio = hypeRatio > 10e18 ? 10e18 : hypeRatio;\\n    hypeRatio = hypeRatio < 10e16 ? 10e16 : hypeRatio;\\n    return (FullMath.mulDiv(depositRatio, deltaScale, hypeRatio) < depositDelta &&\\n            FullMath.mulDiv(hypeRatio, deltaScale, depositRatio) < depositDelta);\\n  }\\n  return true;\\n}\\n```\\n
UniProxy.depositSwap doesn't deposit all the users' fundsчmediumчWhen executing the swap, the minimal amount out is passed to the router (deposit1 in this example), but the actual swap amount will be `amountOut`. But after the trade, instead of depositing `amountOut`, the contract tries to deposit `deposit1`, which is lower. This may result in some users' funds staying in the `UniProxy` contract.\\n```\\nelse{\\n    //swap token1 for token0\\n    swap = uint256(swapAmount);\\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit1\\n        )\\n    );     \\n}\\n\\nrequire(amountOut > 0, \"Swap failed\");\\n\\nif (positions[pos].version < 2) {\\n  // requires lp token transfer from proxy to msg.sender\\n  shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\\n  IHypervisor(pos).transfer(to, shares);\\n}\\n```\\nчResolution\\nFixed in GammaStrategies/[email protected]9a7a3dd by deleting the `depositSwap` function.\\nDeposit all the user's funds to the Hypervisor.чч```\\nelse{\\n    //swap token1 for token0\\n    swap = uint256(swapAmount);\\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n    amountOut = router.exactInput(\\n        ISwapRouter.ExactInputParams(\\n            path,\\n            address(this),\\n            block.timestamp + swapLife,\\n            swap,\\n            deposit1\\n        )\\n    );     \\n}\\n\\nrequire(amountOut > 0, \"Swap failed\");\\n\\nif (positions[pos].version < 2) {\\n  // requires lp token transfer from proxy to msg.sender\\n  shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\\n  IHypervisor(pos).transfer(to, shares);\\n}\\n```\\n
Hypervisor - Multiple “sandwiching” front running vectorsчmediumчThe amount of tokens received from `UniswapV3Pool` functions might be manipulated by front-runners due to the decentralized nature of AMMs, where the order of transactions can not be pre-determined. A potential “sandwicher” may insert a buying order before the user's call to `Hypervisor.rebalance` for instance, and a sell order after.\\nMore specifically, calls to `pool.swap`, `pool.mint`, `pool.burn` are susceptible to “sandwiching” vectors.\\n`Hypervisor.rebalance`\\n```\\nif (swapQuantity != 0) {\\n    pool.swap(\\n        address(this),\\n        swapQuantity > 0,\\n        swapQuantity > 0 ? swapQuantity : -swapQuantity,\\n        swapQuantity > 0 ? TickMath.MIN\\_SQRT\\_RATIO + 1 : TickMath.MAX\\_SQRT\\_RATIO - 1,\\n        abi.encode(address(this))\\n    );\\n}\\n```\\n\\n```\\nfunction \\_mintLiquidity(\\n    int24 tickLower,\\n    int24 tickUpper,\\n    uint128 liquidity,\\n    address payer\\n) internal returns (uint256 amount0, uint256 amount1) {\\n    if (liquidity > 0) {\\n        (amount0, amount1) = pool.mint(\\n            address(this),\\n            tickLower,\\n            tickUpper,\\n            liquidity,\\n            abi.encode(payer)\\n        );\\n    }\\n}\\n```\\n\\n```\\nfunction \\_burnLiquidity(\\n    int24 tickLower,\\n    int24 tickUpper,\\n    uint128 liquidity,\\n    address to,\\n    bool collectAll\\n) internal returns (uint256 amount0, uint256 amount1) {\\n    if (liquidity > 0) {\\n        // Burn liquidity\\n        (uint256 owed0, uint256 owed1) = pool.burn(tickLower, tickUpper, liquidity);\\n\\n        // Collect amount owed\\n        uint128 collect0 = collectAll ? type(uint128).max : \\_uint128Safe(owed0);\\n        uint128 collect1 = collectAll ? type(uint128).max : \\_uint128Safe(owed1);\\n        if (collect0 > 0 || collect1 > 0) {\\n            (amount0, amount1) = pool.collect(to, tickLower, tickUpper, collect0, collect1);\\n        }\\n    }\\n}\\n```\\nчConsider adding an `amountMin` parameter(s) to ensure that at least the `amountMin` of tokens was received.чч```\\nif (swapQuantity != 0) {\\n    pool.swap(\\n        address(this),\\n        swapQuantity > 0,\\n        swapQuantity > 0 ? swapQuantity : -swapQuantity,\\n        swapQuantity > 0 ? TickMath.MIN\\_SQRT\\_RATIO + 1 : TickMath.MAX\\_SQRT\\_RATIO - 1,\\n        abi.encode(address(this))\\n    );\\n}\\n```\\n
Uniswap v3 callbacks access control should be hardenedчlowчResolution\\nFixed in GammaStrategies/[email protected]9a7a3dd by implementing the auditor's recommendation for `uniswapV3MintCallback`, and deleting `uniswapV3SwapCallback` and the call to `pool.swap`.\\nUniswap v3 uses a callback pattern to pull funds from the caller. The caller, (in this case Hypervisor) has to implement a callback function which will be called by the Uniswap's `pool`. Both `uniswapV3MintCallback` and `uniswapV3SwapCallback` restrict the access to the callback functions only for the `pool`. However, this alone will not block a random call from the `pool` contract in case the latter was hacked, which will result in stealing all the funds held in `Hypervisor` or of any user that approved the `Hypervisor` contract to transfer tokens on his behalf.\\n```\\nfunction uniswapV3MintCallback(\\n    uint256 amount0,\\n    uint256 amount1,\\n    bytes calldata data\\n) external override {\\n    require(msg.sender == address(pool));\\n    address payer = abi.decode(data, (address));\\n\\n    if (payer == address(this)) {\\n        if (amount0 > 0) token0.safeTransfer(msg.sender, amount0);\\n        if (amount1 > 0) token1.safeTransfer(msg.sender, amount1);\\n    } else {\\n        if (amount0 > 0) token0.safeTransferFrom(payer, msg.sender, amount0);\\n        if (amount1 > 0) token1.safeTransferFrom(payer, msg.sender, amount1);\\n    }\\n}\\n\\nfunction uniswapV3SwapCallback(\\n    int256 amount0Delta,\\n    int256 amount1Delta,\\n    bytes calldata data\\n) external override {\\n    require(msg.sender == address(pool));\\n    address payer = abi.decode(data, (address));\\n\\n    if (amount0Delta > 0) {\\n        if (payer == address(this)) {\\n            token0.safeTransfer(msg.sender, uint256(amount0Delta));\\n        } else {\\n            token0.safeTransferFrom(payer, msg.sender, uint256(amount0Delta));\\n        }\\n    } else if (amount1Delta > 0) {\\n        if (payer == address(this)) {\\n            token1.safeTransfer(msg.sender, uint256(amount1Delta));\\n        } else {\\n            token1.safeTransferFrom(payer, msg.sender, uint256(amount1Delta));\\n        }\\n    }\\n}\\n```\\nчConsider adding (boolean) storage variables that will help to track whether a call to `uniswapV3MintCallback | uniswapV3SwapCallback` was preceded by a call to _mintLiquidity | `rebalance` respectively. An example for the `rebalance` function would be `bool rebalanceCalled`, this variable will be assigned a `true` value in `rebalance` before the external call of `pool.swap`, then `uniswapV3SwapCallback` will require that `rebalanceCalled` == `true`, and then right after `rebalanceCalled` will be assigned a `false` value.чч```\\nfunction uniswapV3MintCallback(\\n    uint256 amount0,\\n    uint256 amount1,\\n    bytes calldata data\\n) external override {\\n    require(msg.sender == address(pool));\\n    address payer = abi.decode(data, (address));\\n\\n    if (payer == address(this)) {\\n        if (amount0 > 0) token0.safeTransfer(msg.sender, amount0);\\n        if (amount1 > 0) token1.safeTransfer(msg.sender, amount1);\\n    } else {\\n        if (amount0 > 0) token0.safeTransferFrom(payer, msg.sender, amount0);\\n        if (amount1 > 0) token1.safeTransferFrom(payer, msg.sender, amount1);\\n    }\\n}\\n\\nfunction uniswapV3SwapCallback(\\n    int256 amount0Delta,\\n    int256 amount1Delta,\\n    bytes calldata data\\n) external override {\\n    require(msg.sender == address(pool));\\n    address payer = abi.decode(data, (address));\\n\\n    if (amount0Delta > 0) {\\n        if (payer == address(this)) {\\n            token0.safeTransfer(msg.sender, uint256(amount0Delta));\\n        } else {\\n            token0.safeTransferFrom(payer, msg.sender, uint256(amount0Delta));\\n        }\\n    } else if (amount1Delta > 0) {\\n        if (payer == address(this)) {\\n            token1.safeTransfer(msg.sender, uint256(amount1Delta));\\n        } else {\\n            token1.safeTransferFrom(payer, msg.sender, uint256(amount1Delta));\\n        }\\n    }\\n}\\n```\\n
UniProxy.depositSwap doesn't deposit all the users' fundsчmediumчResolution\\nFixed in GammaStrategies/[email protected]9a7a3dd by deleting the `depositSwap` function.\\nWhen executing the swap, the minimal amount out is passed to the router (deposit1 in this example), but the actual swap amount will be `amountOut`. But after the trade, instead of depositing `amountOut`, the contract tries to deposit `deposit1`, which is lower. This may result in some users' funds staying in the `UniProxy` contract.\\n```\\nelse{\\n //swap token1 for token0\\n swap = uint256(swapAmount);\\n IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n amountOut = router.exactInput(\\n ISwapRouter.ExactInputParams(\\n path,\\n address(this),\\n block.timestamp + swapLife,\\n swap,\\n deposit1\\n )\\n ); \\n}\\n\\nrequire(amountOut > 0, \"Swap failed\");\\n\\nif (positions[pos].version < 2) {\\n // requires lp token transfer from proxy to msg.sender\\n shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\\n IHypervisor(pos).transfer(to, shares);\\n}\\n```\\nчDeposit all the user's funds to the Hypervisor.чч```\\nelse{\\n //swap token1 for token0\\n swap = uint256(swapAmount);\\n IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\\n\\n amountOut = router.exactInput(\\n ISwapRouter.ExactInputParams(\\n path,\\n address(this),\\n block.timestamp + swapLife,\\n swap,\\n deposit1\\n )\\n ); \\n}\\n\\nrequire(amountOut > 0, \"Swap failed\");\\n\\nif (positions[pos].version < 2) {\\n // requires lp token transfer from proxy to msg.sender\\n shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\\n IHypervisor(pos).transfer(to, shares);\\n}\\n```\\n
Initialization flawsчlowчFor non-upgradeable contracts, the Solidity compiler takes care of chaining the constructor calls of an inheritance hierarchy in the right order; for upgradeable contracts, taking care of initialization is a manual task – and with extensive use of inheritance, it is tedious and error-prone. The convention in OpenZeppelin Contracts Upgradeable is to have a `__C_init_unchained` function that contains the actual initialization logic for contract `C` and a `__C_init` function that calls the `*_init_unchained` function for every super-contract – direct and indirect – in the inheritance hierarchy (including C) in the C3-linearized order from most basic to most derived. This pattern imitates what the compiler does for constructors.\\nAll `*_init` functions in the contracts (__ERC20WrapperGluwacoin_init, `__ERC20Reservable_init`, `__ERC20ETHless_init`, and __ERC20Wrapper_init) are missing some `_init_unchained` calls, and sometimes the existing calls are not in the correct order.\\nThe `__ERC20WrapperGluwacoin_init` function is implemented as follows:\\n```\\nfunction \\_\\_ERC20WrapperGluwacoin\\_init(\\n    string memory name,\\n    string memory symbol,\\n    IERC20 token\\n) internal initializer {\\n    \\_\\_Context\\_init\\_unchained();\\n    \\_\\_ERC20\\_init\\_unchained(name, symbol);\\n    \\_\\_ERC20ETHless\\_init\\_unchained();\\n    \\_\\_ERC20Reservable\\_init\\_unchained();\\n    \\_\\_AccessControlEnumerable\\_init\\_unchained();\\n    \\_\\_ERC20Wrapper\\_init\\_unchained(token);\\n    \\_\\_ERC20WrapperGluwacoin\\_init\\_unchained();\\n}\\n```\\n\\nAnd the C3 linearization is:\\n```\\nERC20WrapperGluwacoin\\n  ↖ ERC20Reservable\\n  ↖ ERC20ETHless\\n  ↖ ERC20Wrapper\\n  ↖ ERC20Upgradeable\\n  ↖ IERC20MetadataUpgradeable\\n  ↖ IERC20Upgradeable\\n  ↖ AccessControlEnumerableUpgradeable\\n  ↖ AccessControlUpgradeable\\n  ↖ ERC165Upgradeable\\n  ↖ IERC165Upgradeable\\n  ↖ IAccessControlEnumerableUpgradeable\\n  ↖ IAccessControlUpgradeable\\n  ↖ ContextUpgradeable\\n  ↖ Initializable\\n```\\n\\nThe calls `__ERC165_init_unchained();` and `__AccessControl_init_unchained();` are missing, and `__ERC20Wrapper_init_unchained(token);` should move between `__ERC20_init_unchained(name, symbol);` and `__ERC20ETHless_init_unchained();`.чReview all `*_init` functions, add the missing `*_init_unchained` calls, and fix the order of these calls.чч```\\nfunction \\_\\_ERC20WrapperGluwacoin\\_init(\\n    string memory name,\\n    string memory symbol,\\n    IERC20 token\\n) internal initializer {\\n    \\_\\_Context\\_init\\_unchained();\\n    \\_\\_ERC20\\_init\\_unchained(name, symbol);\\n    \\_\\_ERC20ETHless\\_init\\_unchained();\\n    \\_\\_ERC20Reservable\\_init\\_unchained();\\n    \\_\\_AccessControlEnumerable\\_init\\_unchained();\\n    \\_\\_ERC20Wrapper\\_init\\_unchained(token);\\n    \\_\\_ERC20WrapperGluwacoin\\_init\\_unchained();\\n}\\n```\\n
Flaw in _beforeTokenTransfer call chain and missing testsчlowчIn OpenZeppelin's ERC-20 implementation, the virtual `_beforeTokenTransfer` function provides a hook that is called before tokens are transferred, minted, or burned. In the Gluwacoin codebase, it is used to check whether the unreserved balance (as opposed to the regular balance, which is checked by the ERC-20 implementation) of the sender is sufficient to allow this transfer or burning.\\nIn `ERC20WrapperGluwacoin`, `ERC20Reservable`, and `ERC20Wrapper`, the `_beforeTokenTransfer` function is implemented in the following way:\\n```\\nfunction \\_beforeTokenTransfer(\\n    address from,\\n    address to,\\n    uint256 amount\\n) internal override(ERC20Upgradeable, ERC20Wrapper, ERC20Reservable) {\\n    ERC20Wrapper.\\_beforeTokenTransfer(from, to, amount);\\n    ERC20Reservable.\\_beforeTokenTransfer(from, to, amount);\\n}\\n```\\n\\n```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal virtual override (ERC20Upgradeable) {\\n    if (from != address(0)) {\\n        require(\\_unreservedBalance(from) >= amount, \"ERC20Reservable: transfer amount exceeds unreserved balance\");\\n    }\\n\\n    super.\\_beforeTokenTransfer(from, to, amount);\\n}\\n```\\n\\n```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal virtual override (ERC20Upgradeable) {\\n    super.\\_beforeTokenTransfer(from, to, amount);\\n}\\n```\\n\\nFinally, the C3-linearization of the contracts is:\\n```\\nERC20WrapperGluwacoin\\n  ↖ ERC20Reservable\\n  ↖ ERC20ETHless\\n  ↖ ERC20Wrapper\\n  ↖ ERC20Upgradeable\\n  ↖ IERC20MetadataUpgradeable\\n  ↖ IERC20Upgradeable\\n  ↖ AccessControlEnumerableUpgradeable\\n  ↖ AccessControlUpgradeable\\n  ↖ ERC165Upgradeable\\n  ↖ IERC165Upgradeable\\n  ↖ IAccessControlEnumerableUpgradeable\\n  ↖ IAccessControlUpgradeable\\n  ↖ ContextUpgradeable\\n  ↖ Initializable\\n```\\n\\nThis means `ERC20Wrapper._beforeTokenTransfer` is ultimately called twice – once directly in `ERC20WrapperGluwacoin._beforeTokenTransfer` and then a second time because the `super._beforeTokenTransfer` call in `ERC20Reservable._beforeTokenTransfer` resolves to `ERC20Wrapper._beforeTokenTransfer`. (ERC20ETHless doesn't override _beforeTokenTransfer.)\\nMoreover, while reviewing the correctness and coverage of the tests is not in scope for this engagement, we happened to notice that there are no tests that check whether the unreserved balance is sufficient for transferring or burning tokens.ч`ERC20WrapperGluwacoin._beforeTokenTransfer` should just call `super._beforeTokenTransfer`. Moreover, the `_beforeTokenTransfer` implementation can be removed from `ERC20Wrapper`.\\nWe would like to stress the importance of careful and comprehensive testing in general and of this functionality in particular, as it is crucial for the system's integrity. We also encourage investigating whether there are more such omissions and an evaluation of the test quality and coverage in general.чч```\\nfunction \\_beforeTokenTransfer(\\n    address from,\\n    address to,\\n    uint256 amount\\n) internal override(ERC20Upgradeable, ERC20Wrapper, ERC20Reservable) {\\n    ERC20Wrapper.\\_beforeTokenTransfer(from, to, amount);\\n    ERC20Reservable.\\_beforeTokenTransfer(from, to, amount);\\n}\\n```\\n
Hard-coded decimalsчlowчThe Gluwacoin wrapper token should have the same number of decimals as the wrapped ERC-20. Currently, the number of decimals is hard-coded to 6. This limits flexibility or requires source code changes and recompilation if a token with a different number of decimals is to be wrapped.\\n```\\nfunction decimals() public pure override returns (uint8) {\\n    return 6;\\n}\\n```\\nчWe recommend supplying the number of `decimals` as an initialization parameter and storing it in a state variable. That increases gas consumption of the `decimals` function, but we doubt this view function will be frequently called from a contract, and even if it was, we think the benefits far outweigh the costs.\\nMoreover, we believe the `decimals` logic (i.e., function `decimals` and the new state variable) should be implemented in the `ERC20Wrapper` contract – which holds the basic ERC-20 functionality of the wrapper token – and not in `ERC20WrapperGluwacoin`, which is the base contract of the entire system.чч```\\nfunction decimals() public pure override returns (uint8) {\\n    return 6;\\n}\\n```\\n
Re-initialization of the Balancer pool is potentially possibleчlowчInstead of creating a new Balancer pool for an auction every time, the same pool is getting re-used repeatedly. When this happens, the old liquidity is withdrawn, and if there is enough FEI in the contract, the weights are shifted pool is filled with new tokens. If there is not enough FEI, the pool is left empty, and users can still interact with it. When there's enough FEI again, it's re-initialized again, which is not the intention:\\n```\\nuint256 bptTotal = pool.totalSupply();\\nuint256 bptBalance = pool.balanceOf(address(this));\\n\\n// Balancer locks a small amount of bptTotal after init, so 0 bpt means pool needs initializing\\nif (bptTotal == 0) {\\n    \\_initializePool();\\n    return;\\n}\\n```\\n\\nTheoretically, this will never happen because there should be minimal leftover liquidity tokens after the withdrawal. But we couldn't strictly verify that fact because it requires looking into balancer code much deeper.чOne of the options would be only to allow re-using the pool in atomic transactions. So if there are not enough FEI tokens for the next auction, the `swap` transaction reverts. That will help with another issue (issue 3.2) too.чч```\\nuint256 bptTotal = pool.totalSupply();\\nuint256 bptBalance = pool.balanceOf(address(this));\\n\\n// Balancer locks a small amount of bptTotal after init, so 0 bpt means pool needs initializing\\nif (bptTotal == 0) {\\n    \\_initializePool();\\n    return;\\n}\\n```\\n
The BalancerLBPSwapper may not have enough Tribe tokensчlowчWhenever the `swap` function is called, it should re-initialize the Balancer pool that requires adding liquidity: 99% Fei and 1% Tribe. So the Tribe should initially be in the contract.\\n```\\nfunction \\_getTokensIn(uint256 spentTokenBalance) internal view returns(uint256[] memory amountsIn) {\\n    amountsIn = new uint256[](2);\\n\\n    uint256 receivedTokenBalance = readOracle().mul(spentTokenBalance).mul(ONE\\_PERCENT).div(NINETY\\_NINE\\_PERCENT).asUint256();\\n\\n    if (address(assets[0]) == tokenSpent) {\\n        amountsIn[0] = spentTokenBalance;\\n        amountsIn[1] = receivedTokenBalance;\\n    } else {\\n        amountsIn[0] = receivedTokenBalance;\\n        amountsIn[1] = spentTokenBalance;\\n    }\\n}\\n```\\n\\nAdditionally, when the `swap` is called, and there is not enough FEI to re-initiate the Balancer auction, all the Tribe gets withdrawn. So the next time the `swap` is called, there is no Tribe in the contract again.\\n```\\n// 5. Send remaining tokenReceived to target\\nIERC20(tokenReceived).transfer(tokenReceivingAddress, IERC20(tokenReceived).balanceOf(address(this)));\\n```\\nчCreate an automated mechanism that mints/transfers Tribe when it is needed in the swapper contract.чч```\\nfunction \\_getTokensIn(uint256 spentTokenBalance) internal view returns(uint256[] memory amountsIn) {\\n    amountsIn = new uint256[](2);\\n\\n    uint256 receivedTokenBalance = readOracle().mul(spentTokenBalance).mul(ONE\\_PERCENT).div(NINETY\\_NINE\\_PERCENT).asUint256();\\n\\n    if (address(assets[0]) == tokenSpent) {\\n        amountsIn[0] = spentTokenBalance;\\n        amountsIn[1] = receivedTokenBalance;\\n    } else {\\n        amountsIn[0] = receivedTokenBalance;\\n        amountsIn[1] = spentTokenBalance;\\n    }\\n}\\n```\\n
StableSwapOperatorV1 - resistantFei value is not correct in the resistantBalanceAndFei functionчhighчThe `resistantBalanceAndFei` function of a `PCVDeposit` contract is supposed to return the amount of funds that the contract controls; it is then used to evaluate the total value of PCV (collateral in the protocol). Additionally, this function returns the number of FEI tokens that are protocol-controlled. These FEI tokens are “temporarily minted”; they are not backed up by the collateral and shouldn't be used in calculations that determine the collateralization of the protocol.\\nIdeally, the amount of these FEI tokens should be the same during the deposit, withdrawal, and the `resistantBalanceAndFei` function call. In the `StableSwapOperatorV1` contract, all these values are totally different:\\nduring the deposit, the amount of required FEI tokens is calculated. It's done in a way so the values of FEI and 3pool tokens in the metapool should be equal after the deposit. So if there is the initial imbalance of FEI and 3pool tokens, the deposit value of these tokens will be different:\\n```\\n// get the amount of tokens in the pool\\n(uint256 \\_3crvAmount, uint256 \\_feiAmount) = (\\n    IStableSwap2(pool).balances(\\_3crvIndex),\\n    IStableSwap2(pool).balances(\\_feiIndex)\\n);\\n// // rest of code and the expected amount of 3crv in it after deposit\\nuint256 \\_3crvAmountAfter = \\_3crvAmount + \\_3crvBalanceAfter;\\n \\n// get the usd value of 3crv in the pool\\nuint256 \\_3crvUsdValue = \\_3crvAmountAfter \\* IStableSwap3(\\_3pool).get\\_virtual\\_price() / 1e18;\\n \\n// compute the number of FEI to deposit\\nuint256 \\_feiToDeposit = 0;\\nif (\\_3crvUsdValue > \\_feiAmount) {\\n    \\_feiToDeposit = \\_3crvUsdValue - \\_feiAmount;\\n}\\n```\\n\\nduring the withdrawal, the FEI and 3pool tokens are withdrawn in the same proportion as they are present in the metapool:\\n```\\nuint256[2] memory \\_minAmounts; // [0, 0]\\nIERC20(pool).approve(pool, \\_lpToWithdraw);\\nuint256 \\_3crvBalanceBefore = IERC20(\\_3crv).balanceOf(address(this));\\nIStableSwap2(pool).remove\\_liquidity(\\_lpToWithdraw, \\_minAmounts);\\n```\\n\\nin the `resistantBalanceAndFei` function, the value of protocol-controlled FEI tokens and the value of 3pool tokens deposited are considered equal:\\n```\\nresistantBalance = \\_lpPriceUSD / 2;\\nresistantFei = resistantBalance;\\n```\\n\\nSome of these values may be equal under some circumstances, but that is not enforced. After one of the steps (deposit or withdrawal), the total PCV value and collateralization may be changed significantly.чMake sure that deposit, withdrawal, and the `resistantBalanceAndFei` are consistent and won't instantly change the PCV value significantly.чч```\\n// get the amount of tokens in the pool\\n(uint256 \\_3crvAmount, uint256 \\_feiAmount) = (\\n    IStableSwap2(pool).balances(\\_3crvIndex),\\n    IStableSwap2(pool).balances(\\_feiIndex)\\n);\\n// // rest of code and the expected amount of 3crv in it after deposit\\nuint256 \\_3crvAmountAfter = \\_3crvAmount + \\_3crvBalanceAfter;\\n \\n// get the usd value of 3crv in the pool\\nuint256 \\_3crvUsdValue = \\_3crvAmountAfter \\* IStableSwap3(\\_3pool).get\\_virtual\\_price() / 1e18;\\n \\n// compute the number of FEI to deposit\\nuint256 \\_feiToDeposit = 0;\\nif (\\_3crvUsdValue > \\_feiAmount) {\\n    \\_feiToDeposit = \\_3crvUsdValue - \\_feiAmount;\\n}\\n```\\n
CollateralizationOracle - Fei in excluded deposits contributes to userCirculatingFeiчhighч`CollateralizationOracle.pcvStats` iterates over all deposits, queries the resistant balance and FEI for each deposit, and accumulates the total value of the resistant balances and the total resistant FEI. Any Guardian or Governor can exclude (and re-include) a deposit that has become problematic in some way, for example, because it is reporting wrong numbers. Finally, the `pcvStats` function computes the `userCirculatingFei` as the total FEI supply minus the accumulated resistant FEI balances; the idea here is to determine the amount of “free” FEI, or FEI that is not PCV. However, the FEI balances from excluded deposits contribute to the `userCirculatingFei`, although they are clearly not “free” FEI. That leads to a wrong `protocolEquity` and a skewed collateralization ratio and might therefore have a significant impact on the economics of the system.\\nIt should be noted that even the exclusion from the total PCV leads to a `protocolEquity` and a collateralization ratio that could be considered skewed (again, it might depend on the exact reasons for exclusion), but “adding” the missing FEI to the `userCirculatingFei` distorts these numbers even more.\\nIn the extreme scenario that all deposits have been excluded, the entire Fei supply is currently reported as `userCirculatingFei`.\\n```\\n/// @notice returns the Protocol-Controlled Value, User-circulating FEI, and\\n/// Protocol Equity.\\n/// @return protocolControlledValue : the total USD value of all assets held\\n/// by the protocol.\\n/// @return userCirculatingFei : the number of FEI not owned by the protocol.\\n/// @return protocolEquity : the difference between PCV and user circulating FEI.\\n/// If there are more circulating FEI than $ in the PCV, equity is 0.\\n/// @return validityStatus : the current oracle validity status (false if any\\n/// of the oracles for tokens held in the PCV are invalid, or if\\n/// this contract is paused).\\nfunction pcvStats() public override view returns (\\n  uint256 protocolControlledValue,\\n  uint256 userCirculatingFei,\\n  int256 protocolEquity,\\n  bool validityStatus\\n) {\\n    uint256 \\_protocolControlledFei = 0;\\n    validityStatus = !paused();\\n\\n    // For each token// rest of code\\n    for (uint256 i = 0; i < tokensInPcv.length(); i++) {\\n        address \\_token = tokensInPcv.at(i);\\n        uint256 \\_totalTokenBalance  = 0;\\n\\n        // For each deposit// rest of code\\n        for (uint256 j = 0; j < tokenToDeposits[\\_token].length(); j++) {\\n            address \\_deposit = tokenToDeposits[\\_token].at(j);\\n\\n            // ignore deposits that are excluded by the Guardian\\n            if (!excludedDeposits[\\_deposit]) {\\n                // read the deposit, and increment token balance/protocol fei\\n                (uint256 \\_depositBalance, uint256 \\_depositFei) = IPCVDepositBalances(\\_deposit).resistantBalanceAndFei();\\n                \\_totalTokenBalance += \\_depositBalance;\\n                \\_protocolControlledFei += \\_depositFei;\\n            }\\n        }\\n\\n        // If the protocol holds non-zero balance of tokens, fetch the oracle price to\\n        // increment PCV by \\_totalTokenBalance \\* oracle price USD.\\n        if (\\_totalTokenBalance != 0) {\\n            (Decimal.D256 memory \\_oraclePrice, bool \\_oracleValid) = IOracle(tokenToOracle[\\_token]).read();\\n            if (!\\_oracleValid) {\\n                validityStatus = false;\\n            }\\n            protocolControlledValue += \\_oraclePrice.mul(\\_totalTokenBalance).asUint256();\\n        }\\n    }\\n\\n    userCirculatingFei = fei().totalSupply() - \\_protocolControlledFei;\\n    protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);\\n}\\n```\\nчIt is unclear how to fix this. One might want to exclude the FEI in excluded deposits entirely from the calculation, but not knowing the amount was the reason to exclude the deposit in the first place.\\nOne option could be to let the entity that excludes a deposit specify substitute values that should be used instead of querying the numbers from the deposit. However, it is questionable whether this approach is practical if the numbers we'd like to see as substitute values change quickly or repeatedly over time. Ultimately, the querying function itself should be fixed. Moreover, as the substitute values can dramatically impact the system economics, we'd only like to trust the Governor with this and not give this permission to a Guardian. However, the original intention was to give a role with less trust than the Governor the possibility to react quickly to a deposit that reports wrong numbers; if the exclusion of deposits becomes the Governor's privilege, such a quick and lightweight intervention isn't possible anymore.\\nIndependently, we recommend taking proper care of the situation that all deposits – or just too many – have been excluded, for example, by setting the returned `validityStatus` to `false`, as in this case, there is not enough information to compute the collateralization ratio even as a crude approximation.чч```\\n/// @notice returns the Protocol-Controlled Value, User-circulating FEI, and\\n/// Protocol Equity.\\n/// @return protocolControlledValue : the total USD value of all assets held\\n/// by the protocol.\\n/// @return userCirculatingFei : the number of FEI not owned by the protocol.\\n/// @return protocolEquity : the difference between PCV and user circulating FEI.\\n/// If there are more circulating FEI than $ in the PCV, equity is 0.\\n/// @return validityStatus : the current oracle validity status (false if any\\n/// of the oracles for tokens held in the PCV are invalid, or if\\n/// this contract is paused).\\nfunction pcvStats() public override view returns (\\n  uint256 protocolControlledValue,\\n  uint256 userCirculatingFei,\\n  int256 protocolEquity,\\n  bool validityStatus\\n) {\\n    uint256 \\_protocolControlledFei = 0;\\n    validityStatus = !paused();\\n\\n    // For each token// rest of code\\n    for (uint256 i = 0; i < tokensInPcv.length(); i++) {\\n        address \\_token = tokensInPcv.at(i);\\n        uint256 \\_totalTokenBalance  = 0;\\n\\n        // For each deposit// rest of code\\n        for (uint256 j = 0; j < tokenToDeposits[\\_token].length(); j++) {\\n            address \\_deposit = tokenToDeposits[\\_token].at(j);\\n\\n            // ignore deposits that are excluded by the Guardian\\n            if (!excludedDeposits[\\_deposit]) {\\n                // read the deposit, and increment token balance/protocol fei\\n                (uint256 \\_depositBalance, uint256 \\_depositFei) = IPCVDepositBalances(\\_deposit).resistantBalanceAndFei();\\n                \\_totalTokenBalance += \\_depositBalance;\\n                \\_protocolControlledFei += \\_depositFei;\\n            }\\n        }\\n\\n        // If the protocol holds non-zero balance of tokens, fetch the oracle price to\\n        // increment PCV by \\_totalTokenBalance \\* oracle price USD.\\n        if (\\_totalTokenBalance != 0) {\\n            (Decimal.D256 memory \\_oraclePrice, bool \\_oracleValid) = IOracle(tokenToOracle[\\_token]).read();\\n            if (!\\_oracleValid) {\\n                validityStatus = false;\\n            }\\n            protocolControlledValue += \\_oraclePrice.mul(\\_totalTokenBalance).asUint256();\\n        }\\n    }\\n\\n    userCirculatingFei = fei().totalSupply() - \\_protocolControlledFei;\\n    protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);\\n}\\n```\\n
BalancerLBPSwapper - init() can be front-run to potentially steal tokensчmediumчThe deployment process for `BalancerLBPSwapper` appears to be the following:\\ndeploy `BalancerLBPSwapper`.\\nrun `ILiquidityBootstrappingPoolFactory.create()` proving the newly deployed swapper address as the owner of the pool.\\ninitialize `BalancerLBPSwapper.init()` with the address of the newly created pool.\\nThis process may be split across multiple transactions as in the `v2Phase1.js` deployment scenario.\\nBetween step (1) and (3) there is a window of opportunity for someone to maliciously initialize contract. This should be easily detectable because calling `init()` twice should revert the second transaction. If this is not caught in the deployment script this may have more severe security implications. Otherwise, this window can be used to grief the deployment initializing it before the original initializer does forcing them to redeploy the contract or to steal any tokenSpent/tokenReceived that are owned by the contract at this time.\\nNote: It is assumed that the contract will not own a lot of tokens right after deployment rendering the scenario of stealing tokens more unlikely. However, that highly depends on the deployment script for the contract system.\\n```\\nfunction init(IWeightedPool \\_pool) external {\\n    require(address(pool) == address(0), \"BalancerLBPSwapper: initialized\");\\n\\n    pool = \\_pool;\\n    IVault \\_vault = \\_pool.getVault();\\n\\n    vault = \\_vault;\\n\\n    // Check ownership\\n    require(\\_pool.getOwner() == address(this), \"BalancerLBPSwapper: contract not pool owner\");\\n```\\n\\n```\\nIERC20(tokenSpent).approve(address(\\_vault), type(uint256).max);\\nIERC20(tokenReceived).approve(address(\\_vault), type(uint256).max);\\n```\\nчprotect `BalancerLBPSwapper.init()` and only allow a trusted entity (e.g. the initial deployer) to call this method.чч```\\nfunction init(IWeightedPool \\_pool) external {\\n    require(address(pool) == address(0), \"BalancerLBPSwapper: initialized\");\\n\\n    pool = \\_pool;\\n    IVault \\_vault = \\_pool.getVault();\\n\\n    vault = \\_vault;\\n\\n    // Check ownership\\n    require(\\_pool.getOwner() == address(this), \"BalancerLBPSwapper: contract not pool owner\");\\n```\\n
PCVEquityMinter and BalancerLBPSwapper - desynchronisation raceчmediumчThere is nothing that prevents other actors from calling `BalancerLBPSwapper.swap()` `afterTime` but right before `PCVEquityMinter.mint()` would as long as the `minAmount` required for the call to pass is deposited to `BalancerLBPSwapper`.\\nBoth the `PCVEquityMinter.mint()` and `BalancerLBPSwapper.swap()` are timed (via the `afterTime` modifier) and are ideally in sync. In an ideal world the incentive to call `mint()` would be enough to ensure that both contracts are always in sync, however, a malicious actor might interfere by calling `.swap()` directly, providing the `minAmount` required for the call to pass. This will have two effects:\\ninstead of taking the newly minted FEI from `PCVEquityMinter`, existing FEI from the malicious user will be used with the pool. (instead of inflating the token the malicious actor basically pays for it)\\nthe `Timed` modifiers of both contracts will be out of sync with `BalancerLBPSwapper.swap()` being reset (and failing until it becomes available again) and `PCVEquityMinter.mint()` still being available. Furthermore, keeper-scripts (or actors that want to get the incentive) might continue to attempt to `mint()` while the call will ultimately fail in `.swap()` due to the resynchronization of `timed` (unless they simulate the calls first).\\nNote: There are not a lot of incentives to actually exploit this other than preventing protocol inflation (mint) and potentially griefing users. A malicious user will lose out on the incentivized call and has to ensure that the `minAmount` required for `.swap()` to work is available. It is, however, in the best interest of security to defuse the unpredictable racy character of the contract interaction.\\n```\\nfunction \\_afterMint() internal override {\\n    IPCVSwapper(target).swap();\\n}\\n```\\n\\n```\\nfunction swap() external override afterTime whenNotPaused {\\n    (\\n        uint256 spentReserves,\\n        uint256 receivedReserves, \\n        uint256 lastChangeBlock\\n    ) = getReserves();\\n\\n    // Ensures no actor can change the pool contents earlier in the block\\n    require(lastChangeBlock < block.number, \"BalancerLBPSwapper: pool changed this block\");\\n```\\nчIf `BalancerLBPSwapper.swap()` is only to be called within the flows of action from a `PCVEquityMinter.mint()` it is suggested to authenticate the call and only let `PCVEquityMinter` call `.swap()`чч```\\nfunction \\_afterMint() internal override {\\n    IPCVSwapper(target).swap();\\n}\\n```\\n
CollateralizationOracleWrapper - the deviation threshold check in update() always returns falseчmediumчA call to `update()` returns a boolean flag indicating whether the update was performed on outdated data. This flag is being checked in `updateIfOutdated()` which is typically called by an incentivized keeper function.\\nThe `_isExceededDeviationThreshold` calls at the end of the `_update()` function always return `false` as they are comparing the same values (cachedProtocolControlledValue to the `_protocolControlledValue` value and `cachedProtocolControlledValue` has just been set to `_protocolControlledValue` a couple of lines before). `_isExceededDeviationThreshold` will, therefore, never detect a deviation and return `false´.\\nThere may currently be no incentive (e.g. from the keeper side) to call `update()` if the values are not outdated but they deviated too much from the target. However, anyone can force an update by calling the non-incentivized public `update()` method instead.\\n```\\n    require(\\_validityStatus, \"CollateralizationOracleWrapper: CollateralizationOracle is invalid\");\\n\\n    // set cache variables\\n    cachedProtocolControlledValue = \\_protocolControlledValue;\\n    cachedUserCirculatingFei = \\_userCirculatingFei;\\n    cachedProtocolEquity = \\_protocolEquity;\\n\\n    // reset time\\n    \\_initTimed();\\n\\n    // emit event\\n    emit CachedValueUpdate(\\n        msg.sender,\\n        cachedProtocolControlledValue,\\n        cachedUserCirculatingFei,\\n        cachedProtocolEquity\\n    );\\n\\n    return outdated\\n        || \\_isExceededDeviationThreshold(cachedProtocolControlledValue, \\_protocolControlledValue)\\n        || \\_isExceededDeviationThreshold(cachedUserCirculatingFei, \\_userCirculatingFei);\\n}\\n```\\nчAdd unit tests to check for all three return conditions (timed, deviationA, deviationB)\\nMake sure to compare the current to the stored value before updating the cached values when calling `_isExceededDeviationThreshold`.чч```\\n    require(\\_validityStatus, \"CollateralizationOracleWrapper: CollateralizationOracle is invalid\");\\n\\n    // set cache variables\\n    cachedProtocolControlledValue = \\_protocolControlledValue;\\n    cachedUserCirculatingFei = \\_userCirculatingFei;\\n    cachedProtocolEquity = \\_protocolEquity;\\n\\n    // reset time\\n    \\_initTimed();\\n\\n    // emit event\\n    emit CachedValueUpdate(\\n        msg.sender,\\n        cachedProtocolControlledValue,\\n        cachedUserCirculatingFei,\\n        cachedProtocolEquity\\n    );\\n\\n    return outdated\\n        || \\_isExceededDeviationThreshold(cachedProtocolControlledValue, \\_protocolControlledValue)\\n        || \\_isExceededDeviationThreshold(cachedUserCirculatingFei, \\_userCirculatingFei);\\n}\\n```\\n
ChainlinkOracleWrapper - latestRoundData might return stale resultsчmediumчThe oracle wrapper calls out to a chainlink oracle receiving the `latestRoundData()`. It then checks freshness by verifying that the answer is indeed for the last known round. The returned `updatedAt` timestamp is not checked.\\nIf there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle (e.g. chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale data (if oracles are unable to submit no new round is started)\\n```\\n/// @notice read the oracle price\\n/// @return oracle price\\n/// @return true if price is valid\\nfunction read() external view override returns (Decimal.D256 memory, bool) {\\n    (uint80 roundId, int256 price,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();\\n    bool valid = !paused() && price > 0 && answeredInRound == roundId;\\n\\n    Decimal.D256 memory value = Decimal.from(uint256(price)).div(oracleDecimalsNormalizer);\\n    return (value, valid);\\n}\\n```\\n\\n```\\n/// @notice determine if read value is stale\\n/// @return true if read value is stale\\nfunction isOutdated() external view override returns (bool) {\\n    (uint80 roundId,,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();\\n    return answeredInRound != roundId;\\n}\\n```\\nчConsider checking the oracle responses `updatedAt` value after calling out to `chainlinkOracle.latestRoundData()` verifying that the result is within an allowed margin of freshness.чч```\\n/// @notice read the oracle price\\n/// @return oracle price\\n/// @return true if price is valid\\nfunction read() external view override returns (Decimal.D256 memory, bool) {\\n    (uint80 roundId, int256 price,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();\\n    bool valid = !paused() && price > 0 && answeredInRound == roundId;\\n\\n    Decimal.D256 memory value = Decimal.from(uint256(price)).div(oracleDecimalsNormalizer);\\n    return (value, valid);\\n}\\n```\\n
CollateralizationOracle - missing events and incomplete event informationчlowчThe `CollateralizationOracle.setDepositExclusion` function is used to exclude and re-include deposits from collateralization calculations. Unlike the other state-changing functions in this contract, it doesn't emit an event to inform about the exclusion or re-inclusion.\\n```\\nfunction setDepositExclusion(address \\_deposit, bool \\_excluded) external onlyGuardianOrGovernor {\\n    excludedDeposits[\\_deposit] = \\_excluded;\\n}\\n```\\n\\nThe `DepositAdd` event emits not only the deposit address but also the deposit's token. Despite the symmetry, the `DepositRemove` event does not emit the token.\\n```\\nevent DepositAdd(address from, address indexed deposit, address indexed token);\\nevent DepositRemove(address from, address indexed deposit);\\n```\\nч`setDepositInclusion` should emit an event that informs about the deposit and whether it was included or excluded.\\nFor symmetry reasons and because it is indeed useful information, the `DepositRemove` event could include the deposit's token.чч```\\nfunction setDepositExclusion(address \\_deposit, bool \\_excluded) external onlyGuardianOrGovernor {\\n    excludedDeposits[\\_deposit] = \\_excluded;\\n}\\n```\\n
RateLimited - Contract starts with a full buffer at deploymentчlowчA contract that inherits from `RateLimited` starts out with a full buffer when it is deployed.\\n```\\n\\_bufferStored = \\_bufferCap;\\n```\\n\\nThat means the full `bufferCap` is immediately available after deployment; it doesn't have to be built up over time. This behavior might be unexpected.чWe recommend starting with an empty buffer, or – if there are valid reasons for the current implementation – at least document it clearly.чч```\\n\\_bufferStored = \\_bufferCap;\\n```\\n
BalancerLBPSwapper - tokenSpent and tokenReceived should be immutableчlowчAcc. to the inline comment both `tokenSpent` and `tokenReceived` should be immutable but they are not declared as such.\\n```\\n// tokenSpent and tokenReceived are immutable\\ntokenSpent = \\_tokenSpent;\\ntokenReceived = \\_tokenReceived;\\n```\\n\\n```\\n/// @notice the token to be auctioned\\naddress public override tokenSpent;\\n\\n/// @notice the token to buy\\naddress public override tokenReceived;\\n```\\nчDeclare both variable `immutable`.чч```\\n// tokenSpent and tokenReceived are immutable\\ntokenSpent = \\_tokenSpent;\\ntokenReceived = \\_tokenReceived;\\n```\\n
CollateralizationOracle - potentially unsafe castsчlowч`protocolControlledValue` is the cumulative USD token value of all tokens in the PCV. The USD value is determined using external chainlink oracles. To mitigate some effects of attacks on chainlink to propagate to this protocol it is recommended to implement a defensive approach to handling values derived from the external source. Arithm. overflows are checked by the compiler (0.8.4), however, it does not guarantee safe casting from unsigned to signed integer. The scenario of this happening might be rather unlikely, however, there is no guarantee that the external price-feed is not taken over by malicious actors and this is when every line of defense counts.\\n```\\n//solidity 0.8.7\\n »  int(uint(2\\*\\*255))\\n-57896044618658097711785492504343953926634992332820282019728792003956564819968\\n »  int(uint(2\\*\\*255-2))\\n57896044618658097711785492504343953926634992332820282019728792003956564819966\\n```\\n\\n```\\nprotocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);\\n```\\n\\n```\\nprotocolControlledValue += \\_oraclePrice.mul(\\_totalTokenBalance).asUint256();\\n```\\nчPerform overflow checked SafeCast as another line of defense against oracle manipulation.чч```\\n//solidity 0.8.7\\n »  int(uint(2\\*\\*255))\\n-57896044618658097711785492504343953926634992332820282019728792003956564819968\\n »  int(uint(2\\*\\*255-2))\\n57896044618658097711785492504343953926634992332820282019728792003956564819966\\n```\\n
FeiTimedMinter - constructor does not enforce the same boundaries as setter for frequencyчlowчThe setter method for `frequency` enforced upper and lower bounds while the constructor does not. Users cannot trust that the `frequency` is actually set to be within bounds on deployment.\\n```\\nconstructor(\\n    address \\_core,\\n    address \\_target,\\n    uint256 \\_incentive,\\n    uint256 \\_frequency,\\n    uint256 \\_initialMintAmount\\n)\\n    CoreRef(\\_core)\\n    Timed(\\_frequency)\\n    Incentivized(\\_incentive)\\n    RateLimitedMinter((\\_initialMintAmount + \\_incentive) / \\_frequency, (\\_initialMintAmount + \\_incentive), true)\\n{\\n    \\_initTimed();\\n\\n    \\_setTarget(\\_target);\\n    \\_setMintAmount(\\_initialMintAmount);\\n}\\n```\\n\\n```\\nfunction setFrequency(uint256 newFrequency) external override onlyGovernorOrAdmin {\\n    require(newFrequency >= MIN\\_MINT\\_FREQUENCY, \"FeiTimedMinter: frequency low\");\\n    require(newFrequency <= MAX\\_MINT\\_FREQUENCY, \"FeiTimedMinter: frequency high\");\\n\\n    \\_setDuration(newFrequency);\\n}\\n```\\nчPerform the same checks on `frequency` in the constructor as in the `setFrequency` method.\\nThis contract is also inherited by a range of contracts that might specify different boundaries to what is hardcoded in the `FeiTimedMinter`. A way to enforce bounds-checks could be to allow overriding the setter method and using the setter in the constructor as well ensuring that bounds are also checked on deployment.чч```\\nconstructor(\\n    address \\_core,\\n    address \\_target,\\n    uint256 \\_incentive,\\n    uint256 \\_frequency,\\n    uint256 \\_initialMintAmount\\n)\\n    CoreRef(\\_core)\\n    Timed(\\_frequency)\\n    Incentivized(\\_incentive)\\n    RateLimitedMinter((\\_initialMintAmount + \\_incentive) / \\_frequency, (\\_initialMintAmount + \\_incentive), true)\\n{\\n    \\_initTimed();\\n\\n    \\_setTarget(\\_target);\\n    \\_setMintAmount(\\_initialMintAmount);\\n}\\n```\\n
CollateralizationOracle - swapDeposit should call internal functions to remove/add depositsчlowчInstead of calling `removeDeposit` and `addDeposit`, `swapDeposit` should call its internal sister functions `_removeDeposit` and `_addDeposit` to avoid running the `onlyGovernor` checks multiple times.\\n```\\n/// @notice Swap a PCVDeposit with a new one, for instance when a new version\\n/// of a deposit (holding the same token) is deployed.\\n/// @param \\_oldDeposit : the PCVDeposit to remove from the list.\\n/// @param \\_newDeposit : the PCVDeposit to add to the list.\\nfunction swapDeposit(address \\_oldDeposit, address \\_newDeposit) external onlyGovernor {\\n    removeDeposit(\\_oldDeposit);\\n    addDeposit(\\_newDeposit);\\n}\\n```\\nчCall the internal functions instead. addDeposit's and removeDeposit's visibility can then be changed from `public` to `external`.чч```\\n/// @notice Swap a PCVDeposit with a new one, for instance when a new version\\n/// of a deposit (holding the same token) is deployed.\\n/// @param \\_oldDeposit : the PCVDeposit to remove from the list.\\n/// @param \\_newDeposit : the PCVDeposit to add to the list.\\nfunction swapDeposit(address \\_oldDeposit, address \\_newDeposit) external onlyGovernor {\\n    removeDeposit(\\_oldDeposit);\\n    addDeposit(\\_newDeposit);\\n}\\n```\\n
CollateralizationOracle - misleading commentsчlowчAccording to an inline comment in `isOvercollateralized`, the validity status of `pcvStats` is ignored, while it is actually being checked.\\nSimilarly, a comment in `pcvStats` mentions that the returned `protocolEquity` is 0 if there is less PCV than circulating FEI, while in reality, `pcvStats` always returns the difference between the former and the latter, even if it is negative.\\n```\\n/// Controlled Value) than the circulating (user-owned) FEI, i.e.\\n/// a positive Protocol Equity.\\n/// Note: the validity status is ignored in this function.\\nfunction isOvercollateralized() external override view whenNotPaused returns (bool) {\\n    (,, int256 \\_protocolEquity, bool \\_valid) = pcvStats();\\n    require(\\_valid, \"CollateralizationOracle: reading is invalid\");\\n    return \\_protocolEquity > 0;\\n}\\n```\\n\\n```\\n/// @return protocolEquity : the difference between PCV and user circulating FEI.\\n/// If there are more circulating FEI than $ in the PCV, equity is 0.\\n```\\n\\n```\\nprotocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);\\n```\\nчRevise the comments.чч```\\n/// Controlled Value) than the circulating (user-owned) FEI, i.e.\\n/// a positive Protocol Equity.\\n/// Note: the validity status is ignored in this function.\\nfunction isOvercollateralized() external override view whenNotPaused returns (bool) {\\n    (,, int256 \\_protocolEquity, bool \\_valid) = pcvStats();\\n    require(\\_valid, \"CollateralizationOracle: reading is invalid\");\\n    return \\_protocolEquity > 0;\\n}\\n```\\n
The withdrawUnstakedTokens may run out of gasчhighчThe `withdrawUnstakedTokens` is iterating over all batches of unstaked tokens. One user, if unstaked many times, could get their tokens stuck in the contract.\\n```\\nfunction withdrawUnstakedTokens(address staker)\\n public\\n virtual\\n override\\n whenNotPaused\\n{\\n require(staker == \\_msgSender(), \"LQ20\");\\n uint256 \\_withdrawBalance;\\n uint256 \\_unstakingExpirationLength = \\_unstakingExpiration[staker]\\n  .length;\\n uint256 \\_counter = \\_withdrawCounters[staker];\\n for (\\n  uint256 i = \\_counter;\\n  i < \\_unstakingExpirationLength;\\n  i = i.add(1)\\n ) {\\n  //get getUnstakeTime and compare it with current timestamp to check if 21 days + epoch difference has passed\\n  (uint256 \\_getUnstakeTime, , ) = getUnstakeTime(\\n   \\_unstakingExpiration[staker][i]\\n  );\\n  if (block.timestamp >= \\_getUnstakeTime) {\\n   //if 21 days + epoch difference has passed, then add the balance and then mint uTokens\\n   \\_withdrawBalance = \\_withdrawBalance.add(\\n    \\_unstakingAmount[staker][i]\\n   );\\n   \\_unstakingExpiration[staker][i] = 0;\\n   \\_unstakingAmount[staker][i] = 0;\\n   \\_withdrawCounters[staker] = \\_withdrawCounters[staker].add(1);\\n  }\\n }\\n\\n require(\\_withdrawBalance > 0, \"LQ21\");\\n emit WithdrawUnstakeTokens(staker, \\_withdrawBalance, block.timestamp);\\n \\_uTokens.mint(staker, \\_withdrawBalance);\\n}\\n```\\nчResolution\\nComment from pSTAKE Finance team:\\nHave implemented a batchingLimit variable which enforces a definite number of iterations during withdrawal of unstaked tokens, instead of indefinite iterations.\\nLimit the number of processed unstaked batches, and possibly add pagination.чч```\\nfunction withdrawUnstakedTokens(address staker)\\n public\\n virtual\\n override\\n whenNotPaused\\n{\\n require(staker == \\_msgSender(), \"LQ20\");\\n uint256 \\_withdrawBalance;\\n uint256 \\_unstakingExpirationLength = \\_unstakingExpiration[staker]\\n  .length;\\n uint256 \\_counter = \\_withdrawCounters[staker];\\n for (\\n  uint256 i = \\_counter;\\n  i < \\_unstakingExpirationLength;\\n  i = i.add(1)\\n ) {\\n  //get getUnstakeTime and compare it with current timestamp to check if 21 days + epoch difference has passed\\n  (uint256 \\_getUnstakeTime, , ) = getUnstakeTime(\\n   \\_unstakingExpiration[staker][i]\\n  );\\n  if (block.timestamp >= \\_getUnstakeTime) {\\n   //if 21 days + epoch difference has passed, then add the balance and then mint uTokens\\n   \\_withdrawBalance = \\_withdrawBalance.add(\\n    \\_unstakingAmount[staker][i]\\n   );\\n   \\_unstakingExpiration[staker][i] = 0;\\n   \\_unstakingAmount[staker][i] = 0;\\n   \\_withdrawCounters[staker] = \\_withdrawCounters[staker].add(1);\\n  }\\n }\\n\\n require(\\_withdrawBalance > 0, \"LQ21\");\\n emit WithdrawUnstakeTokens(staker, \\_withdrawBalance, block.timestamp);\\n \\_uTokens.mint(staker, \\_withdrawBalance);\\n}\\n```\\n
The _calculatePendingRewards can run out of gasчmediumчThe reward rate in STokens can be changed, and the history of these changes are stored in the contract:\\n```\\nfunction setRewardRate(uint256 rewardRate)\\n public\\n virtual\\n override\\n returns (bool success)\\n{\\n // range checks for rewardRate. Since rewardRate cannot be more than 100%, the max cap\\n // is \\_valueDivisor \\* 100, which then brings the fees to 100 (percentage)\\n require(rewardRate <= \\_valueDivisor.mul(100), \"ST17\");\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"ST2\");\\n \\_rewardRate.push(rewardRate);\\n \\_lastMovingRewardTimestamp.push(block.timestamp);\\n emit SetRewardRate(rewardRate);\\n\\n return true;\\n}\\n```\\n\\nWhen the reward is calculated `for` each user, all changes of the `_rewardRate` are considered. So there is a `for` loop that iterates over all changes since the last reward update. If the reward rate was changed many times, the `_calculatePendingRewards` function could run out of gas.чProvide an option to partially update the reward, so the full update can be split in multiple transactions.чч```\\nfunction setRewardRate(uint256 rewardRate)\\n public\\n virtual\\n override\\n returns (bool success)\\n{\\n // range checks for rewardRate. Since rewardRate cannot be more than 100%, the max cap\\n // is \\_valueDivisor \\* 100, which then brings the fees to 100 (percentage)\\n require(rewardRate <= \\_valueDivisor.mul(100), \"ST17\");\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"ST2\");\\n \\_rewardRate.push(rewardRate);\\n \\_lastMovingRewardTimestamp.push(block.timestamp);\\n emit SetRewardRate(rewardRate);\\n\\n return true;\\n}\\n```\\n
The calculateRewards should not be callable by the whitelisted contractчmediumчThe `calculateRewards` function should only be called for non-whitelisted addresses:\\n```\\nfunction calculateRewards(address to)\\n public\\n virtual\\n override\\n whenNotPaused\\n returns (bool success)\\n{\\n require(to == \\_msgSender(), \"ST5\");\\n uint256 reward = \\_calculateRewards(to);\\n emit TriggeredCalculateRewards(to, reward, block.timestamp);\\n return true;\\n}\\n```\\n\\nFor all the whitelisted addresses, the `calculateHolderRewards` function is called. But if the `calculateRewards` function is called by the whitelisted address directly, the function will execute, and the rewards will be distributed to the caller instead of the intended recipients.чResolution\\nComment from pSTAKE Finance team:\\nHave created a require condition in Smart Contract code to disallow whitelisted contracts from calling the function\\nWhile this scenario is unlikely to happen, adding the additional check in the `calculateRewards` is a good option.чч```\\nfunction calculateRewards(address to)\\n public\\n virtual\\n override\\n whenNotPaused\\n returns (bool success)\\n{\\n require(to == \\_msgSender(), \"ST5\");\\n uint256 reward = \\_calculateRewards(to);\\n emit TriggeredCalculateRewards(to, reward, block.timestamp);\\n return true;\\n}\\n```\\n
Presence of testnet codeчmediumчBased on the discussions with pStake team and in-line comments, there are a few instances of code and commented code in the code base under audit that are not finalized for mainnet deployment.\\n```\\nfunction initialize(address pauserAddress) public virtual initializer {\\n \\_\\_ERC20\\_init(\"pSTAKE Token\", \"PSTAKE\");\\n \\_\\_AccessControl\\_init();\\n \\_\\_Pausable\\_init();\\n \\_setupRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender());\\n \\_setupRole(PAUSER\\_ROLE, pauserAddress);\\n // PSTAKE IS A SIMPLE ERC20 TOKEN HENCE 18 DECIMAL PLACES\\n \\_setupDecimals(18);\\n // pre-allocate some tokens to an admin address which will air drop PSTAKE tokens\\n // to each of holder contracts. This is only for testnet purpose. in Mainnet, we\\n // will use a vesting contract to allocate tokens to admin in a certain schedule\\n \\_mint(\\_msgSender(), 5000000000000000000000000);\\n}\\n```\\n\\nThe initialize function currently mints all the tokens to msg.sender, however the goal for mainnet is to use a vesting contract which is not present in the current code.чIt is recommended to fully test the final code before deployment to the mainnet.чч```\\nfunction initialize(address pauserAddress) public virtual initializer {\\n \\_\\_ERC20\\_init(\"pSTAKE Token\", \"PSTAKE\");\\n \\_\\_AccessControl\\_init();\\n \\_\\_Pausable\\_init();\\n \\_setupRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender());\\n \\_setupRole(PAUSER\\_ROLE, pauserAddress);\\n // PSTAKE IS A SIMPLE ERC20 TOKEN HENCE 18 DECIMAL PLACES\\n \\_setupDecimals(18);\\n // pre-allocate some tokens to an admin address which will air drop PSTAKE tokens\\n // to each of holder contracts. This is only for testnet purpose. in Mainnet, we\\n // will use a vesting contract to allocate tokens to admin in a certain schedule\\n \\_mint(\\_msgSender(), 5000000000000000000000000);\\n}\\n```\\n
Sanity check on all important variablesчlowчMost of the functionalities have proper sanity checks when it comes to setting system-wide variables, such as whitelist addresses. However there are a few key setters that lack such sanity checks.\\nSanity check (!= address(0)) on all token contracts.\\n```\\nfunction setUTokensContract(address uAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP9\");\\n \\_uTokens = IUTokens(uAddress);\\n emit SetUTokensContract(uAddress);\\n}\\n\\n/\\*\\*\\n \\* @dev Set 'contract address', called from constructor\\n \\* @param sAddress: stoken contract address\\n \\*\\n \\* Emits a {SetSTokensContract} event with '\\_contract' set to the stoken contract address.\\n \\*\\n \\*/\\nfunction setSTokensContract(address sAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP10\");\\n \\_sTokens = ISTokens(sAddress);\\n emit SetSTokensContract(sAddress);\\n}\\n\\n/\\*\\*\\n \\* @dev Set 'contract address', called from constructor\\n \\* @param pstakeAddress: pStake contract address\\n \\*\\n \\* Emits a {SetPSTAKEContract} event with '\\_contract' set to the stoken contract address.\\n \\*\\n \\*/\\nfunction setPSTAKEContract(address pstakeAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP11\");\\n \\_pstakeTokens = IPSTAKE(pstakeAddress);\\n emit SetPSTAKEContract(pstakeAddress);\\n}\\n```\\n\\nSanity check on `unstakingLockTime` to be in the acceptable range (21 hours to 21 days)\\n```\\n/\\*\\*\\n \\* @dev Set 'unstake props', called from admin\\n \\* @param unstakingLockTime: varies from 21 hours to 21 days\\n \\*\\n \\* Emits a {SetUnstakeProps} event with 'fee' set to the stake and unstake.\\n \\*\\n \\*/\\nfunction setUnstakingLockTime(uint256 unstakingLockTime)\\n public\\n virtual\\n returns (bool success)\\n{\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LQ3\");\\n \\_unstakingLockTime = unstakingLockTime;\\n emit SetUnstakingLockTime(unstakingLockTime);\\n return true;\\n}\\n```\\nчResolution\\nComment from pSTAKE Finance team:\\nPost the implementation of new emission logic there have been a rearrangement of some variables, but the rest have been sanity tested and correctedчч```\\nfunction setUTokensContract(address uAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP9\");\\n \\_uTokens = IUTokens(uAddress);\\n emit SetUTokensContract(uAddress);\\n}\\n\\n/\\*\\*\\n \\* @dev Set 'contract address', called from constructor\\n \\* @param sAddress: stoken contract address\\n \\*\\n \\* Emits a {SetSTokensContract} event with '\\_contract' set to the stoken contract address.\\n \\*\\n \\*/\\nfunction setSTokensContract(address sAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP10\");\\n \\_sTokens = ISTokens(sAddress);\\n emit SetSTokensContract(sAddress);\\n}\\n\\n/\\*\\*\\n \\* @dev Set 'contract address', called from constructor\\n \\* @param pstakeAddress: pStake contract address\\n \\*\\n \\* Emits a {SetPSTAKEContract} event with '\\_contract' set to the stoken contract address.\\n \\*\\n \\*/\\nfunction setPSTAKEContract(address pstakeAddress) public virtual override {\\n require(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"LP11\");\\n \\_pstakeTokens = IPSTAKE(pstakeAddress);\\n emit SetPSTAKEContract(pstakeAddress);\\n}\\n```\\n
TransactionManager - Receiver-side check also on sending sideчhighчThe functions `prepare`, `cancel`, and `fulfill` in the `TransactionManager` all have a “common part” that is executed on both the sending and the receiving chain and side-specific parts that are only executed either on the sending or on the receiving side.\\nThe following lines occur in fulfill's common part, but this should only be checked on the receiving chain. In fact, on the sending chain, we might even compare amounts of different assets.\\n```\\n// Sanity check: fee <= amount. Allow `=` in case of only wanting to execute\\n// 0-value crosschain tx, so only providing the fee amount\\nrequire(relayerFee <= txData.amount, \"#F:023\");\\n```\\n\\nThis could prevent a legitimate `fulfill` on the sending chain, causing a loss of funds for the router.чResolution\\nThe Connext team claims to have fixed this in commit `4adbfd52703441ee5de655130fc2e0252eae4661`. We have not reviewed this commit or, generally, the codebase at this point.\\nMove these lines to the receiving-side part.\\nRemark\\nThe `callData` supplied to `fulfill` is not used at all on the sending chain, but the check whether its hash matches `txData.callDataHash` happens in the common part.\\n```\\n// Check provided callData matches stored hash\\nrequire(keccak256(callData) == txData.callDataHash, \"#F:024\");\\n```\\n\\nIn principle, this check could also be moved to the receiving-chain part, allowing the router to save some gas by calling sending-side `fulfill` with empty `callData` and skip the check. Note, however, that the `TransactionFulfilled` event will then also emit the “wrong” `callData` on the sending chain, so the off-chain code has to be able to deal with that if you want to employ this optimization.чч```\\n// Sanity check: fee <= amount. Allow `=` in case of only wanting to execute\\n// 0-value crosschain tx, so only providing the fee amount\\nrequire(relayerFee <= txData.amount, \"#F:023\");\\n```\\n
TransactionManager - Missing nonReentrant modifier on removeLiquidityчmediumчResolution\\nThis issue has been fixed.\\nThe `removeLiquidity` function does not have a `nonReentrant` modifier.\\n```\\n/\\*\\*\\n \\* @notice This is used by any router to decrease their available\\n \\* liquidity for a given asset.\\n \\* @param shares The amount of liquidity to remove for the router in shares\\n \\* @param assetId The address (or `address(0)` if native asset) of the\\n \\* asset you're removing liquidity for\\n \\* @param recipient The address that will receive the liquidity being removed\\n \\*/\\nfunction removeLiquidity(\\n  uint256 shares,\\n  address assetId,\\n  address payable recipient\\n) external override {\\n  // Sanity check: recipient is sensible\\n  require(recipient != address(0), \"#RL:007\");\\n\\n  // Sanity check: nonzero shares\\n  require(shares > 0, \"#RL:035\");\\n\\n  // Get stored router shares\\n  uint256 routerShares = issuedShares[msg.sender][assetId];\\n\\n  // Get stored outstanding shares\\n  uint256 outstanding = outstandingShares[assetId];\\n\\n  // Sanity check: owns enough shares\\n  require(routerShares >= shares, \"#RL:018\");\\n\\n  // Convert shares to amount\\n  uint256 amount = getAmountFromIssuedShares(\\n    shares,\\n    outstanding,\\n    Asset.getOwnBalance(assetId)\\n  );\\n\\n  // Update router issued shares\\n  // NOTE: unchecked due to require above\\n  unchecked {\\n    issuedShares[msg.sender][assetId] = routerShares - shares;\\n  }\\n\\n  // Update the total shares for asset\\n  outstandingShares[assetId] = outstanding - shares;\\n\\n  // Transfer from contract to specified recipient\\n  Asset.transferAsset(assetId, recipient, amount);\\n\\n  // Emit event\\n  emit LiquidityRemoved(\\n    msg.sender,\\n    assetId,\\n    shares,\\n    amount,\\n    recipient\\n  );\\n}\\n```\\n\\nAssuming we're dealing with a token contract that allows execution of third-party-supplied code, that means it is possible to leave the `TransactionManager` contract in one of the functions that call into the token contract and then reenter via `removeLiquidity`. Alternatively, we can leave the contract in `removeLiquidity` and reenter through an arbitrary external function, even if it has a `nonReentrant` modifier.\\nExample\\nAssume a token contract allows the execution of third-party-supplied code in its `transfer` function before the actual balance change takes place. If a router calls `removeLiquidity` with half of their shares and then, in a reentering `removeLiquidity` call, supplies the other half of their shares, they will receive more tokens than if they had liquidated all their shares at once because the reentering call occurs after the (first half of the) shares have been burnt but before the corresponding amount of tokens has actually been transferred out of the contract, leading to an artificially increased share value in the reentering call. Similarly, reentering the contract with a `fulfill` call on the receiving chain instead of a second `removeLiquidity` would `transfer` too many tokens to the recipient due to the artificially inflated share value.чWhile tokens that behave as described in the example might be rare or not exist at all, caution is advised when integrating with unknown tokens or calling untrusted code in general. We strongly recommend adding a `nonReentrant` modifier to `removeLiquidity`.чч```\\n/\\*\\*\\n \\* @notice This is used by any router to decrease their available\\n \\* liquidity for a given asset.\\n \\* @param shares The amount of liquidity to remove for the router in shares\\n \\* @param assetId The address (or `address(0)` if native asset) of the\\n \\* asset you're removing liquidity for\\n \\* @param recipient The address that will receive the liquidity being removed\\n \\*/\\nfunction removeLiquidity(\\n  uint256 shares,\\n  address assetId,\\n  address payable recipient\\n) external override {\\n  // Sanity check: recipient is sensible\\n  require(recipient != address(0), \"#RL:007\");\\n\\n  // Sanity check: nonzero shares\\n  require(shares > 0, \"#RL:035\");\\n\\n  // Get stored router shares\\n  uint256 routerShares = issuedShares[msg.sender][assetId];\\n\\n  // Get stored outstanding shares\\n  uint256 outstanding = outstandingShares[assetId];\\n\\n  // Sanity check: owns enough shares\\n  require(routerShares >= shares, \"#RL:018\");\\n\\n  // Convert shares to amount\\n  uint256 amount = getAmountFromIssuedShares(\\n    shares,\\n    outstanding,\\n    Asset.getOwnBalance(assetId)\\n  );\\n\\n  // Update router issued shares\\n  // NOTE: unchecked due to require above\\n  unchecked {\\n    issuedShares[msg.sender][assetId] = routerShares - shares;\\n  }\\n\\n  // Update the total shares for asset\\n  outstandingShares[assetId] = outstanding - shares;\\n\\n  // Transfer from contract to specified recipient\\n  Asset.transferAsset(assetId, recipient, amount);\\n\\n  // Emit event\\n  emit LiquidityRemoved(\\n    msg.sender,\\n    assetId,\\n    shares,\\n    amount,\\n    recipient\\n  );\\n}\\n```\\n
TransactionManager - Relayer may use user's cancel after expiry signature to steal user's funds by colluding with a router  AcknowledgedчmediumчUsers that are willing to have a lower trust dependency on a relayer should have the ability to opt-in only for the service that allows the relayer to withdraw back users' funds from the sending chain after expiry. However, in practice, a user is forced to opt-in for the service that refunds the router before the expiry, since the same signature is used for both services (lines 795,817 use the same signature).\\nLet's consider the case of a user willing to call `fulfill` on his own, but to use the relayer only to withdraw back his funds from the sending chain after expiry. In this case, the relayer can collude with the router and use the user's `cancel` signature (meant for withdrawing his only after expiry) as a front-running transaction for a user call to `fulfill`. This way the router will be able to withdraw both his funds and the user's funds since the user's `fulfill` signature is now public data residing in the mem-pool.\\n```\\n      require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\\n\\n      Asset.transferAsset(txData.sendingAssetId, payable(msg.sender), relayerFee);\\n    }\\n\\n    // Get the amount to refund the user\\n    uint256 toRefund;\\n    unchecked {\\n      toRefund = amount - relayerFee;\\n    }\\n\\n    // Return locked funds to sending chain fallback\\n    if (toRefund > 0) {\\n      Asset.transferAsset(txData.sendingAssetId, payable(txData.sendingChainFallback), toRefund);\\n    }\\n  }\\n\\n} else {\\n  // Receiver side, router liquidity is returned\\n  if (txData.expiry >= block.timestamp) {\\n    // Timeout has not expired and tx may only be cancelled by user\\n    // Validate signature\\n    require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\\n```\\nчThe crucial point here is that the user must never sign a “cancel” that could be used on the receiving chain while fulfillment on the sending chain is still a possibility.\\nOr, to put it differently: A user may only sign a “cancel” that is valid on the receiving chain after sending-chain expiry or if they never have and won't ever sign a “fulfill” (or at least won't sign until sending-chain expiry — but it is pointless to sign a “fulfill” after that, so “never” is a reasonable simplification).\\nOr, finally, a more symmetric perspective on this requirement: If a user has signed “fulfill”, they must not sign a receiving-chain-valid “cancel” until sending-chain expiry, and if they have signed a receiving-chain-valid “cancel”, they must not sign a “fulfill” (until sending-chain expiry).\\nIn this sense, “cancel” signatures that are valid on the receiving chain are dangerous, while sending-side cancellations are not. So the principle stated in the previous paragraph might be easier to follow with different signatures for sending- and receiving-chain cancellations.чч```\\n      require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\\n\\n      Asset.transferAsset(txData.sendingAssetId, payable(msg.sender), relayerFee);\\n    }\\n\\n    // Get the amount to refund the user\\n    uint256 toRefund;\\n    unchecked {\\n      toRefund = amount - relayerFee;\\n    }\\n\\n    // Return locked funds to sending chain fallback\\n    if (toRefund > 0) {\\n      Asset.transferAsset(txData.sendingAssetId, payable(txData.sendingChainFallback), toRefund);\\n    }\\n  }\\n\\n} else {\\n  // Receiver side, router liquidity is returned\\n  if (txData.expiry >= block.timestamp) {\\n    // Timeout has not expired and tx may only be cancelled by user\\n    // Validate signature\\n    require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\\n```\\n
ProposedOwnable - two-step ownership transfer should be confirmed by the new ownerчmediumчIn order to avoid losing control of the contract, the two-step ownership transfer should be confirmed by the new owner's address instead of the current owner.\\n`acceptProposedOwner` is restricted to `onlyOwner` while ownership should be accepted by the newOwner\\n```\\n/\\*\\*\\n \\* @notice Transfers ownership of the contract to a new account (`newOwner`).\\n \\* Can only be called by the current owner.\\n \\*/\\nfunction acceptProposedOwner() public virtual onlyOwner {\\n  require((block.timestamp - \\_proposedTimestamp) > \\_delay, \"#APO:030\");\\n  \\_setOwner(\\_proposed);\\n}\\n```\\n\\nmove `renounced()` to `ProposedOwnable` as this is where it logically belongs to\\n```\\nfunction renounced() public view override returns (bool) {\\n  return owner() == address(0);\\n}\\n```\\n\\n`onlyOwner` can directly access state-var `_owner` instead of spending more gas on calling `owner()`\\n```\\nmodifier onlyOwner() {\\n    require(owner() == msg.sender, \"#OO:029\");\\n    \\_;\\n}\\n```\\nчResolution\\nAll recommendations given below have been implemented. In addition to that, the privilege to manage assets and the privilege to manage routers can now be renounced separately.\\n`onlyOwner` can directly access `_owner` (gas optimization)\\nadd a method to explicitly renounce ownership of the contract\\nmove `TransactionManager.renounced()` to `ProposedOwnable` as this is where it logically belongs to\\nchange the access control for `acceptProposedOwner` from `onlyOwner` to `require(msg.sender == _proposed)` (new owner).чч```\\n/\\*\\*\\n \\* @notice Transfers ownership of the contract to a new account (`newOwner`).\\n \\* Can only be called by the current owner.\\n \\*/\\nfunction acceptProposedOwner() public virtual onlyOwner {\\n  require((block.timestamp - \\_proposedTimestamp) > \\_delay, \"#APO:030\");\\n  \\_setOwner(\\_proposed);\\n}\\n```\\n
FulfillInterpreter - Wrong order of actions in fallback handlingчlowчWhen a transaction with a `callTo` that is not `address(0)` is fulfilled, the funds to be withdrawn on the user's behalf are first transferred to the `FulfillInterpreter` instance that is associated with this `TransactionManager` instance. After that, `execute` is called on that interpreter instance, which, in turn, tries to make a call to `callTo`. If that call reverts or isn't made in the first place because `callTo` is not a contract address, the funds are transferred directly to the `receivingAddress` in the transaction (which becomes `fallbackAddress` in execute); otherwise, it's the called contract's task to transfer the previously approved funds from the interpreter.\\n```\\nbool isNative = LibAsset.isNativeAsset(assetId);\\nif (!isNative) {\\n  LibAsset.increaseERC20Allowance(assetId, callTo, amount);\\n}\\n\\n// Check if the callTo is a contract\\nbool success;\\nbytes memory returnData;\\nif (Address.isContract(callTo)) {\\n  // Try to execute the callData\\n  // the low level call will return `false` if its execution reverts\\n  (success, returnData) = callTo.call{value: isNative ? amount : 0}(callData);\\n}\\n\\n// Handle failure cases\\nif (!success) {\\n  // If it fails, transfer to fallback\\n  LibAsset.transferAsset(assetId, fallbackAddress, amount);\\n  // Decrease allowance\\n  if (!isNative) {\\n    LibAsset.decreaseERC20Allowance(assetId, callTo, amount);\\n  }\\n}\\n```\\n\\nFor the fallback scenario, i.e., the call isn't executed or fails, the funds are first transferred to `fallbackAddress`, and the previously increased allowance is decreased after that. If the token supports it, the recipient of the direct transfer could try to exploit that the approval hasn't been revoked yet, so the logically correct order is to decrease the allowance first and transfer the funds later. However, it should be noted that the `FulfillInterpreter` should, at any point in time, only hold the funds that are supposed to be transferred as part of the current transaction; if there are any excess funds, these are leftovers from a previous failure to withdraw everything that could have been withdrawn, so these can be considered up for grabs. Hence, this is only a minor issue.чWe recommend reversing the order of actions for the fallback case: Decrease the allowance first, and transfer later. Moreover, it would be better to increase the allowance only in case a call will actually be made, i.e., if `Address.isContract(callTo)` is `true`.\\nRemark\\nThis issue was already present in the original version of the code but was missed initially and only found during the re-audit.чч```\\nbool isNative = LibAsset.isNativeAsset(assetId);\\nif (!isNative) {\\n  LibAsset.increaseERC20Allowance(assetId, callTo, amount);\\n}\\n\\n// Check if the callTo is a contract\\nbool success;\\nbytes memory returnData;\\nif (Address.isContract(callTo)) {\\n  // Try to execute the callData\\n  // the low level call will return `false` if its execution reverts\\n  (success, returnData) = callTo.call{value: isNative ? amount : 0}(callData);\\n}\\n\\n// Handle failure cases\\nif (!success) {\\n  // If it fails, transfer to fallback\\n  LibAsset.transferAsset(assetId, fallbackAddress, amount);\\n  // Decrease allowance\\n  if (!isNative) {\\n    LibAsset.decreaseERC20Allowance(assetId, callTo, amount);\\n  }\\n}\\n```\\n
FulfillInterpreter - Missing check whether callTo address contains codeчlowчResolution\\nThis issue has been fixed.\\nThe receiver-side `prepare` checks whether the `callTo` address is either zero or a contract:\\n```\\n// Check that the callTo is a contract\\n// NOTE: This cannot happen on the sending chain (different chain\\n// contexts), so a user could mistakenly create a transfer that must be\\n// cancelled if this is incorrect\\nrequire(invariantData.callTo == address(0) || Address.isContract(invariantData.callTo), \"#P:031\");\\n```\\n\\nHowever, as a contract may `selfdestruct` and the check is not repeated later, there is no guarantee that `callTo` still contains code when the call to this address (assuming it is non-zero) is actually executed in FulfillInterpreter.execute:\\n```\\n// Try to execute the callData\\n// the low level call will return `false` if its execution reverts\\n(bool success, bytes memory returnData) = callTo.call{value: isEther ? amount : 0}(callData);\\n\\nif (!success) {\\n  // If it fails, transfer to fallback\\n  Asset.transferAsset(assetId, fallbackAddress, amount);\\n  // Decrease allowance\\n  if (!isEther) {\\n    Asset.decreaseERC20Allowance(assetId, callTo, amount);\\n  }\\n}\\n```\\n\\nAs a result, if the contract at `callTo` self-destructs between `prepare` and `fulfill` (both on the receiving chain), `success` will be `true`, and the funds will probably be lost to the user.\\nA user could currently try to avoid this by checking that the contract still exists before calling `fulfill` on the receiving chain, but even then, they might get front-run by `selfdestruct`, and the situation is even worse with a relayer, so this provides no reliable protection.чRepeat the `Address.isContract` check on `callTo` before making the external call in `FulfillInterpreter.execute` and send the funds to the `fallbackAddress` if the result is `false`.\\nIt is, perhaps, debatable whether the check in `prepare` should be kept or removed. In principle, if the contract gets deployed between `prepare` and `fulfill`, that is still soon enough. However, if the `callTo` address doesn't have code at the time of `prepare`, this seems more likely to be a mistake than a “late deployment”. So unless there is a demonstrated use case for “late deployments”, failing in `prepare` (even though it's receiver-side) might still be the better choice.\\nRemark\\nIt should be noted that an unsuccessful call, i.e., a revert, is the only behavior that is recognized by `FulfillInterpreter.execute` as failure. While it is prevalent to indicate failure by reverting, this doesn't have to be the case; a well-known example is an ERC20 token that indicates a failing transfer by returning `false`.\\nA user who wants to utilize this feature has to make sure that the called contract behaves accordingly; if that is not the case, an intermediary contract may be employed, which, for example, reverts for return value `false`.чч```\\n// Check that the callTo is a contract\\n// NOTE: This cannot happen on the sending chain (different chain\\n// contexts), so a user could mistakenly create a transfer that must be\\n// cancelled if this is incorrect\\nrequire(invariantData.callTo == address(0) || Address.isContract(invariantData.callTo), \"#P:031\");\\n```\\n
TransactionManager - Adherence to EIP-712  Won't Fixчlowч`fulfill` function requires the user signature on a `transactionId`. While currently, the user SDK code is using a cryptographically secured pseudo-random function to generate the `transactionId`, it should not be counted upon and measures should be placed on the smart-contract level to ensure replay-attack protection.\\n```\\nfunction recoverSignature(\\n  bytes32 transactionId,\\n  uint256 relayerFee,\\n  string memory functionIdentifier,\\n  bytes calldata signature\\n) internal pure returns (address) {\\n  // Create the signed payload\\n  SignedData memory payload = SignedData({\\n    transactionId: transactionId,\\n    relayerFee: relayerFee,\\n    functionIdentifier: functionIdentifier\\n  });\\n\\n  // Recover\\n  return ECDSA.recover(ECDSA.toEthSignedMessageHash(keccak256(abi.encode(payload))), signature);\\n}\\n```\\nчConsider adhering to EIP-712, or at least including `address(this), block.chainId` as part of the data signed by the user.чч```\\nfunction recoverSignature(\\n  bytes32 transactionId,\\n  uint256 relayerFee,\\n  string memory functionIdentifier,\\n  bytes calldata signature\\n) internal pure returns (address) {\\n  // Create the signed payload\\n  SignedData memory payload = SignedData({\\n    transactionId: transactionId,\\n    relayerFee: relayerFee,\\n    functionIdentifier: functionIdentifier\\n  });\\n\\n  // Recover\\n  return ECDSA.recover(ECDSA.toEthSignedMessageHash(keccak256(abi.encode(payload))), signature);\\n}\\n```\\n
TransactionManager - Hard-coded chain ID might lead to problems after a chain split  PendingчlowчThe ID of the chain on which the contract is deployed is supplied as a constructor argument and stored as an `immutable` state variable:\\n```\\n/\\*\\*\\n \\* @dev The chain id of the contract, is passed in to avoid any evm issues\\n \\*/\\nuint256 public immutable chainId;\\n```\\n\\n```\\nconstructor(uint256 \\_chainId) {\\n  chainId = \\_chainId;\\n  interpreter = new FulfillInterpreter(address(this));\\n}\\n```\\n\\nHence, `chainId` can never change, and even after a chain split, both contracts would continue to use the same chain ID. That can have undesirable consequences. For example, a transaction that was prepared before the split could be fulfilled on both chains.чIt would be better to query the chain ID directly from the chain via `block.chainId`. However, the development team informed us that they had encountered problems with this approach as some chains apparently are not implementing this correctly. They resorted to the method described above, a constructor-supplied, hard-coded value. For chains that do indeed not inform correctly about their chain ID, this is a reasonable solution. However, for the reasons outlined above, we still recommend querying the chain ID via `block.chainId` for chains that do support that — which should be the vast majority — and using the fallback mechanism only when necessary.чч```\\n/\\*\\*\\n \\* @dev The chain id of the contract, is passed in to avoid any evm issues\\n \\*/\\nuint256 public immutable chainId;\\n```\\n
TribalChief - A wrong user.rewardDebt value is calculated during the withdrawFromDeposit function callчhighчWhen withdrawing a single deposit, the reward debt is updated:\\n```\\nuint128 virtualAmountDelta = uint128( ( amount \\* poolDeposit.multiplier ) / SCALE\\_FACTOR );\\n\\n// Effects\\npoolDeposit.amount -= amount;\\nuser.rewardDebt = user.rewardDebt - toSigned128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\\nuser.virtualAmount -= virtualAmountDelta;\\npool.virtualTotalSupply -= virtualAmountDelta;\\n```\\n\\nInstead of the `user.virtualAmount` in reward debt calculation, the `virtualAmountDelta` should be used. Because of that bug, the reward debt is much lower than it would be, which means that the reward itself will be much larger during the harvest. By making multiple deposit-withdraw actions, any user can steal all the Tribe tokens from the contract.чUse the `virtualAmountDelta` instead of the `user.virtualAmount`.чч```\\nuint128 virtualAmountDelta = uint128( ( amount \\* poolDeposit.multiplier ) / SCALE\\_FACTOR );\\n\\n// Effects\\npoolDeposit.amount -= amount;\\nuser.rewardDebt = user.rewardDebt - toSigned128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\\nuser.virtualAmount -= virtualAmountDelta;\\npool.virtualTotalSupply -= virtualAmountDelta;\\n```\\n
TribalChief - Unlocking users' funds in a pool where a multiplier has been increased is missingчmediumчWhen a user deposits funds to a pool, the current multiplier in use for this pool is being stored locally for this deposit. The value that is used later in a withdrawal operation is the local one, and not the one that is changing when a `governor` calls `governorAddPoolMultiplier`. It means that a decrease in the multiplier value for a given pool does not affect users that already deposited, but an increase does. Users that had already deposited should have the right to withdraw their funds when the multiplier for their pool increases by the `governor`.\\n```\\nfunction governorAddPoolMultiplier(\\n    uint256 \\_pid,\\n    uint64 lockLength,\\n    uint64 newRewardsMultiplier\\n) external onlyGovernor {\\n    PoolInfo storage pool = poolInfo[\\_pid];\\n    uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\\n    // if the new multplier is less than the current multiplier,\\n    // then, you need to unlock the pool to allow users to withdraw\\n    if (newRewardsMultiplier < currentMultiplier) {\\n        pool.unlocked = true;\\n    }\\n    rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\\n\\n    emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\\n}\\n```\\nчReplace the `<` operator with `>` in `TribalChief` line 152.чч```\\nfunction governorAddPoolMultiplier(\\n    uint256 \\_pid,\\n    uint64 lockLength,\\n    uint64 newRewardsMultiplier\\n) external onlyGovernor {\\n    PoolInfo storage pool = poolInfo[\\_pid];\\n    uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\\n    // if the new multplier is less than the current multiplier,\\n    // then, you need to unlock the pool to allow users to withdraw\\n    if (newRewardsMultiplier < currentMultiplier) {\\n        pool.unlocked = true;\\n    }\\n    rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\\n\\n    emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\\n}\\n```\\n
TribalChief - Unsafe down-castingsчmediumч`TribalChief` consists of multiple unsafe down-casting operations. While the usage of types that can be packed into a single storage slot is more gas efficient, it may introduce hidden risks in some cases that can lead to loss of funds.\\nVarious instances in `TribalChief`, including (but not necessarily only) :\\n```\\nuser.rewardDebt = int128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\\n```\\n\\n```\\npool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward \\* ACC\\_TRIBE\\_PRECISION) / virtualSupply));\\n```\\n\\n```\\nuserPoolData.rewardDebt += int128(virtualAmountDelta \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\\n```\\nчGiven the time constraints of this audit engagement, we could not verify the implications and provide mitigation actions for each of the unsafe down-castings operations. However, we do recommend to either use numeric types that use 256 bits, or to add proper validation checks and handle these scenarios to avoid silent over/under-flow errors. Keep in mind that reverting these scenarios can sometimes lead to a denial of service, which might be harmful in some cases.чч```\\nuser.rewardDebt = int128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\\n```\\n
TribalChief - Governor decrease of pool's allocation point should unlock depositors' fundsчlowчWhen the `TribalChief` governor decreases the ratio between the allocation point (PoolInfo.allocPoint) and the total allocation point (totalAllocPoint) for a specific pool (either be directly decreasing `PoolInfo.allocPoint` of a given pool, or by increasing this value for other pools), the total reward for this pool is decreased as well. Depositors should be able to withdraw their funds immediately after this kind of change.\\n```\\nfunction set(uint256 \\_pid, uint128 \\_allocPoint, IRewarder \\_rewarder, bool overwrite) public onlyGovernor {\\n    totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint) + \\_allocPoint;\\n    poolInfo[\\_pid].allocPoint = \\_allocPoint.toUint64();\\n\\n    if (overwrite) {\\n        rewarder[\\_pid] = \\_rewarder;\\n    }\\n\\n    emit LogSetPool(\\_pid, \\_allocPoint, overwrite ? \\_rewarder : rewarder[\\_pid], overwrite);\\n}\\n```\\nчMake sure that depositors' funds are unlocked for pools that affected negatively by calling `TribalChief.set`.чч```\\nfunction set(uint256 \\_pid, uint128 \\_allocPoint, IRewarder \\_rewarder, bool overwrite) public onlyGovernor {\\n    totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint) + \\_allocPoint;\\n    poolInfo[\\_pid].allocPoint = \\_allocPoint.toUint64();\\n\\n    if (overwrite) {\\n        rewarder[\\_pid] = \\_rewarder;\\n    }\\n\\n    emit LogSetPool(\\_pid, \\_allocPoint, overwrite ? \\_rewarder : rewarder[\\_pid], overwrite);\\n}\\n```\\n
TribalChief - new block reward retrospectively takes effect on pools that have not been updated recentlyчlowчWhen the governor updates the block reward `tribalChiefTribePerBlock` the new reward is applied for the outstanding duration of blocks in `updatePool`. This means, if a pool hasn't updated in a while (unlikely) the new block reward is retrospectively applied to the pending duration instead of starting from when the block reward changed.\\nrewards calculation\\n```\\nif (virtualSupply > 0) {\\n    uint256 blocks = block.number - pool.lastRewardBlock;\\n    uint256 tribeReward = (blocks \\* tribePerBlock() \\* pool.allocPoint) / totalAllocPoint;\\n    pool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward \\* ACC\\_TRIBE\\_PRECISION) / virtualSupply));\\n}\\n```\\n\\nupdating the block reward\\n```\\n/// @notice Allows governor to change the amount of tribe per block\\n/// @param newBlockReward The new amount of tribe per block to distribute\\nfunction updateBlockReward(uint256 newBlockReward) external onlyGovernor {\\n    tribalChiefTribePerBlock = newBlockReward;\\n    emit NewTribePerBlock(newBlockReward);\\n}\\n```\\nчIt is recommended to update pools before changing the block reward. Document and make users aware that the new reward is applied to the outstanding duration when calling `updatePool`.чч```\\nif (virtualSupply > 0) {\\n    uint256 blocks = block.number - pool.lastRewardBlock;\\n    uint256 tribeReward = (blocks \\* tribePerBlock() \\* pool.allocPoint) / totalAllocPoint;\\n    pool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward \\* ACC\\_TRIBE\\_PRECISION) / virtualSupply));\\n}\\n```\\n
TribalChief - resetRewards should emit an eventчlowчThe method `resetRewards` silently resets a pools tribe allocation.\\n```\\n/// @notice Reset the given pool's TRIBE allocation to 0 and unlock the pool. Can only be called by the governor or guardian.\\n/// @param \\_pid The index of the pool. See `poolInfo`. \\nfunction resetRewards(uint256 \\_pid) public onlyGuardianOrGovernor {\\n    // set the pool's allocation points to zero\\n    totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint);\\n    poolInfo[\\_pid].allocPoint = 0;\\n   \\n    // unlock all staked tokens in the pool\\n    poolInfo[\\_pid].unlocked = true;\\n\\n    // erase any IRewarder mapping\\n    rewarder[\\_pid] = IRewarder(address(0));\\n}\\n```\\nчFor transparency and to create an easily accessible audit trail of events consider emitting an event when resetting a pools allocation.чч```\\n/// @notice Reset the given pool's TRIBE allocation to 0 and unlock the pool. Can only be called by the governor or guardian.\\n/// @param \\_pid The index of the pool. See `poolInfo`. \\nfunction resetRewards(uint256 \\_pid) public onlyGuardianOrGovernor {\\n    // set the pool's allocation points to zero\\n    totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint);\\n    poolInfo[\\_pid].allocPoint = 0;\\n   \\n    // unlock all staked tokens in the pool\\n    poolInfo[\\_pid].unlocked = true;\\n\\n    // erase any IRewarder mapping\\n    rewarder[\\_pid] = IRewarder(address(0));\\n}\\n```\\n
TribalChief - Unlocking users' funds in a pool where a multiplier has been increased is missingчmediumчWhen a user deposits funds to a pool, the current multiplier in use for this pool is being stored locally for this deposit. The value that is used later in a withdrawal operation is the local one, and not the one that is changing when a `governor` calls `governorAddPoolMultiplier`. It means that a decrease in the multiplier value for a given pool does not affect users that already deposited, but an increase does. Users that had already deposited should have the right to withdraw their funds when the multiplier for their pool increases by the `governor`.\\n```\\nfunction governorAddPoolMultiplier(\\n uint256 \\_pid,\\n uint64 lockLength,\\n uint64 newRewardsMultiplier\\n) external onlyGovernor {\\n PoolInfo storage pool = poolInfo[\\_pid];\\n uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\\n // if the new multplier is less than the current multiplier,\\n // then, you need to unlock the pool to allow users to withdraw\\n if (newRewardsMultiplier < currentMultiplier) {\\n pool.unlocked = true;\\n }\\n rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\\n\\n emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\\n}\\n```\\nчReplace the `<` operator with `>` in `TribalChief` line 152.чч```\\nfunction governorAddPoolMultiplier(\\n uint256 \\_pid,\\n uint64 lockLength,\\n uint64 newRewardsMultiplier\\n) external onlyGovernor {\\n PoolInfo storage pool = poolInfo[\\_pid];\\n uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\\n // if the new multplier is less than the current multiplier,\\n // then, you need to unlock the pool to allow users to withdraw\\n if (newRewardsMultiplier < currentMultiplier) {\\n pool.unlocked = true;\\n }\\n rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\\n\\n emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\\n}\\n```\\n
TribalChief - Governor decrease of pool's allocation point should unlock depositors' fundsчlowчWhen the `TribalChief` governor decreases the ratio between the allocation point (PoolInfo.allocPoint) and the total allocation point (totalAllocPoint) for a specific pool (either be directly decreasing `PoolInfo.allocPoint` of a given pool, or by increasing this value for other pools), the total reward for this pool is decreased as well. Depositors should be able to withdraw their funds immediately after this kind of change.\\n```\\nfunction set(uint256 \\_pid, uint128 \\_allocPoint, IRewarder \\_rewarder, bool overwrite) public onlyGovernor {\\n totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint) + \\_allocPoint;\\n poolInfo[\\_pid].allocPoint = \\_allocPoint.toUint64();\\n\\n if (overwrite) {\\n rewarder[\\_pid] = \\_rewarder;\\n }\\n\\n emit LogSetPool(\\_pid, \\_allocPoint, overwrite ? \\_rewarder : rewarder[\\_pid], overwrite);\\n}\\n```\\nчMake sure that depositors' funds are unlocked for pools that affected negatively by calling `TribalChief.set`.чч```\\nfunction set(uint256 \\_pid, uint128 \\_allocPoint, IRewarder \\_rewarder, bool overwrite) public onlyGovernor {\\n totalAllocPoint = (totalAllocPoint - poolInfo[\\_pid].allocPoint) + \\_allocPoint;\\n poolInfo[\\_pid].allocPoint = \\_allocPoint.toUint64();\\n\\n if (overwrite) {\\n rewarder[\\_pid] = \\_rewarder;\\n }\\n\\n emit LogSetPool(\\_pid, \\_allocPoint, overwrite ? \\_rewarder : rewarder[\\_pid], overwrite);\\n}\\n```\\n
IdleCDO._deposit() allows re-entrancy from hookable tokens.чmediumчThe function `IdleCDO._deposit()` updates the system's internal accounting and mints shares to the caller, then transfers the deposited funds from the user. Some token standards, such as ERC777, allow a callback to the source of the funds before the balances are updated in `transferFrom()`. This callback could be used to re-enter the protocol while already holding the minted tranche tokens and at a point where the system accounting reflects a receipt of funds that has not yet occurred.\\nWhile an attacker could not interact with `IdleCDO.withdraw()` within this callback because of the `_checkSameTx()` restriction, they would be able to interact with the rest of the protocol.\\n```\\nfunction \\_deposit(uint256 \\_amount, address \\_tranche) internal returns (uint256 \\_minted) {\\n  // check that we are not depositing more than the contract available limit\\n  \\_guarded(\\_amount);\\n  // set \\_lastCallerBlock hash\\n  \\_updateCallerBlock();\\n  // check if strategyPrice decreased\\n  \\_checkDefault();\\n  // interest accrued since last depositXX/withdrawXX/harvest is splitted between AA and BB\\n  // according to trancheAPRSplitRatio. NAVs of AA and BB are updated and tranche\\n  // prices adjusted accordingly\\n  \\_updateAccounting();\\n  // mint tranche tokens according to the current tranche price\\n  \\_minted = \\_mintShares(\\_amount, msg.sender, \\_tranche);\\n  // get underlyings from sender\\n  IERC20Detailed(token).safeTransferFrom(msg.sender, address(this), \\_amount);\\n}\\n```\\nчMove the `transferFrom()` action in `_deposit()` to immediately after `_updateCallerBlock()`.чч```\\nfunction \\_deposit(uint256 \\_amount, address \\_tranche) internal returns (uint256 \\_minted) {\\n  // check that we are not depositing more than the contract available limit\\n  \\_guarded(\\_amount);\\n  // set \\_lastCallerBlock hash\\n  \\_updateCallerBlock();\\n  // check if strategyPrice decreased\\n  \\_checkDefault();\\n  // interest accrued since last depositXX/withdrawXX/harvest is splitted between AA and BB\\n  // according to trancheAPRSplitRatio. NAVs of AA and BB are updated and tranche\\n  // prices adjusted accordingly\\n  \\_updateAccounting();\\n  // mint tranche tokens according to the current tranche price\\n  \\_minted = \\_mintShares(\\_amount, msg.sender, \\_tranche);\\n  // get underlyings from sender\\n  IERC20Detailed(token).safeTransferFrom(msg.sender, address(this), \\_amount);\\n}\\n```\\n
IdleCDO.virtualPrice() and _updatePrices() yield different prices in a number of casesчmediumчThe function `IdleCDO.virtualPrice()` is used to determine the current price of a tranche. Similarly, `IdleCDO._updatePrices()` is used to store the latest price of a tranche, as well as update other parts of the system accounting. There are a number of cases where the prices yielded by these two functions differ. While these are primarily corner cases that are not obviously exploitable in practice, potential violations of key accounting invariants should always be considered serious.\\nAdditionally, the use of two separate implementations of the same calculation suggest the potential for more undiscovered discrepancies, possibly of higher consequence.\\nAs an example, in `_updatePrices()` the precision loss from splitting the strategy returns favors BB tranche holders. In `virtualPrice()` both branches of the price calculation incur precision loss, favoring the `IdleCDO` contract itself.\\n`_updatePrices()`\\n```\\nif (BBTotSupply == 0) {\\n  // if there are no BB holders, all gain to AA\\n  AAGain = gain;\\n} else if (AATotSupply == 0) {\\n  // if there are no AA holders, all gain to BB\\n  BBGain = gain;\\n} else {\\n  // split the gain between AA and BB holders according to trancheAPRSplitRatio\\n  AAGain = gain \\* trancheAPRSplitRatio / FULL\\_ALLOC;\\n  BBGain = gain - AAGain;\\n}\\n```\\n\\n`virtualPrice()`\\n```\\nif (\\_tranche == AATranche) {\\n  // calculate gain for AA tranche\\n  // trancheGain (AAGain) = gain \\* trancheAPRSplitRatio / FULL\\_ALLOC;\\n  trancheNAV = lastNAVAA + (gain \\* \\_trancheAPRSplitRatio / FULL\\_ALLOC);\\n} else {\\n  // calculate gain for BB tranche\\n  // trancheGain (BBGain) = gain \\* (FULL\\_ALLOC - trancheAPRSplitRatio) / FULL\\_ALLOC;\\n  trancheNAV = lastNAVBB + (gain \\* (FULL\\_ALLOC - \\_trancheAPRSplitRatio) / FULL\\_ALLOC);\\n}\\n```\\nчImplement a single method that determines the current price for a tranche, and use this same implementation anywhere the price is needed.чч```\\nif (BBTotSupply == 0) {\\n  // if there are no BB holders, all gain to AA\\n  AAGain = gain;\\n} else if (AATotSupply == 0) {\\n  // if there are no AA holders, all gain to BB\\n  BBGain = gain;\\n} else {\\n  // split the gain between AA and BB holders according to trancheAPRSplitRatio\\n  AAGain = gain \\* trancheAPRSplitRatio / FULL\\_ALLOC;\\n  BBGain = gain - AAGain;\\n}\\n```\\n
IdleCDO.harvest() allows price manipulation in certain circumstancesчmediumчThe function `IdleCDO.harvest()` uses Uniswap to liquidate rewards earned by the contract's strategy, then updates the relevant positions and internal accounting. This function can only be called by the contract `owner` or the designated `rebalancer` address, and it accepts an array which indicates the minimum buy amounts for the liquidation of each reward token.\\nThe purpose of permissioning this method and specifying minimum buy amounts is to prevent a sandwiching attack from manipulating the reserves of the Uniswap pools and forcing the `IdleCDO` contract to incur loss due to price slippage.\\nHowever, this does not effectively prevent price manipulation in all cases. Because the contract sells it's entire balance of redeemed rewards for the specified minimum buy amount, this approach does not enforce a minimum price for the executed trades. If the balance of `IdleCDO` or the amount of claimable rewards increases between the submission of the `harvest()` transaction and its execution, it may be possible to perform a profitable sandwiching attack while still satisfying the required minimum buy amounts.\\nThe viability of this exploit depends on how effectively an attacker can increase the amount of rewards tokens to be sold without incurring an offsetting loss. The strategy contracts used by `IdleCDO` are expected to vary widely in their implementations, and this manipulation could potentially be done either through direct interaction with the protocol or as part of a flashbots bundle containing a large position adjustment from an honest user.\\n```\\nfunction harvest(bool \\_skipRedeem, bool \\_skipIncentivesUpdate, bool[] calldata \\_skipReward, uint256[] calldata \\_minAmount) external {\\n  require(msg.sender == rebalancer || msg.sender == owner(), \"IDLE:!AUTH\");\\n```\\n\\n```\\n// approve the uniswap router to spend our reward\\nIERC20Detailed(rewardToken).safeIncreaseAllowance(address(\\_uniRouter), \\_currentBalance);\\n// do the uniswap trade\\n\\_uniRouter.swapExactTokensForTokensSupportingFeeOnTransferTokens(\\n  \\_currentBalance,\\n  \\_minAmount[i],\\n  \\_path,\\n  address(this),\\n  block.timestamp + 1\\n);\\n```\\nчUpdate `IdleCDO.harvest()` to enforce a minimum price rather than a minimum buy amount. One method of doing so would be taking an additional array parameter indicating the amount of each token to sell in exchange for the respective buy amount.чч```\\nfunction harvest(bool \\_skipRedeem, bool \\_skipIncentivesUpdate, bool[] calldata \\_skipReward, uint256[] calldata \\_minAmount) external {\\n  require(msg.sender == rebalancer || msg.sender == owner(), \"IDLE:!AUTH\");\\n```\\n
Missing Sanity checksчlowчThe implementation of `initialize()` functions are missing some sanity checks. The proper checks are implemented in some of the setter functions but missing in some others.\\nMissing sanity check for `!= address(0)`\\n```\\ntoken = \\_guardedToken;\\nstrategy = \\_strategy;\\nstrategyToken = IIdleCDOStrategy(\\_strategy).strategyToken();\\nrebalancer = \\_rebalancer;\\n```\\n\\n```\\nguardian = \\_owner;\\n```\\n\\n```\\naddress \\_currAAStaking = AAStaking;\\naddress \\_currBBStaking = BBStaking;\\n```\\n\\n```\\nidleCDO = \\_idleCDO;\\ntranche = \\_trancheToken;\\nrewards = \\_rewards;\\ngovernanceRecoveryFund = \\_governanceRecoveryFund;\\n```\\nчResolution\\nThe development team has addressed this concern in commit `a1d5dac0ad5f562d4c75bff99e770d92bcc2a72f`. This change has not been reviewed by the audit team.\\nAdd sanity checks before assigning system variables.чч```\\ntoken = \\_guardedToken;\\nstrategy = \\_strategy;\\nstrategyToken = IIdleCDOStrategy(\\_strategy).strategyToken();\\nrebalancer = \\_rebalancer;\\n```\\n
Frontrunning attacks by the ownerчhighчThere are few possible attack vectors by the owner:\\nAll strategies have fees from rewards. In addition to that, the PancakeSwap strategy has deposit fees. The default deposit fees equal zero; the maximum is limited to 5%:\\n```\\nuint256 constant MAXIMUM\\_DEPOSIT\\_FEE = 5e16; // 5%\\nuint256 constant DEFAULT\\_DEPOSIT\\_FEE = 0e16; // 0%\\n  \\nuint256 constant MAXIMUM\\_PERFORMANCE\\_FEE = 50e16; // 50%\\nuint256 constant DEFAULT\\_PERFORMANCE\\_FEE = 10e16; // 10%\\n```\\n\\nWhen a user deposits tokens, expecting to have zero deposit fees, the `owner` can frontrun the deposit and increase fees to 5%. If the deposit size is big enough, that may be a significant amount of money. 2. In the `gulp` function, the reward tokens are exchanged for the reserve tokens on the exchange:\\n```\\nfunction gulp(uint256 \\_minRewardAmount) external onlyEOAorWhitelist nonReentrant\\n{\\n  uint256 \\_pendingReward = \\_getPendingReward();\\n  if (\\_pendingReward > 0) {\\n      \\_withdraw(0);\\n  }\\n  {\\n      uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\\n      uint256 \\_feeReward = \\_totalReward.mul(performanceFee) / 1e18;\\n      Transfers.\\_pushFunds(rewardToken, collector, \\_feeReward);\\n  }\\n  if (rewardToken != routingToken) {\\n      require(exchange != address(0), \"exchange not set\");\\n      uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\\n      Transfers.\\_approveFunds(rewardToken, exchange, \\_totalReward);\\n      IExchange(exchange).convertFundsFromInput(rewardToken, routingToken, \\_totalReward, 1);\\n  }\\n  if (routingToken != reserveToken) {\\n      require(exchange != address(0), \"exchange not set\");\\n      uint256 \\_totalRouting = Transfers.\\_getBalance(routingToken);\\n      Transfers.\\_approveFunds(routingToken, exchange, \\_totalRouting);\\n      IExchange(exchange).joinPoolFromInput(reserveToken, routingToken, \\_totalRouting, 1);\\n  }\\n  uint256 \\_totalBalance = Transfers.\\_getBalance(reserveToken);\\n  require(\\_totalBalance >= \\_minRewardAmount, \"high slippage\");\\n  \\_deposit(\\_totalBalance);\\n}\\n```\\n\\nThe `owner` can change the `exchange` parameter to the malicious address that steals tokens. The `owner` then calls `gulp` with `_minRewardAmount==0`, and all the rewards will be stolen. The same attack can be implemented in fee collectors and the buyback contract.чResolution\\nThe client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b.\\nUse a timelock to avoid instant changes of the parameters.чч```\\nuint256 constant MAXIMUM\\_DEPOSIT\\_FEE = 5e16; // 5%\\nuint256 constant DEFAULT\\_DEPOSIT\\_FEE = 0e16; // 0%\\n  \\nuint256 constant MAXIMUM\\_PERFORMANCE\\_FEE = 50e16; // 50%\\nuint256 constant DEFAULT\\_PERFORMANCE\\_FEE = 10e16; // 10%\\n```\\n
Expected amounts of tokens in the withdraw functionчmediumчEvery `withdraw` function in the strategy contracts is calculating the expected amount of the returned tokens before withdrawing them:\\n```\\nfunction withdraw(uint256 \\_shares, uint256 \\_minAmount) external onlyEOAorWhitelist nonReentrant\\n{\\n address \\_from = msg.sender;\\n (uint256 \\_amount, uint256 \\_withdrawalAmount, uint256 \\_netAmount) = \\_calcAmountFromShares(\\_shares);\\n require(\\_netAmount >= \\_minAmount, \"high slippage\");\\n \\_burn(\\_from, \\_shares);\\n \\_withdraw(\\_amount);\\n Transfers.\\_pushFunds(reserveToken, \\_from, \\_withdrawalAmount);\\n}\\n```\\n\\nAfter that, the contract is trying to transfer this pre-calculated amount to the `msg.sender`. It is never checked whether the intended amount was actually transferred to the strategy contract. If the amount is lower, that may result in reverting the `withdraw` function all the time and locking up tokens.\\nEven though we did not find any specific case of returning a different amount of tokens, it is still a good idea to handle this situation to minimize relying on the security of the external contracts.чResolution\\nClient's statement : “This issue did not really need fixing. The mitigation was already in place by depositing a tiny amount of the reserve into the contract, if necessary”\\nThere are a few options how to mitigate the issue:\\nDouble-check the balance difference before and after the MasterChef's `withdraw` function is called.\\nHandle this situation in the emergency mode (https://github.com/ConsenSys/growthdefi-audit-2021-06/issues/11).чч```\\nfunction withdraw(uint256 \\_shares, uint256 \\_minAmount) external onlyEOAorWhitelist nonReentrant\\n{\\n address \\_from = msg.sender;\\n (uint256 \\_amount, uint256 \\_withdrawalAmount, uint256 \\_netAmount) = \\_calcAmountFromShares(\\_shares);\\n require(\\_netAmount >= \\_minAmount, \"high slippage\");\\n \\_burn(\\_from, \\_shares);\\n \\_withdraw(\\_amount);\\n Transfers.\\_pushFunds(reserveToken, \\_from, \\_withdrawalAmount);\\n}\\n```\\n
The capping mechanism for Panther token leads to increased feesчmediumчPanther token has a cap in transfer sizes, so any transfer in the contract is limited beforehand:\\n```\\nfunction gulp(uint256 \\_minRewardAmount) external onlyEOAorWhitelist nonReentrant\\n{\\n uint256 \\_pendingReward = \\_getPendingReward();\\n if (\\_pendingReward > 0) {\\n  \\_withdraw(0);\\n }\\n uint256 \\_\\_totalReward = Transfers.\\_getBalance(rewardToken);\\n (uint256 \\_feeReward, uint256 \\_retainedReward) = \\_capFeeAmount(\\_\\_totalReward.mul(performanceFee) / 1e18);\\n Transfers.\\_pushFunds(rewardToken, buyback, \\_feeReward);\\n if (rewardToken != routingToken) {\\n  require(exchange != address(0), \"exchange not set\");\\n  uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\\n  \\_totalReward = \\_capTransferAmount(rewardToken, \\_totalReward, \\_retainedReward);\\n  Transfers.\\_approveFunds(rewardToken, exchange, \\_totalReward);\\n  IExchange(exchange).convertFundsFromInput(rewardToken, routingToken, \\_totalReward, 1);\\n }\\n if (routingToken != reserveToken) {\\n  require(exchange != address(0), \"exchange not set\");\\n  uint256 \\_totalRouting = Transfers.\\_getBalance(routingToken);\\n  \\_totalRouting = \\_capTransferAmount(routingToken, \\_totalRouting, \\_retainedReward);\\n  Transfers.\\_approveFunds(routingToken, exchange, \\_totalRouting);\\n  IExchange(exchange).joinPoolFromInput(reserveToken, routingToken, \\_totalRouting, 1);\\n }\\n uint256 \\_totalBalance = Transfers.\\_getBalance(reserveToken);\\n \\_totalBalance = \\_capTransferAmount(reserveToken, \\_totalBalance, \\_retainedReward);\\n require(\\_totalBalance >= \\_minRewardAmount, \"high slippage\");\\n \\_deposit(\\_totalBalance);\\n}\\n```\\n\\nFees here are calculated from the full amount of rewards (__totalReward ):\\n```\\n(uint256 \\_feeReward, uint256 \\_retainedReward) = \\_capFeeAmount(\\_\\_totalReward.mul(performanceFee) / 1e18);\\n```\\n\\nBut in fact, if the amount of the rewards is too big, it will be capped, and the residuals will be “taxed” again during the next call of the `gulp` function. That behavior leads to multiple taxations of the same tokens, which means increased fees.чResolution\\nThe client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b.\\nThe best solution would be to cap `__totalReward` first and then calculate fees from the capped value.чч```\\nfunction gulp(uint256 \\_minRewardAmount) external onlyEOAorWhitelist nonReentrant\\n{\\n uint256 \\_pendingReward = \\_getPendingReward();\\n if (\\_pendingReward > 0) {\\n  \\_withdraw(0);\\n }\\n uint256 \\_\\_totalReward = Transfers.\\_getBalance(rewardToken);\\n (uint256 \\_feeReward, uint256 \\_retainedReward) = \\_capFeeAmount(\\_\\_totalReward.mul(performanceFee) / 1e18);\\n Transfers.\\_pushFunds(rewardToken, buyback, \\_feeReward);\\n if (rewardToken != routingToken) {\\n  require(exchange != address(0), \"exchange not set\");\\n  uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\\n  \\_totalReward = \\_capTransferAmount(rewardToken, \\_totalReward, \\_retainedReward);\\n  Transfers.\\_approveFunds(rewardToken, exchange, \\_totalReward);\\n  IExchange(exchange).convertFundsFromInput(rewardToken, routingToken, \\_totalReward, 1);\\n }\\n if (routingToken != reserveToken) {\\n  require(exchange != address(0), \"exchange not set\");\\n  uint256 \\_totalRouting = Transfers.\\_getBalance(routingToken);\\n  \\_totalRouting = \\_capTransferAmount(routingToken, \\_totalRouting, \\_retainedReward);\\n  Transfers.\\_approveFunds(routingToken, exchange, \\_totalRouting);\\n  IExchange(exchange).joinPoolFromInput(reserveToken, routingToken, \\_totalRouting, 1);\\n }\\n uint256 \\_totalBalance = Transfers.\\_getBalance(reserveToken);\\n \\_totalBalance = \\_capTransferAmount(reserveToken, \\_totalBalance, \\_retainedReward);\\n require(\\_totalBalance >= \\_minRewardAmount, \"high slippage\");\\n \\_deposit(\\_totalBalance);\\n}\\n```\\n
The _capFeeAmount function is not working as intendedчmediumчPanther token has a limit on the transfer size. Because of that, all the Panther transfer values in the `PantherSwapCompoundingStrategyToken` are also capped beforehand. The following function is called to cap the size of fees:\\n```\\nfunction \\_capFeeAmount(uint256 \\_amount) internal view returns (uint256 \\_capped, uint256 \\_retained)\\n{\\n \\_retained = 0;\\n uint256 \\_limit = \\_calcMaxRewardTransferAmount();\\n if (\\_amount > \\_limit) {\\n  \\_amount = \\_limit;\\n  \\_retained = \\_amount.sub(\\_limit);\\n }\\n return (\\_amount, \\_retained);\\n}\\n```\\n\\nThis function should return the capped amount and the amount of retained tokens. But because the `_amount` is changed before calculating the `_retained`, the retained amount will always be 0.чCalculate the `retained` value before changing the `amount`.чч```\\nfunction \\_capFeeAmount(uint256 \\_amount) internal view returns (uint256 \\_capped, uint256 \\_retained)\\n{\\n \\_retained = 0;\\n uint256 \\_limit = \\_calcMaxRewardTransferAmount();\\n if (\\_amount > \\_limit) {\\n  \\_amount = \\_limit;\\n  \\_retained = \\_amount.sub(\\_limit);\\n }\\n return (\\_amount, \\_retained);\\n}\\n```\\n
Stale split ratios in UniversalBuybackчmediumчThe `gulp` and `pendingBurning` functions of the `UniversalBuyback` contract use the hardcoded, constant values of `DEFAULT_REWARD_BUYBACK1_SHARE` and `DEFAULT_REWARD_BUYBACK2_SHARE` to determine the ratio the trade value is split with.\\nConsequently, any call to `setRewardSplit` to set a new ratio will be ineffective but still result in a `ChangeRewardSplit` event being emitted. This event can deceive system operators and users as it does not reflect the correct values of the contract.\\n```\\nuint256 \\_amount1 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK1\\_SHARE) / 1e18;\\nuint256 \\_amount2 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK2\\_SHARE) / 1e18;\\n```\\n\\n```\\nuint256 \\_amount1 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK1\\_SHARE) / 1e18;\\nuint256 \\_amount2 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK2\\_SHARE) / 1e18;\\n```\\nчInstead of the default values, `rewardBuyback1Share` and `rewardBuyback2Share` should be used.чч```\\nuint256 \\_amount1 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK1\\_SHARE) / 1e18;\\nuint256 \\_amount2 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK2\\_SHARE) / 1e18;\\n```\\n
Exchange owner might steal users' funds using reentrancyчmediumчThe practice of pulling funds from a user (by using safeTransferFrom) and then later pushing (some) of the funds back to the user occurs in various places in the `Exchange` contract. In case one of the used token contracts (or one of its dependent calls) externally calls the `Exchange` owner, the owner may utilize that to call back `Exchange.recoverLostFunds` and drain (some) user funds.\\n```\\nfunction convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_outputAmount;\\n}\\n```\\n\\n```\\nfunction joinPoolFromInput(address \\_pool, address \\_token, uint256 \\_inputAmount, uint256 \\_minOutputShares) external override returns (uint256 \\_outputShares)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_token, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_token)); // deals with potential transfer tax\\n \\_outputShares = UniswapV2LiquidityPoolAbstraction.\\_joinPoolFromInput(router, \\_pool, \\_token, \\_inputAmount, \\_minOutputShares);\\n \\_outputShares = Math.\\_min(\\_outputShares, Transfers.\\_getBalance(\\_pool)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_pool, \\_sender, \\_outputShares);\\n return \\_outputShares;\\n}\\n```\\n\\n```\\nfunction convertFundsFromOutput(address \\_from, address \\_to, uint256 \\_outputAmount, uint256 \\_maxInputAmount) external override returns (uint256 \\_inputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_maxInputAmount);\\n \\_maxInputAmount = Math.\\_min(\\_maxInputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_inputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromOutput(router, \\_from, \\_to, \\_outputAmount, \\_maxInputAmount);\\n uint256 \\_refundAmount = \\_maxInputAmount - \\_inputAmount;\\n \\_refundAmount = Math.\\_min(\\_refundAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_from, \\_sender, \\_refundAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_inputAmount;\\n}\\n```\\n\\n```\\nfunction recoverLostFunds(address \\_token) external onlyOwner\\n{\\n uint256 \\_balance = Transfers.\\_getBalance(\\_token);\\n Transfers.\\_pushFunds(\\_token, treasury, \\_balance);\\n}\\n```\\nчReentrancy guard protection should be added to `Exchange.convertFundsFromInput`, `Exchange.convertFundsFromOutput`, `Exchange.joinPoolFromInput`, `Exchange.recoverLostFunds` at least, and in general to all public/external functions since gas price considerations are less relevant for contracts deployed on BSC.чч```\\nfunction convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_outputAmount;\\n}\\n```\\n
Exchange owner might steal users' funds using reentrancyчmediumчThe practice of pulling funds from a user (by using safeTransferFrom) and then later pushing (some) of the funds back to the user occurs in various places in the `Exchange` contract. In case one of the used token contracts (or one of its dependent calls) externally calls the `Exchange` owner, the owner may utilize that to call back `Exchange.recoverLostFunds` and drain (some) user funds.\\n```\\nfunction convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_outputAmount;\\n}\\n```\\n\\n```\\nfunction joinPoolFromInput(address \\_pool, address \\_token, uint256 \\_inputAmount, uint256 \\_minOutputShares) external override returns (uint256 \\_outputShares)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_token, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_token)); // deals with potential transfer tax\\n \\_outputShares = UniswapV2LiquidityPoolAbstraction.\\_joinPoolFromInput(router, \\_pool, \\_token, \\_inputAmount, \\_minOutputShares);\\n \\_outputShares = Math.\\_min(\\_outputShares, Transfers.\\_getBalance(\\_pool)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_pool, \\_sender, \\_outputShares);\\n return \\_outputShares;\\n}\\n```\\n\\n```\\nfunction convertFundsFromOutput(address \\_from, address \\_to, uint256 \\_outputAmount, uint256 \\_maxInputAmount) external override returns (uint256 \\_inputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_maxInputAmount);\\n \\_maxInputAmount = Math.\\_min(\\_maxInputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_inputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromOutput(router, \\_from, \\_to, \\_outputAmount, \\_maxInputAmount);\\n uint256 \\_refundAmount = \\_maxInputAmount - \\_inputAmount;\\n \\_refundAmount = Math.\\_min(\\_refundAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_from, \\_sender, \\_refundAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_inputAmount;\\n}\\n```\\n\\n```\\nfunction recoverLostFunds(address \\_token) external onlyOwner\\n{\\n uint256 \\_balance = Transfers.\\_getBalance(\\_token);\\n Transfers.\\_pushFunds(\\_token, treasury, \\_balance);\\n}\\n```\\nчReentrancy guard protection should be added to `Exchange.convertFundsFromInput`, `Exchange.convertFundsFromOutput`, `Exchange.joinPoolFromInput`, `Exchange.recoverLostFunds` at least, and in general to all public/external functions since gas price considerations are less relevant for contracts deployed on BSC.чч```\\nfunction convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\\n{\\n address \\_sender = msg.sender;\\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\\n \\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\\n return \\_outputAmount;\\n}\\n```\\n
Yearn: Re-entrancy attack during depositчhighчDuring the deposit in the `supplyTokenTo` function, the token transfer is happening after the shares are minted and before tokens are deposited to the yearn vault:\\n```\\nfunction supplyTokenTo(uint256 \\_amount, address to) override external {\\n    uint256 shares = \\_tokenToShares(\\_amount);\\n\\n    \\_mint(to, shares);\\n\\n    // NOTE: we have to deposit after calculating shares to mint\\n    token.safeTransferFrom(msg.sender, address(this), \\_amount);\\n\\n    \\_depositInVault();\\n\\n    emit SuppliedTokenTo(msg.sender, shares, \\_amount, to);\\n}\\n```\\n\\nIf the token allows the re-entrancy (e.g., ERC-777), the attacker can do one more transaction during the token transfer and call the `supplyTokenTo` function again. This second call will be done with already modified shares from the first deposit but non-modified token balances. That will lead to an increased amount of shares minted during the `supplyTokenTo`. By using that technique, it's possible to steal funds from other users of the contract.чHave the re-entrancy guard on all the external functions.чч```\\nfunction supplyTokenTo(uint256 \\_amount, address to) override external {\\n    uint256 shares = \\_tokenToShares(\\_amount);\\n\\n    \\_mint(to, shares);\\n\\n    // NOTE: we have to deposit after calculating shares to mint\\n    token.safeTransferFrom(msg.sender, address(this), \\_amount);\\n\\n    \\_depositInVault();\\n\\n    emit SuppliedTokenTo(msg.sender, shares, \\_amount, to);\\n}\\n```\\n
Yearn: Partial deposits are not processed properlyчhighчThe deposit is usually made with all the token balance of the contract:\\n```\\n// this will deposit full balance (for cases like not enough room in Vault)\\nreturn v.deposit();\\n```\\n\\nThe Yearn vault contract has a limit of how many tokens can be deposited there. If the deposit hits the limit, only part of the tokens is deposited (not to exceed the limit). That case is not handled properly, the shares are minted as if all the tokens are accepted, and the “change” is not transferred back to the caller:\\n```\\nfunction supplyTokenTo(uint256 \\_amount, address to) override external {\\n    uint256 shares = \\_tokenToShares(\\_amount);\\n\\n    \\_mint(to, shares);\\n\\n    // NOTE: we have to deposit after calculating shares to mint\\n    token.safeTransferFrom(msg.sender, address(this), \\_amount);\\n\\n    \\_depositInVault();\\n\\n    emit SuppliedTokenTo(msg.sender, shares, \\_amount, to);\\n}\\n```\\nчHandle the edge cases properly.чч```\\n// this will deposit full balance (for cases like not enough room in Vault)\\nreturn v.deposit();\\n```\\n
Sushi: redeemToken redeems less than it shouldчmediumчThe `redeemToken` function takes as argument the amount of SUSHI to redeem. Because the SushiBar's `leave` function – which has to be called to achieve this goal – takes an amount of xSUSHI that is to be burned in exchange for SUSHI, `redeemToken` has to compute the amount of xSUSHI that will result in a return of as many SUSHI tokens as were requested.\\n```\\n/// @notice Redeems tokens from the yield source from the msg.sender, it burn yield bearing tokens and return token to the sender.\\n/// @param amount The amount of `token()` to withdraw. Denominated in `token()` as above.\\n/// @return The actual amount of tokens that were redeemed.\\nfunction redeemToken(uint256 amount) public override returns (uint256) {\\n    ISushiBar bar = ISushiBar(sushiBar);\\n    ISushi sushi = ISushi(sushiAddr);\\n\\n    uint256 totalShares = bar.totalSupply();\\n    uint256 barSushiBalance = sushi.balanceOf(address(bar));\\n    uint256 requiredShares = amount.mul(totalShares).div(barSushiBalance);\\n\\n    uint256 barBeforeBalance = bar.balanceOf(address(this));\\n    uint256 sushiBeforeBalance = sushi.balanceOf(address(this));\\n\\n    bar.leave(requiredShares);\\n\\n    uint256 barAfterBalance = bar.balanceOf(address(this));\\n    uint256 sushiAfterBalance = sushi.balanceOf(address(this));\\n\\n    uint256 barBalanceDiff = barBeforeBalance.sub(barAfterBalance);\\n    uint256 sushiBalanceDiff = sushiAfterBalance.sub(sushiBeforeBalance);\\n\\n    balances[msg.sender] = balances[msg.sender].sub(barBalanceDiff);\\n    sushi.transfer(msg.sender, sushiBalanceDiff);\\n    return (sushiBalanceDiff);\\n}\\n```\\n\\nBecause the necessary calculations involve division and amounts have to be integral values, it is usually not possible to get the exact amount of SUSHI tokens that were requested. More precisely, let `a` denote the total supply of xSUSHI and `b` the SushiBar's balance of SUSHI at `a` certain point in time. If the SushiBar's `leave` function is supplied with `x` xSUSHI, then it will transfer `floor(x * `b` / a)` SUSHI. (We assume throughout this discussion that the numbers involved are small enough such that no overflow occurs and that `a` and `b` are not zero.)\\nHence, if `y` is the amount of SUSHI requested, it would make sense to call `leave` with the biggest number `x` that satisfies floor(x * b / a) <= `y` or the smallest number `x` that satisfies floor(x * b / a) >= `y`. Which of the two is “better” or “correct” needs to be specified, based on the requirements of the caller of `redeemToken`. It seems plausible, though, that the first variant is the one that makes more sense in this context, and the current implementation of `redeemToken` supports this hypothesis. It calls `leave` with `x1 := floor(y * a / b)`, which gives us floor(x1 * b / a) <= `y`. However, `x1` is not necessarily the biggest number that satisfies the relation, so the caller of `redeemToken` might end up with less SUSHI than they could have gotten while still not exceeding `y`.\\nThe correct amount to call `leave` with isx2 := floor((y * a + a - 1) / b) = max { x | floor(x * b / a) <= y }. Since `|x2 - x1| <= 1`, the difference in SUSHI is at most `floor(b / a)`. Nevertheless, even this small difference might subvert fairly reasonable expectations. For example, if someone queries `balanceOfToken` and immediately after that feeds the result into `redeemToken`, they might very well expect to redeem exactly the given amount and not less; it's their current balance, after all. However, that's not always the case with the current implementation.чCalculate `requiredShares` based on the formula above (x2). We also recommend dealing in a clean way with the special cases `totalShares == 0` and `barSushiBalance == 0`.чч```\\n/// @notice Redeems tokens from the yield source from the msg.sender, it burn yield bearing tokens and return token to the sender.\\n/// @param amount The amount of `token()` to withdraw. Denominated in `token()` as above.\\n/// @return The actual amount of tokens that were redeemed.\\nfunction redeemToken(uint256 amount) public override returns (uint256) {\\n    ISushiBar bar = ISushiBar(sushiBar);\\n    ISushi sushi = ISushi(sushiAddr);\\n\\n    uint256 totalShares = bar.totalSupply();\\n    uint256 barSushiBalance = sushi.balanceOf(address(bar));\\n    uint256 requiredShares = amount.mul(totalShares).div(barSushiBalance);\\n\\n    uint256 barBeforeBalance = bar.balanceOf(address(this));\\n    uint256 sushiBeforeBalance = sushi.balanceOf(address(this));\\n\\n    bar.leave(requiredShares);\\n\\n    uint256 barAfterBalance = bar.balanceOf(address(this));\\n    uint256 sushiAfterBalance = sushi.balanceOf(address(this));\\n\\n    uint256 barBalanceDiff = barBeforeBalance.sub(barAfterBalance);\\n    uint256 sushiBalanceDiff = sushiAfterBalance.sub(sushiBeforeBalance);\\n\\n    balances[msg.sender] = balances[msg.sender].sub(barBalanceDiff);\\n    sushi.transfer(msg.sender, sushiBalanceDiff);\\n    return (sushiBalanceDiff);\\n}\\n```\\n
Sushi: balanceOfToken underestimates balanceчmediumчThe `balanceOfToken` computation is too pessimistic, i.e., it can underestimate the current balance slightly.\\n```\\n/// @notice Returns the total balance (in asset tokens). This includes the deposits and interest.\\n/// @return The underlying balance of asset tokens\\nfunction balanceOfToken(address addr) public override returns (uint256) {\\n    if (balances[addr] == 0) return 0;\\n    ISushiBar bar = ISushiBar(sushiBar);\\n\\n    uint256 shares = bar.balanceOf(address(this));\\n    uint256 totalShares = bar.totalSupply();\\n\\n    uint256 sushiBalance =\\n        shares.mul(ISushi(sushiAddr).balanceOf(address(sushiBar))).div(\\n            totalShares\\n        );\\n    uint256 sourceShares = bar.balanceOf(address(this));\\n\\n    return (balances[addr].mul(sushiBalance).div(sourceShares));\\n}\\n```\\n\\nFirst, it calculates the amount of SUSHI that “belongs to” the yield source contract (sushiBalance), and then it determines the fraction of that amount that would be owed to the address in question. However, the “belongs to” above is a purely theoretical concept; it never happens that the yield source contract as a whole redeems and then distributes that amount among its shareholders; instead, if a shareholder redeems tokens, their request is passed through to the `SushiBar`. So in reality, there's no reason for this two-step process, and the holder's balance of SUSHI is more accurately computed as `balances[addr].mul(ISushi(sushiAddr).balanceOf(address(sushiBar))).div(totalShares)`, which can be greater than what `balanceOfToken` currently returns. Note that this is the amount of SUSHI that `addr` could withdraw directly from the `SushiBar`, based on their amount of shares. Observe also that if we sum these numbers up over all holders in the yield source contract, the result is smaller than or equal to `sushiBalance`. So the sum still doesn't exceed what “belongs to” the yield source contract.чThe `balanceOfToken` function should use the formula above.чч```\\n/// @notice Returns the total balance (in asset tokens). This includes the deposits and interest.\\n/// @return The underlying balance of asset tokens\\nfunction balanceOfToken(address addr) public override returns (uint256) {\\n    if (balances[addr] == 0) return 0;\\n    ISushiBar bar = ISushiBar(sushiBar);\\n\\n    uint256 shares = bar.balanceOf(address(this));\\n    uint256 totalShares = bar.totalSupply();\\n\\n    uint256 sushiBalance =\\n        shares.mul(ISushi(sushiAddr).balanceOf(address(sushiBar))).div(\\n            totalShares\\n        );\\n    uint256 sourceShares = bar.balanceOf(address(this));\\n\\n    return (balances[addr].mul(sushiBalance).div(sourceShares));\\n}\\n```\\n
Yearn: Redundant approve callчlowчThe approval for token transfer is done in the following way:\\n```\\nif(token.allowance(address(this), address(v)) < token.balanceOf(address(this))) {\\n    token.safeApprove(address(v), 0);\\n    token.safeApprove(address(v), type(uint256).max);\\n}\\n```\\n\\nSince the approval will be equal to the maximum value, there's no need to make zero-value approval first.чChange two `safeApprove` to one regular `approve` with the maximum value.чч```\\nif(token.allowance(address(this), address(v)) < token.balanceOf(address(this))) {\\n    token.safeApprove(address(v), 0);\\n    token.safeApprove(address(v), type(uint256).max);\\n}\\n```\\n
Sushi: Some state variables should be immutable and have more specific typesчlowчThe state variables `sushiBar` and `sushiAddr` are initialized in the contract's constructor and never changed afterward.\\n```\\ncontract SushiYieldSource is IYieldSource {\\n    using SafeMath for uint256;\\n    address public sushiBar;\\n    address public sushiAddr;\\n    mapping(address => uint256) public balances;\\n\\n    constructor(address \\_sushiBar, address \\_sushiAddr) public {\\n        sushiBar = \\_sushiBar;\\n        sushiAddr = \\_sushiAddr;\\n    }\\n```\\n\\nThey should be immutable; that would save some gas and make it clear that they won't (and can't) be changed once the contract has been deployed.\\nMoreover, they would better have more specific interface types than `address`, i.e., `ISushiBar` for `sushiBar` and `ISushi` for `sushiAddr`. That would be safer and make the code more readable.чMake these two state variables `immutable` and change their types as indicated above. Remove the corresponding explicit type conversions in the rest of the contract, and add explicit conversions to type `address` where necessary.чч```\\ncontract SushiYieldSource is IYieldSource {\\n    using SafeMath for uint256;\\n    address public sushiBar;\\n    address public sushiAddr;\\n    mapping(address => uint256) public balances;\\n\\n    constructor(address \\_sushiBar, address \\_sushiAddr) public {\\n        sushiBar = \\_sushiBar;\\n        sushiAddr = \\_sushiAddr;\\n    }\\n```\\n
Sushi: Unnecessary balance queriesчlowчIn function `redeemToken`, `barBalanceDiff` is always the same as `requiredShares` because the SushiBar's `leave` function burns exactly `requiredShares` xSUSHI.\\n```\\nuint256 barBeforeBalance = bar.balanceOf(address(this));\\nuint256 sushiBeforeBalance = sushi.balanceOf(address(this));\\n\\nbar.leave(requiredShares);\\n\\nuint256 barAfterBalance = bar.balanceOf(address(this));\\nuint256 sushiAfterBalance = sushi.balanceOf(address(this));\\n\\nuint256 barBalanceDiff = barBeforeBalance.sub(barAfterBalance);\\nuint256 sushiBalanceDiff = sushiAfterBalance.sub(sushiBeforeBalance);\\n\\nbalances[msg.sender] = balances[msg.sender].sub(barBalanceDiff);\\n```\\nчUse `requiredShares` instead of `barBalanceDiff`, and remove the unnecessary queries and variables.чч```\\nuint256 barBeforeBalance = bar.balanceOf(address(this));\\nuint256 sushiBeforeBalance = sushi.balanceOf(address(this));\\n\\nbar.leave(requiredShares);\\n\\nuint256 barAfterBalance = bar.balanceOf(address(this));\\nuint256 sushiAfterBalance = sushi.balanceOf(address(this));\\n\\nuint256 barBalanceDiff = barBeforeBalance.sub(barAfterBalance);\\nuint256 sushiBalanceDiff = sushiAfterBalance.sub(sushiBeforeBalance);\\n\\nbalances[msg.sender] = balances[msg.sender].sub(barBalanceDiff);\\n```\\n
Sushi: Unnecessary function declaration in interfaceчlowчThe `ISushiBar` interface declares a `transfer` function.\\n```\\ninterface ISushiBar {\\n    function enter(uint256 \\_amount) external;\\n\\n    function leave(uint256 \\_share) external;\\n\\n    function totalSupply() external view returns (uint256);\\n\\n    function balanceOf(address account) external view returns (uint256);\\n\\n    function transfer(address recipient, uint256 amount)\\n        external\\n        returns (bool);\\n}\\n```\\n\\nHowever, this function is never used, so it could be removed from the interface. Other functions that the `SushiBar` provides but are not used (approve, for example) aren't part of the interface either.чRemove the `transfer` declaration from the `ISushiBar` interface.чч```\\ninterface ISushiBar {\\n    function enter(uint256 \\_amount) external;\\n\\n    function leave(uint256 \\_share) external;\\n\\n    function totalSupply() external view returns (uint256);\\n\\n    function balanceOf(address account) external view returns (uint256);\\n\\n    function transfer(address recipient, uint256 amount)\\n        external\\n        returns (bool);\\n}\\n```\\n
Simplify the harvest method in each SinglePlusчlowчThe `BadgerSBTCCrvPlus` single plus contract implements a custom `harvest` method.\\n```\\n/\\*\\*\\n \\* @dev Harvest additional yield from the investment.\\n \\* Only governance or strategist can call this function.\\n \\*/\\nfunction harvest(address[] calldata \\_tokens, uint256[] calldata \\_cumulativeAmounts, uint256 \\_index, uint256 \\_cycle,\\n```\\n\\nThis method can only be called by the strategist because of the `onlyStrategist` modifier.\\nThis method has a few steps which take one asset and transform it into another asset a few times.\\nIt first claims the Badger tokens:\\n```\\n// 1. Harvest from Badger Tree\\nIBadgerTree(BADGER\\_TREE).claim(\\_tokens, \\_cumulativeAmounts, \\_index, \\_cycle, \\_merkleProof, \\_amountsToClaim);\\n```\\n\\nThen it transforms the Badger tokens into WBTC using Uniswap.\\n```\\n// 2. Sushi: Badger --> WBTC\\nuint256 \\_badger = IERC20Upgradeable(BADGER).balanceOf(address(this));\\nif (\\_badger > 0) {\\n    IERC20Upgradeable(BADGER).safeApprove(SUSHISWAP, 0);\\n    IERC20Upgradeable(BADGER).safeApprove(SUSHISWAP, \\_badger);\\n\\n    address[] memory \\_path = new address[](2);\\n    \\_path[0] = BADGER;\\n    \\_path[1] = WBTC;\\n\\n    IUniswapRouter(SUSHISWAP).swapExactTokensForTokens(\\_badger, uint256(0), \\_path, address(this), block.timestamp.add(1800));\\n}\\n```\\n\\nThis step can be simplified in two ways.\\nFirst, the `safeApprove` method isn't useful because its usage is not recommended anymore.\\nThe OpenZeppelin version 4 implementation states the method is deprecated and its usage is discouraged.\\n```\\n\\* @dev Deprecated. This function has issues similar to the ones found in\\n\\* {IERC20-approve}, and its usage is discouraged.\\n```\\n\\n```\\n     \\* @dev Deprecated. This function has issues similar to the ones found in\\n     \\* {IERC20-approve}, and its usage is discouraged.\\n```\\n\\nAnother step is swapping the tokens on Uniswap.\\n```\\nIUniswapRouter(SUSHISWAP).swapExactTokensForTokens(\\_badger, uint256(0), \\_path, address(this), block.timestamp.add(1800));\\n```\\n\\nIn this case, the last argument `block.timestamp.add(1800)` is the deadline. This is useful when the transaction is sent to the network and a deadline is needed to expire the transaction. However, the execution is right now and there's no need for a future expiration date.\\nRemoving the safe math addition will have the same end effect, the tokens will be swapped and the call is not at risk to expire.чResolution\\nComment from NUTS Finance team:\\nWe have replaced all safeApprove() usage with approve() and used block.timestamp as the expiration date.\\nDo not use safe math when sending the expiration date. Use `block.timestamp` for the same effect and a reduced gas cost.\\nApply the same principles for other Single Plus Tokens.чч```\\n/\\*\\*\\n \\* @dev Harvest additional yield from the investment.\\n \\* Only governance or strategist can call this function.\\n \\*/\\nfunction harvest(address[] calldata \\_tokens, uint256[] calldata \\_cumulativeAmounts, uint256 \\_index, uint256 \\_cycle,\\n```\\n
Reduce complexity in modifiers related to governance and strategistчlowчThe modifier onlyGovernance:\\n```\\nmodifier onlyGovernance() {\\n    \\_checkGovernance();\\n    \\_;\\n}\\n```\\n\\nCalls the internal function _checkGovernance:\\n```\\nfunction \\_checkGovernance() internal view {\\n    require(msg.sender == governance, \"not governance\");\\n}\\n```\\n\\nThere is no other case where the internal method `_checkGovernance` is called directly.\\nOne can reduce complexity by removing the internal function and moving its code directly in the modifier. This will increase code size but reduce gas used and code complexity.\\nThere are multiple similar instances:\\n```\\nfunction \\_checkStrategist() internal view {\\n    require(msg.sender == governance || strategists[msg.sender], \"not strategist\");\\n}\\n\\nmodifier onlyStrategist {\\n    \\_checkStrategist();\\n    \\_;\\n}\\n```\\n\\n```\\nfunction \\_checkGovernance() internal view {\\n    require(msg.sender == governance, \"not governance\");\\n}\\n\\nmodifier onlyGovernance() {\\n    \\_checkGovernance();\\n    \\_;\\n}\\n```\\n\\n```\\nfunction \\_checkGovernance() internal view {\\n    require(msg.sender == IGaugeController(controller).governance(), \"not governance\");\\n}\\n\\nmodifier onlyGovernance() {\\n    \\_checkGovernance();\\n    \\_;\\n}\\n```\\nчConsider removing the internal function and including its body in the modifier directly if the code size is not an issue.чч```\\nmodifier onlyGovernance() {\\n    \\_checkGovernance();\\n    \\_;\\n}\\n```\\n
zAuction - incomplete / dead code zWithdraw and zDepositчhighчThe code generally does not appear to be production-ready. The methods `zWithdraw` and `zDeposit` do not appear to be properly implemented. `zWithdraw` rather burns `ETH` balance than withdrawing it for an account (missing transfer) and `zDeposit` manipulates an accounts balance but never receives the `ETH` amount it credits to an account.\\n```\\n    function zDeposit(address to) external payable onlyZauction {\\n        ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);\\n        emit zDeposited(to, msg.value);\\n    }\\n\\n    function zWithdraw(address from, uint256 amount) external onlyZauction {\\n        ethbalance[from] = SafeMath.sub(ethbalance[from], amount);\\n        emit zWithdrew(from, amount);\\n    }\\n```\\nчResolution\\nobsolete with changes from zer0-os/[email protected]135b2aa removing the `zAccountAccountant`.\\nThe methods do not seem to be used by the zAuction contract. It is highly discouraged from shipping incomplete implementations in productive code. Remove dead/unreachable code. Fix the implementations to perform proper accounting before reintroducing them if they are called by zAuction.чч```\\n    function zDeposit(address to) external payable onlyZauction {\\n        ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);\\n        emit zDeposited(to, msg.value);\\n    }\\n\\n    function zWithdraw(address from, uint256 amount) external onlyZauction {\\n        ethbalance[from] = SafeMath.sub(ethbalance[from], amount);\\n        emit zWithdrew(from, amount);\\n    }\\n```\\n
zAuction - Unpredictable behavior for users due to admin front running or general bad timingчhighчAn administrator of `zAuctionAccountant` contract can update the `zAuction` contract without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.\\nIn general users of the system should have assurances about the behavior of the action they're about to take.\\nupdating the `zAuction` takes effect immediately. This has the potential to fail acceptance of bids by sellers on the now outdated `zAuction` contract as interaction with the accountant contract is now rejected. This forces bidders to reissue their bids in order for the seller to be able to accept them using the Accountant contract. This may also be used by admins to selectively censor the acceptance of accountant based bids by changing the active `zAuction` address.\\n```\\n    function SetZauction(address zauctionaddress) external onlyAdmin{\\n        zauction = zauctionaddress;\\n        emit ZauctionSet(zauctionaddress);\\n    }\\n\\n    function SetAdmin(address newadmin) external onlyAdmin{\\n        admin = newadmin;\\n        emit AdminSet(msg.sender, newadmin);\\n    }\\n```\\n\\nUpgradeable contracts may introduce the same unpredictability issues where the proxyUpgradeable owner may divert execution to a new zNS registrar implementation selectively for certain transactions or without prior notice to users.чThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.\\nValidate arguments before updating contract addresses (at least != current/0x0). Consider implementing a 2-step admin ownership transfer (transfer+accept) to avoid losing control of the contract by providing the wrong `ETH` address.чч```\\n    function SetZauction(address zauctionaddress) external onlyAdmin{\\n        zauction = zauctionaddress;\\n        emit ZauctionSet(zauctionaddress);\\n    }\\n\\n    function SetAdmin(address newadmin) external onlyAdmin{\\n        admin = newadmin;\\n        emit AdminSet(msg.sender, newadmin);\\n    }\\n```\\n
zAuction, zNS - Bids cannot be cancelled, never expire, and the auction lifecycle is unclearчhighчThe lifecycle of a bid both for `zAuction` and `zNS` is not clear, and has many flaws.\\n`zAuction` - Consider the case where a bid is placed, then the underlying asset in being transferred to a new owner. The new owner can now force to sell the asset even though it's might not be relevant anymore.\\n`zAuction` - Once a bid was accepted and the asset was transferred, all other bids need to be invalidated automatically, otherwise and old bid might be accepted even after the formal auction is over.\\n`zAuction`, `zNS` - There is no way for the bidder to cancel an old bid. That might be useful in the event of a significant change in market trend, where the old pricing is no longer relevant. Currently, in order to cancel a bid, the bidder can either withdraw his ether balance from the `zAuctionAccountant`, or disapprove `WETH` which requires an extra transaction that might be front-runned by the seller.\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\n\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\nчConsider adding an expiration field to the message signed by the bidder both for `zAuction` and `zNS`. Consider adding auction control, creating an `auctionId`, and have users bid on specific auctions. By adding this id to the signed message, all other bids are invalidated automatically and users would have to place new bids for a new auction. Optionally allow users to cancel bids explicitly.\\nчч```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\n
zAuction - pot. initialization fronrunning and unnecessary init functionчmediumчThe `zAuction` initialization method is unprotected and while only being executable once, can be called by anyone. This might allow someone to monitor the mempool for new deployments of this contract and fron-run the initialization to initialize it with different parameters.\\nA mitigating factor is that this condition can be detected by the deployer as subsequent calls to `init()` will fail.\\nNote: this doesn't adhere to common interface naming convention/oz naming convention where this method would be called `initialize`.\\nNote: that zNS in contrast relies on ou/initializable pattern with proper naming.\\nNote: that this function might not be necessary at all and should be replaced by a constructor instead, as the contract is not used with a proxy pattern.\\n```\\nfunction init(address accountantaddress) external {\\n    require(!initialized);\\n    initialized = true;\\n    accountant = zAuctionAccountant(accountantaddress);\\n}\\n```\\nчThe contract is not used in a proxy pattern, hence, the initialization should be performed in the `constructor` instead.чч```\\nfunction init(address accountantaddress) external {\\n    require(!initialized);\\n    initialized = true;\\n    accountant = zAuctionAccountant(accountantaddress);\\n}\\n```\\n
zAuction - unclear upgrade pathчmediumч`zAuction` appears to implement an upgrade path for the auction system via `zAuctionAccountant`. `zAuction` itself does not hold any value. The `zAuctionAccountant` can be configured to allow only one `zAution` contract to interact with it. The update of the contract reference takes effect immediately (https://github.com/ConsenSys/zer0-zauction-audit-2021-05/issues/7).\\nAcceptance of bids via the accountant on the old contract immediately fail after an admin updates the referenced `zAuction` contract while `WETH` bids may still continue. This may create an unfavorable scenario where two contracts may be active in parallel accepting `WETH` bids.\\nIt should also be noted that 2nd layer bids (signed data) using the accountant for the old contract will not be acceptable anymore.\\n```\\nfunction SetZauction(address zauctionaddress) external onlyAdmin{\\n    zauction = zauctionaddress;\\n    emit ZauctionSet(zauctionaddress);\\n}\\n```\\nчConsider re-thinking the upgrade path. Avoid keeping multiple versions of the auction contact active.чч```\\nfunction SetZauction(address zauctionaddress) external onlyAdmin{\\n    zauction = zauctionaddress;\\n    emit ZauctionSet(zauctionaddress);\\n}\\n```\\n
zAuction, zNS - gas griefing by spamming offchain fake bids  AcknowledgedчmediumчThe execution status of both `zAuction.acceptBid` and `StakingController.fulfillDomainBid` transactions depend on the bidder, as his approval is needed, his signature is being validated, etc. However, these transactions can be submitted by accounts that are different from the bidder account, or for accounts that do not have the required funds/deposits available, luring the account that has to perform the on-chain call into spending gas on a transaction that is deemed to fail (gas griefing). E.g. posting high-value fake bids for zAuction without having funds deposited or `WETH` approved.\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\nчRevert early for checks that depend on the bidder before performing gas-intensive computations.\\nConsider adding a dry-run validation for off-chain components before transaction submission.чч```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n
zAuction - hardcoded ropsten token addressчlowчThe auction contract hardcodes the WETH ERC20 token address. this address will not be functional when deploying to mainnet.\\n```\\n    IERC20 weth = IERC20(address(0xc778417E063141139Fce010982780140Aa0cD5Ab)); // rinkeby weth\\n```\\nчResolution\\nAddressed with zer0-os/[email protected]135b2aa and the following statement:\\n5.30 weth address in constructor\\nNote: does not perform input validation as recommended\\nConsider taking the used `WETH` token address as a constructor argument. Avoid code changes to facilitate testing! Perform input validation on arguments rejecting `address(0x0)` to facilitate the detection of potential misconfiguration in the deployment pipeline.чч```\\n    IERC20 weth = IERC20(address(0xc778417E063141139Fce010982780140Aa0cD5Ab)); // rinkeby weth\\n```\\n
zAuction - accountant allows zero value withdrawals/deposits/exchangeчlowчZero value transfers effectively perform a no-operation sometimes followed by calling out to the recipient of the withdrawal.\\nA transfer where `from==to` or where the value is `0` is ineffective.\\n```\\nfunction Withdraw(uint256 amount) external {\\n    ethbalance[msg.sender] = SafeMath.sub(ethbalance[msg.sender], amount);\\n    payable(msg.sender).transfer(amount);\\n    emit Withdrew(msg.sender, amount);\\n}\\n```\\n\\n```\\nfunction Deposit() external payable {\\n    ethbalance[msg.sender] = SafeMath.add(ethbalance[msg.sender], msg.value);\\n    emit Deposited(msg.sender, msg.value);\\n}\\n```\\n\\n```\\n    function zDeposit(address to) external payable onlyZauction {\\n        ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);\\n        emit zDeposited(to, msg.value);\\n    }\\n\\n    function zWithdraw(address from, uint256 amount) external onlyZauction {\\n        ethbalance[from] = SafeMath.sub(ethbalance[from], amount);\\n        emit zWithdrew(from, amount);\\n    }\\n\\n    function Exchange(address from, address to, uint256 amount) external onlyZauction {\\n        ethbalance[from] = SafeMath.sub(ethbalance[from], amount);\\n        ethbalance[to] = SafeMath.add(ethbalance[to], amount);\\n        emit zExchanged(from, to, amount);\\n    }\\n```\\nчConsider rejecting ineffective withdrawals (zero value) or at least avoid issuing a zero value `ETH` transfers. Avoid emitting successful events for ineffective calls to not trigger 3rd party components on noop's.чч```\\nfunction Withdraw(uint256 amount) external {\\n    ethbalance[msg.sender] = SafeMath.sub(ethbalance[msg.sender], amount);\\n    payable(msg.sender).transfer(amount);\\n    emit Withdrew(msg.sender, amount);\\n}\\n```\\n
zAuction - seller should not be able to accept their own bidчlowчA seller can accept their own bid which is an ineffective action that is emitting an event.\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n\\n/// @dev 'true' in the hash here is the eth/weth switch\\nfunction acceptWethBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid, true))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    weth.transferFrom(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit WethBidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\nчDisallow transfers to self.чч```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n\\n/// @dev 'true' in the hash here is the eth/weth switch\\nfunction acceptWethBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid, true))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    weth.transferFrom(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit WethBidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\n
zBanc - DynamicLiquidTokenConverter ineffective reentrancy protectionчhighч`reduceWeight` calls `_protected()` in an attempt to protect from reentrant calls but this check is insufficient as it will only check for the `locked` statevar but never set it. A potential for direct reentrancy might be present when an erc-777 token is used as reserve.\\nIt is assumed that the developer actually wanted to use the `protected` modifier that sets the lock before continuing with the method.\\n```\\nfunction reduceWeight(IERC20Token \\_reserveToken)\\n    public\\n    validReserve(\\_reserveToken)\\n    ownerOnly\\n{\\n    \\_protected();\\n```\\n\\n```\\ncontract ReentrancyGuard {\\n    // true while protected code is being executed, false otherwise\\n    bool private locked = false;\\n\\n    /\\*\\*\\n \\* @dev ensures instantiation only by sub-contracts\\n \\*/\\n    constructor() internal {}\\n\\n    // protects a function against reentrancy attacks\\n    modifier protected() {\\n        \\_protected();\\n        locked = true;\\n        \\_;\\n        locked = false;\\n    }\\n\\n    // error message binary size optimization\\n    function \\_protected() internal view {\\n        require(!locked, \"ERR\\_REENTRANCY\");\\n    }\\n}\\n```\\nчTo mitigate potential attack vectors from reentrant calls remove the call to `_protected()` and decorate the function with `protected` instead. This will properly set the lock before executing the function body rejecting reentrant calls.чч```\\nfunction reduceWeight(IERC20Token \\_reserveToken)\\n    public\\n    validReserve(\\_reserveToken)\\n    ownerOnly\\n{\\n    \\_protected();\\n```\\n
zBanc - DynamicLiquidTokenConverter input validationчmediumчCheck that the value in `PPM` is within expected bounds before updating system settings that may lead to functionality not working correctly. For example, setting out-of-bounds values for `stepWeight` or `setMinimumWeight` may make calls to `reduceWeight` fail. These values are usually set in the beginning of the lifecycle of the contract and misconfiguration may stay unnoticed until trying to reduce the weights. The settings can be fixed, however, by setting the contract inactive and updating it with valid settings. Setting the contract to inactive may temporarily interrupt the normal operation of the contract which may be unfavorable.\\nBoth functions allow the full `uint32` range to be used, which, interpreted as `PPM` would range from `0%` to `4.294,967295%`\\n```\\nfunction setMinimumWeight(uint32 \\_minimumWeight)\\n    public\\n    ownerOnly\\n    inactive\\n{\\n    //require(\\_minimumWeight > 0, \"Min weight 0\");\\n    //\\_validReserveWeight(\\_minimumWeight);\\n    minimumWeight = \\_minimumWeight;\\n    emit MinimumWeightUpdated(\\_minimumWeight);\\n}\\n```\\n\\n```\\nfunction setStepWeight(uint32 \\_stepWeight)\\n    public\\n    ownerOnly\\n    inactive\\n{\\n    //require(\\_stepWeight > 0, \"Step weight 0\");\\n    //\\_validReserveWeight(\\_stepWeight);\\n    stepWeight = \\_stepWeight;\\n    emit StepWeightUpdated(\\_stepWeight);\\n}\\n```\\nчReintroduce the checks for `_validReserveWeight` to check that a percent value denoted in `PPM` is within valid bounds `_weight > 0 && _weight <= PPM_RESOLUTION`. There is no need to separately check for the value to be `>0` as this is already ensured by `_validReserveWeight`.\\nNote that there is still room for misconfiguration (step size too high, min-step too high), however, this would at least allow to catch obviously wrong and often erroneously passed parameters early.чч```\\nfunction setMinimumWeight(uint32 \\_minimumWeight)\\n    public\\n    ownerOnly\\n    inactive\\n{\\n    //require(\\_minimumWeight > 0, \"Min weight 0\");\\n    //\\_validReserveWeight(\\_minimumWeight);\\n    minimumWeight = \\_minimumWeight;\\n    emit MinimumWeightUpdated(\\_minimumWeight);\\n}\\n```\\n
zBanc - DynamicLiquidTokenConverter introduces breaking changes to the underlying bancorprotocol baseчmediumчIntroducing major changes to the complex underlying smart contract system that zBanc was forked from(bancorprotocol) may result in unnecessary complexity to be added. Complexity usually increases the attack surface and potentially introduces software misbehavior. Therefore, it is recommended to focus on reducing the changes to the base system as much as possible and comply with the interfaces and processes of the system instead of introducing diverging behavior.\\nFor example, `DynamicLiquidTokenConverterFactory` does not implement the `ITypedConverterFactory` while other converters do. Furthermore, this interface and the behavior may be expected to only perform certain tasks e.g. when called during an upgrade process. Not adhering to the base systems expectations may result in parts of the system failing to function for the new convertertype. Changes introduced to accommodate the custom behavior/interfaces may result in parts of the system failing to operate with existing converters. This risk is best to be avoided.\\nIn the case of `DynamicLiquidTokenConverterFactory` the interface is imported but not implemented at all (unused import). The reason for this is likely because the function `createConverter` in `DynamicLiquidTokenConverterFactory` does not adhere to the bancor-provided interface anymore as it is doing way more than “just” creating and returning a new converter. This can create problems when trying to upgrade the converter as the upgraded expected the shared interface to be exposed unless the update mechanisms are modified as well.\\nIn general, the factories `createConverter` method appears to perform more tasks than comparable type factories. It is questionable if this is needed but may be required by the design of the system. We would, however, highly recommend to not diverge from how other converters are instantiated unless it is required to provide additional security guarantees (i.e. the token was instantiated by the factory and is therefore trusted).\\nThe `ConverterUpgrader` changed in a way that it now can only work with the `DynamicLiquidTokenconverter` instead of the more generalized `IConverter` interface. This probably breaks the update for all other converter types in the system.\\nThe severity is estimated to be medium based on the fact that the development team seems to be aware of the breaking changes but the direction of the design of the system was not yet decided.\\nunused import\\nconverterType should be external as it is not called from within the same or inherited contracts\\n```\\nfunction converterType() public pure returns (uint16) {\\n    return 3;\\n}\\n```\\n\\ncreateToken can be external and is actually creating a token and converter that is using that token (the converter is not returned)(consider renaming to createTokenAndConverter)\\n```\\n{\\n    DSToken token = new DSToken(\\_name, \\_symbol, \\_decimals);\\n\\n    token.issue(msg.sender, \\_initialSupply);\\n\\n    emit NewToken(token);\\n\\n    createConverter(\\n      token,\\n      \\_reserveToken,\\n      \\_reserveWeight,\\n      \\_reserveBalance,\\n      \\_registry,\\n      \\_maxConversionFee,\\n      \\_minimumWeight,\\n      \\_stepWeight,\\n      \\_marketCapThreshold\\n    );\\n\\n    return token;\\n}\\n```\\n\\nthe upgrade interface changed and now requires the converter to be a `DynamicLiquidTokenConverter`. Other converters may potentially fail to upgrade unless they implement the called interfaces.\\n```\\n    function upgradeOld(DynamicLiquidTokenConverter \\_converter, bytes32 \\_version) public {\\n        \\_version;\\n        DynamicLiquidTokenConverter converter = DynamicLiquidTokenConverter(\\_converter);\\n        address prevOwner = converter.owner();\\n        acceptConverterOwnership(converter);\\n        DynamicLiquidTokenConverter newConverter = createConverter(converter);\\n       \\n        copyReserves(converter, newConverter);\\n        copyConversionFee(converter, newConverter);\\n        transferReserveBalances(converter, newConverter);\\n        IConverterAnchor anchor = converter.token();\\n       \\n        // get the activation status before it's being invalidated\\n        bool activate = isV28OrHigherConverter(converter) && converter.isActive();\\n       \\n        if (anchor.owner() == address(converter)) {\\n            converter.transferTokenOwnership(address(newConverter));\\n            newConverter.acceptAnchorOwnership();\\n        }\\n\\n        handleTypeSpecificData(converter, newConverter, activate);\\n        converter.transferOwnership(prevOwner);\\n       \\n        newConverter.transferOwnership(prevOwner);\\n       \\n        emit ConverterUpgrade(address(converter), address(newConverter));\\n    }\\n```\\n\\n```\\nfunction upgradeOld(\\n    IConverter \\_converter,\\n    bytes32 /\\* \\_version \\*/\\n) public {\\n    // the upgrader doesn't require the version for older converters\\n    upgrade(\\_converter, 0);\\n}\\n```\\nчIt is a fundamental design decision to either follow the bancorsystems converter API or diverge into a more customized system with a different design, functionality, or even security assumptions. From the current documentation, it is unclear which way the development team wants to go.\\nHowever, we highly recommend re-evaluating whether the newly introduced type and components should comply with the bancor API (recommended; avoid unnecessary changes to the underlying system,) instead of changing the API for the new components. Decide if the new factory should adhere to the usually commonly shared `ITypedConverterFactory` (recommended) and if not, remove the import and provide a new custom shared interface. It is highly recommended to comply and use the bancor systems extensibility mechanisms as intended, keeping the previously audited bancor code in-tact and voiding unnecessary re-assessments of the security impact of changes.чч```\\nfunction converterType() public pure returns (uint16) {\\n    return 3;\\n}\\n```\\n
zBanc - DynamicLiquidTokenConverter isActive should only be returned if converter is fully configured and converter parameters should only be updateable while converter is inactiveчmediumчBy default, a converter is `active` once the anchor ownership was transferred. This is true for converters that do not require to be properly set up with additional parameters before they can be used.\\n```\\n/\\*\\*\\n \\* @dev returns true if the converter is active, false otherwise\\n \\*\\n \\* @return true if the converter is active, false otherwise\\n\\*/\\nfunction isActive() public view virtual override returns (bool) {\\n    return anchor.owner() == address(this);\\n}\\n```\\n\\nFor a simple converter, this might be sufficient. If a converter requires additional setup steps (e.g. setting certain internal variables, an oracle, limits, etc.) it should return `inactive` until the setup completes. This is to avoid that users are interacting with (or even pot. frontrunning) a partially configured converter as this may have unexpected outcomes.\\nFor example, the `LiquidityPoolV2Converter` overrides the `isActive` method to require additional variables be set (oracle) to actually be in `active` state.\\n```\\n  \\* @dev returns true if the converter is active, false otherwise\\n  \\*\\n  \\* @return true if the converter is active, false otherwise\\n\\*/\\nfunction isActive() public view override returns (bool) {\\n    return super.isActive() && address(priceOracle) != address(0);\\n}\\n```\\n\\nAdditionally, settings can only be updated while the contract is `inactive` which will be the case during an upgrade. This ensures that the `owner` cannot adjust settings at will for an active contract.\\n```\\nfunction activate(\\n    IERC20Token \\_primaryReserveToken,\\n    IChainlinkPriceOracle \\_primaryReserveOracle,\\n    IChainlinkPriceOracle \\_secondaryReserveOracle)\\n    public\\n    inactive\\n    ownerOnly\\n    validReserve(\\_primaryReserveToken)\\n    notThis(address(\\_primaryReserveOracle))\\n    notThis(address(\\_secondaryReserveOracle))\\n    validAddress(address(\\_primaryReserveOracle))\\n    validAddress(address(\\_secondaryReserveOracle))\\n{\\n```\\n\\nThe `DynamicLiquidTokenConverter` is following a different approach. It inherits the default `isActive` which sets the contract active right after anchor ownership is transferred. This kind of breaks the upgrade process for `DynamicLiquidTokenConverter` as settings cannot be updated while the contract is active (as anchor ownership might be transferred before updating values). To unbreak this behavior a new authentication modifier was added, that allows updates for the upgrade contradict while the contract is active. Now this is a behavior that should be avoided as settings should be predictable while a contract is active. Instead it would make more sense initially set all the custom settings of the converter to zero (uninitialized) and require them to be set and only the return the contract as active. The behavior basically mirrors the upgrade process of `LiquidityPoolV2Converter`.\\n```\\n    modifier ifActiveOnlyUpgrader(){\\n      if(isActive()){\\n        require(owner == addressOf(CONVERTER\\_UPGRADER), \"ERR\\_ACTIVE\\_NOTUPGRADER\");\\n      }\\n      \\_;\\n    }\\n```\\n\\nPre initialized variables should be avoided. The marketcap threshold can only be set by the calling entity as it may be very different depending on the type of reserve (eth, token).\\n```\\nuint32 public minimumWeight = 30000;\\nuint32 public stepWeight = 10000;\\nuint256 public marketCapThreshold = 10000 ether;\\nuint256 public lastWeightAdjustmentMarketCap = 0;\\n```\\n\\nHere's one of the setter functions that can be called while the contract is active (only by the upgrader contract but changing the ACL commonly followed with other converters).\\n```\\nfunction setMarketCapThreshold(uint256 \\_marketCapThreshold)\\n    public\\n    ownerOnly\\n    ifActiveOnlyUpgrader\\n{\\n    marketCapThreshold = \\_marketCapThreshold;\\n    emit MarketCapThresholdUpdated(\\_marketCapThreshold);\\n}\\n```\\nчAlign the upgrade process as much as possible to how `LiquidityPoolV2Converter` performs it. Comply with the bancor API.\\noverride `isActive` and require the contracts main variables to be set.\\ndo not pre initialize the contracts settings to “some” values. Require them to be set by the caller (and perform input validation)\\nmirror the upgrade process of `LiquidityPoolV2Converter` and instead of `activate` call the setter functions that set the variables. After setting the last var and anchor ownership been transferred, the contract should return active.чч```\\n/\\*\\*\\n \\* @dev returns true if the converter is active, false otherwise\\n \\*\\n \\* @return true if the converter is active, false otherwise\\n\\*/\\nfunction isActive() public view virtual override returns (bool) {\\n    return anchor.owner() == address(this);\\n}\\n```\\n
zBanc - inconsistent DynamicContractRegistry, admin risksчmediumч`DynamicContractRegistry` is a wrapper registry that allows the zBanc to use the custom upgrader contract while still providing access to the normal bancor registry.\\nFor this to work, the registry owner can add or override any registry setting. Settings that don't exist in this contract are attempted to be retrieved from an underlying registry (contractRegistry).\\n```\\nfunction registerAddress(bytes32 \\_contractName, address \\_contractAddress)\\n    public\\n    ownerOnly\\n    validAddress(\\_contractAddress)\\n{\\n```\\n\\nIf the item does not exist in the registry, the request is forwarded to the underlying registry.\\n```\\nfunction addressOf(bytes32 \\_contractName) public view override returns (address) {\\n    if(items[\\_contractName].contractAddress != address(0)){\\n      return items[\\_contractName].contractAddress;\\n    }else{\\n      return contractRegistry.addressOf(\\_contractName);\\n    }\\n}\\n```\\n\\nAccording to the documentation this registry is owned by zer0 admins and this means users have to trust zer0 admins to play fair.\\nTo handle this, we deploy our own ConverterUpgrader and ContractRegistry owned by zer0 admins who can register new addresses\\nThe owner of the registry (zer0 admins) can change the underlying registry contract at will. The owner can also add new or override any settings that already exist in the underlying registry. This may for example allow a malicious owner to change the upgrader contract in an attempt to potentially steal funds from a token converter or upgrade to a new malicious contract. The owner can also front-run registry calls changing registry settings and thus influencing the outcome. Such an event will not go unnoticed as events are emitted.\\nIt should also be noted that `itemCount` will return only the number of items in the wrapper registry but not the number of items in the underlying registry. This may have an unpredictable effect on components consuming this information.\\n```\\n/\\*\\*\\n \\* @dev returns the number of items in the registry\\n \\*\\n \\* @return number of items\\n\\*/\\nfunction itemCount() public view returns (uint256) {\\n    return contractNames.length;\\n}\\n```\\nчResolution\\nThe client acknowledged the admin risk and addressed the `itemCount` concerns by exposing another method that only returns the overridden entries. The following statement was provided:\\n5.10 - keeping this pattern which matches the bancor pattern, and noting the DCR should be owned by a DAO, which is our plan. solved itemCount issue - Added dcrItemCount and made itemCount call the bancor registry's itemCount, so unpredictable behavior due to the count should be eliminated.\\nRequire the owner/zer0 admins to be a DAO or multisig and enforce 2-step (notify->wait->upgrade) registry updates (e.g. by requiring voting or timelocks in the admin contract). Provide transparency about who is the owner of the registry as this may not be clear for everyone. Evaluate the impact of `itemCount` only returning the number of settings in the wrapper not taking into account entries in the subcontract (including pot. overlaps).чч```\\nfunction registerAddress(bytes32 \\_contractName, address \\_contractAddress)\\n    public\\n    ownerOnly\\n    validAddress(\\_contractAddress)\\n{\\n```\\n
zBanc - DynamicLiquidTokenConverter consider using PPM_RESOLUTION instead of hardcoding integer literalsчlowч`getMarketCap` calculates the reserve's market capitalization as reserveBalance * `1e6` / weight where `1e6` should be expressed as the constant `PPM_RESOLUTION`.\\n```\\nfunction getMarketCap(IERC20Token \\_reserveToken)\\n    public\\n    view\\n    returns(uint256)\\n{\\n    Reserve storage reserve = reserves[\\_reserveToken];\\n    return reserveBalance(\\_reserveToken).mul(1e6).div(reserve.weight);\\n}\\n```\\nчAvoid hardcoding integer literals directly into source code when there is a better expression available. In this case `1e6` is used because weights are denoted in percent to base `PPM_RESOLUTION` (=100%).чч```\\nfunction getMarketCap(IERC20Token \\_reserveToken)\\n    public\\n    view\\n    returns(uint256)\\n{\\n    Reserve storage reserve = reserves[\\_reserveToken];\\n    return reserveBalance(\\_reserveToken).mul(1e6).div(reserve.weight);\\n}\\n```\\n
zBanc - DynamicLiquidTokenConverter avoid potential converter type overlap with bancor  AcknowledgedчlowчThe system is forked frombancorprotocol/contracts-solidity. As such, it is very likely that security vulnerabilities reported to bancorprotocol upstream need to be merged into the zer0/zBanc fork if they also affect this codebase. There is also a chance that security fixes will only be available with feature releases or that the zer0 development team wants to merge upstream features into the zBanc codebase.\\nzBanc introduced `converterType=3` for the `DynamicLiquidTokenConverter` as `converterType=1` and `converterType=2` already exist in the bancorprotocol codebase. Now, since it is unclear if `DynamicLiquidTokenConverter` will be merged into bancorprotocol there is a chance that bancor introduces new types that overlap with the `DynamicLiquidTokenConverter` converter type (3). It is therefore suggested to map the `DynamicLiquidTokenConverter` to a converterType that is unlikely to create an overlap with the system it was forked from. E.g. use converter type id `1001` instead of `3` (Note: converterType is an uint16).\\nNote that the current master of the bancorprotocol already appears to defined converterType 3 and 4: https://github.com/bancorprotocol/contracts-solidity/blob/5f4c53ebda784751c3a90b06aa2c85e9fdb36295/solidity/test/helpers/Converter.js#L51-L54\\nThe new custom converter\\n```\\nfunction converterType() public pure override returns (uint16) {\\n    return 3;\\n}\\n```\\n\\nConverterTypes from the bancor base system\\n```\\nfunction converterType() public pure override returns (uint16) {\\n    return 1;\\n}\\n```\\n\\n```\\n\\*/\\nfunction converterType() public pure override returns (uint16) {\\n    return 2;\\n}\\n```\\nчChoose a converterType id for this custom implementation that does not overlap with the codebase the system was forked from. e.g. `uint16(-1)` or `1001` instead of `3` which might already be used upstream.чч```\\nfunction converterType() public pure override returns (uint16) {\\n    return 3;\\n}\\n```\\n
zDAO Token - Specification violation - Snapshots are never taken  Partially AddressedчhighчResolution\\nAddressed with zer0-os/[email protected]81946d4 by exposing the `_snapshot()` method to a dedicated snapshot role (likely to be a DAO) and the owner of the contract.\\nWe would like to note that we informed the client that depending on how the snapshot method is used and how predictably snapshots are consumed this might open up a frontrunning vector where someone observing that a `_snapshot()` is about to be taken might sandwich the snapshot call, accumulate a lot of stake (via 2nd markets, lending platforms), and returning it right after it's been taken. The risk of losing funds may be rather low (especially if performed by a miner) and the benefit from a DAO proposal using this snapshot might outweigh it. It is still recommended to increase the number of snapshots taken or take them on a regular basis (e.g. with every first transaction to the contract in a block) to make it harder to sandwich the snapshot taking.\\nAccording to the zDAO Token specification the DAO token should implement a snapshot functionality to allow it being used for DAO governance votings.\\nAny transfer, mint, or burn operation should result in a snapshot of the token balances of involved users being taken.\\nWhile the corresponding functionality is implemented and appears to update balances for snapshots, `_snapshot()` is never called, therefore, the snapshot is never taken. e.g. attempting to call `balanceOfAt` always results in an error as no snapshot is available.\\n```\\ncontract ZeroDAOToken is\\n  OwnableUpgradeable,\\n  ERC20Upgradeable,\\n  ERC20PausableUpgradeable,\\n  ERC20SnapshotUpgradeable\\n{\\n```\\n\\n```\\n\\_updateAccountSnapshot(sender);\\n```\\n\\nNote that this is an explicit requirement as per specification but unit tests do not seem to attempt calls to `balanceOfAt` at all.чActually, take a snapshot by calling `_snapshot()` once per block when executing the first transaction in a new block. Follow the openzeppeling documentation for ERC20Snapshot.чч```\\ncontract ZeroDAOToken is\\n  OwnableUpgradeable,\\n  ERC20Upgradeable,\\n  ERC20PausableUpgradeable,\\n  ERC20SnapshotUpgradeable\\n{\\n```\\n
zDAO-Token - Revoking vesting tokens right before cliff period expiration might be delayed/front-runnedчlowчThe owner of `TokenVesting` contract has the right to revoke the vesting of tokens for any `beneficiary`. By doing so, the amount of tokens that are already vested and weren't released yet are being transferred to the `beneficiary`, and the rest are being transferred to the owner. The `beneficiary` is expected to receive zero tokens in case the revocation transaction was executed before the cliff period is over. Although unlikely, the `beneficiary` may front run this revocation transaction by delaying the revocation (and) or inserting a release transaction right before that, thus withdrawing the vested amount.\\n```\\nfunction release(address beneficiary) public {\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  require(unreleased > 0, \"Nothing to release\");\\n\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n  award.released += unreleased;\\n\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n\\n  emit Released(beneficiary, unreleased);\\n}\\n\\n/\\*\\*\\n \\* @notice Allows the owner to revoke the vesting. Tokens already vested\\n \\* are transfered to the beneficiary, the rest are returned to the owner.\\n \\* @param beneficiary Who the tokens are being released to\\n \\*/\\nfunction revoke(address beneficiary) public onlyOwner {\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n\\n  require(award.revocable, \"Cannot be revoked\");\\n  require(!award.revoked, \"Already revoked\");\\n\\n  // Figure out how many tokens were owed up until revocation\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  award.released += unreleased;\\n\\n  uint256 refund = award.amount - award.released;\\n\\n  // Mark award as revoked\\n  award.revoked = true;\\n  award.amount = award.released;\\n\\n  // Transfer owed vested tokens to beneficiary\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n  // Transfer unvested tokens to owner (revoked amount)\\n  targetToken.safeTransfer(owner(), refund);\\n\\n  emit Released(beneficiary, unreleased);\\n  emit Revoked(beneficiary, refund);\\n}\\n```\\nчThe issue described above is possible, but very unlikely. However, the `TokenVesting` owner should be aware of that, and make sure not to revoke vested tokens closely to cliff period ending.чч```\\nfunction release(address beneficiary) public {\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  require(unreleased > 0, \"Nothing to release\");\\n\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n  award.released += unreleased;\\n\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n\\n  emit Released(beneficiary, unreleased);\\n}\\n\\n/\\*\\*\\n \\* @notice Allows the owner to revoke the vesting. Tokens already vested\\n \\* are transfered to the beneficiary, the rest are returned to the owner.\\n \\* @param beneficiary Who the tokens are being released to\\n \\*/\\nfunction revoke(address beneficiary) public onlyOwner {\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n\\n  require(award.revocable, \"Cannot be revoked\");\\n  require(!award.revoked, \"Already revoked\");\\n\\n  // Figure out how many tokens were owed up until revocation\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  award.released += unreleased;\\n\\n  uint256 refund = award.amount - award.released;\\n\\n  // Mark award as revoked\\n  award.revoked = true;\\n  award.amount = award.released;\\n\\n  // Transfer owed vested tokens to beneficiary\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n  // Transfer unvested tokens to owner (revoked amount)\\n  targetToken.safeTransfer(owner(), refund);\\n\\n  emit Released(beneficiary, unreleased);\\n  emit Revoked(beneficiary, refund);\\n}\\n```\\n
zDAO-Token - Vested tokens revocation depends on claiming stateчlowчThe owner of the `TokenVesting` contract can revoke the vesting of tokens for any beneficiary by calling `TokenVesting.revoke` only for tokens that have already been claimed using `MerkleTokenVesting.claimAward`. Although anyone can call `MerkleTokenVesting.claimAward` for a given beneficiary, in practice it is mostly the beneficiary's responsibility. This design decision, however, incentivizes the beneficiary to delay the call to `MerkleTokenVesting.claimAward` up to the point when he wishes to cash out, to avoid potential revocation. To revoke vesting tokens the owner will have to claim the award on the beneficiary's behalf first (which might be a gas burden), then call `TokenVesting.revoke`.\\n```\\nfunction revoke(address beneficiary) public onlyOwner {\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n\\n  require(award.revocable, \"Cannot be revoked\");\\n  require(!award.revoked, \"Already revoked\");\\n\\n  // Figure out how many tokens were owed up until revocation\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  award.released += unreleased;\\n\\n  uint256 refund = award.amount - award.released;\\n\\n  // Mark award as revoked\\n  award.revoked = true;\\n  award.amount = award.released;\\n\\n  // Transfer owed vested tokens to beneficiary\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n  // Transfer unvested tokens to owner (revoked amount)\\n  targetToken.safeTransfer(owner(), refund);\\n\\n  emit Released(beneficiary, unreleased);\\n  emit Revoked(beneficiary, refund);\\n}\\n```\\nчMake sure that the potential owner of a `TokenVesting` contract is aware of this potential issue, and has the required processes in place to handle it.чч```\\nfunction revoke(address beneficiary) public onlyOwner {\\n  TokenAward storage award = getTokenAwardStorage(beneficiary);\\n\\n  require(award.revocable, \"Cannot be revoked\");\\n  require(!award.revoked, \"Already revoked\");\\n\\n  // Figure out how many tokens were owed up until revocation\\n  uint256 unreleased = getReleasableAmount(beneficiary);\\n  award.released += unreleased;\\n\\n  uint256 refund = award.amount - award.released;\\n\\n  // Mark award as revoked\\n  award.revoked = true;\\n  award.amount = award.released;\\n\\n  // Transfer owed vested tokens to beneficiary\\n  targetToken.safeTransfer(beneficiary, unreleased);\\n  // Transfer unvested tokens to owner (revoked amount)\\n  targetToken.safeTransfer(owner(), refund);\\n\\n  emit Released(beneficiary, unreleased);\\n  emit Revoked(beneficiary, refund);\\n}\\n```\\n
zNS - Domain bid might be approved by non owner accountчhighчThe spec allows anyone to place a bid for a domain, while only parent domain owners are allowed to approve a bid. Bid placement is actually enforced and purely informational. In practice, `approveDomainBid` allows any parent domain owner to approve bids (signatures) for any other domain even if they do not own it. Once approved, anyone can call `fulfillDomainBid` to create a domain.\\n```\\nfunction approveDomainBid(\\n    uint256 parentId,\\n    string memory bidIPFSHash,\\n    bytes memory signature\\n) external authorizedOwner(parentId) {\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  approvedBids[hashOfSig] = true;\\n  emit DomainBidApproved(bidIPFSHash);\\n}\\n```\\nчResolution\\nAddressed with zer0-os/[email protected] by storing the domain request data on-chain.\\nConsider adding a validation check that allows only the parent domain owner to approve bids on one of its domains. Reconsider the design of the system introducing more on-chain guarantees for bids.чч```\\nfunction approveDomainBid(\\n    uint256 parentId,\\n    string memory bidIPFSHash,\\n    bytes memory signature\\n) external authorizedOwner(parentId) {\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  approvedBids[hashOfSig] = true;\\n  emit DomainBidApproved(bidIPFSHash);\\n}\\n```\\n
zAuction, zNS - Bids cannot be cancelled, never expire, and the auction lifecycle is unclearчhighчThe lifecycle of a bid both for `zAuction` and `zNS` is not clear, and has many flaws.\\n`zAuction` - Consider the case where a bid is placed, then the underlying asset in being transferred to a new owner. The new owner can now force to sell the asset even though it's might not be relevant anymore.\\n`zAuction` - Once a bid was accepted and the asset was transferred, all other bids need to be invalidated automatically, otherwise and old bid might be accepted even after the formal auction is over.\\n`zAuction`, `zNS` - There is no way for the bidder to cancel an old bid. That might be useful in the event of a significant change in market trend, where the old pricing is no longer relevant. Currently, in order to cancel a bid, the bidder can either withdraw his ether balance from the `zAuctionAccountant`, or disapprove `WETH` which requires an extra transaction that might be front-runned by the seller.\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\n\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\nчConsider adding an expiration field to the message signed by the bidder both for `zAuction` and `zNS`. Consider adding auction control, creating an `auctionId`, and have users bid on specific auctions. By adding this id to the signed message, all other bids are invalidated automatically and users would have to place new bids for a new auction. Optionally allow users to cancel bids explicitly.\\nчч```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\n
zNS - Insufficient protection against replay attacksчhighчThere is no dedicated data structure to prevent replay attacks on `StakingController`. `approvedBids` mapping offers only partial mitigation, due to the fact that after a domain bid is fulfilled, the only mechanism in place to prevent a replay attack is the `Registrar` contract that might be replaced in the case where `StakingController` is being re-deployed with a different `Registrar` instance. Additionally, the digital signature used for domain bids does not identify the buyer request uniquely enough. The bidder's signature could be replayed in future similar contracts that are deployed with a different registrar or in a different network.\\n```\\nfunction createBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  string memory bidIPFSHash,\\n  string memory name\\n) public pure returns(bytes32) {\\n  return keccak256(abi.encode(parentId, bidAmount, bidIPFSHash, name));\\n}\\n```\\nчConsider adding a dedicated mapping to store the a unique identifier of a bid, as well as adding `address(this)`, `block.chainId`, `registrar` and `nonce` to the message that is being signed by the bidder.чч```\\nfunction createBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  string memory bidIPFSHash,\\n  string memory name\\n) public pure returns(bytes32) {\\n  return keccak256(abi.encode(parentId, bidAmount, bidIPFSHash, name));\\n}\\n```\\n
zNS - domain name collisionsчhighчDomain registration accepts an empty (zero-length) name. This may allow a malicious entity to register two different NFT's for the same visually indinstinguishable text representation of a domain. Similar to this the domain name is mapped to an NFT via a subgraph that connects parent names to the new subdomain using a domain separation character (dot/slash/…). Someone might be able to register `a.b` to `cats.cool` which might resolve to the same domain as if someone registers `cats.cool.a` and then `cats.cool.a.b`.\\n`0/cats/` = `0xfe`\\n`0/cats/<empty-string/` = `0xfe.keccak(\"\")`\\n```\\nfunction registerDomain(\\n  uint256 parentId,\\n  string memory name,\\n  address domainOwner,\\n  address minter\\n) external override onlyController returns (uint256) {\\n  // Create the child domain under the parent domain\\n  uint256 labelHash = uint256(keccak256(bytes(name)));\\n  address controller = msg.sender;\\n\\n  // Domain parents must exist\\n  require(\\_exists(parentId), \"Zer0 Registrar: No parent\");\\n\\n  // Calculate the new domain's id and create it\\n  uint256 domainId =\\n    uint256(keccak256(abi.encodePacked(parentId, labelHash)));\\n  \\_createDomain(domainId, domainOwner, minter, controller);\\n\\n  emit DomainCreated(domainId, name, labelHash, parentId, minter, controller);\\n\\n  return domainId;\\n```\\nчDisallow empty subdomain names. Disallow domain separators in names (in the offchain component or smart contract).чч```\\nfunction registerDomain(\\n  uint256 parentId,\\n  string memory name,\\n  address domainOwner,\\n  address minter\\n) external override onlyController returns (uint256) {\\n  // Create the child domain under the parent domain\\n  uint256 labelHash = uint256(keccak256(bytes(name)));\\n  address controller = msg.sender;\\n\\n  // Domain parents must exist\\n  require(\\_exists(parentId), \"Zer0 Registrar: No parent\");\\n\\n  // Calculate the new domain's id and create it\\n  uint256 domainId =\\n    uint256(keccak256(abi.encodePacked(parentId, labelHash)));\\n  \\_createDomain(domainId, domainOwner, minter, controller);\\n\\n  emit DomainCreated(domainId, name, labelHash, parentId, minter, controller);\\n\\n  return domainId;\\n```\\n
zAuction, zNS - gas griefing by spamming offchain fake bids  AcknowledgedчmediumчThe execution status of both `zAuction.acceptBid` and `StakingController.fulfillDomainBid` transactions depend on the bidder, as his approval is needed, his signature is being validated, etc. However, these transactions can be submitted by accounts that are different from the bidder account, or for accounts that do not have the required funds/deposits available, luring the account that has to perform the on-chain call into spending gas on a transaction that is deemed to fail (gas griefing). E.g. posting high-value fake bids for zAuction without having funds deposited or `WETH` approved.\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n    IERC721 nftcontract = IERC721(nftaddress);\\n    accountant.Exchange(bidder, msg.sender, bid);\\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\\n}\\n```\\nчRevert early for checks that depend on the bidder before performing gas-intensive computations.\\nConsider adding a dry-run validation for off-chain components before transaction submission.чч```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n
zNS - anyone can front-run fulfillDomainBid to lock the domain setting or set different metadataчmediumчAnyone observing a call to `fulfillDomainBid` can front-run this call for the original bidder, provide different metadata/royalty amount, or lock the metadata, as these parameters are not part of the bidder's signature. The impact is limited as both metadata, royalty amount, and lock state can be changed by the domain owner after creation.\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n```\\nчConsider adding `metadata`, `royaltyAmount`, and `lockOnCreation` to the message signed by the bidder if the parent should have some control over `metadata` and lockstatus and restrict access to this function to `msg.sender==recoveredbidder`.чч```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n```\\n
zNS- Using a digital signature as a hash preimageчmediumчUsing the encoded signature (r,s,v) or the hash of the signature to prevent replay or track if signatures have been seen/used is not recommended in general, as it may introduce signature malleability issues, as two different signature params (r,s,v) may be producable that validly sign the same data.\\nThe impact for this codebase, however, is limited, due to the fact that openzeppelins `ECDSA` wrapper library is used which checks for malleable `ECDSA` signatures (high s value). We still decided to keep this as a medium issue to raise awareness, that it is bad practice to rely on the hash of signatures instead of the hash of the actual signed data for checks.\\nIn another instance in zAuction, a global random nonce is used to prevent replay attacks. This is suboptimal and instead, the hash of the signed data (including a nonce) should be used.\\n```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n\\n```\\nfunction acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\\n    require(!randUsed[rand], 'Random nonce already used');\\n    randUsed[rand] = true;\\n```\\nчConsider creating the bid identifier by hashing the concatenation of all bid parameters instead. Ensure to add replay protection https://github.com/ConsenSys/zer0-zns-audit-2021-05/issues/19. Always check for the hash of the signed data instead of the hash of the encoded signature to track whether a signature has been seen before.\\nConsider implementing Ethereum typed structured data hashing and signing according to EIP-712.чч```\\n  function fulfillDomainBid(\\n  uint256 parentId,\\n  uint256 bidAmount,\\n  uint256 royaltyAmount,\\n  string memory bidIPFSHash,\\n  string memory name,\\n  string memory metadata,\\n  bytes memory signature,\\n  bool lockOnCreation,\\n  address recipient\\n) external {\\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\\n  address recoveredBidder = recover(recoveredBidHash, signature);\\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\\n  registrar.setDomainMetadataUri(id, metadata);\\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\\n  registrar.transferFrom(controller, recoveredBidder, id);\\n  if (lockOnCreation) {\\n    registrar.lockDomainMetadataForOwner(id);\\n  }\\n  approvedBids[hashOfSig] = false;\\n  emit DomainBidFulfilled(\\n    metadata,\\n    name,\\n    recoveredBidder,\\n    id,\\n    parentId\\n  );\\n}\\n```\\n
zNS - Registrar skips __ERC721Pausable_init()чlowчThe initialization function of registrar skips the chained initializer `__ERC721Pausable_init` to initialize `__ERC721_init(\"Zer0 Name Service\", \"ZNS\")`. This basically skips the following initialization calls:\\n```\\nabstract contract ERC721PausableUpgradeable is Initializable, ERC721Upgradeable, PausableUpgradeable {\\n    function \\_\\_ERC721Pausable\\_init() internal initializer {\\n        \\_\\_Context\\_init\\_unchained(); \\n        \\_\\_ERC165\\_init\\_unchained();\\n        \\_\\_Pausable\\_init\\_unchained();\\n        \\_\\_ERC721Pausable\\_init\\_unchained();\\n    }\\n```\\n\\n```\\nfunction initialize() public initializer {\\n  \\_\\_Ownable\\_init();\\n  \\_\\_ERC721\\_init(\"Zer0 Name Service\", \"ZNS\");\\n\\n  // create the root domain\\n  \\_createDomain(0, msg.sender, msg.sender, address(0));\\n}\\n```\\nчconsider calling the missing initializers to register the interface for erc165 if needed.чч```\\nabstract contract ERC721PausableUpgradeable is Initializable, ERC721Upgradeable, PausableUpgradeable {\\n    function \\_\\_ERC721Pausable\\_init() internal initializer {\\n        \\_\\_Context\\_init\\_unchained(); \\n        \\_\\_ERC165\\_init\\_unchained();\\n        \\_\\_Pausable\\_init\\_unchained();\\n        \\_\\_ERC721Pausable\\_init\\_unchained();\\n    }\\n```\\n
zNS - Registrar is ERC721PausableUpgradeable but there is no way to actually pause itчlowчThe registrar is ownable and pausable but the functionality to pause the contract is not implemented.\\n```\\ncontract Registrar is\\n  IRegistrar,\\n  OwnableUpgradeable,\\n  ERC721PausableUpgradeable\\n{\\n```\\nчSimplification is key. Remove the pausable functionality if the contract is not meant to be paused or consider implementing an external `pause()` function decorated `onlyOwner`.чч```\\ncontract Registrar is\\n  IRegistrar,\\n  OwnableUpgradeable,\\n  ERC721PausableUpgradeable\\n{\\n```\\n
zNS - Avoid no-opsчlowчCode paths that are causing transactions to be ended with an ineffective outcome or no-operation (no actual state changes) are not advisable, as they consume more gas, hide misconfiguration or error cases (e.g. adding the same controller multiple times), and may impact other processes that rely upon transaction's logs.\\nReject adding an already existing controller, and removing non existing controller.\\n```\\n/\\*\\*\\n @notice Authorizes a controller to control the registrar\\n @param controller The address of the controller\\n \\*/\\nfunction addController(address controller) external override onlyOwner {\\n  controllers[controller] = true;\\n  emit ControllerAdded(controller);\\n}\\n\\n/\\*\\*\\n @notice Unauthorizes a controller to control the registrar\\n @param controller The address of the controller\\n \\*/\\nfunction removeController(address controller) external override onlyOwner {\\n  controllers[controller] = false;\\n  emit ControllerRemoved(controller);\\n}\\n```\\nчConsider reverting code paths that end up in ineffective outcomes (i.e. no-operation) as early as possible.чч```\\n/\\*\\*\\n @notice Authorizes a controller to control the registrar\\n @param controller The address of the controller\\n \\*/\\nfunction addController(address controller) external override onlyOwner {\\n  controllers[controller] = true;\\n  emit ControllerAdded(controller);\\n}\\n\\n/\\*\\*\\n @notice Unauthorizes a controller to control the registrar\\n @param controller The address of the controller\\n \\*/\\nfunction removeController(address controller) external override onlyOwner {\\n  controllers[controller] = false;\\n  emit ControllerRemoved(controller);\\n}\\n```\\n
RocketRewardPool - Unpredictable staking rewards as stake can be added just before claiming and rewards may be paid to to operators that do not provide a service to the system  Partially AddressedчhighчNodes/TrustedNodes earn rewards based on the current share of the effective RPL stake provided backing the number of Minipools they run. The reward is paid out regardless of when the effective node stake was provided, as long as it is present just before the call to `claim()`. This means the reward does not take into account how long the stake was provided. The effective RPL stake is the nodes RPL stake capped at a maximum of `halfDepositUserAmount * 150% * nr_of_minipools(node) / RPLPrice`. If the node does not run any Minipools, the effective RPL stake is zero.\\nSince effective stake can be added just before calling the `claim()` method (effectively trying to get a reward for a period that passed without RPL being staked for the full duration), this might create an unpredictable outcome for other participants, as adding significant stake (requires creating Minipools and staking the max per pool; the stake is locked for at least the duration of a reward period rpl.rewards.claim.period.blocks) shifts the shares users get for the fixed total amount of rewards. This can be unfair if the first users claimed their reward, and then someone is artificially inflating the total amount of shares by adding more stake to get a bigger part of the remaining reward. However, this comes at the cost of the registered node having to create more Minipools to stake more, requiring an initial deposit (16ETH, or 0ETH under certain circumstances for trusted nodes) by the actor attempting to get a larger share of the rewards. The risk of losing funds for this actor, however, is rather low, as they can immediately `dissolve()` and `close()` the Minipool to refund their node deposit as `NETH` right after claiming the reward only losing the gas spent on the various transactions.\\nThis can be extended to a node operator creating a Minipool and staking the maximum amount before calling `claim` to remove the Minipool right after, freeing up the `ETH` that was locked in the Minipool until the next reward period starts. The node operator is not providing any service to the network, loses some value in `ETH` for gas but may compensate that with the RPL staking rewards. If the node amassed a significant amount of RPL stake, they might even try to flash-loan enough `ETH` to spawn Minipools to inflate their effective stake and earn most of the rewards to return the loan RPL profit.\\n```\\n-- reward period ends -- front-run other claimers to maximize profits\\n[create x minipools]\\n[stake to max effective RPL for amount of minipools; locked for 14 days]\\n[claim rewards for inflated effective RPL stake]\\n[dissolve(), close() minipools -> refund NETH]\\n[burn NETH for ETH]\\n// rest of code wait 14 days\\n[withdraw stake OR start again creating Minipools, claiming rewards while the Minipools are dissolved right after, freeing the ETH]\\n```\\n\\nBy staking just before claiming, the node effectively can earn rewards for 2 reward periods by only staking RPL for the duration of one period (claim the previous period, leave it in for 14 days, claim another period, withdraw).\\nThe stake can be withdrawn at the earliest 14 days after staking. However, it can be added back at any time, and the stake addition takes effect immediately. This allows for optimizing the staking reward as follows (assuming we front-run other claimers to maximize profits and perform all transactions in one block):\\n```\\n[stake max effective amount for the number of minipools]\\n[claim() to claim the previous period even though we did not provide any stake for the duration]\\n[optionally dissolve Minipools unlocking ETH]\\n-- stake is locked for at least 14 days --\\n-- 14 days forward - new reward period started --\\n[claim() the period]\\n[withdraw() (leaving min pool stake OR everything if we dissolve all the Minipool)]\\n[lend RPL to other platforms and earn interest]\\n-- 14 days forward -new reward period started --\\n[get RPL back from another platform]\\n[stake & create minipools to inflate effective stake]\\n[claim()]\\n[optionally dissolve Minipools to unlock node ETH]\\n-- stake is locked for at least 14 days --\\n-- 14 days forward - new reward period started --\\n[claim() the period]\\n[withdraw() (leaving min pool stake OR everything if we dissolve all the Minipools)]\\n[lend RPL to other platforms and earn interest]\\n// rest of code\\n```\\n\\nNote that `withdraw()` can be called right at the time the new reward period starts:\\n```\\nrequire(block.number.sub(getNodeRPLStakedBlock(msg.sender)) >= rocketDAOProtocolSettingsRewards.getRewardsClaimIntervalBlocks(), \"The withdrawal cooldown period has not passed\");\\n// Get & check node's current RPL stake\\n```\\n\\nA node may choose to register and stake some RPL to collect rewards but never actually provide registered node duties, e.g., operating a Minipool.\\nNode shares for a passed reward epoch are unpredictable as nodes may change their stake (adding) after/before users claim their rewards.\\nA node can maximize its rewards by adding stake just before claiming it\\nA node can stake to claim rewards, wait 14 days, withdraw, lend on a platform and return the stake in time to claim the next period.чReview the incentive model for the RPL rewards. Consider adjusting it so that nodes that provide a service get a better share of the rewards. Consider accruing rewards for the duration the stake was provided instead of taking a snapshot whenever the node calls `claim()`. Require stake to be locked for > 14 days instead of >=14 days (withdraw()) or have users skip the first reward period after staking.чч```\\n-- reward period ends -- front-run other claimers to maximize profits\\n[create x minipools]\\n[stake to max effective RPL for amount of minipools; locked for 14 days]\\n[claim rewards for inflated effective RPL stake]\\n[dissolve(), close() minipools -> refund NETH]\\n[burn NETH for ETH]\\n// rest of code wait 14 days\\n[withdraw stake OR start again creating Minipools, claiming rewards while the Minipools are dissolved right after, freeing the ETH]\\n```\\n
Prefer using abi.encode in TokenDistributorчmediumчThe method `_hashLeaf` is called when a user claims their airdrop.\\n```\\n// can we repoduce leaf hash included in the claim?\\nrequire(\\_hashLeaf(user\\_id, user\\_amount, leaf), 'TokenDistributor: Leaf Hash Mismatch.');\\n```\\n\\nThis method receives the `user_id` and the `user_amount` as arguments.\\n```\\n/\\*\\*\\n\\* @notice hash user\\_id + claim amount together & compare results to leaf hash \\n\\* @return boolean true on match\\n\\*/\\nfunction \\_hashLeaf(uint32 user\\_id, uint256 user\\_amount, bytes32 leaf) private returns (bool) {\\n```\\n\\nThese arguments are abi encoded and hashed together to produce a unique hash.\\n```\\nbytes32 leaf\\_hash = keccak256(abi.encodePacked(keccak256(abi.encodePacked(user\\_id, user\\_amount))));\\n```\\n\\nThis hash is checked against the third argument for equality.\\n```\\nreturn leaf == leaf\\_hash;\\n```\\n\\nIf the hash matches the third argument, it returns true and considers the provided `user_id` and `user_amount` are correct.\\nHowever, packing differently sized arguments may produce collisions.\\nThe Solidity documentation states that packing dynamic types will produce collisions, but this is also the case if packing `uint32` and `uint256`.\\nBelow there's an example showing that packing `uint32` and `uint256` in both orders can produce collisions with carefully picked values.\\n```\\nlibrary Encode {\\n    function encode32Plus256(uint32 \\_a, uint256 \\_b) public pure returns (bytes memory) {\\n        return abi.encodePacked(\\_a, \\_b);\\n    }\\n   \\n    function encode256Plus32(uint256 \\_a, uint32 \\_b) public pure returns (bytes memory) {\\n        return abi.encodePacked(\\_a, \\_b);\\n    }\\n}\\n\\ncontract Hash {\\n    function checkEqual() public pure returns (bytes32, bytes32) {\\n        // Pack 1\\n        uint32  a1 = 0x12345678;\\n        uint256 b1 = 0x99999999999999999999999999999999999999999999999999999999FFFFFFFF;\\n       \\n        // Pack 2\\n        uint256 a2 = 0x1234567899999999999999999999999999999999999999999999999999999999;\\n        uint32  b2 = 0xFFFFFFFF;\\n       \\n        // Encode these 2 different values\\n        bytes memory packed1 = Encode.encode32Plus256(a1, b1);\\n        bytes memory packed2 = Encode.encode256Plus32(a2, b2);\\n       \\n        // Check if the packed encodings match\\n        require(keccak256(packed1) == keccak256(packed2), \"Hash of representation should match\");\\n       \\n        // The hashes are the same\\n        // 0x9e46e582607c5c6e05587dacf66d311c4ced0819378a41d4b4c5adf99d72408e\\n        return (\\n            keccak256(packed1),\\n            keccak256(packed2)\\n        );\\n    }\\n}\\n```\\n\\nChanging `abi.encodePacked` to `abi.encode` in the library will make the transaction fail with error message `Hash of representation should match`.чResolution\\nFixed in gitcoinco/governance#7\\nUnless there's a specific use case to use `abi.encodePacked`, you should always use `abi.encode`. You might need a few more bytes in the transaction data, but it prevents collisions. Similar fix can be achieved by using `unit256` for both values to be packed to prevent any possible collisions.чч```\\n// can we repoduce leaf hash included in the claim?\\nrequire(\\_hashLeaf(user\\_id, user\\_amount, leaf), 'TokenDistributor: Leaf Hash Mismatch.');\\n```\\n
Simplify claim tokens for a gas discount and less codeчlowчThe method `claimTokens` in `TokenDistributor` needs to do a few checks before it can distribute the tokens.\\nA few of these checks can be simplified and optimized.\\nThe method `hashMatch` can be removed because it's only used once and the contents can be moved directly into the parent method.\\n```\\n// can we reproduce the same hash from the raw claim metadata?\\nrequire(hashMatch(user\\_id, user\\_address, user\\_amount, delegate\\_address, leaf, eth\\_signed\\_message\\_hash\\_hex), 'TokenDistributor: Hash Mismatch.');\\n```\\n\\nBecause this method also uses a few other internal calls, they also need to be moved into the parent method.\\n```\\nreturn getDigest(claim) == eth\\_signed\\_message\\_hash\\_hex;\\n```\\n\\n```\\nhashClaim(claim)\\n```\\n\\nMoving the code directly in the parent method and removing them will improve gas costs for users.\\nThe structure `Claim` can also be removed because it's not used anywhere else in the code.чConsider simplifying `claimTokens` and remove unused methods.чч```\\n// can we reproduce the same hash from the raw claim metadata?\\nrequire(hashMatch(user\\_id, user\\_address, user\\_amount, delegate\\_address, leaf, eth\\_signed\\_message\\_hash\\_hex), 'TokenDistributor: Hash Mismatch.');\\n```\\n
Rename method _hashLeaf to something that represents the validity of the leafчlowчThe method `_hashLeaf` accepts 3 arguments.\\n```\\nfunction \\_hashLeaf(uint32 user\\_id, uint256 user\\_amount, bytes32 leaf) private returns (bool) {\\n```\\n\\nThe arguments `user_id` and `user_amount` are used to create a keccak256 hash.\\n```\\nbytes32 leaf\\_hash = keccak256(abi.encodePacked(keccak256(abi.encodePacked(user\\_id, user\\_amount))));\\n```\\n\\nThis hash is then checked if it matches the third argument.\\n```\\nreturn leaf == leaf\\_hash;\\n```\\n\\nThe result of the equality is returned by the method.\\nThe name of the method is confusing because it should say that it returns true if the leaf is considered valid.чResolution\\nClosed because the method was removed in gitcoinco/governance#4\\nConsider renaming the method to something like `isValidLeafHash`.чч```\\nfunction \\_hashLeaf(uint32 user\\_id, uint256 user\\_amount, bytes32 leaf) private returns (bool) {\\n```\\n
Method returns bool but result is never used in TokenDistributor.claimTokensчlowчThe method `_delegateTokens` is called when a user claims their tokens to automatically delegate the claimed tokens to their own address or to a different one.\\n```\\n\\_delegateTokens(user\\_address, delegate\\_address);\\n```\\n\\nThe method accepts the addresses of the delegator and the delegate and returns a boolean.\\n```\\n/\\*\\*\\n\\* @notice execute call on token contract to delegate tokens \\n\\* @return boolean true on success \\n\\*/\\nfunction \\_delegateTokens(address delegator, address delegatee) private returns (bool) {\\n     GTCErc20  GTCToken = GTCErc20(token);\\n     GTCToken.delegateOnDist(delegator, delegatee);\\n     return true; \\n} \\n```\\n\\nBut this boolean is never used.чRemove the returned boolean because it's always returned as `true` anyway and the transaction will be a bit cheaper.чч```\\n\\_delegateTokens(user\\_address, delegate\\_address);\\n```\\n
Improve efficiency by using immutable in TreasuryVesterчlowчThe `TreasuryVester` contract when deployed has a few fixed storage variables.\\n```\\ngtc = gtc\\_;\\n```\\n\\n```\\nvestingAmount = vestingAmount\\_;\\nvestingBegin = vestingBegin\\_;\\nvestingCliff = vestingCliff\\_;\\nvestingEnd = vestingEnd\\_;\\n```\\n\\nThese storage variables are defined in the contract.\\n```\\naddress public gtc;\\n```\\n\\n```\\nuint public vestingAmount;\\nuint public vestingBegin;\\nuint public vestingCliff;\\nuint public vestingEnd;\\n```\\n\\nBut they are never changed.чResolution\\nFixed in gitcoinco/governance#5\\nConsider setting storage variables as `immutable` type for a considerable gas improvement.чч```\\ngtc = gtc\\_;\\n```\\n
RocketDaoNodeTrusted - DAO takeover during deployment/bootstrappingчhighчThe initial deployer of the `RocketStorage` contract is set as the Guardian/Bootstrapping role. This guardian can bootstrap the TrustedNode and Protocol DAO, add members, upgrade components, change settings.\\nRight after deploying the DAO contract the member count is zero. The Guardian can now begin calling any of the bootstrapping functions to add members, change settings, upgrade components, interact with the treasury, etc. The bootstrapping configuration by the Guardian is unlikely to all happen within one transaction which might allow other parties to interact with the system while it is being set up.\\n`RocketDaoNodeTrusted` also implements a recovery mode that allows any registered node to invite themselves directly into the DAO without requiring approval from the Guardian or potential other DAO members as long as the total member count is below `daoMemberMinCount` (3). The Guardian itself is not counted as a DAO member as it is a supervisory role.\\n```\\n/\\*\\*\\*\\* Recovery \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\\n   \\n// In an explicable black swan scenario where the DAO loses more than the min membership required (3), this method can be used by a regular node operator to join the DAO\\n// Must have their ID, email, current RPL bond amount available and must be called by their current registered node account\\nfunction memberJoinRequired(string memory \\_id, string memory \\_email) override public onlyLowMemberMode onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets add them\\n    (bool successPropose, bytes memory responsePropose) = getContractAddress('rocketDAONodeTrustedProposals').call(abi.encodeWithSignature(\"proposalInvite(string,string,address)\", \\_id, \\_email, msg.sender));\\n    // Was there an error?\\n    require(successPropose, getRevertMsg(responsePropose));\\n    // Get the to automatically join as a member (by a regular proposal, they would have to manually accept, but this is no ordinary situation)\\n    (bool successJoin, bytes memory responseJoin) = getContractAddress(\"rocketDAONodeTrustedActions\").call(abi.encodeWithSignature(\"actionJoinRequired(address)\", msg.sender));\\n    // Was there an error?\\n    require(successJoin, getRevertMsg(responseJoin));\\n}\\n```\\n\\nThis opens up a window during the bootstrapping phase where any Ethereum Address might be able to register as a node (RocketNodeManager.registerNode) if node registration is enabled (default=true) rushing into `RocketDAONodeTrusted.memberJoinRequired` adding themselves (up to 3 nodes) as trusted nodes to the DAO. The new DAO members can now take over the DAO by issuing proposals, waiting 2 blocks to vote/execute them (upgrade, change settings while Guardian is changing settings, etc.). The Guardian role can kick the new DAO members, however, they can invite themselves back into the DAO.\\n```\\nsetSettingBool(\"node.registration.enabled\", true);     \\n```\\nчDisable the DAO recovery mode during bootstrapping. Disable node registration by default and require the guardian to enable it. Ensure that `bootstrapDisable` (in both DAO contracts) performs sanity checks as to whether the DAO bootstrapping finished and permissions can effectively be revoked without putting the DAO at risk or in an irrecoverable state (enough members bootstrapped, vital configurations like registration and other settings are configured, …).чч```\\n/\\*\\*\\*\\* Recovery \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\\n   \\n// In an explicable black swan scenario where the DAO loses more than the min membership required (3), this method can be used by a regular node operator to join the DAO\\n// Must have their ID, email, current RPL bond amount available and must be called by their current registered node account\\nfunction memberJoinRequired(string memory \\_id, string memory \\_email) override public onlyLowMemberMode onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\\n    // Ok good to go, lets add them\\n    (bool successPropose, bytes memory responsePropose) = getContractAddress('rocketDAONodeTrustedProposals').call(abi.encodeWithSignature(\"proposalInvite(string,string,address)\", \\_id, \\_email, msg.sender));\\n    // Was there an error?\\n    require(successPropose, getRevertMsg(responsePropose));\\n    // Get the to automatically join as a member (by a regular proposal, they would have to manually accept, but this is no ordinary situation)\\n    (bool successJoin, bytes memory responseJoin) = getContractAddress(\"rocketDAONodeTrustedActions\").call(abi.encodeWithSignature(\"actionJoinRequired(address)\", msg.sender));\\n    // Was there an error?\\n    require(successJoin, getRevertMsg(responseJoin));\\n}\\n```\\n
RocketDaoNodeTrustedActions - Incomplete implementation of member challenge processчhighчAny registered (even untrusted) node can challenge a trusted DAO node to respond. The challenge is initiated by calling `actionChallengeMake`. Trusted nodes can challenge for free, other nodes have to provide `members.challenge.cost` as a tribute to the Ethereum gods. The challenged node must call `actionChallengeDecide` before `challengeStartBlock + members.challenge.window` blocks are over (default approx 7 days). However, the Golang codebase does not actively monitor for the `ActionChallengeMade` event, nor does the node - regularly - check if it is being challenged. Means to respond to the challenge (calling `actionChallengeDecide` to stop the challenge) are not implemented.\\nNodes do not seem to monitor `ActionChallengeMade` events so that they could react to challenges\\nNodes do not implement `actionChallengeDecide` and, therefore, cannot successfully stop a challenge\\nFunds/Tribute sent along with the challenge will be locked forever in the `RocketDAONodeTrustedActions` contract. There's no means to recover the funds.\\nIt is questionable whether the incentives are aligned well enough for anyone to challenge stale nodes. The default of `1 eth` compared to the risk of the “malicious” or “stale” node exiting themselves is quite high. The challenger is not incentivized to challenge someone other than for taking over the DAO. If the tribute is too low, this might incentivize users to grief trusted nodes and force them to close a challenge.\\nRequiring that the challenge initiator is a different registered node than the challenge finalized is a weak protection since the system is open to anyone to register as a node (even without depositing any funds.)\\nblock time is subject to fluctuations. With the default of `43204` blocks, the challenge might expire at `5 days` (10 seconds block time), `6.5 days` (13 seconds Ethereum target median block time), `7 days` (14 seconds), or more with historic block times going up to `20 seconds` for shorter periods.\\nA minority of trusted nodes may use this functionality to boot other trusted node members off the DAO issuing challenges once a day until the DAO member number is low enough to allow them to reach quorum for their own proposals or until the member threshold allows them to add new nodes without having to go through the proposal process at all.\\n```\\nsetSettingUint('members.challenge.cooldown', 6172);              // How long a member must wait before performing another challenge, approx. 1 day worth of blocks\\nsetSettingUint('members.challenge.window', 43204);               // How long a member has to respond to a challenge. 7 days worth of blocks\\nsetSettingUint('members.challenge.cost', 1 ether);               // How much it costs a non-member to challenge a members node. It's free for current members to challenge other members.\\n```\\n\\n```\\n// In the event that the majority/all of members go offline permanently and no more proposals could be passed, a current member or a regular node can 'challenge' a DAO members node to respond\\n// If it does not respond in the given window, it can be removed as a member. The one who removes the member after the challenge isn't met, must be another node other than the proposer to provide some oversight\\n// This should only be used in an emergency situation to recover the DAO. Members that need removing when consensus is still viable, should be done via the 'kick' method.\\n```\\nчImplement the challenge-response process before enabling users to challenge other nodes. Implement means to detect misuse of this feature for griefing e.g. when one trusted node member forces another trusted node to defeat challenges over and over again (technical controls, monitoring).чч```\\nsetSettingUint('members.challenge.cooldown', 6172);              // How long a member must wait before performing another challenge, approx. 1 day worth of blocks\\nsetSettingUint('members.challenge.window', 43204);               // How long a member has to respond to a challenge. 7 days worth of blocks\\nsetSettingUint('members.challenge.cost', 1 ether);               // How much it costs a non-member to challenge a members node. It's free for current members to challenge other members.\\n```\\n
RocketDAOProtocolSettings/RocketDAONodeTrustedSettings - anyone can set/overwrite settings until contract is declared “deployed”  AcknowledgedчhighчThe `onlyDAOProtocolProposal` modifier guards all state-changing methods in this contract. However, analog to https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/7, the access control is disabled until the variable `settingsNameSpace.deployed` is set. If this contract is not deployed and configured in one transaction, anyone can update the contract while left unprotected on the blockchain.\\nSee issue 6.5 for a similar issue.\\n```\\nmodifier onlyDAOProtocolProposal() {\\n    // If this contract has been initialised, only allow access from the proposals contract\\n    if(getBool(keccak256(abi.encodePacked(settingNameSpace, \"deployed\")))) require(getContractAddress('rocketDAOProtocolProposals') == msg.sender, \"Only DAO Protocol Proposals contract can update a setting\");\\n    \\_;\\n}\\n```\\n\\n```\\nmodifier onlyDAONodeTrustedProposal() {\\n    // If this contract has been initialised, only allow access from the proposals contract\\n    if(getBool(keccak256(abi.encodePacked(settingNameSpace, \"deployed\")))) require(getContractAddress('rocketDAONodeTrustedProposals') == msg.sender, \"Only DAO Node Trusted Proposals contract can update a setting\");\\n    \\_;\\n}\\n```\\n\\nThere are at least 9 more occurrences of this pattern.чRestrict access to the methods to a temporary trusted account (e.g. guardian) until the system bootstrapping phase ends by setting `deployed` to `true.`чч```\\nmodifier onlyDAOProtocolProposal() {\\n    // If this contract has been initialised, only allow access from the proposals contract\\n    if(getBool(keccak256(abi.encodePacked(settingNameSpace, \"deployed\")))) require(getContractAddress('rocketDAOProtocolProposals') == msg.sender, \"Only DAO Protocol Proposals contract can update a setting\");\\n    \\_;\\n}\\n```\\n
RocketStorage - anyone can set/update values before the contract is initializedчhighчAccording to the deployment script, the contract is deployed, and settings are configured in multiple transactions. This also means that for a period of time, the contract is left unprotected on the blockchain. Anyone can delete/set any value in the centralized data store. An attacker might monitor the mempool for new deployments of the `RocketStorage` contract and front-run calls to `contract.storage.initialised` setting arbitrary values in the system.\\n```\\nmodifier onlyLatestRocketNetworkContract() {\\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\\n        // Make sure the access is permitted to only contracts in our Dapp\\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\\n    }\\n    \\_;\\n}\\n```\\nчRestrict access to the methods to a temporary trusted account (e.g. guardian) until the system bootstrapping phase ends by setting `initialised` to `true.`чч```\\nmodifier onlyLatestRocketNetworkContract() {\\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\\n        // Make sure the access is permitted to only contracts in our Dapp\\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\\n    }\\n    \\_;\\n}\\n```\\n
RocketDAOProposals - Unpredictable behavior due to short vote delayчhighчA proposal can be voted and passed when it enters the `ACTIVE` state. Voting starts when the current `block.number` is greater than the `startBlock` configured in the proposal (up until the endBlock). The requirement for the `startBlock` is to be at least greater than `block.number` when the proposal is submitted.\\n```\\nrequire(\\_startBlock > block.number, \"Proposal start block must be in the future\");\\nrequire(\\_durationBlocks > 0, \"Proposal cannot have a duration of 0 blocks\");\\nrequire(\\_expiresBlocks > 0, \"Proposal cannot have a execution expiration of 0 blocks\");\\nrequire(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\\n```\\n\\nThe default vote delay configured in the system is `1` block.\\n```\\nsetSettingUint('proposal.vote.delay.blocks', 1);                 // How long before a proposal can be voted on after it is created. Approx. Next Block\\n```\\n\\nA vote is immediately passed when the required quorum is reached which allows it to be executed. This means that a group that is holding enough voting power can propose a change, wait for two blocks (block.number (of time of proposal creation) + configuredDelay (1) + 1 (for ACTIVE state), then vote and execute for the proposal to pass for it to take effect almost immediately after only 2 blocks (<30seconds).\\nSettings can be changed after 30 seconds which might be unpredictable for other DAO members and not give them enough time to oppose and leave the DAO.чThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change after two blocks. The only guarantee is that users can be sure the settings don't change for the next block if no proposal is active.\\nWe recommend giving the user advance notice of changes with a delay. For example, all upgrades should require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.чч```\\nrequire(\\_startBlock > block.number, \"Proposal start block must be in the future\");\\nrequire(\\_durationBlocks > 0, \"Proposal cannot have a duration of 0 blocks\");\\nrequire(\\_expiresBlocks > 0, \"Proposal cannot have a execution expiration of 0 blocks\");\\nrequire(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\\n```\\n
RocketNodeStaking - Node operators can reduce slashing impact by withdrawing excess staked RPLчhighчOracle nodes update the Minipools' balance and progress it to the withdrawable state when they observe the minipools stake to become withdrawable. If the observed stakingEndBalance is less than the user deposit for that pool, the node operator is punished for the difference.\\n```\\nrocketMinipoolManager.setMinipoolWithdrawalBalances(\\_minipoolAddress, \\_stakingEndBalance, nodeAmount);\\n// Apply node penalties by liquidating RPL stake\\nif (\\_stakingEndBalance < userDepositBalance) {\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    rocketNodeStaking.slashRPL(minipool.getNodeAddress(), userDepositBalance - \\_stakingEndBalance);\\n}\\n```\\n\\nThe amount slashed is at max `userDepositBalance - stakingEndBalance`. The `userDepositBalance` is at least `16 ETH` (minipool.half/.full) and at max `32 ETH` (minipool.empty). The maximum amount to be slashed is therefore `32 ETH` (endBalance = 0, minipool.empty).\\nThe slashing amount is denoted in `ETH`. The `RPL` price (in ETH) is updated regularly by oracle nodes (see related issue https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/32; note that the `RPL` token is potentially affected by a similar issue as one can stake `RPL`, wait for the cooldown period & wait for the price to change, and withdraw stake at higher `RPL` price/ETH). The `ETH` amount to be slashed is converted to `RPL`, and the corresponding `RPL` stake is slashed.\\n```\\nuint256 rplSlashAmount = calcBase.mul(\\_ethSlashAmount).div(rocketNetworkPrices.getRPLPrice());\\n// Cap slashed amount to node's RPL stake\\nuint256 rplStake = getNodeRPLStake(\\_nodeAddress);\\nif (rplSlashAmount > rplStake) { rplSlashAmount = rplStake; }\\n// Transfer slashed amount to auction contract\\nrocketVault.transferToken(\"rocketAuctionManager\", getContractAddress(\"rocketTokenRPL\"), rplSlashAmount);\\n// Update RPL stake amounts\\ndecreaseTotalRPLStake(rplSlashAmount);\\ndecreaseNodeRPLStake(\\_nodeAddress, rplSlashAmount);\\n```\\n\\nIf the node does not have a sufficient `RPL` stake to cover the losses, the slashing amount is capped at whatever amount of `RPL` the node has left staked.\\nThe minimum amount of `RPL` a node needs to have staked if it operates minipools is calculated as follows:\\n```\\n    // Calculate minimum RPL stake\\n    return rocketDAOProtocolSettingsMinipool.getHalfDepositUserAmount()\\n        .mul(rocketDAOProtocolSettingsNode.getMinimumPerMinipoolStake())\\n        .mul(rocketMinipoolManager.getNodeMinipoolCount(\\_nodeAddress))\\n        .div(rocketNetworkPrices.getRPLPrice());\\n}\\n```\\n\\nWith the current configuration, this would resolve in a minimum stake of `16 ETH` * 0.1 (10% collateralization) * 1 (nr_minipools) * RPL_Price for a node operating 1 minipool. This means a node operator basically only needs to have 10% of `16 ETH` staked to operate one minipool.\\nAn operator can withdraw their stake at any time, but they have to wait at least 14 days after the last time they staked (cooldown period). They can, at max, withdraw all but the minimum stake required to run the pools (nr_of_minipools * 16 ETH * 10%). This also means that after the cooldown period, they can reduce their stake to 10% of the half deposit amount (16ETH), then perform a voluntary exit on ETH2 so that the minipool becomes `withdrawable`. If they end up with less than the `userDepositBalance` in staking rewards, they would only get slashed the `1.6 ETH` at max (10% of 16ETH half deposit amount for 1 minipool) even though they incurred a loss that may be up to 32 ETH (empty Minipool empty amount).\\nFurthermore, if a node operator runs multiple minipools, let's say 5, then they would have to provide at least `5*16ETH*0.1 = 8ETH` as a security guarantee in the form of staked RPL. If the node operator incurs a loss with one of their minipools, their 8 ETH RPL stake will likely be slashed in full. Their other - still operating - minipools are not backed by any RPL anymore, and they effectively cannot be slashed anymore. This means that a malicious node operator can create multiple minipools, stake the minimum amount of RPL, get slashed for one minipool, and still operate the others without having the minimum RPL needed to run the minipools staked (getNodeMinipoolLimit).\\nThe RPL stake is donated to the RocketAuctionManager, where they can attempt to buy back RPL potentially at a discount.\\nNote: Staking more RPL (e.g., to add another Minipool) resets the cooldown period for the total RPL staked (not only for the newly added)чIt is recommended to redesign the withdrawal process to prevent users from withdrawing their stake while slashable actions can still occur. A potential solution may be to add a locking period in the process. A node operator may schedule the withdrawal of funds, and after a certain time has passed, may withdraw them. This prevents the immediate withdrawal of funds that may need to be reduced while slashable events can still occur. E.g.:\\nA node operator requests to withdraw all but the minimum required stake to run their pools.\\nThe funds are scheduled for withdrawal and locked until a period of X days has passed.\\n(optional) In this period, a slashable event occurs. The funds for compensation are taken from the user's stake including the funds scheduled for withdrawal.\\nAfter the time has passed, the node operator may call a function to trigger the withdrawal and get paid out.чч```\\nrocketMinipoolManager.setMinipoolWithdrawalBalances(\\_minipoolAddress, \\_stakingEndBalance, nodeAmount);\\n// Apply node penalties by liquidating RPL stake\\nif (\\_stakingEndBalance < userDepositBalance) {\\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\\n    rocketNodeStaking.slashRPL(minipool.getNodeAddress(), userDepositBalance - \\_stakingEndBalance);\\n}\\n```\\n
RocketTokenRPL - inaccurate inflation rate and potential for manipulation lowering the real APYчhighчRocketTokenRPL allows users to swap their fixed-rate tokens to the inflationary RocketTokenRPL ERC20 token via a `swapToken` function. The DAO defines the inflation rate of this token and is initially set to be 5% APY. This APY is configured as a daily inflation rate (APD) with the corresponding `1 day in blocks` inflation interval in the `rocketDAOProtocolSettingsInflation` contract. The DAO members control the inflation settings.\\nAnyone can call `inflationMintTokens` to inflate the token, which mints tokens to the contracts RocketVault. Tokens are minted for discreet intervals since the last time `inflationMintTokens` was called (recorded as inflationCalcBlock). The inflation is then calculated for the passed intervals without taking the current not yet completed interval. However, the `inflationCalcBlock` is set to the current `block.number`, effectively skipping some “time”/blocks of the APY calculation.\\nThe more often `inflationMintTokens` is called, the higher the APY likelihood dropping below the configured 5%. In the worst case, one could manipulate the APY down to 2.45% (assuming that the APD for a 5% APY was configured) by calling `inflationMintTokens` close to the end of every second interval. This would essentially restart the APY interval at `block.number`, skipping blocks of the current interval that have not been accounted for.\\nThe following diagram illustrates the skipped blocks due to the incorrect recording of `inflationCalcBlock` as `block.number`. The example assumes that we are in interval 4 but have not completed it. `3` APD intervals have passed, and this is what the inflation rate is based on. However, the `inflationCalcBlock` is updated to the current `block.number`, skipping some time/blocks that are now unaccounted in the APY restarting the 4th interval at `block.number`.\\n\\nNote: updating the inflation rate will directly affect past inflation intervals that have not been minted! this might be undesirable, and it could be considered to force an inflation mint if the APY changes\\nNote: if the interval is small enough and there is a history of unaccounted intervals to be minted, and the Ethereum network is congested, gas fees may be high and block limits hit, the calculations in the for loop might be susceptible to DoS the inflation mechanism because of gas constraints.\\nNote: The inflation seems only to be triggered regularly on `RocketRewardsPool.claim` (or at any point by external actors). If the price establishes based on the total supply of tokens, then this may give attackers an opportunity to front-run other users trading large amounts of RPL that may previously have calculated their prices based on the un-inflated supply.\\nNote: that the discrete interval-based inflation (e.g., once a day) might create dynamics that put pressure on users to trade their RPL in windows instead of consecutively\\nthe inflation intervals passed is the number of completed intervals. The current interval that is started is not included.\\n```\\nfunction getInlfationIntervalsPassed() override public view returns(uint256) {\\n    // The block that inflation was last calculated at\\n    uint256 inflationLastCalculatedBlock = getInflationCalcBlock();\\n    // Get the daily inflation in blocks\\n    uint256 inflationInterval = getInflationIntervalBlocks();\\n    // Calculate now if inflation has begun\\n    if(inflationLastCalculatedBlock > 0) {\\n        return (block.number).sub(inflationLastCalculatedBlock).div(inflationInterval);\\n    }else{\\n        return 0;\\n    }\\n}\\n```\\n\\nthe inflation calculation calculates the to-be-minted tokens for the inflation rate at `newTokens = supply * rateAPD^intervals - supply`\\n```\\nfunction inflationCalculate() override public view returns (uint256) {\\n    // The inflation amount\\n    uint256 inflationTokenAmount = 0;\\n    // Optimisation\\n    uint256 inflationRate = getInflationIntervalRate();\\n    // Compute the number of inflation intervals elapsed since the last time we minted infation tokens\\n    uint256 intervalsSinceLastMint = getInlfationIntervalsPassed();\\n    // Only update if last interval has passed and inflation rate is > 0\\n    if(intervalsSinceLastMint > 0 && inflationRate > 0) {\\n        // Our inflation rate\\n        uint256 rate = inflationRate;\\n        // Compute inflation for total inflation intervals elapsed\\n        for (uint256 i = 1; i < intervalsSinceLastMint; i++) {\\n            rate = rate.mul(inflationRate).div(10 \\*\\* 18);\\n        }\\n        // Get the total supply now\\n        uint256 totalSupplyCurrent = totalSupply();\\n        // Return inflation amount\\n        inflationTokenAmount = totalSupplyCurrent.mul(rate).div(10 \\*\\* 18).sub(totalSupplyCurrent);\\n    }\\n    // Done\\n    return inflationTokenAmount;\\n}\\n```\\nчProperly track `inflationCalcBlock` as the end of the previous interval, as this is up to where the inflation was calculated, instead of the block at which the method was invoked.\\nEnsure APY/APD and interval configuration match up. Ensure the interval is not too small (potential gas DoS blocking inflation mint and RocketRewardsPool.claim).чч```\\nfunction getInlfationIntervalsPassed() override public view returns(uint256) {\\n    // The block that inflation was last calculated at\\n    uint256 inflationLastCalculatedBlock = getInflationCalcBlock();\\n    // Get the daily inflation in blocks\\n    uint256 inflationInterval = getInflationIntervalBlocks();\\n    // Calculate now if inflation has begun\\n    if(inflationLastCalculatedBlock > 0) {\\n        return (block.number).sub(inflationLastCalculatedBlock).div(inflationInterval);\\n    }else{\\n        return 0;\\n    }\\n}\\n```\\n
RocketDAONodeTrustedUpgrade - upgrade does not prevent the use of the same address multiple times creating an inconsistency where getContractAddress returns outdated informationчhighчWhen adding a new contract, it is checked whether the address is already in use. This check is missing when upgrading a named contract to a new implementation, potentially allowing someone to register one address to multiple names creating an inconsistent configuration.\\nThe crux of this is, that, `getContractAddress()` will now return a contract address that is not registered anymore (while `getContractName` may throw). `getContractAddress` can therefore not relied upon when checking ACL.\\nadd contract `name=test, address=0xfefe` –>\\n```\\n sets contract.exists.0xfefe=true\\n sets contract.name.0xfefe=test\\n sets contract.address.test=0xfefe\\n sets contract.abi.test=abi\\n```\\n\\nadd another contract `name=badcontract, address=0xbadbad` –>\\n```\\nsets contract.exists.0xbadbad=true\\nsets contract.name.0xbadbad=badcontract\\nsets contract.address.badcontract=0xbadbad\\nsets contract.abi.badcontract=abi\\n```\\n\\nupdate contract `name=test, address=0xbadbad` reusing badcontradcts address, the address is now bound to 2 names (test, badcontract)\\n```\\noverwrites contract.exists.0xbadbad=true` (even though its already true)\\nupdates contract.name.0xbadbad=test (overwrites the reference to badcontract; badcontracts config is now inconsistent)\\nupdates contract.address.test=0xbadbad (ok, expected)\\nupdates contract.abi.test=abi (ok, expected)\\nremoves contract.name.0xfefe (ok)\\nremoves contract.exists.0xfefe (ok)\\n```\\n\\nupdate contract `name=test, address=0xc0c0`\\n```\\nsets contract.exists.0xc0c0=true\\nsets contract.name.0xc0c0=test (ok, expected)\\nupdates contract.address.test=0xc0c0 (ok, expected)\\nupdates contract.abi.test=abi (ok, expected)\\nremoves contract.name.0xbadbad (the contract is still registered as badcontract, but is indirectly removed now)\\nremoves contract.exists.0xbadbad (the contract is still registered as badcontract, but is indirectly removed now)\\n```\\n\\nAfter this, `badcontract` is partially cleared, `getContractName(0xbadbad)` throws while `getContractAddress(badcontract)` returns `0xbadbad` which is already unregistered (contract.exists.0xbadbad=false)\\n```\\n(removed) contract.exists.0xbadbad\\n(removed) contract.name.0xbadbad=badcontract\\nsets contract.address.badcontract=0xbadbad\\nsets contract.abi.badcontract=abi\\n```\\n\\ncheck in `_addContract``\\n```\\nrequire(\\_contractAddress != address(0x0), \"Invalid contract address\");\\n```\\n\\nno checks in `upgrade.`\\n```\\nrequire(\\_contractAddress != address(0x0), \"Invalid contract address\");\\nrequire(\\_contractAddress != oldContractAddress, \"The contract address cannot be set to its current address\");\\n// Register new contract\\nsetBool(keccak256(abi.encodePacked(\"contract.exists\", \\_contractAddress)), true);\\nsetString(keccak256(abi.encodePacked(\"contract.name\", \\_contractAddress)), \\_name);\\nsetAddress(keccak256(abi.encodePacked(\"contract.address\", \\_name)), \\_contractAddress);\\nsetString(keccak256(abi.encodePacked(\"contract.abi\", \\_name)), \\_contractAbi);\\n```\\nчResolution\\nA check has been introduced to make sure that the new contract address is not already in use by checking against the corresponding `contract.exists` storage key.\\nCheck that the address being upgraded to is not yet registered and properly clean up `contract.address.<name|abi>`.чч```\\n sets contract.exists.0xfefe=true\\n sets contract.name.0xfefe=test\\n sets contract.address.test=0xfefe\\n sets contract.abi.test=abi\\n```\\n
RocketStorage - Risk concentration by giving all registered contracts permissions to change any settings in RocketStorage  AcknowledgedчhighчThe ACL for changing settings in the centralized `RocketStorage` allows any registered contract (listed under contract.exists) to change settings that belong to other parts of the system.\\nThe concern is that if someone finds a way to add their malicious contract to the registered contact list, they will override any setting in the system. The storage is authoritative when checking certain ACLs. Being able to set any value might allow an attacker to gain control of the complete system. Allowing any contract to overwrite other contracts' settings dramatically increases the attack surface.\\n```\\nmodifier onlyLatestRocketNetworkContract() {\\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\\n        // Make sure the access is permitted to only contracts in our Dapp\\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\\n    }\\n    \\_;\\n}\\n```\\n\\n```\\nfunction setAddress(bytes32 \\_key, address \\_value) onlyLatestRocketNetworkContract override external {\\n    addressStorage[\\_key] = \\_value;\\n}\\n\\n/// @param \\_key The key for the record\\nfunction setUint(bytes32 \\_key, uint \\_value) onlyLatestRocketNetworkContract override external {\\n    uIntStorage[\\_key] = \\_value;\\n}\\n```\\nчResolution\\nThe client provided the following statement:\\nWe've looked at adding access control contracts using namespaces, but the increase in gas usage would be significant and could hinder upgrades.\\nAllow contracts to only change settings related to their namespace.чч```\\nmodifier onlyLatestRocketNetworkContract() {\\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\\n        // Make sure the access is permitted to only contracts in our Dapp\\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\\n    }\\n    \\_;\\n}\\n```\\n
RocketDAOProposals - require a minimum participation quorum for DAO proposalsчmediumчIf the DAO falls below the minimum viable membership threshold, voting for proposals still continues as DAO proposals do not require a minimum participation quorum. In the worst case, this would allow the last standing DAO member to create a proposal that would be passable with only one vote even if new members would be immediately ready to join via the recovery mode (which has its own risks) as the minimum votes requirement for proposals is set as `>0`.\\n```\\nrequire(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\\n```\\n\\n```\\nfunction propose(string memory \\_proposalMessage, bytes memory \\_payload) override public onlyTrustedNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrustedProposals\", address(this)) returns (uint256) {\\n    // Load contracts\\n    RocketDAOProposalInterface daoProposal = RocketDAOProposalInterface(getContractAddress('rocketDAOProposal'));\\n    RocketDAONodeTrustedInterface daoNodeTrusted = RocketDAONodeTrustedInterface(getContractAddress('rocketDAONodeTrusted'));\\n    RocketDAONodeTrustedSettingsProposalsInterface rocketDAONodeTrustedSettingsProposals = RocketDAONodeTrustedSettingsProposalsInterface(getContractAddress(\"rocketDAONodeTrustedSettingsProposals\"));\\n    // Check this user can make a proposal now\\n    require(daoNodeTrusted.getMemberLastProposalBlock(msg.sender).add(rocketDAONodeTrustedSettingsProposals.getCooldown()) <= block.number, \"Member has not waited long enough to make another proposal\");\\n    // Record the last time this user made a proposal\\n    setUint(keccak256(abi.encodePacked(daoNameSpace, \"member.proposal.lastblock\", msg.sender)), block.number);\\n    // Create the proposal\\n    return daoProposal.add(msg.sender, 'rocketDAONodeTrustedProposals', \\_proposalMessage, block.number.add(rocketDAONodeTrustedSettingsProposals.getVoteDelayBlocks()), rocketDAONodeTrustedSettingsProposals.getVoteBlocks(), rocketDAONodeTrustedSettingsProposals.getExecuteBlocks(), daoNodeTrusted.getMemberQuorumVotesRequired(), \\_payload);\\n}\\n```\\n\\nSidenote: Since a proposals acceptance quorum is recorded on proposal creation, this may lead to another scenario where proposals acceptance quorum may never be reached if members leave the DAO. This would require a re-submission of the proposal.чDo not accept proposals if the member count falls below the minimum DAO membercount threshold.чч```\\nrequire(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\\n```\\n
RocketDAONodeTrustedUpgrade - inconsistent upgrade blacklistчmediumч`upgradeContract` defines a hardcoded list of contracts that cannot be upgraded because they manage their own settings (statevars) or they hold value in the system.\\nthe list is hardcoded and cannot be extended when new contracts are added via `addcontract`. E.g. what if another contract holding value is added to the system? This would require an upgrade of the upgrade contract to update the whitelist (gas hungry, significant risk of losing access to the upgrade mechanisms if a bug is being introduced).\\na contract named `rocketPoolToken` is blacklisted from being upgradeable but the system registers no contract called `rocketPoolToken`. This may be an oversight or artifact of a previous iteration of the code. However, it may allow a malicious group of nodes to add a contract that is not yet in the system which cannot be removed anymore as there is no `removeContract` functionality and `upgradeContract` to override the malicious contract will fail due to the blacklist.\\nNote that upgrading `RocketTokenRPL` requires an account balance migration as contracts in the system may hold value in `RPL` (e.g. a lot in AuctionManager) that may vanish after an upgrade. The contract is not exempt from upgrading. A migration may not be easy to perform as the system cannot be paused to e.g. snapshot balances.\\n```\\nfunction \\_upgradeContract(string memory \\_name, address \\_contractAddress, string memory \\_contractAbi) internal {\\n    // Check contract being upgraded\\n    bytes32 nameHash = keccak256(abi.encodePacked(\\_name));\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketVault\")),        \"Cannot upgrade the vault\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketPoolToken\")),    \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenRETH\")),     \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenNETH\")), \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"casperDeposit\")),      \"Cannot upgrade the casper deposit contract\");\\n    // Get old contract address & check contract exists\\n```\\nчConsider implementing a whitelist of contracts that are allowed to be upgraded instead of a more error-prone blacklist of contracts that cannot be upgraded.\\nProvide documentation that outlines what contracts are upgradeable and why.\\nCreate a process to verify the blacklist before deploying/operating the system.\\nPlan for migration paths when upgrading contracts in the system\\nAny proposal that reaches the upgrade contract must be scrutinized for potential malicious activity (e.g. as any registered contract can directly modify storage or may contain subtle backdoors. Upgrading without performing a thorough security inspection may easily put the DAO at risk)чч```\\nfunction \\_upgradeContract(string memory \\_name, address \\_contractAddress, string memory \\_contractAbi) internal {\\n    // Check contract being upgraded\\n    bytes32 nameHash = keccak256(abi.encodePacked(\\_name));\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketVault\")),        \"Cannot upgrade the vault\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketPoolToken\")),    \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenRETH\")),     \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenNETH\")), \"Cannot upgrade token contracts\");\\n    require(nameHash != keccak256(abi.encodePacked(\"casperDeposit\")),      \"Cannot upgrade the casper deposit contract\");\\n    // Get old contract address & check contract exists\\n```\\n
RocketMinipoolStatus - DAO Membership changes can result in votes getting stuckчmediumчChanges in the DAO's trusted node members are reflected in the `RocketDAONodeTrusted.getMemberCount()` function. When compared with the vote on consensus threshold, a DAO-driven decision is made, e.g., when updating token price feeds and changing Minipool states.\\nEspecially in the early phase of the DAO, the functions below can get stuck as execution is restricted to DAO members who have not voted yet. Consider the following scenario:\\nThe DAO consists of five members\\nTwo members vote to make a Minipool withdrawable\\nThe other three members are inactive, the community votes, and they get kicked from the DAO\\nThe two remaining members have no way to change the Minipool state now. All method calls to trigger the state update fails because the members have already voted before.\\nNote: votes of members that are kicked/leave are still count towards the quorum!\\nSetting a Minipool into the withdrawable state:\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\\n}\\n```\\n\\nSubmitting a block's network balances:\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    updateBalances(\\_block, \\_totalEth, \\_stakingEth, \\_rethSupply);\\n}\\n```\\n\\nSubmitting a block's RPL price information:\\n```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    updatePrices(\\_block, \\_rplPrice);\\n}\\n```\\nчResolution\\nThis issue has been fixed in PR https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/204 by introducing a public method that allows anyone to manually trigger a DAO consensus threshold check and a subsequent balance update in case the issue's example scenario occurs.\\nThe conditional check and update of price feed information, Minipool state transition, etc., should be externalized into a separate public function. This function is also called internally in the existing code. In case the DAO gets into the scenario above, anyone can call the function to trigger a reevaluation of the condition with updated membership numbers and thus get the process unstuck.чч```\\nRocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\\n}\\n```\\n
Trusted/Oracle-Nodes can vote multiple times for different outcomesчmediumчTrusted/oracle nodes submit various ETH2 observations to the RocketPool contracts. When 51% of nodes submitted the same observation, the result is stored in the contract. However, while it is recorded that a node already voted for a specific minipool (being withdrawable & balance) or block (price/balance), a re-submission with different parameters for the same minipool/block is not rejected.\\nSince the oracle values should be distinct, clear, and there can only be one valid value, it should not be allowed for trusted nodes to change their mind voting for multiple different outcomes within one block or one minipool\\n`RocketMinipoolStatus` - a trusted node can submit multiple different results for one minipool\\nNote that `setBool(keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, _minipoolAddress)), true);` is recorded but never checked. (as for the other two instances)\\n```\\n// Get submission keys\\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.count\", \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\\n// Check & update node submission status\\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\\nsetBool(nodeSubmissionKey, true);\\nsetBool(keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress)), true);\\n// Increment submission count\\nuint256 submissionCount = getUint(submissionCountKey).add(1);\\nsetUint(submissionCountKey, submissionCount);\\n```\\n\\n`RocketNetworkBalances` - a trusted node can submit multiple different results for the balances at a specific block\\n```\\n// Get submission keys\\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"network.balances.submitted.node\", msg.sender, \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply));\\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"network.balances.submitted.count\", \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply));\\n// Check & update node submission status\\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\\nsetBool(nodeSubmissionKey, true);\\nsetBool(keccak256(abi.encodePacked(\"network.balances.submitted.node\", msg.sender, \\_block)), true);\\n// Increment submission count\\nuint256 submissionCount = getUint(submissionCountKey).add(1);\\nsetUint(submissionCountKey, submissionCount);\\n// Emit balances submitted event\\nemit BalancesSubmitted(msg.sender, \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply, block.timestamp);\\n// Check submission count & update network balances\\n```\\n\\n`RocketNetworkPrices` - a trusted node can submit multiple different results for the price at a specific block\\n```\\n// Get submission keys\\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"network.prices.submitted.node\", msg.sender, \\_block, \\_rplPrice));\\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"network.prices.submitted.count\", \\_block, \\_rplPrice));\\n// Check & update node submission status\\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\\nsetBool(nodeSubmissionKey, true);\\nsetBool(keccak256(abi.encodePacked(\"network.prices.submitted.node\", msg.sender, \\_block)), true);\\n// Increment submission count\\nuint256 submissionCount = getUint(submissionCountKey).add(1);\\nsetUint(submissionCountKey, submissionCount);\\n// Emit prices submitted event\\nemit PricesSubmitted(msg.sender, \\_block, \\_rplPrice, block.timestamp);\\n// Check submission count & update network prices\\n```\\nчOnly allow one vote per minipool/block. Don't give nodes the possibility to vote multiple times for different outcomes.чч```\\n// Get submission keys\\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.count\", \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\\n// Check & update node submission status\\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\\nsetBool(nodeSubmissionKey, true);\\nsetBool(keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress)), true);\\n// Increment submission count\\nuint256 submissionCount = getUint(submissionCountKey).add(1);\\nsetUint(submissionCountKey, submissionCount);\\n```\\n
RocketTokenNETH - Pot. discrepancy between minted tokens and deposited collateralчmediumчThe `nETH` token is paid to node operators when minipool becomes withdrawable. `nETH` is supposed to be backed by `ETH` 1:1. However, in most cases, this will not be the case.\\nThe `nETH` minting and deposition of collateral happens in two different stages of a minipool. `nETH` is minted in the minipool state transition from `Staking` to `Withdrawable` when the trusted/oracle nodes find consensus on the fact that the minipool became withdrawable (submitWinipoolWithdrawable).\\n```\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\\n}\\n```\\n\\nWhen consensus is found on the state of the `minipool`, `nETH` tokens are minted to the `minipool` address according to the withdrawal amount observed by the trusted/oracle nodes. At this stage, `ETH` backing the newly minted `nETH` was not yet provided.\\n```\\nuint256 nodeAmount = getMinipoolNodeRewardAmount(\\n    minipool.getNodeFee(),\\n    userDepositBalance,\\n    minipool.getStakingStartBalance(),\\n    minipool.getStakingEndBalance()\\n);\\n// Mint nETH to minipool contract\\nif (nodeAmount > 0) { rocketTokenNETH.mint(nodeAmount, \\_minipoolAddress); }\\n```\\n\\nThe `nETH` token contract now holds more `nETH.totalsupply` than actual `ETH` collateral. It is out of sync with the `ETH` reserve and therefore becomes undercollateralized. This should generally be avoided as the security guarantees that for every `nETH` someone deposited, `ETH` does not hold. However, the newly minted `nETH` is locked to the `minipoolAddress`, and the minipool has no means of redeeming the `nETH` for `ETH` directly (via nETH.burn()).\\nThe transition from Withdrawable to `Destroyed` the actual collateral for the previously minted `nETH` (still locked to minipoolAddress) is provided by the `Eth2` withdrawal contract. There is no specification for the withdrawal contract as of now. Still, it is assumed that some entity triggers the payout for the `Eth2` rewards on the withdrawal contract, which sends the amount of `ETH` to the configured withdrawal address (the minipoolAddress).\\nThe `minipool.receive()` function receives the `ETH`\\n```\\nreceive() external payable {\\n    (bool success, bytes memory data) = getContractAddress(\"rocketMinipoolDelegate\").delegatecall(abi.encodeWithSignature(\"receiveValidatorBalance()\"));\\n    if (!success) { revert(getRevertMessage(data)); }\\n}\\n```\\n\\nand forwards it to `minipooldelegate.receiveValidatorBalance`\\n```\\nrequire(msg.sender == rocketDAOProtocolSettingsNetworkInterface.getSystemWithdrawalContractAddress(), \"The minipool's validator balance can only be sent by the eth1 system withdrawal contract\");\\n// Set validator balance withdrawn status\\nvalidatorBalanceWithdrawn = true;\\n// Process validator withdrawal for minipool\\nrocketNetworkWithdrawal.processWithdrawal{value: msg.value}();\\n```\\n\\nWhich calculates the `nodeAmount` based on the `ETH` received and submits it as collateral to back the previously minted `nodeAmount` of `nETH`.\\n```\\nuint256 totalShare = rocketMinipoolManager.getMinipoolWithdrawalTotalBalance(msg.sender);\\nuint256 nodeShare = rocketMinipoolManager.getMinipoolWithdrawalNodeBalance(msg.sender);\\nuint256 userShare = totalShare.sub(nodeShare);\\n// Get withdrawal amounts based on shares\\nuint256 nodeAmount = 0;\\nuint256 userAmount = 0;\\nif (totalShare > 0) {\\n    nodeAmount = msg.value.mul(nodeShare).div(totalShare);\\n    userAmount = msg.value.mul(userShare).div(totalShare);\\n}\\n// Set withdrawal processed status\\nrocketMinipoolManager.setMinipoolWithdrawalProcessed(msg.sender);\\n// Transfer node balance to nETH contract\\nif (nodeAmount > 0) { rocketTokenNETH.depositRewards{value: nodeAmount}(); }\\n// Transfer user balance to rETH contract or deposit pool\\n```\\n\\nLooking at how the `nodeAmount` of `nETH` that was minted was calculated and comparing it to how `nodeAmount` of `ETH` is calculated, we can observe the following:\\nthe `nodeAmount` of `nETH` minted is an absolute number of tokens based on the rewards observed by the trusted/oracle nodes. the `nodeAmount` is stored in the storage and later used to calculate the collateral deposit in a later step.\\nthe `nodeAmount` calculated when depositing the collateral is first assumed to be a `nodeShare` (line 47), while it is actually an absolute number. the `nodeShare` is then turned into a `nodeAmount` relative to the `ETH` supplied to the contract.\\nDue to rounding errors, this might not always exactly match the `nETH` minted (see https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/26).\\nThe collateral calculation is based on the `ETH` value provided to the contract. If this value does not exactly match what was reported by the oracle/trusted nodes when minting `nETH`, less/more collateral will be provided.\\nNote: excess collateral will be locked in the `nETH` contract as it is unaccounted for in the `nETH` token contract and therefore cannot be redeemed.\\nNote: providing less collateral will go unnoticed and mess up the 1:1 `nETH:ETH` peg. In the worst case, there will be less `nETH` than `ETH`. Not everybody will be able to redeem their `ETH`.\\nNote: keep in mind that the `receive()` function might be subject to gas restrictions depending on the implementation of the withdrawal contract (.call() vs. .transfer())\\nThe `nETH` minted is initially uncollateralized and locked to the `minipoolAddress`, which cannot directly redeem it for `ETH`. The next step (next stage) is collateralized with the staking rewards (which, as noted, might not always completely add up to the minted nETH). At the last step in `withdraw()`, the `nETH` is transferred to the `withdrawalAddress` of the minipool.\\n```\\nuint256 nethBalance = rocketTokenNETH.balanceOf(address(this));\\nif (nethBalance > 0) {\\n    // Get node withdrawal address\\n    RocketNodeManagerInterface rocketNodeManager = RocketNodeManagerInterface(getContractAddress(\"rocketNodeManager\"));\\n    address nodeWithdrawalAddress = rocketNodeManager.getNodeWithdrawalAddress(nodeAddress);\\n    // Transfer\\n    require(rocketTokenNETH.transfer(nodeWithdrawalAddress, nethBalance), \"nETH balance was not successfully transferred to node operator\");\\n    // Emit nETH withdrawn event\\n    emit NethWithdrawn(nodeWithdrawalAddress, nethBalance, block.timestamp);\\n}\\n```\\n\\nSince the `nETH` initially minted can never take part in the `nETH` token market (as it is locked to the minipool address, which can only transfer it to the withdrawal address in the last step), the question arises why it is actually minted early in the lifecycle of the minipool. At the same time, it could as well be just directly minted to `withdrawalAddress` when providing the right amount of collateral in the last step of the minipool lifecycle. Furthermore, if `nETH` is minted at this stage, it should be questioned why `nETH` is actually needed when you can directly forward the `nodeAmount` to the `withdrawalAddress` instead of minting an intermediary token that is pegged 1:1 to `ETH`.\\nFor reference, `depositRewards` (providing collateral) and `mint` are not connected at all, hence the risk of `nETH` being an undercollateralized token.\\n```\\nfunction depositRewards() override external payable onlyLatestContract(\"rocketNetworkWithdrawal\", msg.sender) {\\n    // Emit ether deposited event\\n    emit EtherDeposited(msg.sender, msg.value, block.timestamp);\\n}\\n\\n// Mint nETH\\n// Only accepts calls from the RocketMinipoolStatus contract\\nfunction mint(uint256 \\_amount, address \\_to) override external onlyLatestContract(\"rocketMinipoolStatus\", msg.sender) {\\n    // Check amount\\n    require(\\_amount > 0, \"Invalid token mint amount\");\\n    // Update balance & supply\\n    \\_mint(\\_to, \\_amount);\\n    // Emit tokens minted event\\n    emit TokensMinted(\\_to, \\_amount, block.timestamp);\\n}\\n```\\nчIt looks like `nETH` might not be needed at all, and it should be discussed if the added complexity of having a potentially out-of-sync `nETH` token contract is necessary and otherwise remove it from the contract system as the `nodeAmount` of `ETH` can directly be paid out to the `withdrawalAddress` in the `receiveValidatorBalance` or `withdraw` transitions.\\nIf `nETH` cannot be removed, consider minting `nodeAmount` of `nETH` directly to `withdrawalAddress` on `withdraw` instead of first minting uncollateralized tokens. This will also reduce the gas footprint of the Minipool.\\nEnsure that the initial `nodeAmount` calculation matches the minted `nETH` and deposited to the contract as collateral (absolute amount vs. fraction).\\nEnforce that `nETH` requires collateral to be provided when minting tokens.чч```\\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\\n}\\n```\\n
RocketMiniPoolDelegate - on destroy() leftover ETH is sent to RocketVault where it cannot be recoveredчmediumчWhen destroying the `MiniPool`, leftover `ETH` is sent to the `RocketVault`. Since `RocketVault` has no means to recover “unaccounted” `ETH` (not deposited via depositEther), funds forcefully sent to the vault will end up being locked.\\n```\\n// Destroy the minipool\\nfunction destroy() private {\\n    // Destroy minipool\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    rocketMinipoolManager.destroyMinipool();\\n    // Self destruct & send any remaining ETH to vault\\n    selfdestruct(payable(getContractAddress(\"rocketVault\")));\\n}\\n```\\nчImplement means to recover and reuse `ETH` that was forcefully sent to the contract by `MiniPool` instances.чч```\\n// Destroy the minipool\\nfunction destroy() private {\\n    // Destroy minipool\\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\\n    rocketMinipoolManager.destroyMinipool();\\n    // Self destruct & send any remaining ETH to vault\\n    selfdestruct(payable(getContractAddress(\"rocketVault\")));\\n}\\n```\\n
RocketDAO - personally identifiable member information (PII) stored on-chain  AcknowledgedчmediumчLike a DAO user's e-mail address, PII is stored on-chain and can, therefore, be accessed by anyone. This may allow de-pseudonymize users (and correlate Ethereum addresses to user email addresses) and be used for spamming or targeted phishing campaigns putting the DAO users at risk.\\nrocketpool-go-2.5-Tokenomics/dao/trustednode/dao.go:L173-L183\\n```\\n// Return\\nreturn MemberDetails{\\n    Address: memberAddress,\\n    Exists: exists,\\n    ID: id,\\n    Email: email,\\n    JoinedBlock: joinedBlock,\\n    LastProposalBlock: lastProposalBlock,\\n    RPLBondAmount: rplBondAmount,\\n    UnbondedValidatorCount: unbondedValidatorCount,\\n}, nil\\n```\\n\\n```\\nfunction getMemberEmail(address \\_nodeAddress) override public view returns (string memory) {\\n    return getString(keccak256(abi.encodePacked(daoNameSpace, \"member.email\", \\_nodeAddress))); \\n}\\n```\\nчAvoid storing PII on-chain where it is readily available for anyone.чч```\\n// Return\\nreturn MemberDetails{\\n    Address: memberAddress,\\n    Exists: exists,\\n    ID: id,\\n    Email: email,\\n    JoinedBlock: joinedBlock,\\n    LastProposalBlock: lastProposalBlock,\\n    RPLBondAmount: rplBondAmount,\\n    UnbondedValidatorCount: unbondedValidatorCount,\\n}, nil\\n```\\n
RocketPoolMinipool - should check for address(0x0)чmediumчThe two implementations for `getContractAddress()` in `Minipool/Delegate` are not checking whether the requested contract's address was ever set before. If it were never set, the method would return `address(0x0)`, which would silently make all delegatecalls succeed without executing any code. In contrast, `RocketBase.getContractAddress()` fails if the requested contract is not known.\\nIt should be noted that this can happen if `rocketMinipoolDelegate` is not set in global storage, or it was cleared afterward, or if `_rocketStorageAddress` points to a contract that implements a non-throwing fallback function (may not even be storage at all).\\nMissing checks\\n```\\nfunction getContractAddress(string memory \\_contractName) private view returns (address) {\\n    return rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\\n}\\n```\\n\\n```\\nfunction getContractAddress(string memory \\_contractName) private view returns (address) {\\n    return rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\\n}\\n```\\n\\nChecks implemented\\n```\\nfunction getContractAddress(string memory \\_contractName) internal view returns (address) {\\n    // Get the current contract address\\n    address contractAddress = getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\\n    // Check it\\n    require(contractAddress != address(0x0), \"Contract not found\");\\n    // Return\\n    return contractAddress;\\n}\\n```\\nчResolution\\nAddressed in branch `rp3.0-updates` (rocket-pool/[email protected]b424ca1) by changing requiring that the contract address is not `0x0`.\\nSimilar to `RocketBase.getContractAddress()` require that the contract is set.чч```\\nfunction getContractAddress(string memory \\_contractName) private view returns (address) {\\n    return rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\\n}\\n```\\n
RocketDAONodeTrustedAction - ambiguous event emitted in actionChallengeDecideчlowч`actionChallengeDecide` succeeds and emits `challengeSuccess=False` in case the challenged node defeats the challenge. It also emits the same event if another node calls `actionChallengeDecided` before the refute window passed. This ambiguity may make a defeated challenge indistinguishable from a challenge that was attempted to be decided too early (unless the component listening for the event also checks the refute window).\\n```\\n    // Allow the challenged member to refute the challenge at anytime. If the window has passed and the challenge node does not run this method, any member can decide the challenge and eject the absent member\\n    // Is it the node being challenged?\\n    if(\\_nodeAddress == msg.sender) {\\n        // Challenge is defeated, node has responded\\n        deleteUint(keccak256(abi.encodePacked(daoNameSpace, \"member.challenged.block\", \\_nodeAddress)));\\n    }else{\\n        // The challenge refute window has passed, the member can be ejected now\\n        if(getUint(keccak256(abi.encodePacked(daoNameSpace, \"member.challenged.block\", \\_nodeAddress))).add(rocketDAONodeTrustedSettingsMembers.getChallengeWindow()) < block.number) {\\n            // Node has been challenged and failed to respond in the given window, remove them as a member and their bond is burned\\n            \\_memberRemove(\\_nodeAddress);\\n            // Challenge was successful\\n            challengeSuccess = true;\\n        }\\n    }\\n    // Log it\\n    emit ActionChallengeDecided(\\_nodeAddress, msg.sender, challengeSuccess, block.timestamp);\\n}\\n```\\nчAvoid ambiguities when emitting events. Consider throwing an exception in the else branch if the refute window has not passed yet (minimal gas savings; it's clear that the call failed; other components can rely on the event only being emitted if there was a decision.чч```\\n    // Allow the challenged member to refute the challenge at anytime. If the window has passed and the challenge node does not run this method, any member can decide the challenge and eject the absent member\\n    // Is it the node being challenged?\\n    if(\\_nodeAddress == msg.sender) {\\n        // Challenge is defeated, node has responded\\n        deleteUint(keccak256(abi.encodePacked(daoNameSpace, \"member.challenged.block\", \\_nodeAddress)));\\n    }else{\\n        // The challenge refute window has passed, the member can be ejected now\\n        if(getUint(keccak256(abi.encodePacked(daoNameSpace, \"member.challenged.block\", \\_nodeAddress))).add(rocketDAONodeTrustedSettingsMembers.getChallengeWindow()) < block.number) {\\n            // Node has been challenged and failed to respond in the given window, remove them as a member and their bond is burned\\n            \\_memberRemove(\\_nodeAddress);\\n            // Challenge was successful\\n            challengeSuccess = true;\\n        }\\n    }\\n    // Log it\\n    emit ActionChallengeDecided(\\_nodeAddress, msg.sender, challengeSuccess, block.timestamp);\\n}\\n```\\n
RocketDAOProtocolProposals, RocketDAONodeTrustedProposals - unused enum ProposalTypeчlowчThe enum `ProposalType` is defined but never used.\\n```\\nenum ProposalType {\\n    Invite,             // Invite a registered node to join the trusted node DAO\\n    Leave,              // Leave the DAO\\n    Replace,            // Replace a current trusted node with a new registered node, they take over their bond\\n    Kick,               // Kick a member from the DAO with optional penalty applied to their RPL deposit\\n    Setting             // Change a DAO setting (Quorum threshold, RPL deposit size, voting periods etc)\\n}\\n```\\n\\n```\\nenum ProposalType {\\n    Setting             // Change a DAO setting (Node operator min/max fees, inflation rate etc)\\n}\\n```\\nчRemove unnecessary code.чч```\\nenum ProposalType {\\n    Invite,             // Invite a registered node to join the trusted node DAO\\n    Leave,              // Leave the DAO\\n    Replace,            // Replace a current trusted node with a new registered node, they take over their bond\\n    Kick,               // Kick a member from the DAO with optional penalty applied to their RPL deposit\\n    Setting             // Change a DAO setting (Quorum threshold, RPL deposit size, voting periods etc)\\n}\\n```\\n
RocketDaoNodeTrusted - Unused eventsчlowчThe `MemberJoined` `MemberLeave` events are not used within `RocketDaoNodeTrusted`.\\n```\\n// Events\\nevent MemberJoined(address indexed \\_nodeAddress, uint256 \\_rplBondAmount, uint256 time); \\nevent MemberLeave(address indexed \\_nodeAddress, uint256 \\_rplBondAmount, uint256 time);\\n```\\nчConsider removing the events. Note: `RocketDAONodeTrustedAction` is emitting `ActionJoin` and `ActionLeave` event.sчч```\\n// Events\\nevent MemberJoined(address indexed \\_nodeAddress, uint256 \\_rplBondAmount, uint256 time); \\nevent MemberLeave(address indexed \\_nodeAddress, uint256 \\_rplBondAmount, uint256 time);\\n```\\n
RocketDAOProposal - expired, and defeated proposals can be canceledчlowчThe `RocketDAOProposal.getState` function defaults a proposal's state to `ProposalState.Defeated`. While this fallback can be considered secure, the remaining code does not perform checks that prevent defeated proposals from changing their state. As such, a user can transition a proposal that is `Expired` or `Defeated` to `Cancelled` by using the `RocketDAOProposal.cancel` function. This can be used to deceive users and potentially bias future votes.\\nThe method emits an event that might trigger other components to perform actions.\\n```\\n} else {\\n    // Check the votes, was it defeated?\\n    // if (votesFor <= votesAgainst || votesFor < getVotesRequired(\\_proposalID))\\n    return ProposalState.Defeated;\\n}\\n```\\n\\n```\\nfunction cancel(address \\_member, uint256 \\_proposalID) override public onlyDAOContract(getDAO(\\_proposalID)) {\\n    // Firstly make sure this proposal that hasn't already been executed\\n    require(getState(\\_proposalID) != ProposalState.Executed, \"Proposal has already been executed\");\\n    // Make sure this proposal hasn't already been successful\\n    require(getState(\\_proposalID) != ProposalState.Succeeded, \"Proposal has already succeeded\");\\n    // Only allow the proposer to cancel\\n    require(getProposer(\\_proposalID) == \\_member, \"Proposal can only be cancelled by the proposer\");\\n    // Set as cancelled now\\n    setBool(keccak256(abi.encodePacked(daoProposalNameSpace, \"cancelled\", \\_proposalID)), true);\\n    // Log it\\n    emit ProposalCancelled(\\_proposalID, \\_member, block.timestamp);\\n}\\n```\\nчPreserve the true outcome. Do not allow to cancel proposals that are already in an end-state like `canceled`, `expired`, `defeated`.чч```\\n} else {\\n    // Check the votes, was it defeated?\\n    // if (votesFor <= votesAgainst || votesFor < getVotesRequired(\\_proposalID))\\n    return ProposalState.Defeated;\\n}\\n```\\n
RocketDAOProposal - preserve the proposals correct state after expirationчlowчThe state of proposals is resolved to give a preference to a proposal being `expired` over the actual result which may be `defeated`. The preference for a proposal's status is checked in order: `cancelled? -> executed? -> `expired`? -> succeeded? -> pending? -> active? -> `defeated` (default)`\\n```\\nif (getCancelled(\\_proposalID)) {\\n    // Cancelled by the proposer?\\n    return ProposalState.Cancelled;\\n    // Has it been executed?\\n} else if (getExecuted(\\_proposalID)) {\\n    return ProposalState.Executed;\\n    // Has it expired?\\n} else if (block.number >= getExpires(\\_proposalID)) {\\n    return ProposalState.Expired;\\n    // Vote was successful, is now awaiting execution\\n} else if (votesFor >= getVotesRequired(\\_proposalID)) {\\n    return ProposalState.Succeeded;\\n    // Is the proposal pending? Eg. waiting to be voted on\\n} else if (block.number <= getStart(\\_proposalID)) {\\n    return ProposalState.Pending;\\n    // The proposal is active and can be voted on\\n} else if (block.number <= getEnd(\\_proposalID)) {\\n    return ProposalState.Active;\\n} else {\\n    // Check the votes, was it defeated?\\n    // if (votesFor <= votesAgainst || votesFor < getVotesRequired(\\_proposalID))\\n    return ProposalState.Defeated;\\n}\\n```\\nчconsider checking for `voteAgainst` explicitly and return `defeated` instead of `expired` if a proposal was `defeated` and is queried after expiration. Preserve the actual proposal result.чч```\\nif (getCancelled(\\_proposalID)) {\\n    // Cancelled by the proposer?\\n    return ProposalState.Cancelled;\\n    // Has it been executed?\\n} else if (getExecuted(\\_proposalID)) {\\n    return ProposalState.Executed;\\n    // Has it expired?\\n} else if (block.number >= getExpires(\\_proposalID)) {\\n    return ProposalState.Expired;\\n    // Vote was successful, is now awaiting execution\\n} else if (votesFor >= getVotesRequired(\\_proposalID)) {\\n    return ProposalState.Succeeded;\\n    // Is the proposal pending? Eg. waiting to be voted on\\n} else if (block.number <= getStart(\\_proposalID)) {\\n    return ProposalState.Pending;\\n    // The proposal is active and can be voted on\\n} else if (block.number <= getEnd(\\_proposalID)) {\\n    return ProposalState.Active;\\n} else {\\n    // Check the votes, was it defeated?\\n    // if (votesFor <= votesAgainst || votesFor < getVotesRequired(\\_proposalID))\\n    return ProposalState.Defeated;\\n}\\n```\\n
RocketRewardsPool - registerClaimer should check if a node is already disabled before decrementing rewards.pool.claim.interval.claimers.total.nextчlowчThe other branch in `registerClaimer` does not check whether the provided `_claimerAddress` is already disabled (or invalid). This might lead to inconsistencies where `rewards.pool.claim.interval.claimers.total.next` is decremented because the caller provided an already deactivated address.\\nThis issue is flagged as `minor` since we have not found an exploitable version of this issue in the current codebase. However, we recommend safeguarding the implementation instead of relying on the caller to provide sane parameters. Registered Nodes cannot unregister, and Trusted Nodes are unregistered when they leave.\\n```\\nfunction registerClaimer(address \\_claimerAddress, bool \\_enabled) override external onlyClaimContract {\\n    // The name of the claiming contract\\n    string memory contractName = getContractName(msg.sender);\\n    // Record the block they are registering at\\n    uint256 registeredBlock = 0;\\n    // How many users are to be included in next interval\\n    uint256 claimersIntervalTotalUpdate = getClaimingContractUserTotalNext(contractName);\\n    // Ok register\\n    if(\\_enabled) {\\n        // Make sure they are not already registered\\n        require(getClaimingContractUserRegisteredBlock(contractName, \\_claimerAddress) == 0, \"Claimer is already registered\");\\n        // Update block number\\n        registeredBlock = block.number;\\n        // Update the total registered claimers for next interval\\n        setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.interval.claimers.total.next\", contractName)), claimersIntervalTotalUpdate.add(1));\\n    }else{\\n        setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.interval.claimers.total.next\", contractName)), claimersIntervalTotalUpdate.sub(1));\\n    }\\n    // Save the registered block\\n    setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.contract.registered.block\", contractName, \\_claimerAddress)), registeredBlock);\\n}\\n```\\nчEnsure that `getClaimingContractUserRegisteredBlock(contractName, _claimerAddress)` returns `!=0` before decrementing the `.total.next`.чч```\\nfunction registerClaimer(address \\_claimerAddress, bool \\_enabled) override external onlyClaimContract {\\n    // The name of the claiming contract\\n    string memory contractName = getContractName(msg.sender);\\n    // Record the block they are registering at\\n    uint256 registeredBlock = 0;\\n    // How many users are to be included in next interval\\n    uint256 claimersIntervalTotalUpdate = getClaimingContractUserTotalNext(contractName);\\n    // Ok register\\n    if(\\_enabled) {\\n        // Make sure they are not already registered\\n        require(getClaimingContractUserRegisteredBlock(contractName, \\_claimerAddress) == 0, \"Claimer is already registered\");\\n        // Update block number\\n        registeredBlock = block.number;\\n        // Update the total registered claimers for next interval\\n        setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.interval.claimers.total.next\", contractName)), claimersIntervalTotalUpdate.add(1));\\n    }else{\\n        setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.interval.claimers.total.next\", contractName)), claimersIntervalTotalUpdate.sub(1));\\n    }\\n    // Save the registered block\\n    setUint(keccak256(abi.encodePacked(\"rewards.pool.claim.contract.registered.block\", contractName, \\_claimerAddress)), registeredBlock);\\n}\\n```\\n
RocketNetworkPrices - Price feed update lacks block number sanity checkчlowчTrusted nodes submit the RPL price feed. The function is called specifying a block number and the corresponding RPL price for that block. If a DAO vote goes through for that block-price combination, it is written to storage. In the unlikely scenario that a vote confirms a very high block number such as `uint(-1)`, all future price updates will fail due to the `require` check below.\\nThis issue becomes less likely the more active members the DAO has. Thus, it's considered a minor issue that mainly affects the initial bootstrapping process.\\n```\\n// Check block\\nrequire(\\_block > getPricesBlock(), \"Network prices for an equal or higher block are set\");\\n```\\nчThe function's `_block` parameter should be checked to prevent large block numbers from being submitted. This check could, e.g., specify that node operators are only allowed to submit price updates for a maximum of x blocks ahead of `block.number`.чч```\\n// Check block\\nrequire(\\_block > getPricesBlock(), \"Network prices for an equal or higher block are set\");\\n```\\n
RocketDepositPool - Potential gasDoS in assignDeposits  Acknowledgedчlowч`assignDeposits` seems to be a gas heavy function, with many external calls in general, and few of them are inside the for loop itself. By default, `rocketDAOProtocolSettingsDeposit.getMaximumDepositAssignments()` returns `2`, which is not a security concern. Through a DAO vote, the settings key `deposit.assign.maximum` can be set to a value that exhausts the block gas limit and effectively deactivates the deposit assignment process.\\n```\\nfor (uint256 i = 0; i < rocketDAOProtocolSettingsDeposit.getMaximumDepositAssignments(); ++i) {\\n    // Get & check next available minipool capacity\\n```\\nчThe `rocketDAOProtocolSettingsDeposit.getMaximumDepositAssignments()` return value could be cached outside the loop. Additionally, a check should be added that prevents unreasonably high values.чч```\\nfor (uint256 i = 0; i < rocketDAOProtocolSettingsDeposit.getMaximumDepositAssignments(); ++i) {\\n    // Get & check next available minipool capacity\\n```\\n
RocketNetworkWithdrawal - ETH dust lockup due to rounding errorsчlowчThere's a potential `ETH` dust lockup when processing a withdrawal due to rounding errors when performing a division.\\n```\\nuint256 totalShare = rocketMinipoolManager.getMinipoolWithdrawalTotalBalance(msg.sender);\\nuint256 nodeShare = rocketMinipoolManager.getMinipoolWithdrawalNodeBalance(msg.sender);\\nuint256 userShare = totalShare.sub(nodeShare);\\n// Get withdrawal amounts based on shares\\nuint256 nodeAmount = 0;\\nuint256 userAmount = 0;\\nif (totalShare > 0) {\\n    nodeAmount = msg.value.mul(nodeShare).div(totalShare);\\n    userAmount = msg.value.mul(userShare).div(totalShare);\\n}\\n```\\nчCalculate `userAmount` as `msg.value - nodeAmount` instead. This should also save some gas.чч```\\nuint256 totalShare = rocketMinipoolManager.getMinipoolWithdrawalTotalBalance(msg.sender);\\nuint256 nodeShare = rocketMinipoolManager.getMinipoolWithdrawalNodeBalance(msg.sender);\\nuint256 userShare = totalShare.sub(nodeShare);\\n// Get withdrawal amounts based on shares\\nuint256 nodeAmount = 0;\\nuint256 userAmount = 0;\\nif (totalShare > 0) {\\n    nodeAmount = msg.value.mul(nodeShare).div(totalShare);\\n    userAmount = msg.value.mul(userShare).div(totalShare);\\n}\\n```\\n
RocketAuctionManager - calcBase should be declared constantчlowчDeclaring the same constant value `calcBase` multiple times as local variables to some methods in `RocketAuctionManager` carries the risk that if that value is ever updated, one of the value assignments might be missed. It is therefore highly recommended to reduce duplicate code and declare the value as a public constant. This way, it is clear that the same `calcBase` is used throughout the contract, and there is a single point of change in case it ever needs to be changed.\\n```\\nfunction getLotPriceByTotalBids(uint256 \\_index) override public view returns (uint256) {\\n    uint256 calcBase = 1 ether;\\n    return calcBase.mul(getLotTotalBidAmount(\\_index)).div(getLotTotalRPLAmount(\\_index));\\n}\\n```\\n\\n```\\nfunction getLotClaimedRPLAmount(uint256 \\_index) override public view returns (uint256) {\\n    uint256 calcBase = 1 ether;\\n    return calcBase.mul(getLotTotalBidAmount(\\_index)).div(getLotCurrentPrice(\\_index));\\n}\\n```\\n\\n```\\n// Calculation base value\\nuint256 calcBase = 1 ether;\\n```\\n\\n```\\nuint256 bidAmount = msg.value;\\nuint256 calcBase = 1 ether;\\n```\\n\\n```\\n// Calculate RPL claim amount\\nuint256 calcBase = 1 ether;\\nuint256 rplAmount = calcBase.mul(bidAmount).div(currentPrice);\\n```\\nчConsider declaring `calcBase` as a private const state var instead of re-declaring it with the same value in multiple, multiple functions. Constant, literal state vars are replaced in a preprocessing step and do not require significant additional gas when accessed than normal state vars.чч```\\nfunction getLotPriceByTotalBids(uint256 \\_index) override public view returns (uint256) {\\n    uint256 calcBase = 1 ether;\\n    return calcBase.mul(getLotTotalBidAmount(\\_index)).div(getLotTotalRPLAmount(\\_index));\\n}\\n```\\n
RocketDAO* - daoNamespace is missing a trailing dot; should be declared constant/immutableчlowч`string private daoNameSpace = 'dao.trustednodes'` is missing a trailing dot, or else there's no separator when concatenating the namespace with the vars.\\nrequests `dao.trustednodesmember.index` instead of `dao.trustednodes.member.index`\\n```\\nfunction getMemberAt(uint256 \\_index) override public view returns (address) {\\n    AddressSetStorageInterface addressSetStorage = AddressSetStorageInterface(getContractAddress(\"addressSetStorage\"));\\n    return addressSetStorage.getItem(keccak256(abi.encodePacked(daoNameSpace, \"member.index\")), \\_index);\\n}\\n```\\n\\n```\\n// The namespace for any data stored in the trusted node DAO (do not change)\\nstring private daoNameSpace = 'dao.trustednodes';\\n```\\n\\n```\\n// Calculate using this as the base\\nuint256 private calcBase = 1 ether;\\n\\n// The namespace for any data stored in the trusted node DAO (do not change)\\nstring private daoNameSpace = 'dao.trustednodes';\\n```\\n\\n```\\n// The namespace for any data stored in the network DAO (do not change)\\nstring private daoNameSpace = 'dao.protocol';\\n```\\nчRemove the `daoNameSpace` and add the prefix to the respective variables directly.чч```\\nfunction getMemberAt(uint256 \\_index) override public view returns (address) {\\n    AddressSetStorageInterface addressSetStorage = AddressSetStorageInterface(getContractAddress(\"addressSetStorage\"));\\n    return addressSetStorage.getItem(keccak256(abi.encodePacked(daoNameSpace, \"member.index\")), \\_index);\\n}\\n```\\n
RocketVault - consider rejecting zero amount deposit/withdrawal requestsчlowчConsider disallowing zero amount token transfers unless the system requires this to work. In most cases, zero amount token transfers will emit an event (that potentially triggers off-chain components). In some cases, they allow the caller without holding any balance to call back to themselves (pot. reentrancy) or the caller provided token address.\\n`depositEther` allows to deposit zero ETH\\nemits `EtherDeposited`\\n`withdrawEther` allows to withdraw zero ETH\\ncalls back to `withdrawer` (msg.sender)!\\nemits `EtherWithdrawn`\\n(depositToken checks for amount >0)\\n`withdrawToken` allows zero amount token withdrawals\\ncalls into user provided (actually a network contract) tokenAddress)\\nemits `TokenWithdrawn`\\n`transferToken` allows zero amount token transfers\\nemits `TokenTransfer`\\n```\\nfunction depositEther() override external payable onlyLatestNetworkContract {\\n    // Get contract key\\n    bytes32 contractKey = keccak256(abi.encodePacked(getContractName(msg.sender)));\\n    // Update contract balance\\n    etherBalances[contractKey] = etherBalances[contractKey].add(msg.value);\\n    // Emit ether deposited event\\n    emit EtherDeposited(contractKey, msg.value, block.timestamp);\\n}\\n```\\nчZero amount transfers are no-operation calls in most cases and should be avoided. However, as all vault actions are authenticated (to registered system contracts), the risk of something going wrong is rather low. Nevertheless, it is recommended to deny zero amount transfers to avoid running code unnecessarily (gas consumption), emitting unnecessary events, or potentially call back to callers/token address for ineffective transfers.чч```\\nfunction depositEther() override external payable onlyLatestNetworkContract {\\n    // Get contract key\\n    bytes32 contractKey = keccak256(abi.encodePacked(getContractName(msg.sender)));\\n    // Update contract balance\\n    etherBalances[contractKey] = etherBalances[contractKey].add(msg.value);\\n    // Emit ether deposited event\\n    emit EtherDeposited(contractKey, msg.value, block.timestamp);\\n}\\n```\\n
RocketVault - methods returning static return values and unchecked return parametersчlowчThe `Token*` methods in `RocketVault` either throw or return `true`, but they can never return `false`. If the method fails, it will always throw. Therefore, it is questionable if the static return value is needed at all. Furthermore, callees are in most cases not checking the return value of\\nstatic return value `true`\\n```\\n// Emit token transfer\\nemit TokenDeposited(contractKey, \\_tokenAddress, \\_amount, block.timestamp);\\n// Done\\nreturn true;\\n```\\n\\n```\\nemit TokenWithdrawn(contractKey, \\_tokenAddress, \\_amount, block.timestamp);\\n// Done\\nreturn true;\\n```\\n\\n```\\n// Emit token withdrawn event\\nemit TokenTransfer(contractKeyFrom, contractKeyTo, \\_tokenAddress, \\_amount, block.timestamp);\\n// Done\\nreturn true;\\n```\\n\\nreturn value not checked\\n```\\nrocketVault.depositToken(\"rocketNodeStaking\", rplTokenAddress, \\_amount);\\n// Update RPL stake amounts & node RPL staked block\\n```\\n\\n```\\nrocketVault.withdrawToken(msg.sender, getContractAddress(\"rocketTokenRPL\"), rplAmount);\\n```\\n\\n```\\nrocketVault.withdrawToken(msg.sender, getContractAddress(\"rocketTokenRPL\"), \\_amount);\\n```\\n\\n```\\nrocketVault.transferToken(\"rocketAuctionManager\", getContractAddress(\"rocketTokenRPL\"), rplSlashAmount);\\n```\\nчDefine a clear interface for these functions. Remove the static return value in favor of having the method throw on failure (which is already the current behavior).чч```\\n// Emit token transfer\\nemit TokenDeposited(contractKey, \\_tokenAddress, \\_amount, block.timestamp);\\n// Done\\nreturn true;\\n```\\n
RocketMinipoolDelegate - enforce that the delegate contract cannot be called directlyчlowчThis contract is not meant to be consumed directly and will only be delegate called from `Minipool`. Being able to call it directly might even create the problem that, in the worst case, someone might be able to `selfdestruct` the contract rendering all other contracts that link to it dysfunctional. This might even not be easily detectable because `delegatecall` to an EOA will act as a NOP.\\nThe access control checks on the methods currently prevent methods from being called directly on the delegate. They require state variables to be set correctly, or the delegate is registered as a valid minipool in the system. Both conditions are improbable to be fulfilled, hence, mitigation any security risk. However, it looks like this is more of a side-effect than a design decision, and we would recommend not explicitly stating that the delegate contract cannot be used directly.\\n```\\nconstructor(address \\_rocketStorageAddress) {\\n    // Initialise RocketStorage\\n    require(\\_rocketStorageAddress != address(0x0), \"Invalid storage address\");\\n    rocketStorage = RocketStorageInterface(\\_rocketStorageAddress);\\n}\\n```\\nчResolution\\nAddressed in branch `rp3.0-updates` (rocket-pool/[email protected]b424ca1) by removing the constructor and therefore the initialization code from the RocketMinipoolDelegate contract. The contract cannot be used directly anymore as all relevant methods are decorated `onlyInitialised` and there is no way to initialize it in the implementation directly.\\nRemove the initialization from the constructor in the delegate contract. Consider adding a flag that indicates that the delegate contract is initialized and only set in the Minipool contract and not in the logic contract (delegate). On calls, check that the contract is initialized.чч```\\nconstructor(address \\_rocketStorageAddress) {\\n    // Initialise RocketStorage\\n    require(\\_rocketStorageAddress != address(0x0), \"Invalid storage address\");\\n    rocketStorage = RocketStorageInterface(\\_rocketStorageAddress);\\n}\\n```\\n
Re-entrancy issue for ERC1155чhighчERC1155 tokens have callback functions on some of the transfers, like `safeTransferFrom`, `safeBatchTransferFrom`. During these transfers, the `IERC1155ReceiverUpgradeable(to).onERC1155Received` function is called in the `to` address.\\nFor example, `safeTransferFrom` is used in the `LiquidityMining` contract:\\n```\\nfunction distributeAllNFT() external {\\n    require(block.timestamp > getEndLMTime(),\\n        \"2 weeks after liquidity mining time has not expired\");\\n    require(!isNFTDistributed, \"NFT is already distributed\");\\n\\n    for (uint256 i = 0; i < leaderboard.length; i++) {\\n        address[] memory \\_groupLeaders = groupsLeaders[leaderboard[i]];\\n\\n        for (uint256 j = 0; j < \\_groupLeaders.length; j++) {\\n            \\_sendNFT(j, \\_groupLeaders[j]);\\n        }\\n    }\\n\\n    for (uint256 i = 0; i < topUsers.length; i++) {\\n        address \\_currentAddress = topUsers[i];\\n        LMNFT.safeTransferFrom(address(this), \\_currentAddress, 1, 1, \"\");\\n        emit NFTSent(\\_currentAddress, 1);\\n    }\\n\\n    isNFTDistributed = true;\\n}\\n```\\n\\nDuring that transfer, the `distributeAllNFT` function can be called again and again. So multiple transfers will be done for each user.\\nIn addition to that, any receiver of the tokens can revert the transfer. If that happens, nobody will be able to receive their tokens.чAdd a reentrancy guard.\\nAvoid transferring tokens for different receivers in a single transaction.чч```\\nfunction distributeAllNFT() external {\\n    require(block.timestamp > getEndLMTime(),\\n        \"2 weeks after liquidity mining time has not expired\");\\n    require(!isNFTDistributed, \"NFT is already distributed\");\\n\\n    for (uint256 i = 0; i < leaderboard.length; i++) {\\n        address[] memory \\_groupLeaders = groupsLeaders[leaderboard[i]];\\n\\n        for (uint256 j = 0; j < \\_groupLeaders.length; j++) {\\n            \\_sendNFT(j, \\_groupLeaders[j]);\\n        }\\n    }\\n\\n    for (uint256 i = 0; i < topUsers.length; i++) {\\n        address \\_currentAddress = topUsers[i];\\n        LMNFT.safeTransferFrom(address(this), \\_currentAddress, 1, 1, \"\");\\n        emit NFTSent(\\_currentAddress, 1);\\n    }\\n\\n    isNFTDistributed = true;\\n}\\n```\\n
Winning pods can be frontrun with large depositsчhighч`Pod.depositTo()` grants users shares of the pod pool in exchange for `tokenAmount` of `token`.\\n```\\nfunction depositTo(address to, uint256 tokenAmount)\\n    external\\n    override\\n    returns (uint256)\\n{\\n    require(tokenAmount > 0, \"Pod:invalid-amount\");\\n\\n    // Allocate Shares from Deposit To Amount\\n    uint256 shares = \\_deposit(to, tokenAmount);\\n\\n    // Transfer Token Transfer Message Sender\\n    IERC20Upgradeable(token).transferFrom(\\n        msg.sender,\\n        address(this),\\n        tokenAmount\\n    );\\n\\n    // Emit Deposited\\n    emit Deposited(to, tokenAmount, shares);\\n\\n    // Return Shares Minted\\n    return shares;\\n}\\n```\\n\\nThe winner of a prize pool is typically determined by an off-chain random number generator, which requires a request to first be made on-chain. The result of this RNG request can be seen in the mempool and frontrun. In this case, an attacker could identify a winning `Pod` contract and make a large deposit, diluting existing user shares and claiming the entire prize.чThe modifier `pauseDepositsDuringAwarding` is included in the `Pod` contract but is unused.\\n```\\nmodifier pauseDepositsDuringAwarding() {\\n    require(\\n        !IPrizeStrategyMinimal(\\_prizePool.prizeStrategy()).isRngRequested(),\\n        \"Cannot deposit while prize is being awarded\"\\n    );\\n    \\_;\\n}\\n```\\n\\nAdd this modifier to the `depositTo()` function along with corresponding test cases.чч```\\nfunction depositTo(address to, uint256 tokenAmount)\\n    external\\n    override\\n    returns (uint256)\\n{\\n    require(tokenAmount > 0, \"Pod:invalid-amount\");\\n\\n    // Allocate Shares from Deposit To Amount\\n    uint256 shares = \\_deposit(to, tokenAmount);\\n\\n    // Transfer Token Transfer Message Sender\\n    IERC20Upgradeable(token).transferFrom(\\n        msg.sender,\\n        address(this),\\n        tokenAmount\\n    );\\n\\n    // Emit Deposited\\n    emit Deposited(to, tokenAmount, shares);\\n\\n    // Return Shares Minted\\n    return shares;\\n}\\n```\\n
TokenDrop: Unprotected initialize() functionчhighчThe `TokenDrop.initialize()` function is unprotected and can be called multiple times.\\n```\\nfunction initialize(address \\_measure, address \\_asset) external {\\n    measure = IERC20Upgradeable(\\_measure);\\n    asset = IERC20Upgradeable(\\_asset);\\n\\n    // Set Factory Deployer\\n    factory = msg.sender;\\n}\\n```\\n\\nAmong other attacks, this would allow an attacker to re-initialize any `TokenDrop` with the same `asset` and a malicious `measure` token. By manipulating the balance of a user in this malicious `measure` token, the entire `asset` token balance of the `TokenDrop` contract could be drained.чAdd the `initializer` modifier to the `initialize()` function and include an explicit test that every initialization function in the system can be called once and only once.чч```\\nfunction initialize(address \\_measure, address \\_asset) external {\\n    measure = IERC20Upgradeable(\\_measure);\\n    asset = IERC20Upgradeable(\\_asset);\\n\\n    // Set Factory Deployer\\n    factory = msg.sender;\\n}\\n```\\n
Pod: Re-entrancy during deposit or withdrawal can lead to stealing fundsчhighчDuring the deposit, the token transfer is made after the Pod shares are minted:\\n```\\nuint256 shares = \\_deposit(to, tokenAmount);\\n\\n// Transfer Token Transfer Message Sender\\nIERC20Upgradeable(token).transferFrom(\\n    msg.sender,\\n    address(this),\\n    tokenAmount\\n);\\n```\\n\\nThat means that if the `token` allows re-entrancy, the attacker can deposit one more time inside the `token` transfer. If that happens, the second call will mint more tokens than it is supposed to, because the first `token` transfer will still not be finished. By doing so with big amounts, it's possible to drain the pod.чAdd re-entrancy guard to the external functions.чч```\\nuint256 shares = \\_deposit(to, tokenAmount);\\n\\n// Transfer Token Transfer Message Sender\\nIERC20Upgradeable(token).transferFrom(\\n    msg.sender,\\n    address(this),\\n    tokenAmount\\n);\\n```\\n
TokenDrop: Re-entrancy in the claim function can cause to draining fundsчhighчIf the `asset` token is making a call before the `transfer` to the `receiver` or to any other 3-d party contract (like it's happening in the `Pod` token using the `_beforeTokenTransfer` function), the attacker can call the `drop` function inside the `transfer` call here:\\n```\\nfunction claim(address user) external returns (uint256) {\\n    drop();\\n    \\_captureNewTokensForUser(user);\\n    uint256 balance = userStates[user].balance;\\n    userStates[user].balance = 0;\\n    totalUnclaimed = uint256(totalUnclaimed).sub(balance).toUint112();\\n\\n    // Transfer asset/reward token to user\\n    asset.transfer(user, balance);\\n\\n    // Emit Claimed\\n    emit Claimed(user, balance);\\n\\n    return balance;\\n}\\n```\\n\\nBecause the `totalUnclaimed` is already changed, but the current balance is not, the `drop` function will consider the funds from the unfinished transfer as the new tokens. These tokens will be virtually redistributed to everyone.\\nAfter that, the transfer will still happen, and further calls of the `drop()` function will fail because the following line will revert:\\n`uint256 newTokens = assetTotalSupply.sub(totalUnclaimed);`\\nThat also means that any transfers of the `Pod` token will fail because they all are calling the `drop` function. The `TokenDrop` will “unfreeze” only if someone transfers enough tokens to the `TokenDrop` contract.\\nThe severity of this issue is hard to evaluate because, at the moment, there's not a lot of tokens that allow this kind of re-entrancy.чSimply adding re-entrancy guard to the `drop` and the `claim` function won't help because the `drop` function is called from the `claim`. For that, the transfer can be moved to a separate function, and this function can have the re-entrancy guard as well as the `drop` function.\\nAlso, it's better to make sure that `_beforeTokenTransfer` will not revert to prevent the token from being frozen.чч```\\nfunction claim(address user) external returns (uint256) {\\n    drop();\\n    \\_captureNewTokensForUser(user);\\n    uint256 balance = userStates[user].balance;\\n    userStates[user].balance = 0;\\n    totalUnclaimed = uint256(totalUnclaimed).sub(balance).toUint112();\\n\\n    // Transfer asset/reward token to user\\n    asset.transfer(user, balance);\\n\\n    // Emit Claimed\\n    emit Claimed(user, balance);\\n\\n    return balance;\\n}\\n```\\n
Pod: Having multiple token drops is inconsistentчmediumчThe `Pod` contract had the `drop` storage field and mapping of different TokenDrops `(token => TokenDrop)`. When adding a new `TokenDrop` in the mapping, the `drop` field is also changed to the added _tokenDrop:\\n```\\nfunction setTokenDrop(address \\_token, address \\_tokenDrop)\\n    external\\n    returns (bool)\\n{\\n    require(\\n        msg.sender == factory || msg.sender == owner(),\\n        \"Pod:unauthorized-set-token-drop\"\\n    );\\n\\n    // Check if target<>tokenDrop mapping exists\\n    require(\\n        drops[\\_token] == TokenDrop(0),\\n        \"Pod:target-tokendrop-mapping-exists\"\\n    );\\n\\n    // Set TokenDrop Referance\\n    drop = TokenDrop(\\_tokenDrop);\\n\\n    // Set target<>tokenDrop mapping\\n    drops[\\_token] = drop;\\n\\n    return true;\\n}\\n```\\n\\nOn the other hand, the `measure` token and the `asset` token of the `drop` are strictly defined by the Pod contract. They cannot be changed, so all `TokenDrops` are supposed to have the same `asset` and `measure` tokens. So it is useless to have different `TokenDrops`.чThe mapping seems to be unused, and only one `TokenDrop` will normally be in the system. If that code is not used, it should be deleted.чч```\\nfunction setTokenDrop(address \\_token, address \\_tokenDrop)\\n    external\\n    returns (bool)\\n{\\n    require(\\n        msg.sender == factory || msg.sender == owner(),\\n        \"Pod:unauthorized-set-token-drop\"\\n    );\\n\\n    // Check if target<>tokenDrop mapping exists\\n    require(\\n        drops[\\_token] == TokenDrop(0),\\n        \"Pod:target-tokendrop-mapping-exists\"\\n    );\\n\\n    // Set TokenDrop Referance\\n    drop = TokenDrop(\\_tokenDrop);\\n\\n    // Set target<>tokenDrop mapping\\n    drops[\\_token] = drop;\\n\\n    return true;\\n}\\n```\\n
Pod: Fees are not limited by a user during the withdrawalчmediumчWhen withdrawing from the Pod, the shares are burned, and the deposit is removed from the Pod. If there are not enough deposit tokens in the contract, the remaining tokens are withdrawn from the pool contract:\\n```\\nif (amount > currentBalance) {\\n    // Calculate Withdrawl Amount\\n    uint256 \\_withdraw = amount.sub(currentBalance);\\n\\n    // Withdraw from Prize Pool\\n    uint256 exitFee = \\_withdrawFromPool(\\_withdraw);\\n\\n    // Add Exit Fee to Withdrawl Amount\\n    amount = amount.sub(exitFee);\\n}\\n```\\n\\nThese tokens are withdrawn with a fee from the pool, which is not controlled or limited by the user.чAllow users to pass a `maxFee` parameter to control fees.чч```\\nif (amount > currentBalance) {\\n    // Calculate Withdrawl Amount\\n    uint256 \\_withdraw = amount.sub(currentBalance);\\n\\n    // Withdraw from Prize Pool\\n    uint256 exitFee = \\_withdrawFromPool(\\_withdraw);\\n\\n    // Add Exit Fee to Withdrawl Amount\\n    amount = amount.sub(exitFee);\\n}\\n```\\n
Pod.setManager() checks validity of wrong addressчlowчThe function `Pod.setManager()` allows the `owner` of the Pod contract to change the Pod's `manager`. It checks that the value of the existing `manager` in storage is nonzero. This is presumably intended to ensure that the `owner` has provided a valid `newManager` parameter in calldata.\\nThe current check will always pass once the contract is initialized with a nonzero `manager`. But, the contract can currently be initialized with a `manager` of `IPodManager(address(0))`. In this case, the check would prevent the `manager` from ever being updated.\\n```\\nfunction setManager(IPodManager newManager)\\n    public\\n    virtual\\n    onlyOwner\\n    returns (bool)\\n{\\n    // Require Valid Address\\n    require(address(manager) != address(0), \"Pod:invalid-manager-address\");\\n```\\nчChange the check to:\\n```\\nrequire(address(newManager) != address(0), \"Pod:invalid-manager-address\");\\n```\\n\\nMore generally, attempt to define validity criteria for all input values that are as strict as possible. Consider preventing zero inputs or inputs that might conflict with other addresses in the smart contract system altogether, including in contract initialization functions.чч```\\nfunction setManager(IPodManager newManager)\\n    public\\n    virtual\\n    onlyOwner\\n    returns (bool)\\n{\\n    // Require Valid Address\\n    require(address(manager) != address(0), \"Pod:invalid-manager-address\");\\n```\\n
Reuse of CHAINID from contract deploymentчlowчThe internal function `_validateWithdrawSignature()` is used to check whether a sponsored token withdrawal is approved by the owner of the stealth address that received the tokens. Among other data, the chain ID is signed over to prevent replay of signatures on other EVM-compatible chains.\\n```\\nfunction \\_validateWithdrawSignature(\\n  address \\_stealthAddr,\\n  address \\_acceptor,\\n  address \\_tokenAddr,\\n  address \\_sponsor,\\n  uint256 \\_sponsorFee,\\n  IUmbraHookReceiver \\_hook,\\n  bytes memory \\_data,\\n  uint8 \\_v,\\n  bytes32 \\_r,\\n  bytes32 \\_s\\n) internal view {\\n  bytes32 \\_digest =\\n    keccak256(\\n      abi.encodePacked(\\n        \"\\x19Ethereum Signed Message:\\n32\",\\n        keccak256(abi.encode(chainId, version, \\_acceptor, \\_tokenAddr, \\_sponsor, \\_sponsorFee, address(\\_hook), \\_data))\\n      )\\n    );\\n\\n  address \\_recoveredAddress = ecrecover(\\_digest, \\_v, \\_r, \\_s);\\n  require(\\_recoveredAddress != address(0) && \\_recoveredAddress == \\_stealthAddr, \"Umbra: Invalid Signature\");\\n}\\n```\\n\\nHowever, this chain ID is set as an immutable value in the contract constructor. In the case of a future contentious hard fork of the Ethereum network, the same `Umbra` contract would exist on both of the resulting chains. One of these two chains would be expected to change the network's chain ID, but the `Umbra` contracts would not be aware of this change. As a result, signatures to the `Umbra` contract on either chain would be replayable on the other chain.\\nThis is a common pattern in contracts that implement EIP-712 signatures. Presumably, the motivation in most cases for committing to the chain ID at deployment time is to avoid recomputing the EIP-712 domain separator for every signature verification. In this case, the chain ID is a direct input to the generation of the signed digest, so this should not be a concern.чReplace the use of the `chainId` immutable value with the `CHAINID` opcode in `_validateWithdrawSignature()`. Note that `CHAINID` is only available using Solidity's inline assembly, so this would need to be accessed in the same way as it is currently accessed in the contract's constructor:\\n```\\nuint256 \\_chainId;\\n\\nassembly {\\n  \\_chainId := chainid()\\n}\\n```\\nчч```\\nfunction \\_validateWithdrawSignature(\\n  address \\_stealthAddr,\\n  address \\_acceptor,\\n  address \\_tokenAddr,\\n  address \\_sponsor,\\n  uint256 \\_sponsorFee,\\n  IUmbraHookReceiver \\_hook,\\n  bytes memory \\_data,\\n  uint8 \\_v,\\n  bytes32 \\_r,\\n  bytes32 \\_s\\n) internal view {\\n  bytes32 \\_digest =\\n    keccak256(\\n      abi.encodePacked(\\n        \"\\x19Ethereum Signed Message:\\n32\",\\n        keccak256(abi.encode(chainId, version, \\_acceptor, \\_tokenAddr, \\_sponsor, \\_sponsorFee, address(\\_hook), \\_data))\\n      )\\n    );\\n\\n  address \\_recoveredAddress = ecrecover(\\_digest, \\_v, \\_r, \\_s);\\n  require(\\_recoveredAddress != address(0) && \\_recoveredAddress == \\_stealthAddr, \"Umbra: Invalid Signature\");\\n}\\n```\\n
Random task executionчhighчIn a scenario where user takes a flash loan, `_parseFLAndExecute()` gives the flash loan wrapper contract (FLAaveV2, FLDyDx) the permission to execute functions on behalf of the user's `DSProxy`. This execution permission is revoked only after the entire recipe execution is finished, which means that in case that any of the external calls along the recipe execution is malicious, it might call `executeAction()` back and inject any task it wishes (e.g. take user's funds out, drain approved tokens, etc)\\n```\\nfunction executeOperation(\\n    address[] memory \\_assets,\\n    uint256[] memory \\_amounts,\\n    uint256[] memory \\_fees,\\n    address \\_initiator,\\n    bytes memory \\_params\\n) public returns (bool) {\\n    require(msg.sender == AAVE\\_LENDING\\_POOL, ERR\\_ONLY\\_AAVE\\_CALLER);\\n    require(\\_initiator == address(this), ERR\\_SAME\\_CALLER);\\n\\n    (Task memory currTask, address proxy) = abi.decode(\\_params, (Task, address));\\n\\n    // Send FL amounts to user proxy\\n    for (uint256 i = 0; i < \\_assets.length; ++i) {\\n        \\_assets[i].withdrawTokens(proxy, \\_amounts[i]);\\n    }\\n\\n    address payable taskExecutor = payable(registry.getAddr(TASK\\_EXECUTOR\\_ID));\\n\\n    // call Action execution\\n    IDSProxy(proxy).execute{value: address(this).balance}(\\n        taskExecutor,\\n        abi.encodeWithSelector(CALLBACK\\_SELECTOR, currTask, bytes32(\\_amounts[0] + \\_fees[0]))\\n    );\\n\\n    // return FL\\n    for (uint256 i = 0; i < \\_assets.length; i++) {\\n        \\_assets[i].approveToken(address(AAVE\\_LENDING\\_POOL), \\_amounts[i] + \\_fees[i]);\\n    }\\n\\n    return true;\\n}\\n```\\nчA reentrancy guard (mutex) that covers the entire content of FLAaveV2.executeOperation/FLDyDx.callFunction should be used to prevent such attack.чч```\\nfunction executeOperation(\\n    address[] memory \\_assets,\\n    uint256[] memory \\_amounts,\\n    uint256[] memory \\_fees,\\n    address \\_initiator,\\n    bytes memory \\_params\\n) public returns (bool) {\\n    require(msg.sender == AAVE\\_LENDING\\_POOL, ERR\\_ONLY\\_AAVE\\_CALLER);\\n    require(\\_initiator == address(this), ERR\\_SAME\\_CALLER);\\n\\n    (Task memory currTask, address proxy) = abi.decode(\\_params, (Task, address));\\n\\n    // Send FL amounts to user proxy\\n    for (uint256 i = 0; i < \\_assets.length; ++i) {\\n        \\_assets[i].withdrawTokens(proxy, \\_amounts[i]);\\n    }\\n\\n    address payable taskExecutor = payable(registry.getAddr(TASK\\_EXECUTOR\\_ID));\\n\\n    // call Action execution\\n    IDSProxy(proxy).execute{value: address(this).balance}(\\n        taskExecutor,\\n        abi.encodeWithSelector(CALLBACK\\_SELECTOR, currTask, bytes32(\\_amounts[0] + \\_fees[0]))\\n    );\\n\\n    // return FL\\n    for (uint256 i = 0; i < \\_assets.length; i++) {\\n        \\_assets[i].approveToken(address(AAVE\\_LENDING\\_POOL), \\_amounts[i] + \\_fees[i]);\\n    }\\n\\n    return true;\\n}\\n```\\n
Tokens with more than 18 decimal points will cause issuesчhighчIt is assumed that the maximum number of decimals for each token is 18. However uncommon, but it is possible to have tokens with more than 18 decimals, as an Example YAMv2 has 24 decimals. This can result in broken code flow and unpredictable outcomes (e.g. an underflow will result with really high rates).\\n```\\n    function getSellRate(address \\_srcAddr, address \\_destAddr, uint \\_srcAmount, bytes memory) public override view returns (uint rate) {\\n        (rate, ) = KyberNetworkProxyInterface(KYBER\\_INTERFACE)\\n            .getExpectedRate(IERC20(\\_srcAddr), IERC20(\\_destAddr), \\_srcAmount);\\n\\n        // multiply with decimal difference in src token\\n        rate = rate \\* (10\\*\\*(18 - getDecimals(\\_srcAddr)));\\n        // divide with decimal difference in dest token\\n        rate = rate / (10\\*\\*(18 - getDecimals(\\_destAddr)));\\n    }\\n```\\nчMake sure the code won't fail in case the token's decimals is more than 18.чч```\\n    function getSellRate(address \\_srcAddr, address \\_destAddr, uint \\_srcAmount, bytes memory) public override view returns (uint rate) {\\n        (rate, ) = KyberNetworkProxyInterface(KYBER\\_INTERFACE)\\n            .getExpectedRate(IERC20(\\_srcAddr), IERC20(\\_destAddr), \\_srcAmount);\\n\\n        // multiply with decimal difference in src token\\n        rate = rate \\* (10\\*\\*(18 - getDecimals(\\_srcAddr)));\\n        // divide with decimal difference in dest token\\n        rate = rate / (10\\*\\*(18 - getDecimals(\\_destAddr)));\\n    }\\n```\\n
Error codes of Compound's Comptroller.enterMarket, Comptroller.exitMarket are not checkedчhighчCompound's `enterMarket/exitMarket` functions return an error code instead of reverting in case of failure. DeFi Saver smart contracts never check for the error codes returned from Compound smart contracts, although the code flow might revert due to unavailability of the CTokens, however early on checks for Compound errors are suggested.\\n```\\nfunction enterMarket(address \\_cTokenAddr) public {\\n    address[] memory markets = new address[](1);\\n    markets[0] = \\_cTokenAddr;\\n\\n    IComptroller(COMPTROLLER\\_ADDR).enterMarkets(markets);\\n}\\n\\n/// @notice Exits the Compound market\\n/// @param \\_cTokenAddr CToken address of the token\\nfunction exitMarket(address \\_cTokenAddr) public {\\n    IComptroller(COMPTROLLER\\_ADDR).exitMarket(\\_cTokenAddr);\\n}\\n```\\nчCaller contract should revert in case the error code is not 0.чч```\\nfunction enterMarket(address \\_cTokenAddr) public {\\n    address[] memory markets = new address[](1);\\n    markets[0] = \\_cTokenAddr;\\n\\n    IComptroller(COMPTROLLER\\_ADDR).enterMarkets(markets);\\n}\\n\\n/// @notice Exits the Compound market\\n/// @param \\_cTokenAddr CToken address of the token\\nfunction exitMarket(address \\_cTokenAddr) public {\\n    IComptroller(COMPTROLLER\\_ADDR).exitMarket(\\_cTokenAddr);\\n}\\n```\\n
Reversed order of parameters in allowance function callчmediumчWhen trying to pull the maximum amount of tokens from an approver to the allowed spender, the parameters that are used for the `allowance` function call are not in the same order that is used later in the call to `safeTransferFrom`.\\n```\\nfunction pullTokens(\\n    address \\_token,\\n    address \\_from,\\n    uint256 \\_amount\\n) internal returns (uint256) {\\n    // handle max uint amount\\n    if (\\_amount == type(uint256).max) {\\n        uint256 allowance = IERC20(\\_token).allowance(address(this), \\_from);\\n        uint256 balance = getBalance(\\_token, \\_from);\\n\\n        \\_amount = (balance > allowance) ? allowance : balance;\\n    }\\n\\n    if (\\_from != address(0) && \\_from != address(this) && \\_token != ETH\\_ADDR && \\_amount != 0) {\\n        IERC20(\\_token).safeTransferFrom(\\_from, address(this), \\_amount);\\n    }\\n\\n    return \\_amount;\\n}\\n```\\nчReverse the order of parameters in `allowance` function call to fit the order that is in the `safeTransferFrom` function call.чч```\\nfunction pullTokens(\\n    address \\_token,\\n    address \\_from,\\n    uint256 \\_amount\\n) internal returns (uint256) {\\n    // handle max uint amount\\n    if (\\_amount == type(uint256).max) {\\n        uint256 allowance = IERC20(\\_token).allowance(address(this), \\_from);\\n        uint256 balance = getBalance(\\_token, \\_from);\\n\\n        \\_amount = (balance > allowance) ? allowance : balance;\\n    }\\n\\n    if (\\_from != address(0) && \\_from != address(this) && \\_token != ETH\\_ADDR && \\_amount != 0) {\\n        IERC20(\\_token).safeTransferFrom(\\_from, address(this), \\_amount);\\n    }\\n\\n    return \\_amount;\\n}\\n```\\n
Kyber getRates code is unclearчlowч`getSellRate` can be converted into one function to get the rates, which then for buy or sell can swap input and output tokens\\n`getBuyRate` uses a 3% slippage that is not documented.\\n```\\n   function getSellRate(address \\_srcAddr, address \\_destAddr, uint \\_srcAmount, bytes memory) public override view returns (uint rate) {\\n        (rate, ) = KyberNetworkProxyInterface(KYBER\\_INTERFACE)\\n            .getExpectedRate(IERC20(\\_srcAddr), IERC20(\\_destAddr), \\_srcAmount);\\n\\n        // multiply with decimal difference in src token\\n        rate = rate \\* (10\\*\\*(18 - getDecimals(\\_srcAddr)));\\n        // divide with decimal difference in dest token\\n        rate = rate / (10\\*\\*(18 - getDecimals(\\_destAddr)));\\n    }\\n\\n    /// @notice Return a rate for which we can buy an amount of tokens\\n    /// @param \\_srcAddr From token\\n    /// @param \\_destAddr To token\\n    /// @param \\_destAmount To amount\\n    /// @return rate Rate\\n    function getBuyRate(address \\_srcAddr, address \\_destAddr, uint \\_destAmount, bytes memory \\_additionalData) public override view returns (uint rate) {\\n        uint256 srcRate = getSellRate(\\_destAddr, \\_srcAddr, \\_destAmount, \\_additionalData);\\n        uint256 srcAmount = wmul(srcRate, \\_destAmount);\\n\\n        rate = getSellRate(\\_srcAddr, \\_destAddr, srcAmount, \\_additionalData);\\n\\n        // increase rate by 3% too account for inaccuracy between sell/buy conversion\\n        rate = rate + (rate / 30);\\n    }\\n```\\nчRefactoring the code to separate getting rate functionality with `getSellRate` and `getBuyRate`. Explicitly document any assumptions in the code ( slippage, etc)чч```\\n   function getSellRate(address \\_srcAddr, address \\_destAddr, uint \\_srcAmount, bytes memory) public override view returns (uint rate) {\\n        (rate, ) = KyberNetworkProxyInterface(KYBER\\_INTERFACE)\\n            .getExpectedRate(IERC20(\\_srcAddr), IERC20(\\_destAddr), \\_srcAmount);\\n\\n        // multiply with decimal difference in src token\\n        rate = rate \\* (10\\*\\*(18 - getDecimals(\\_srcAddr)));\\n        // divide with decimal difference in dest token\\n        rate = rate / (10\\*\\*(18 - getDecimals(\\_destAddr)));\\n    }\\n\\n    /// @notice Return a rate for which we can buy an amount of tokens\\n    /// @param \\_srcAddr From token\\n    /// @param \\_destAddr To token\\n    /// @param \\_destAmount To amount\\n    /// @return rate Rate\\n    function getBuyRate(address \\_srcAddr, address \\_destAddr, uint \\_destAmount, bytes memory \\_additionalData) public override view returns (uint rate) {\\n        uint256 srcRate = getSellRate(\\_destAddr, \\_srcAddr, \\_destAmount, \\_additionalData);\\n        uint256 srcAmount = wmul(srcRate, \\_destAmount);\\n\\n        rate = getSellRate(\\_srcAddr, \\_destAddr, srcAmount, \\_additionalData);\\n\\n        // increase rate by 3% too account for inaccuracy between sell/buy conversion\\n        rate = rate + (rate / 30);\\n    }\\n```\\n
Return values not used for DFSExchangeCore.onChainSwapчlowчReturn values from `DFSExchangeCore.onChainSwap` are not used.\\n```\\nfunction \\_sell(ExchangeData memory exData) internal returns (address, uint256) {\\n    uint256 amountWithoutFee = exData.srcAmount;\\n    address wrapper = exData.offchainData.wrapper;\\n    bool offChainSwapSuccess;\\n\\n    uint256 destBalanceBefore = exData.destAddr.getBalance(address(this));\\n\\n    // Takes DFS exchange fee\\n    exData.srcAmount -= getFee(\\n        exData.srcAmount,\\n        exData.user,\\n        exData.srcAddr,\\n        exData.dfsFeeDivider\\n    );\\n\\n    // Try 0x first and then fallback on specific wrapper\\n    if (exData.offchainData.price > 0) {\\n        (offChainSwapSuccess, ) = offChainSwap(exData, ExchangeActionType.SELL);\\n    }\\n\\n    // fallback to desired wrapper if 0x failed\\n    if (!offChainSwapSuccess) {\\n        onChainSwap(exData, ExchangeActionType.SELL);\\n        wrapper = exData.wrapper;\\n    }\\n\\n    uint256 destBalanceAfter = exData.destAddr.getBalance(address(this));\\n    uint256 amountBought = sub(destBalanceAfter, destBalanceBefore);\\n\\n    // check slippage\\n    require(amountBought >= wmul(exData.minPrice, exData.srcAmount), ERR\\_SLIPPAGE\\_HIT);\\n\\n    // revert back exData changes to keep it consistent\\n    exData.srcAmount = amountWithoutFee;\\n\\n    return (wrapper, amountBought);\\n}\\n```\\n\\n```\\nfunction \\_buy(ExchangeData memory exData) internal returns (address, uint256) {\\n    require(exData.destAmount != 0, ERR\\_DEST\\_AMOUNT\\_MISSING);\\n\\n    uint256 amountWithoutFee = exData.srcAmount;\\n    address wrapper = exData.offchainData.wrapper;\\n    bool offChainSwapSuccess;\\n\\n    uint256 destBalanceBefore = exData.destAddr.getBalance(address(this));\\n\\n    // Takes DFS exchange fee\\n    exData.srcAmount -= getFee(\\n        exData.srcAmount,\\n        exData.user,\\n        exData.srcAddr,\\n        exData.dfsFeeDivider\\n    );\\n\\n    // Try 0x first and then fallback on specific wrapper\\n    if (exData.offchainData.price > 0) {\\n        (offChainSwapSuccess, ) = offChainSwap(exData, ExchangeActionType.BUY);\\n    }\\n\\n    // fallback to desired wrapper if 0x failed\\n    if (!offChainSwapSuccess) {\\n        onChainSwap(exData, ExchangeActionType.BUY);\\n        wrapper = exData.wrapper;\\n    }\\n\\n    uint256 destBalanceAfter = exData.destAddr.getBalance(address(this));\\n    uint256 amountBought = sub(destBalanceAfter, destBalanceBefore);\\n\\n    // check slippage\\n    require(amountBought >= exData.destAmount, ERR\\_SLIPPAGE\\_HIT);\\n\\n    // revert back exData changes to keep it consistent\\n    exData.srcAmount = amountWithoutFee;\\n\\n    return (wrapper, amountBought);\\n}\\n```\\nчThe return value can be used for verification of the swap or used in the event data.чч```\\nfunction \\_sell(ExchangeData memory exData) internal returns (address, uint256) {\\n    uint256 amountWithoutFee = exData.srcAmount;\\n    address wrapper = exData.offchainData.wrapper;\\n    bool offChainSwapSuccess;\\n\\n    uint256 destBalanceBefore = exData.destAddr.getBalance(address(this));\\n\\n    // Takes DFS exchange fee\\n    exData.srcAmount -= getFee(\\n        exData.srcAmount,\\n        exData.user,\\n        exData.srcAddr,\\n        exData.dfsFeeDivider\\n    );\\n\\n    // Try 0x first and then fallback on specific wrapper\\n    if (exData.offchainData.price > 0) {\\n        (offChainSwapSuccess, ) = offChainSwap(exData, ExchangeActionType.SELL);\\n    }\\n\\n    // fallback to desired wrapper if 0x failed\\n    if (!offChainSwapSuccess) {\\n        onChainSwap(exData, ExchangeActionType.SELL);\\n        wrapper = exData.wrapper;\\n    }\\n\\n    uint256 destBalanceAfter = exData.destAddr.getBalance(address(this));\\n    uint256 amountBought = sub(destBalanceAfter, destBalanceBefore);\\n\\n    // check slippage\\n    require(amountBought >= wmul(exData.minPrice, exData.srcAmount), ERR\\_SLIPPAGE\\_HIT);\\n\\n    // revert back exData changes to keep it consistent\\n    exData.srcAmount = amountWithoutFee;\\n\\n    return (wrapper, amountBought);\\n}\\n```\\n
Return value is not used for TokenUtils.withdrawTokensчlowчThe return value of `TokenUtils.withdrawTokens` which represents the actual amount of tokens that were transferred is never used throughout the repository. This might cause discrepancy in the case where the original value of `_amount` was `type(uint256).max`.\\n```\\nfunction \\_borrow(\\n    address \\_market,\\n    address \\_tokenAddr,\\n    uint256 \\_amount,\\n    uint256 \\_rateMode,\\n    address \\_to,\\n    address \\_onBehalf\\n) internal returns (uint256) {\\n    ILendingPoolV2 lendingPool = getLendingPool(\\_market);\\n\\n    // defaults to onBehalf of proxy\\n    if (\\_onBehalf == address(0)) {\\n        \\_onBehalf = address(this);\\n    }\\n\\n    lendingPool.borrow(\\_tokenAddr, \\_amount, \\_rateMode, AAVE\\_REFERRAL\\_CODE, \\_onBehalf);\\n\\n    \\_tokenAddr.withdrawTokens(\\_to, \\_amount);\\n\\n    logger.Log(\\n        address(this),\\n        msg.sender,\\n        \"AaveBorrow\",\\n        abi.encode(\\_market, \\_tokenAddr, \\_amount, \\_rateMode, \\_to, \\_onBehalf)\\n    );\\n\\n    return \\_amount;\\n}\\n```\\n\\n```\\nfunction withdrawTokens(\\n    address \\_token,\\n    address \\_to,\\n    uint256 \\_amount\\n) internal returns (uint256) {\\n    if (\\_amount == type(uint256).max) {\\n        \\_amount = getBalance(\\_token, address(this));\\n    }\\n```\\nчThe return value can be used to validate the withdrawal or used in the event emitted.чч```\\nfunction \\_borrow(\\n    address \\_market,\\n    address \\_tokenAddr,\\n    uint256 \\_amount,\\n    uint256 \\_rateMode,\\n    address \\_to,\\n    address \\_onBehalf\\n) internal returns (uint256) {\\n    ILendingPoolV2 lendingPool = getLendingPool(\\_market);\\n\\n    // defaults to onBehalf of proxy\\n    if (\\_onBehalf == address(0)) {\\n        \\_onBehalf = address(this);\\n    }\\n\\n    lendingPool.borrow(\\_tokenAddr, \\_amount, \\_rateMode, AAVE\\_REFERRAL\\_CODE, \\_onBehalf);\\n\\n    \\_tokenAddr.withdrawTokens(\\_to, \\_amount);\\n\\n    logger.Log(\\n        address(this),\\n        msg.sender,\\n        \"AaveBorrow\",\\n        abi.encode(\\_market, \\_tokenAddr, \\_amount, \\_rateMode, \\_to, \\_onBehalf)\\n    );\\n\\n    return \\_amount;\\n}\\n```\\n
Anyone is able to mint NFTs by calling mintNFTsForLMчhighчThe contract `LiquidityMiningNFT` has the method `mintNFTsForLM`.\\n```\\nfunction mintNFTsForLM(address \\_liquidiyMiningAddr) external {\\n    uint256[] memory \\_ids = new uint256[](NFT\\_TYPES\\_COUNT);\\n    uint256[] memory \\_amounts = new uint256[](NFT\\_TYPES\\_COUNT);\\n\\n    \\_ids[0] = 1;\\n    \\_amounts[0] = 5;\\n\\n    \\_ids[1] = 2;\\n    \\_amounts[1] = 1 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_ids[2] = 3;\\n    \\_amounts[2] = 3 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_ids[3] = 4;\\n    \\_amounts[3] = 6 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_mintBatch(\\_liquidiyMiningAddr, \\_ids, \\_amounts, \"\");\\n}\\n```\\n\\nHowever, this contract does not have any kind of special permissions to limit who is able to mint tokens.\\nAn attacker could call `LiquidityMiningNFT.mintNFTsForLM(0xhackerAddress)` to mint tokens for their address and sell them on the marketplace. They are also allowed to mint as many tokens as they want by calling the method multiple times.чAdd some permissions to limit only some actors to mint tokens.чч```\\nfunction mintNFTsForLM(address \\_liquidiyMiningAddr) external {\\n    uint256[] memory \\_ids = new uint256[](NFT\\_TYPES\\_COUNT);\\n    uint256[] memory \\_amounts = new uint256[](NFT\\_TYPES\\_COUNT);\\n\\n    \\_ids[0] = 1;\\n    \\_amounts[0] = 5;\\n\\n    \\_ids[1] = 2;\\n    \\_amounts[1] = 1 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_ids[2] = 3;\\n    \\_amounts[2] = 3 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_ids[3] = 4;\\n    \\_amounts[3] = 6 \\* LEADERBOARD\\_SIZE;\\n\\n    \\_mintBatch(\\_liquidiyMiningAddr, \\_ids, \\_amounts, \"\");\\n}\\n```\\n
A liquidity provider can withdraw all his funds anytimeчhighчSince some users provide liquidity to sell the insurance policies, it is important that these providers cannot withdraw their funds when the security breach happens and the policyholders are submitting claims. The liquidity providers can only request their funds first and withdraw them later (in a week).\\n```\\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\\n  WithdrawalStatus \\_status = getWithdrawalStatus(msg.sender);\\n\\n  require(\\_status == WithdrawalStatus.NONE || \\_status == WithdrawalStatus.EXPIRED,\\n    \"PB: Can't request withdrawal\");\\n\\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n  uint256 \\_availableDaiBalance = balanceOf(msg.sender).mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n\\n  if (block.timestamp < liquidityMining.getEndLMTime().add(neededTimeAfterLM)) {\\n    \\_availableDaiBalance = \\_availableDaiBalance.sub(liquidityFromLM[msg.sender]);\\n  }\\n\\n  require(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\\n    \"PB: Not enough liquidity\");\\n\\n  require(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\\n\\n  WithdrawalInfo memory \\_newWithdrawalInfo;\\n  \\_newWithdrawalInfo.amount = \\_tokensToWithdraw;\\n  \\_newWithdrawalInfo.readyToWithdrawDate = block.timestamp.add(withdrawalPeriod);\\n\\n  withdrawalsInfo[msg.sender] = \\_newWithdrawalInfo;\\n  emit RequestWithdraw(msg.sender, \\_tokensToWithdraw, \\_newWithdrawalInfo.readyToWithdrawDate);\\n}\\n```\\n\\n```\\nfunction withdrawLiquidity() external override {\\n  require(getWithdrawalStatus(msg.sender) == WithdrawalStatus.READY,\\n    \"PB: Withdrawal is not ready\");\\n\\n  uint256 \\_tokensToWithdraw = withdrawalsInfo[msg.sender].amount;\\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n\\n  if (withdrawalQueue.length != 0 || totalLiquidity.sub(\\_daiTokensToWithdraw) < totalCoverTokens) {\\n    withdrawalQueue.push(msg.sender);\\n  } else {\\n    \\_withdrawLiquidity(msg.sender, \\_tokensToWithdraw);\\n  }\\n}\\n```\\n\\nThere is a restriction in `requestWithdrawal` that requires the liquidity provider to have enough funds at the moment of request:\\n```\\nrequire(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\\n  \"PB: Not enough liquidity\");\\n\\nrequire(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\\n```\\n\\nBut after the request is created, these funds can then be transferred to another address. When the request is created, the provider should wait for 7 days, and then there will be 2 days to withdraw the requested amount:\\n```\\nwithdrawalPeriod = 1 weeks;\\nwithdrawalExpirePeriod = 2 days;\\n```\\n\\nThe attacker would have 4 addresses that will send the pool tokens to each other and request withdrawal of the full amount one by one every 2 days. So at least one of the addresses can withdraw all of the funds at any point in time. If the liquidity provider needs to withdraw funds immediately, he should transfer all funds to that address and execute the withdrawal.чResolution\\nThe funds are now locked when the withdrawal is requested, so funds cannot be transferred after the request, and this bug cannot be exploited anymore.\\nOne of the solutions would be to block the DAIx tokens from being transferred after the withdrawal request.чч```\\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\\n  WithdrawalStatus \\_status = getWithdrawalStatus(msg.sender);\\n\\n  require(\\_status == WithdrawalStatus.NONE || \\_status == WithdrawalStatus.EXPIRED,\\n    \"PB: Can't request withdrawal\");\\n\\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n  uint256 \\_availableDaiBalance = balanceOf(msg.sender).mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n\\n  if (block.timestamp < liquidityMining.getEndLMTime().add(neededTimeAfterLM)) {\\n    \\_availableDaiBalance = \\_availableDaiBalance.sub(liquidityFromLM[msg.sender]);\\n  }\\n\\n  require(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\\n    \"PB: Not enough liquidity\");\\n\\n  require(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\\n\\n  WithdrawalInfo memory \\_newWithdrawalInfo;\\n  \\_newWithdrawalInfo.amount = \\_tokensToWithdraw;\\n  \\_newWithdrawalInfo.readyToWithdrawDate = block.timestamp.add(withdrawalPeriod);\\n\\n  withdrawalsInfo[msg.sender] = \\_newWithdrawalInfo;\\n  emit RequestWithdraw(msg.sender, \\_tokensToWithdraw, \\_newWithdrawalInfo.readyToWithdrawDate);\\n}\\n```\\n
The buyPolicyFor/addLiquidityFor should transfer funds from msg.senderчhighчWhen calling the buyPolicyFor/addLiquidityFor functions, are called with the parameter _policyHolderAddr/_liquidityHolderAddr who is going to be the beneficiary in buying policy/adding liquidity:\\n```\\nfunction buyPolicyFor(\\n  address \\_policyHolderAddr,\\n  uint256 \\_epochsNumber,\\n  uint256 \\_coverTokens   \\n) external override {\\n  \\_buyPolicyFor(\\_policyHolderAddr, \\_epochsNumber, \\_coverTokens);\\n}\\n```\\n\\n```\\nfunction addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount) external override {\\n  \\_addLiquidityFor(\\_liquidityHolderAddr, \\_liquidityAmount, false);\\n}\\n```\\n\\nDuring the execution, the funds for the policy/liquidity are transferred from the _policyHolderAddr/_liquidityHolderAddr, while it's usually expected that they should be transferred from `msg.sender`. Because of that, anyone can call a function on behalf of a user that gave the allowance to the `PolicyBook`.\\nFor example, a user(victim) wants to add some DAI to the liquidity pool and gives allowance to the `PolicyBook`. After that, the user should call `addLiquidity`, but the attacker can front-run this transaction and buy a policy on behalf of the victim instead.\\nAlso, there is a curious edge case that makes this issue Critical: _policyHolderAddr/_liquidityHolderAddr parameters can be equal to the address of the `PolicyBook` contract. That may lead to multiple different dangerous attack vectors.чMake sure that nobody can transfer funds on behalf of the users if it's not intended.чч```\\nfunction buyPolicyFor(\\n  address \\_policyHolderAddr,\\n  uint256 \\_epochsNumber,\\n  uint256 \\_coverTokens   \\n) external override {\\n  \\_buyPolicyFor(\\_policyHolderAddr, \\_epochsNumber, \\_coverTokens);\\n}\\n```\\n
LiquidityMining can't accept single ERC1155 tokensчhighчThe contract `LiquidityMining` is also defined as an `ERC1155Receiver`\\n```\\ncontract LiquidityMining is ILiquidityMining, ERC1155Receiver, Ownable {\\n```\\n\\nThe finalized EIP-1155 standard states that a contract which acts as an EIP-1155 Receiver must implement all the functions in the `ERC1155TokenReceiver` interface to be able to accept transfers.\\nThese are indeed implemented here:\\n```\\nfunction onERC1155Received(\\n```\\n\\n```\\nfunction onERC1155BatchReceived(\\n```\\n\\nThe standard states that they will be called and they MUST return a specific `byte4` value, otherwise the transfer will fail.\\nHowever one of the methods returns an incorrect value. This seems to an error generated by a copy/paste action.\\n```\\nfunction onERC1155Received(\\n    address operator,\\n    address from,\\n    uint256 id,\\n    uint256 value,\\n    bytes memory data\\n)\\n    external\\n    pure\\n    override\\n    returns(bytes4)\\n{\\n    return bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));\\n}\\n```\\n\\nThe value returned is equal to\\n`bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));`\\nBut it should be\\n`bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\"))`.\\nOn top of this, the contract MUST implement the ERC-165 standard to correctly respond to `supportsInterface`.чChange the return value of `onERC1155Received` to be equal to `0xf23a6e61` which represents `bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\"))`.\\nAlso, make sure to implement `supportsInterface` to signify support of `ERC1155TokenReceiver` to accept transfers.\\nAdd tests to check the functionality is correct and make sure these kinds of bugs do not exist in the future.\\nMake sure to read the EIP-1155 and EIP-165 standards in detail and implement them correctly.чч```\\ncontract LiquidityMining is ILiquidityMining, ERC1155Receiver, Ownable {\\n```\\n
DAI is assumed to have the same price as DAIx in the staking contractчhighчWhen a liquidity provider stakes tokens to the `BMIDAIStaking` contract, the equal amount of DAI and DAIx are transferred from the pool contract.\\n```\\nfunction \\_stakeDAIx(address \\_user, uint256 \\_amount, address \\_policyBookAddr) internal {\\n    require (\\_amount > 0, \"BMIDAIStaking: Can't stake zero tokens\");\\n\\n    PolicyBook \\_policyBook = PolicyBook(\\_policyBookAddr);\\n    // transfer DAI from PolicyBook to yield generator\\n    daiToken.transferFrom(\\_policyBookAddr, address(defiYieldGenerator), \\_amount);            \\n\\n    // transfer bmiDAIx from user to staking\\n    \\_policyBook.transferFrom(\\_user, address(this), \\_amount);       \\n\\n    \\_mintNFT(\\_user, \\_amount, \\_policyBook);\\n}\\n```\\nчOnly the corresponding amount of DAI should be transferred to the pool.чч```\\nfunction \\_stakeDAIx(address \\_user, uint256 \\_amount, address \\_policyBookAddr) internal {\\n    require (\\_amount > 0, \"BMIDAIStaking: Can't stake zero tokens\");\\n\\n    PolicyBook \\_policyBook = PolicyBook(\\_policyBookAddr);\\n    // transfer DAI from PolicyBook to yield generator\\n    daiToken.transferFrom(\\_policyBookAddr, address(defiYieldGenerator), \\_amount);            \\n\\n    // transfer bmiDAIx from user to staking\\n    \\_policyBook.transferFrom(\\_user, address(this), \\_amount);       \\n\\n    \\_mintNFT(\\_user, \\_amount, \\_policyBook);\\n}\\n```\\n
_updateWithdrawalQueue can run out of gasчhighчWhen there's not enough collateral to withdraw liquidity from a policy book, the withdrawal request is added to a queue. The queue is supposed to be processed and cleared once there are enough funds for that. The only way to do so is the `_updateWithdrawalQueue` function that is caller when new liquidity is added:\\n```\\nfunction \\_updateWithdrawalQueue() internal {\\n  uint256 \\_availableLiquidity = totalLiquidity.sub(totalCoverTokens);\\n  uint256 \\_countToRemoveFromQueue;\\n\\n  for (uint256 i = 0; i < withdrawalQueue.length; i++) {     \\n    uint256 \\_tokensToWithdraw = withdrawalsInfo[withdrawalQueue[i]].amount;\\n    uint256 \\_amountInDai = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n\\n    if (balanceOf(withdrawalQueue[i]) < \\_tokensToWithdraw) {\\n      \\_countToRemoveFromQueue++;\\n      continue;\\n    }\\n\\n    if (\\_availableLiquidity >= \\_amountInDai) {\\n      \\_withdrawLiquidity(withdrawalQueue[i], \\_tokensToWithdraw);\\n      \\_availableLiquidity = \\_availableLiquidity.sub(\\_amountInDai);\\n      \\_countToRemoveFromQueue++;\\n    } else {\\n      break;\\n    }\\n  }\\n\\n  \\_removeFromQueue(\\_countToRemoveFromQueue);\\n}\\n```\\n\\nThe problem is that this function can only process all queue until the pool run out of available funds or the whole queue is going to be processed. If the queue is big enough, this process can be stuck.чPass the parameter to the `_updateWithdrawalQueue` that defines how many requests to process in the queue per one call.чч```\\nfunction \\_updateWithdrawalQueue() internal {\\n  uint256 \\_availableLiquidity = totalLiquidity.sub(totalCoverTokens);\\n  uint256 \\_countToRemoveFromQueue;\\n\\n  for (uint256 i = 0; i < withdrawalQueue.length; i++) {     \\n    uint256 \\_tokensToWithdraw = withdrawalsInfo[withdrawalQueue[i]].amount;\\n    uint256 \\_amountInDai = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\\n\\n    if (balanceOf(withdrawalQueue[i]) < \\_tokensToWithdraw) {\\n      \\_countToRemoveFromQueue++;\\n      continue;\\n    }\\n\\n    if (\\_availableLiquidity >= \\_amountInDai) {\\n      \\_withdrawLiquidity(withdrawalQueue[i], \\_tokensToWithdraw);\\n      \\_availableLiquidity = \\_availableLiquidity.sub(\\_amountInDai);\\n      \\_countToRemoveFromQueue++;\\n    } else {\\n      break;\\n    }\\n  }\\n\\n  \\_removeFromQueue(\\_countToRemoveFromQueue);\\n}\\n```\\n
The PolicyBook should make DAI transfers inside the contractчmediumчThe `PolicyBook` contract gives full allowance over DAI tokens to the other contracts:\\n```\\nfunction approveAllDaiTokensForStakingAndVotingAndTransferOwnership() internal {\\n  daiToken.approve(address(bmiDaiStaking), MAX\\_INT);   \\n  daiToken.approve(address(claimVoting), MAX\\_INT);    \\n\\n  transferOwnership(address(bmiDaiStaking));\\n}\\n```\\n\\nThat behavior is dangerous because it's hard to keep track of and control the contract's DAI balance. And it's also hard to track in the code where the balance of the `PolicyBook` can be changed from.чIt's better to perform all the transfers inside the `PolicyBook` contract. So if the `bmiDaiStaking` and the `claimVoting` contracts need DAI tokens from the `PolicyBook`, they should call some function of the `PolicyBook` to perform transfers.чч```\\nfunction approveAllDaiTokensForStakingAndVotingAndTransferOwnership() internal {\\n  daiToken.approve(address(bmiDaiStaking), MAX\\_INT);   \\n  daiToken.approve(address(claimVoting), MAX\\_INT);    \\n\\n  transferOwnership(address(bmiDaiStaking));\\n}\\n```\\n
The totalCoverTokens is only updated when the policy is boughtчmediumчThe `totalCoverTokens` value represents the amount of collateral that needs to be locked in the policy book. It should be changed either by buying a new policy or when an old policy expires. The problem is that when the old policy expires, this value is not updated; it is only updated when someone buys a policy by calling the `_updateEpochsInfo` function:\\n```\\nfunction \\_updateEpochsInfo() internal {\\n  uint256 \\_totalEpochTime = block.timestamp.sub(epochStartTime);\\n  uint256 \\_countOfPassedEpoch = \\_totalEpochTime.div(epochDuration);\\n\\n  uint256 \\_lastEpochUpdate = currentEpochNumber;\\n  currentEpochNumber = \\_countOfPassedEpoch.add(1);\\n\\n  for (uint256 i = \\_lastEpochUpdate; i < currentEpochNumber; i++) {\\n    totalCoverTokens = totalCoverTokens.sub(epochAmounts[i]);\\n    delete epochAmounts[i];\\n  }\\n}\\n```\\n\\nUsers waiting to withdraw liquidity should wait for someone to buy the policy to update the `totalCoverTokens`.чResolution\\nThe `updateEpochsInfo` function is now public and can be called by anyone.\\nMake sure it's possible to call the `_updateEpochsInfo` function without buying a new policy.чч```\\nfunction \\_updateEpochsInfo() internal {\\n  uint256 \\_totalEpochTime = block.timestamp.sub(epochStartTime);\\n  uint256 \\_countOfPassedEpoch = \\_totalEpochTime.div(epochDuration);\\n\\n  uint256 \\_lastEpochUpdate = currentEpochNumber;\\n  currentEpochNumber = \\_countOfPassedEpoch.add(1);\\n\\n  for (uint256 i = \\_lastEpochUpdate; i < currentEpochNumber; i++) {\\n    totalCoverTokens = totalCoverTokens.sub(epochAmounts[i]);\\n    delete epochAmounts[i];\\n  }\\n}\\n```\\n
Unbounded loops in LiquidityMiningчmediumчThere are some methods that have unbounded loops and will fail when enough items exist in the arrays.\\n```\\nfor (uint256 i = 0; i < \\_teamsNumber; i++) {\\n```\\n\\n```\\nfor (uint256 i = 0; i < \\_membersNumber; i++) {\\n```\\n\\n```\\nfor (uint256 i = 0; i < \\_usersNumber; i++) {\\n```\\n\\nThese methods will fail when lots of items will be added to them.чConsider adding limits (from, to) when requesting the items.чч```\\nfor (uint256 i = 0; i < \\_teamsNumber; i++) {\\n```\\n
The _removeFromQueue is very gas greedyчmediumчThe `_removeFromQueue` function is supposed to remove `_countToRemove` elements from the queue:\\n```\\nfunction \\_removeFromQueue(uint256 \\_countToRemove) internal {\\n  for (uint256 i = 0; i < \\_countToRemove; i++) {\\n    delete withdrawalsInfo[withdrawalQueue[i]];\\n  }   \\n\\n  if (\\_countToRemove == withdrawalQueue.length) {\\n    delete withdrawalQueue;\\n  } else {\\n    uint256 \\_remainingArrLength = withdrawalQueue.length.sub(\\_countToRemove);\\n    address[] memory \\_remainingArr = new address[](\\_remainingArrLength);\\n\\n    for (uint256 i = 0; i < \\_remainingArrLength; i++) {\\n      \\_remainingArr[i] = withdrawalQueue[i.add(\\_countToRemove)];\\n    }\\n\\n    withdrawalQueue = \\_remainingArr;\\n  }\\n}\\n```\\n\\nThis function uses too much gas, which makes it easier to make attacks on the system. Even if only one request is removed and executed, this function rewrites all the requests to the storage.чThe data structure should be changed so this function shouldn't rewrite the requests that did not change. For example, it can be a mapping `(unit => address)` with 2 indexes `(start, end)` that are only increasing.чч```\\nfunction \\_removeFromQueue(uint256 \\_countToRemove) internal {\\n  for (uint256 i = 0; i < \\_countToRemove; i++) {\\n    delete withdrawalsInfo[withdrawalQueue[i]];\\n  }   \\n\\n  if (\\_countToRemove == withdrawalQueue.length) {\\n    delete withdrawalQueue;\\n  } else {\\n    uint256 \\_remainingArrLength = withdrawalQueue.length.sub(\\_countToRemove);\\n    address[] memory \\_remainingArr = new address[](\\_remainingArrLength);\\n\\n    for (uint256 i = 0; i < \\_remainingArrLength; i++) {\\n      \\_remainingArr[i] = withdrawalQueue[i.add(\\_countToRemove)];\\n    }\\n\\n    withdrawalQueue = \\_remainingArr;\\n  }\\n}\\n```\\n
Withdrawal with zero amount is possibleчmediumчWhen creating a withdrawal request, the amount of tokens to withdraw is passed as a parameter:\\n```\\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\\n```\\n\\nThe problem is that this parameter can be zero, and the function will be successfully executed. Moreover, this request can then be added to the queue, and the actual withdrawal will also be executed with zero value. Addresses that never added any liquidity could spam the system with these requests.чDo not allow withdrawals of zero tokens.чч```\\nfunction requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\\n```\\n
The withdrawal queue is only updated when the liquidity is addedчmediumчSometimes when the amount of liquidity is not much higher than the number of tokens locked for the collateral, it's impossible to withdraw liquidity. For a user that wants to withdraw liquidity, a withdrawal request is created. If the request can't be executed, it's added to the withdrawal queue, and the user needs to wait until there's enough collateral for withdrawal. There are potentially 2 ways to achieve that: either someone adds more liquidity or some existing policies expire.\\nCurrently, the queue can only be cleared when the internal `_updateWithdrawalQueue` function is called. And it is only called in one place while adding liquidity:\\n```\\nfunction \\_addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount, bool \\_isLM) internal {\\n  daiToken.transferFrom(\\_liquidityHolderAddr, address(this), \\_liquidityAmount);   \\n  \\n  uint256 \\_amountToMint = \\_liquidityAmount.mul(PERCENTAGE\\_100).div(getDAIToDAIxRatio());\\n  totalLiquidity = totalLiquidity.add(\\_liquidityAmount);\\n  \\_mintERC20(\\_liquidityHolderAddr, \\_amountToMint);\\n\\n  if (\\_isLM) {\\n    liquidityFromLM[\\_liquidityHolderAddr] = liquidityFromLM[\\_liquidityHolderAddr].add(\\_liquidityAmount);\\n  }\\n\\n  \\_updateWithdrawalQueue();\\n\\n  emit AddLiquidity(\\_liquidityHolderAddr, \\_liquidityAmount, totalLiquidity);\\n}\\n```\\nчIt would be better if the queue could be processed when some policies expire without adding new liquidity. For example, there may be an external function that allows users to process the queue.чч```\\nfunction \\_addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount, bool \\_isLM) internal {\\n  daiToken.transferFrom(\\_liquidityHolderAddr, address(this), \\_liquidityAmount);   \\n  \\n  uint256 \\_amountToMint = \\_liquidityAmount.mul(PERCENTAGE\\_100).div(getDAIToDAIxRatio());\\n  totalLiquidity = totalLiquidity.add(\\_liquidityAmount);\\n  \\_mintERC20(\\_liquidityHolderAddr, \\_amountToMint);\\n\\n  if (\\_isLM) {\\n    liquidityFromLM[\\_liquidityHolderAddr] = liquidityFromLM[\\_liquidityHolderAddr].add(\\_liquidityAmount);\\n  }\\n\\n  \\_updateWithdrawalQueue();\\n\\n  emit AddLiquidity(\\_liquidityHolderAddr, \\_liquidityAmount, totalLiquidity);\\n}\\n```\\n
Optimize gas usage when checking max length of arraysчlowчThere are a few cases where some arrays have to be limited to a number of items.\\nAnd the max size is enforced by removing the last item if the array reached max size + 1.\\n```\\nif (leaderboard.length == MAX\\_LEADERBOARD\\_SIZE.add(1)) {\\n    leaderboard.pop();\\n}\\n```\\n\\n```\\nif (topUsers.length == MAX\\_TOP\\_USERS\\_SIZE.add(1)) {\\n    topUsers.pop();\\n}\\n```\\n\\n```\\nif (\\_addresses.length == MAX\\_GROUP\\_LEADERS\\_SIZE.add(1)) {\\n    groupsLeaders[\\_referralLink].pop();\\n}\\n```\\n\\nA simpler and cheaper way to check if an item should be removed is to change the condition to\\n```\\nif (limitedSizedArray.length > MAX\\_DEFINED\\_SIZE\\_FOR\\_ARRAY) {\\n    limitedSizedArray.pop();\\n}\\n```\\n\\nThis check does not need or do a SafeMath call (which is more expensive), and because of the limited number of items, as well as a practical impossibility to add enough items to overflow the limit, makes it a preferred way to check the maximum limit.чRewrite the checks and remove SafeMath operations, as well as the addition by 1 and change the check to a “greater than” verification.чч```\\nif (leaderboard.length == MAX\\_LEADERBOARD\\_SIZE.add(1)) {\\n    leaderboard.pop();\\n}\\n```\\n
Methods return values that are never usedчlowчWhen a user calls `investDAI` these 3 methods are called internally:\\n```\\n\\_updateTopUsers();\\n\\_updateLeaderboard(\\_userTeamInfo.teamAddr);\\n\\_updateGroupLeaders(\\_userTeamInfo.teamAddr);\\n```\\n\\nEach method returns a boolean, but the value is never used. It is also unclear what the value should represent.чRemove the returned variable or use it in method `investDAI`.чч```\\n\\_updateTopUsers();\\n\\_updateLeaderboard(\\_userTeamInfo.teamAddr);\\n\\_updateGroupLeaders(\\_userTeamInfo.teamAddr);\\n```\\n
Save some gas when looping over state arraysчlowчThere are a few loops over state arrays in `LiquidutyMining`.\\n```\\nfor (uint256 i = 0; i < leaderboard.length; i++) {\\n```\\n\\n```\\nfor (uint256 i = 0; i < topUsers.length; i++) {\\n```\\n\\nConsider caching the length in a local variable to reduce gas costs.\\nSimilar to\\n```\\nuint256 \\_usersNumber = allUsers.length;\\n```\\n\\n```\\nfor (uint256 i = 0; i < \\_usersNumber; i++) {\\n```\\nчReduce gas cost by caching array state length in a local variable.чч```\\nfor (uint256 i = 0; i < leaderboard.length; i++) {\\n```\\n
Optimize gas costs when handling liquidity start and end timesчlowчWhen the `LiquidityMining` contract is deployed, `startLiquidityMiningTime` saves the current block timestamp.\\n```\\nstartLiquidityMiningTime = block.timestamp;       \\n```\\n\\nThis value is never changed.\\nThere also exists an end limit calculated by `getEndLMTime`.\\n```\\nfunction getEndLMTime() public view override returns (uint256) {\\n    return startLiquidityMiningTime.add(2 weeks);\\n}\\n```\\n\\nThis value is also fixed, once the start was defined.\\nNone of the values change after the contract was deployed. This is why you can use the immutable feature provided by Solidity.\\nIt will reduce costs significantly.\\n```\\ncontract A {\\n    uint public immutable start;\\n    uint public immutable end;\\n   \\n    constructor() {\\n        start = block.timestamp;\\n        end = block.timestamp + 2 weeks;\\n    }\\n}\\n```\\n\\nThis contract defines 2 variables: `start` and `end` and their value is fixed on deploy and cannot be changed.\\nIt does not need to use `SafeMath` because there's no risk of overflowing.\\nSetting `public` on both variables creates getters, and calling `A.start()` and `A.end()` returns the respective values.\\nHaving set as immutable does not request EVM storage and makes them very cheap to access.чUse Solidity's immutable feature to reduce gas costs and rename variables for consistency.\\nUse the example for inspiration.чч```\\nstartLiquidityMiningTime = block.timestamp;       \\n```\\n
Computing the quote should be done for a positive amount of tokensчlowчWhen a policy is bought, a quote is requested from the `PolicyQuote` contract.\\n```\\nfunction \\_buyPolicyFor(\\n  address \\_policyHolderAddr,\\n  uint256 \\_epochsNumber,\\n  uint256 \\_coverTokens\\n) internal {\\n```\\n\\n```\\nuint256 \\_totalPrice = policyQuote.getQuote(\\_totalSeconds, \\_coverTokens, address(this));\\n```\\n\\nThe `getQuote` call is then forwarded to an internal function\\n```\\nfunction getQuote(uint256 \\_durationSeconds, uint256 \\_tokens, address \\_policyBookAddr)\\n  external view override returns (uint256 \\_daiTokens)\\n{\\n  \\_daiTokens = \\_getQuote(\\_durationSeconds, \\_tokens, \\_policyBookAddr);\\n}\\n```\\n\\n```\\nfunction \\_getQuote(uint256 \\_durationSeconds, uint256 \\_tokens, address \\_policyBookAddr)\\n  internal view returns (uint256)\\n{\\n```\\n\\nThere are some basic checks that make sure the total covered tokens with the requested quote do not exceed the total liquidity. On top of that check, it makes sure the total liquidity is positive.\\n```\\nrequire(\\_totalCoverTokens.add(\\_tokens) <= \\_totalLiquidity, \"PolicyBook: Requiring more than there exists\");\\nrequire(\\_totalLiquidity > 0, \"PolicyBook: The pool is empty\");\\n```\\n\\nBut there is no check for the number of quoted tokens. It should also be positive.чAdd an additional check for the number of quoted tokens to be positive. The check could fail or return 0, depending on your use case.\\nIf you add a check for the number of quoted tokens to be positive, the check for `_totalLiquidity` to be positive becomes obsolete and can be removed.чч```\\nfunction \\_buyPolicyFor(\\n  address \\_policyHolderAddr,\\n  uint256 \\_epochsNumber,\\n  uint256 \\_coverTokens\\n) internal {\\n```\\n
Anyone can win all the funds from the LiquidityMining without investing any DAIчhighчWhen a user decides to `investDAI` in the `LiquidityMining` contract, the policy book address is passed as a parameter:\\n```\\nfunction investDAI(uint256 \\_tokensAmount, address \\_policyBookAddr) external override {\\n```\\n\\nBut this parameter is never checked and only used at the end of the function:\\n```\\nIPolicyBook(\\_policyBookAddr).addLiquidityFromLM(msg.sender, \\_tokensAmount);\\n```\\n\\nThe attacker can pass the address of a simple multisig that will process this transaction successfully without doing anything. And pretend to invest a lot of DAI without actually doing that to win all the rewards in the `LiquidityMining` contract.чCheck that the pool address is valid.чч```\\nfunction investDAI(uint256 \\_tokensAmount, address \\_policyBookAddr) external override {\\n```\\n
Liquidity withdrawal can be blockedчhighчThe main problem in that issue is that the liquidity provider may face many potential issues when withdrawing the liquidity. Under some circumstances, a normal user will never be able to withdraw the liquidity. This issue consists of multiple factors that are interconnected and share the same solution.\\nThere are no partial withdrawals when in the queue. When the withdrawal request is added to the queue, it can only be processed fully:\\n```\\naddress \\_currentAddr = withdrawalQueue.head();\\nuint256 \\_tokensToWithdraw = withdrawalsInfo[\\_currentAddr].withdrawalAmount;\\n \\nuint256 \\_amountInDAI = convertDAIXtoDAI(\\_tokensToWithdraw);\\n \\nif (\\_availableLiquidity < \\_amountInDAI) {\\n  break;\\n}\\n```\\n\\nBut when the request is not in the queue, it can still be processed partially, and the rest of the locked tokens will wait in the queue.\\n```\\n} else if (\\_availableLiquidity < convertDAIXtoDAI(\\_tokensToWithdraw)) {\\n  uint256 \\_availableDAIxTokens = convertDAIToDAIx(\\_availableLiquidity);\\n  uint256 \\_currentWithdrawalAmount = \\_tokensToWithdraw.sub(\\_availableDAIxTokens);\\n  withdrawalsInfo[\\_msgSender()].withdrawalAmount = \\_currentWithdrawalAmount;\\n \\n  aggregatedQueueAmount = aggregatedQueueAmount.add(\\_currentWithdrawalAmount);\\n  withdrawalQueue.push(\\_msgSender());\\n \\n  \\_withdrawLiquidity(\\_msgSender(), \\_availableDAIxTokens);\\n} else {\\n```\\n\\nIf there's a huge request in the queue, it can become a bottleneck that does not allow others to withdraw even if there is enough free liquidity.\\nWithdrawals can be blocked forever by the bots.\\nThe withdrawal can only be requested if there are enough free funds in the contract. But once these funds appear, the bots can instantly buy a policy, and for the normal users, it will be impossible to request the withdrawal. Even when a withdrawal is requested and then in the queue, the same problem appears at that stage.\\nThe policy can be bought even if there are pending withdrawals in the queue.чOne of the solutions would be to implement the following changes, but the team should thoroughly consider them:\\nAllow people to request the withdrawal even if there is not enough liquidity at the moment.\\nDo not allow people to buy policies if there are pending withdrawals in the queue and cannot be executed.\\n(Optional) Even when the queue is empty, do not allow people to buy policies if there is not enough liquidity for the pending requests (that are not yet in the queue).\\n(Optional if the points above are implemented) Allow partial executions of the withdrawals in the queue.чч```\\naddress \\_currentAddr = withdrawalQueue.head();\\nuint256 \\_tokensToWithdraw = withdrawalsInfo[\\_currentAddr].withdrawalAmount;\\n \\nuint256 \\_amountInDAI = convertDAIXtoDAI(\\_tokensToWithdraw);\\n \\nif (\\_availableLiquidity < \\_amountInDAI) {\\n  break;\\n}\\n```\\n
The totalCoverTokens can be decreased before the claim is committedчhighчThe `totalCoverTokens` is decreased right after the policy duration ends (_endEpochNumber). When that happens, the liquidity providers can withdraw their funds:\\n```\\npolicyHolders[\\_msgSender()] = PolicyHolder(\\_coverTokens, currentEpochNumber,\\n  \\_endEpochNumber, \\_totalPrice, \\_reinsurancePrice);\\n\\nepochAmounts[\\_endEpochNumber] = epochAmounts[\\_endEpochNumber].add(\\_coverTokens);\\n```\\n\\n```\\nuint256 \\_countOfPassedEpoch = block.timestamp.sub(epochStartTime).div(EPOCH\\_DURATION);\\n\\nnewTotalCoverTokens = totalCoverTokens;\\nlastEpochUpdate = currentEpochNumber;\\nnewEpochNumber = \\_countOfPassedEpoch.add(1);\\n\\nfor (uint256 i = lastEpochUpdate; i < newEpochNumber; i++) {\\n  newTotalCoverTokens = newTotalCoverTokens.sub(epochAmounts[i]);     \\n}\\n```\\n\\nOn the other hand, the claim can be created while the policy is still “active”. And is considered active until one week after the policy expired:\\n```\\nfunction isPolicyActive(address \\_userAddr, address \\_policyBookAddr) public override view returns (bool) {\\n  PolicyInfo storage \\_currentInfo = policyInfos[\\_userAddr][\\_policyBookAddr];\\n\\n  if (\\_currentInfo.endTime == 0) {\\n    return false;\\n  }\\n\\n  return \\_currentInfo.endTime.add(STILL\\_CLAIMABLE\\_FOR) > block.timestamp;\\n}\\n```\\n\\nBy the time when the claim is created + voted, the liquidity provider can potentially withdraw all of their funds already, and the claim will fail.чMake sure that there will always be enough funds for the claim.чч```\\npolicyHolders[\\_msgSender()] = PolicyHolder(\\_coverTokens, currentEpochNumber,\\n  \\_endEpochNumber, \\_totalPrice, \\_reinsurancePrice);\\n\\nepochAmounts[\\_endEpochNumber] = epochAmounts[\\_endEpochNumber].add(\\_coverTokens);\\n```\\n
The totalCoverTokens is not decreased after the claim happenedчhighчWhen the claim happens and the policy is removed, the `totalCoverTokens` should be decreased instantly, that's why the scheduled reduction value is removed:\\n```\\nPolicyHolder storage holder = policyHolders[claimer];\\n\\nepochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\\ntotalLiquidity = totalLiquidity.sub(claimAmount);\\n\\ndaiToken.transfer(claimer, claimAmount);\\n               \\ndelete policyHolders[claimer];\\npolicyRegistry.removePolicy(claimer);\\n```\\n\\nBut the `totalCoverTokens` is not changed and will have the coverage from the removed policy forever.чDecrease the `totalCoverTokens` inside the `commitClaim` function.чч```\\nPolicyHolder storage holder = policyHolders[claimer];\\n\\nepochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\\ntotalLiquidity = totalLiquidity.sub(claimAmount);\\n\\ndaiToken.transfer(claimer, claimAmount);\\n               \\ndelete policyHolders[claimer];\\npolicyRegistry.removePolicy(claimer);\\n```\\n
The Queue remove function does not remove the item completelyчhighчWhen removing an item in a queue, the following function is used:\\n```\\nfunction remove(UniqueAddressQueue storage baseQueue, address addrToRemove) internal returns (bool) {\\n    if (!contains(baseQueue, addrToRemove)) {\\n        return false;\\n    }\\n\\n    if (baseQueue.HEAD == addrToRemove) {\\n        return removeFirst(baseQueue);\\n    }\\n\\n    if (baseQueue.TAIL == addrToRemove) {\\n        return removeLast(baseQueue);\\n    }\\n\\n    address prevAddr = baseQueue.queue[addrToRemove].prev;\\n    address nextAddr = baseQueue.queue[addrToRemove].next;\\n    baseQueue.queue[prevAddr].next = nextAddr;\\n    baseQueue.queue[nextAddr].prev = prevAddr;\\n    baseQueue.queueLength--;\\n\\n    return true;\\n}\\n```\\n\\nAs the result, the `baseQueue.queue[addrToRemove]` is not deleted, so the `contains` function will still return `True` after the removal.чRemove the element from the queue completely.чч```\\nfunction remove(UniqueAddressQueue storage baseQueue, address addrToRemove) internal returns (bool) {\\n    if (!contains(baseQueue, addrToRemove)) {\\n        return false;\\n    }\\n\\n    if (baseQueue.HEAD == addrToRemove) {\\n        return removeFirst(baseQueue);\\n    }\\n\\n    if (baseQueue.TAIL == addrToRemove) {\\n        return removeLast(baseQueue);\\n    }\\n\\n    address prevAddr = baseQueue.queue[addrToRemove].prev;\\n    address nextAddr = baseQueue.queue[addrToRemove].next;\\n    baseQueue.queue[prevAddr].next = nextAddr;\\n    baseQueue.queue[nextAddr].prev = prevAddr;\\n    baseQueue.queueLength--;\\n\\n    return true;\\n}\\n```\\n
Optimization issueчmediumчThe codebase is huge, and there are still a lot of places where these complications and gas efficiency can be improved.\\n`_updateTopUsers`, `_updateGroupLeaders`, `_updateLeaderboard` are having a similar mechanism of adding users to a sorted set which makes more storage operations than needed:\\n```\\nuint256 \\_tmpIndex = \\_currentIndex - 1;\\nuint256 \\_currentUserAmount = usersTeamInfo[msg.sender].stakedAmount;\\n \\nwhile (\\_currentUserAmount > usersTeamInfo[topUsers[\\_tmpIndex]].stakedAmount) {\\n    address \\_tmpAddr = topUsers[\\_tmpIndex];\\n    topUsers[\\_tmpIndex] = msg.sender;\\n    topUsers[\\_tmpIndex + 1] = \\_tmpAddr;\\n \\n    if (\\_tmpIndex == 0) {\\n        break;\\n    }\\n \\n    \\_tmpIndex--;\\n}\\n```\\n\\nInstead of doing 2 operations per item that is lower than the new_item, same can be done with one operation: while `topUsers[_tmpIndex]` is lower than the new itemtopUsers[_tmpIndex + 1] = `topUsers[_tmpIndex]`.\\ncreating the Queue library looks like overkill `for` the intended task. It is only used `for` the withdrawal queue in the PolicyBook. The structure stores and processes extra data, which is unnecessary and more expensive. A larger codebase also has a higher chance of introducing a bug (and it happened here https://github.com/ConsenSys/bridge-mutual-audit-2021-03/issues/25). It's usually better to have a simpler and optimized version like described here issue 5.14.\\nThere are a few `for` loops that are using `uint8` iterators. It's unnecessary and can be even more expensive because, under the hood, it's additionally converted to `uint256` all the time. In general, shrinking data to `uint8` makes sense to optimize storage slots, but that's not the case here.\\nThe value that is calculated in a loop can be obtained simpler by just having a 1-line formula:\\n```\\nfunction \\_getAvailableMonthForReward(address \\_userAddr) internal view returns (uint256) {\\n    uint256 \\_oneMonth = 30 days;\\n    uint256 \\_startRewardTime = getEndLMTime();\\n \\n    uint256 \\_countOfRewardedMonth = countsOfRewardedMonth[usersTeamInfo[\\_userAddr].teamAddr][\\_userAddr];\\n    uint256 \\_numberOfMonthForReward;\\n \\n    for (uint256 i = \\_countOfRewardedMonth; i < MAX\\_MONTH\\_TO\\_GET\\_REWARD; i++) {\\n        if (block.timestamp > \\_startRewardTime.add(\\_oneMonth.mul(i))) {\\n        \\_numberOfMonthForReward++;\\n        } else {\\n            break;\\n        }\\n    }\\n \\n    return \\_numberOfMonthForReward;\\n}\\n```\\n\\nThe mapping is using 2 keys, but the first key is strictly defined by the second one, so there's no need for it:\\n```\\n// Referral link => Address => count of rewarded month\\nmapping (address => mapping (address => uint256)) public countsOfRewardedMonth;\\n```\\n\\nThere are a lot of structures in the code with duplicated and unnecessary data, for example:\\n```\\nstruct UserTeamInfo {\\n    string teamName;\\n    address teamAddr;\\n \\n    uint256 stakedAmount;\\n    bool isNFTDistributed;\\n}\\n```\\n\\nHere the structure is created for every team member, duplicating the team name for each member.чOptimize and simplify the code.чч```\\nuint256 \\_tmpIndex = \\_currentIndex - 1;\\nuint256 \\_currentUserAmount = usersTeamInfo[msg.sender].stakedAmount;\\n \\nwhile (\\_currentUserAmount > usersTeamInfo[topUsers[\\_tmpIndex]].stakedAmount) {\\n    address \\_tmpAddr = topUsers[\\_tmpIndex];\\n    topUsers[\\_tmpIndex] = msg.sender;\\n    topUsers[\\_tmpIndex + 1] = \\_tmpAddr;\\n \\n    if (\\_tmpIndex == 0) {\\n        break;\\n    }\\n \\n    \\_tmpIndex--;\\n}\\n```\\n
The aggregatedQueueAmount value is used inconsistentlyчmediumчThe `aggregatedQueueAmount` variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:\\n```\\nrequire(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(\\_daiTokensToWithdraw),\\n  \"PB: Not enough available liquidity\");\\n```\\n\\nThat may lead to allowing the withdrawal request even if it shouldn't be allowed and the opposite.чConvert `aggregatedQueueAmount` to DAI in the `_requestWithdrawal`.чч```\\nrequire(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(\\_daiTokensToWithdraw),\\n  \"PB: Not enough available liquidity\");\\n```\\n
The claim can only be done onceчmediumчWhen the claim happens, the policy is removed afterward:\\n```\\nfunction commitClaim(address claimer, uint256 claimAmount)\\n  external \\n  override\\n  onlyClaimVoting\\n  updateBMIDAIXStakingReward\\n{\\n  PolicyHolder storage holder = policyHolders[claimer];\\n\\n  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\\n  totalLiquidity = totalLiquidity.sub(claimAmount);\\n \\n  daiToken.transfer(claimer, claimAmount);\\n                 \\n  delete policyHolders[claimer];\\n  policyRegistry.removePolicy(claimer);\\n}\\n```\\n\\nIf the claim amount is much lower than the coverage, the users are incentivized not to submit it and wait until the end of the coverage period to accumulate all the claims into one.чAllow the policyholders to submit multiple claims until the `coverTokens` is not reached.чч```\\nfunction commitClaim(address claimer, uint256 claimAmount)\\n  external \\n  override\\n  onlyClaimVoting\\n  updateBMIDAIXStakingReward\\n{\\n  PolicyHolder storage holder = policyHolders[claimer];\\n\\n  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\\n  totalLiquidity = totalLiquidity.sub(claimAmount);\\n \\n  daiToken.transfer(claimer, claimAmount);\\n                 \\n  delete policyHolders[claimer];\\n  policyRegistry.removePolicy(claimer);\\n}\\n```\\n
iETH.exchangeRateStored may not be accurate when invoked from external contractsчhighч`iETH.exchangeRateStored` returns the exchange rate of the contract as a function of the current cash of the contract. In the case of `iETH`, current cash is calculated as the contract's ETH balance minus msg.value:\\n```\\n/\\*\\*\\n \\* @dev Gets balance of this contract in terms of the underlying\\n \\*/\\nfunction \\_getCurrentCash() internal view override returns (uint256) {\\n    return address(this).balance.sub(msg.value);\\n}\\n```\\n\\n`msg.value` is subtracted because the majority of `iETH` methods are payable, and `msg.value` is implicitly added to a contract's balance before execution begins. If `msg.value` were not subtracted, the value sent with a call could be used to inflate the contract's exchange rate artificially.\\nAs part of execution, `iETH` makes calls to the `Controller`, which performs important checks using (among other things) the stored exchange rate. When `exchangeRateStored` is invoked from the `Controller`, the call context has a `msg.value` of 0. However, the `msg.value` sent by the initial `iETH` execution is still included in the contract's balance. This means that the `Controller` receives an exchange rate inflated by the initial call's `msg.value`.\\nThis problem occurs in multiple locations in the Controller:\\n`beforeMint` uses the exchange rate to ensure the supply capacity of the market is not reached. In this case, inflation would prevent the entire supply capacity of the market from being utilized:\\n```\\n// Check the iToken's supply capacity, -1 means no limit\\nuint256 \\_totalSupplyUnderlying =\\n    IERC20Upgradeable(\\_iToken).totalSupply().rmul(\\n        IiToken(\\_iToken).exchangeRateStored()\\n    );\\nrequire(\\n    \\_totalSupplyUnderlying.add(\\_mintAmount) <= \\_market.supplyCapacity,\\n    \"Token supply capacity reached\"\\n);\\n```\\n\\n`beforeLiquidateBorrow` uses the exchange rate via `calcAccountEquity` to calculate the value of the borrower's collateral. In this case, inflation would increase the account's equity, which could prevent the liquidator from liquidating:\\n```\\n(, uint256 \\_shortfall, , ) = calcAccountEquity(\\_borrower);\\n\\nrequire(\\_shortfall > 0, \"Account does not have shortfall\");\\n```\\nчResolution\\nThis issue was addressed in commit `9876e3a` by using a modifier to track the current `msg.value` of payable functions.\\nRather than having the `Controller` query the `iETH.exchangeRateStored`, the exchange rate could be passed-in to `Controller` methods as a parameter.\\nEnsure no other components in the system rely on `iETH.exchangeRateStored` after being called from `iETH`.чч```\\n/\\*\\*\\n \\* @dev Gets balance of this contract in terms of the underlying\\n \\*/\\nfunction \\_getCurrentCash() internal view override returns (uint256) {\\n    return address(this).balance.sub(msg.value);\\n}\\n```\\n
Unbounded loop in Controller.calcAccountEquity allows DoS on liquidationчhighч`Controller.calcAccountEquity` calculates the relative value of a user's supplied collateral and their active borrow positions. Users may mark an arbitrary number of assets as collateral, and may borrow from an arbitrary number of assets. In order to calculate the value of both of these positions, this method performs two loops.\\nFirst, to calculate the sum of the value of a user's collateral:\\n```\\n// Calculate value of all collaterals\\n// collateralValuePerToken = underlyingPrice \\* exchangeRate \\* collateralFactor\\n// collateralValue = balance \\* collateralValuePerToken\\n// sumCollateral += collateralValue\\nuint256 \\_len = \\_accountData.collaterals.length();\\nfor (uint256 i = 0; i < \\_len; i++) {\\n    IiToken \\_token = IiToken(\\_accountData.collaterals.at(i));\\n```\\n\\nSecond, to calculate the sum of the value of a user's borrow positions:\\n```\\n// Calculate all borrowed value\\n// borrowValue = underlyingPrice \\* underlyingBorrowed / borrowFactor\\n// sumBorrowed += borrowValue\\n\\_len = \\_accountData.borrowed.length();\\nfor (uint256 i = 0; i < \\_len; i++) {\\n    IiToken \\_token = IiToken(\\_accountData.borrowed.at(i));\\n```\\n\\nFrom dForce, we learned that 200 or more assets would be supported by the Controller. This means that a user with active collateral and borrow positions on all 200 supported assets could force any `calcAccountEquity` action to perform some 400 iterations of these loops, each with several expensive external calls.\\nBy modifying dForce's unit test suite, we showed that an attacker could force the cost of `calcAccountEquity` above the block gas limit. This would prevent all of the following actions, as each relies on calcAccountEquity:\\n`iToken.transfer` and `iToken.transferFrom`\\n`iToken.redeem` and `iToken.redeemUnderlying`\\n`iToken.borrow`\\n`iToken.liquidateBorrow` and `iToken.seize`\\nThe following actions would still be possible:\\n`iToken.mint`\\n`iToken.repayBorrow` and `iToken.repayBorrowBehalf`\\nAs a result, an attacker may abuse the unbounded looping in `calcAccountEquity` to prevent the liquidation of underwater positions. We provided dForce with a PoC here: gist.чThere are many possible ways to address this issue. Some ideas have been outlined below, and it may be that a combination of these ideas is the best approach:\\nIn general, cap the number of markets and borrowed assets a user may have: The primary cause of the DoS is that the number of collateral and borrow positions held by a user is only restricted by the number of supported assets. The PoC provided above showed that somewhere around 150 collateral positions and 150 borrow positions, the gas costs of `calcAccountEquity` use most of the gas in a block. Given that gas prices often spike along with turbulent market conditions and that liquidations are far more likely in turbulent market conditions, a cap on active markets / borrows should be much lower than 150 each so as to keep the cost of liquidations as low as possible.\\ndForce should perform their own gas cost estimates to determine a cap, and choose a safe, low value. Estimates should be performed on the high-level `liquidateBorrow` method, so as to simulate an actual liquidation event. Additionally, estimates should factor in a changing block gas limit, and the possibility of opcode gas costs changing in future forks. It may be wise to make this cap configurable, so that the limits may be adjusted for future conditions.чч```\\n// Calculate value of all collaterals\\n// collateralValuePerToken = underlyingPrice \\* exchangeRate \\* collateralFactor\\n// collateralValue = balance \\* collateralValuePerToken\\n// sumCollateral += collateralValue\\nuint256 \\_len = \\_accountData.collaterals.length();\\nfor (uint256 i = 0; i < \\_len; i++) {\\n    IiToken \\_token = IiToken(\\_accountData.collaterals.at(i));\\n```\\n
Fix utilization rate computation and respect reserves when lendingчmediumчThe utilization rate `UR` of an asset forms the basis for interest calculations and is defined as `borrows / ( borrows + cash - reserves)`.\\n```\\n/\\*\\*\\n \\* @notice Calculate the utilization rate: `\\_borrows / (\\_cash + \\_borrows - \\_reserves)`\\n \\* @param \\_cash Asset balance\\n \\* @param \\_borrows Asset borrows\\n \\* @param \\_reserves Asset reserves\\n \\* @return Asset utilization [0, 1e18]\\n \\*/\\nfunction utilizationRate(\\n    uint256 \\_cash,\\n    uint256 \\_borrows,\\n    uint256 \\_reserves\\n) internal pure returns (uint256) {\\n    // Utilization rate is 0 when there are no borrows\\n    if (\\_borrows == 0) return 0;\\n\\n    return \\_borrows.mul(BASE).div(\\_cash.add(\\_borrows).sub(\\_reserves));\\n}\\n```\\n\\nThe implicit assumption here is that `reserves` <= cash; in this case — and if we define `UR` as `0` for borrows == `0` — we have `0` <= `UR` <=1. We can view `cash` - `reserves` as “available cash”. However, the system does not guarantee that `reserves` never exceeds `cash`. If `reserves` > `cash` (and borrows + `cash` - `reserves` > 0), the formula for `UR` above gives a utilization rate above `1`. This doesn't make much sense conceptually and has undesirable technical consequences; an especially severe one is analyzed in issue 4.4.чIf `reserves` > cash — or, in other words, available cash is negative — this means part of the `reserves` have been borrowed, which ideally shouldn't happen in the first place. However, the `reserves` grow automatically over time, so it might be difficult to avoid this entirely. We recommend (1) avoiding this situation whenever it is possible and (2) fixing the `UR` computation such that it deals more gracefully with this scenario. More specifically:\\nLoan amounts should not be checked to be smaller than or equal to `cash` but `cash - reserves` (which might be negative). Note that the current check against `cash` happens more or less implicitly because the transfer just fails for insufficient `cash`.\\nMake the utilization rate computation return `1` if `reserves > cash` (unless borrows == `0`, in which case return `0` as is already the case).\\nRemark\\nInternally, the utilization rate and other fractional values are scaled by `1e18`. The discussion above has a more conceptual than technical perspective, so we used unscaled numbers. When making changes to the code, care must be taken to apply the scaling.чч```\\n/\\*\\*\\n \\* @notice Calculate the utilization rate: `\\_borrows / (\\_cash + \\_borrows - \\_reserves)`\\n \\* @param \\_cash Asset balance\\n \\* @param \\_borrows Asset borrows\\n \\* @param \\_reserves Asset reserves\\n \\* @return Asset utilization [0, 1e18]\\n \\*/\\nfunction utilizationRate(\\n    uint256 \\_cash,\\n    uint256 \\_borrows,\\n    uint256 \\_reserves\\n) internal pure returns (uint256) {\\n    // Utilization rate is 0 when there are no borrows\\n    if (\\_borrows == 0) return 0;\\n\\n    return \\_borrows.mul(BASE).div(\\_cash.add(\\_borrows).sub(\\_reserves));\\n}\\n```\\n
If Base._updateInterest fails, the entire system will haltчmediumчBefore executing most methods, the `iETH` and `iToken` contracts update interest accumulated on borrows via the method `Base._updateInterest`. This method uses the contract's interest rate model to calculate the borrow interest rate. If the calculated value is above `maxBorrowRate` (0.001e18), the method will revert:\\n```\\nfunction \\_updateInterest() internal virtual override {\\n    InterestLocalVars memory \\_vars;\\n    \\_vars.currentCash = \\_getCurrentCash();\\n    \\_vars.totalBorrows = totalBorrows;\\n    \\_vars.totalReserves = totalReserves;\\n\\n    // Gets the current borrow interest rate.\\n    \\_vars.borrowRate = interestRateModel.getBorrowRate(\\n        \\_vars.currentCash,\\n        \\_vars.totalBorrows,\\n        \\_vars.totalReserves\\n    );\\n    require(\\n        \\_vars.borrowRate <= maxBorrowRate,\\n        \"\\_updateInterest: Borrow rate is too high!\"\\n    );\\n```\\n\\nIf this method reverts, the entire contract may halt and be unrecoverable. The only ways to change the values used to calculate this interest rate lie in methods that must first call `Base._updateInterest`. In this case, those methods would fail.\\nOne other potential avenue for recovery exists: the Owner role may update the interest rate calculation contract via TokenAdmin._setInterestRateModel:\\n```\\n/\\*\\*\\n \\* @dev Sets a new interest rate model.\\n \\* @param \\_newInterestRateModel The new interest rate model.\\n \\*/\\nfunction \\_setInterestRateModel(\\n    IInterestRateModelInterface \\_newInterestRateModel\\n) external virtual onlyOwner settleInterest {\\n    // Gets current interest rate model.\\n    IInterestRateModelInterface \\_oldInterestRateModel = interestRateModel;\\n\\n    // Ensures the input address is the interest model contract.\\n    require(\\n        \\_newInterestRateModel.isInterestRateModel(),\\n        \"\\_setInterestRateModel: This is not the rate model contract!\"\\n    );\\n\\n    // Set to the new interest rate model.\\n    interestRateModel = \\_newInterestRateModel;\\n```\\n\\nHowever, this method also calls `Base._updateInterest` before completing the upgrade, so it would fail as well.\\nWe used interest rate parameters taken from dForce's unit tests to determine whether any of the interest rate models could return a borrow rate that would cause this failure. The default `InterestRateModel` is deployed using these values:\\n```\\nbaseInterestPerBlock: 0\\ninterestPerBlock: 5.074e10\\nhighInterestPerBlock: 4.756e11\\nhigh: 0.75e18\\n```\\n\\nPlugging these values in to their borrow rate calculations, we determined that the utilization rate of the contract would need to be `2103e18` in order to reach the max borrow rate and trigger a failure. Plugging this in to the formula for utilization rate, we derived the following ratio:\\n`reserves >= (2102/2103)*borrows + cash`\\nWith the given interest rate parameters, if token reserves, total borrows, and underlying cash meet the above ratio, the interest rate model would return a borrow rate above the maximum, leading to the failure conditions described above.чNote that the examples above depend on the specific interest rate parameters configured by dForce. In general, with reasonable interest rate parameters and a reasonable reserve ratio, it seems unlikely that the maximum borrow rate will be reached. Consider implementing the following changes as a precaution:\\nAs utilization rate should be between `0` and `1` (scaled by 1e18), prevent utilization rate calculations from returning anything above `1e18`. See issue 4.3 for a more thorough discussion of this topic.\\nRemove the `settleInterest` modifier from TokenAdmin._setInterestRateModel: In a worst case scenario, this will allow the Owner role to update the interest rate model without triggering the failure in `Base._updateInterest`.чч```\\nfunction \\_updateInterest() internal virtual override {\\n    InterestLocalVars memory \\_vars;\\n    \\_vars.currentCash = \\_getCurrentCash();\\n    \\_vars.totalBorrows = totalBorrows;\\n    \\_vars.totalReserves = totalReserves;\\n\\n    // Gets the current borrow interest rate.\\n    \\_vars.borrowRate = interestRateModel.getBorrowRate(\\n        \\_vars.currentCash,\\n        \\_vars.totalBorrows,\\n        \\_vars.totalReserves\\n    );\\n    require(\\n        \\_vars.borrowRate <= maxBorrowRate,\\n        \"\\_updateInterest: Borrow rate is too high!\"\\n    );\\n```\\n
RewardDistributor requirement prevents transition of Owner role to smart contractчmediumчFrom dForce, we learned that the eventual plan for the system Owner role is to use a smart contract (a multisig or DAO). However, a requirement in `RewardDistributor` would prevent the `onlyOwner` method `_setDistributionFactors` from working in this case.\\n`_setDistributionFactors` calls `updateDistributionSpeed`, which requires that the caller is an EOA:\\n```\\n/\\*\\*\\n \\* @notice Update each iToken's distribution speed according to current global speed\\n \\* @dev Only EOA can call this function\\n \\*/\\nfunction updateDistributionSpeed() public override {\\n    require(msg.sender == tx.origin, \"only EOA can update speeds\");\\n    require(!paused, \"Can not update speeds when paused\");\\n\\n    // Do the actual update\\n    \\_updateDistributionSpeed();\\n}\\n```\\n\\nIn the event the Owner role is a smart contract, this statement would necessitate a complicated upgrade to restore full functionality.чRather than invoking `updateDistributionSpeed`, have `_setDistributionFactors` directly call the internal helper `_updateDistributionSpeed`, which does not require the caller is an EOA.чч```\\n/\\*\\*\\n \\* @notice Update each iToken's distribution speed according to current global speed\\n \\* @dev Only EOA can call this function\\n \\*/\\nfunction updateDistributionSpeed() public override {\\n    require(msg.sender == tx.origin, \"only EOA can update speeds\");\\n    require(!paused, \"Can not update speeds when paused\");\\n\\n    // Do the actual update\\n    \\_updateDistributionSpeed();\\n}\\n```\\n
MSDController._withdrawReserves does not update interest before withdrawalчmediumч`MSDController._withdrawReserves` allows the Owner to mint the difference between an MSD asset's accumulated debt and earnings:\\n```\\nfunction \\_withdrawReserves(address \\_token, uint256 \\_amount)\\n    external\\n    onlyOwner\\n    onlyMSD(\\_token)\\n{\\n    (uint256 \\_equity, ) = calcEquity(\\_token);\\n\\n    require(\\_equity >= \\_amount, \"Token do not have enough reserve\");\\n\\n    // Increase the token debt\\n    msdTokenData[\\_token].debt = msdTokenData[\\_token].debt.add(\\_amount);\\n\\n    // Directly mint the token to owner\\n    MSD(\\_token).mint(owner, \\_amount);\\n```\\n\\nDebt and earnings are updated each time the asset's `iMSD` and `MSDS` contracts are used for the first time in a given block. Because `_withdrawReserves` does not force an update to these values, it is possible for the withdrawal amount to be calculated using stale values.чEnsure `_withdrawReserves` invokes `iMSD.updateInterest()` and `MSDS.updateInterest()`.чч```\\nfunction \\_withdrawReserves(address \\_token, uint256 \\_amount)\\n    external\\n    onlyOwner\\n    onlyMSD(\\_token)\\n{\\n    (uint256 \\_equity, ) = calcEquity(\\_token);\\n\\n    require(\\_equity >= \\_amount, \"Token do not have enough reserve\");\\n\\n    // Increase the token debt\\n    msdTokenData[\\_token].debt = msdTokenData[\\_token].debt.add(\\_amount);\\n\\n    // Directly mint the token to owner\\n    MSD(\\_token).mint(owner, \\_amount);\\n```\\n
permit functions use deployment-time instead of execution-time chain IDчlowчThe contracts `Base`, `MSD`, and `MSDS` each have an EIP-2612-style `permit` function that supports approvals with EIP-712 signatures. We focus this discussion on the `Base` contract, but the same applies to `MSD` and `MSDS`.\\nWhen the contract is initialized, the chain ID is queried (with the `CHAINID` opcode) and becomes part of the `DOMAIN_SEPARATOR` — a hash of several values which (presumably) don't change over the lifetime of the contract and that can therefore be computed only once, when the contract is deployed.\\n```\\nfunction \\_initialize(\\n    string memory \\_name,\\n    string memory \\_symbol,\\n    uint8 \\_decimals,\\n    IControllerInterface \\_controller,\\n    IInterestRateModelInterface \\_interestRateModel\\n) internal virtual {\\n    controller = \\_controller;\\n    interestRateModel = \\_interestRateModel;\\n    accrualBlockNumber = block.number;\\n    borrowIndex = BASE;\\n    flashloanFeeRatio = 0.0008e18;\\n    protocolFeeRatio = 0.25e18;\\n    \\_\\_Ownable\\_init();\\n    \\_\\_ERC20\\_init(\\_name, \\_symbol, \\_decimals);\\n    \\_\\_ReentrancyGuard\\_init();\\n\\n    uint256 chainId;\\n\\n    assembly {\\n        chainId := chainid()\\n    }\\n    DOMAIN\\_SEPARATOR = keccak256(\\n        abi.encode(\\n            keccak256(\\n                \"EIP712Domain(string name,string version,uint256 chainId,address verifyingContract)\"\\n            ),\\n            keccak256(bytes(\\_name)),\\n            keccak256(bytes(\"1\")),\\n            chainId,\\n            address(this)\\n        )\\n    );\\n}\\n```\\n\\nThe `DOMAIN_SEPARATOR` is supposed to prevent replay attacks by providing context for the signature; it is hashed into the digest to be signed.\\n```\\nbytes32 \\_digest =\\n    keccak256(\\n        abi.encodePacked(\\n            \"\\x19\\x01\",\\n            DOMAIN\\_SEPARATOR,\\n            keccak256(\\n                abi.encode(\\n                    PERMIT\\_TYPEHASH,\\n                    \\_owner,\\n                    \\_spender,\\n                    \\_value,\\n                    \\_currentNonce,\\n                    \\_deadline\\n                )\\n            )\\n        )\\n    );\\naddress \\_recoveredAddress = ecrecover(\\_digest, \\_v, \\_r, \\_s);\\nrequire(\\n    \\_recoveredAddress != address(0) && \\_recoveredAddress == \\_owner,\\n    \"permit: INVALID\\_SIGNATURE!\"\\n);\\n```\\n\\nThe chain ID is not necessarily constant, though. In the event of a chain split, only one of the resulting chains gets to keep the original chain ID and the other will have to use a new one. With the current pattern, a signature will be valid on both chains; if the `DOMAIN_SEPARATOR` is recomputed for every verification, a signature will only be valid on the chain that keeps the original ID — which is probably the intended behavior.\\nRemark\\nThe reason why the not necessarily constant chain ID is part of the supposedly constant `DOMAIN_SEPARATOR` is that EIP-712 predates the introduction of the `CHAINID` opcode. Originally, it was not possible to query the chain ID via opcode, so it had to be supplied to the constructor of a contract by the deployment script.чAn obvious fix is to compute the `DOMAIN_SEPARATOR` dynamically in `permit`. However, since a chain split is a relatively unlikely event, it makes sense to compute the `DOMAIN_SEPARATOR` at deployment/initialization time and then check in `permit` whether the current chain ID equals the one that went into the `DOMAIN_SEPARATOR`. If that is true, we proceed as before. If the chain ID has changed, we could (1) just revert, or (2) recompute the `DOMAIN_SEPARATOR` with the new chain ID. Solution (1) is probably the easiest and most straightforward to implement, but it should be noted that it makes the `permit` functionality of this contract completely unusable on the new chain.чч```\\nfunction \\_initialize(\\n    string memory \\_name,\\n    string memory \\_symbol,\\n    uint8 \\_decimals,\\n    IControllerInterface \\_controller,\\n    IInterestRateModelInterface \\_interestRateModel\\n) internal virtual {\\n    controller = \\_controller;\\n    interestRateModel = \\_interestRateModel;\\n    accrualBlockNumber = block.number;\\n    borrowIndex = BASE;\\n    flashloanFeeRatio = 0.0008e18;\\n    protocolFeeRatio = 0.25e18;\\n    \\_\\_Ownable\\_init();\\n    \\_\\_ERC20\\_init(\\_name, \\_symbol, \\_decimals);\\n    \\_\\_ReentrancyGuard\\_init();\\n\\n    uint256 chainId;\\n\\n    assembly {\\n        chainId := chainid()\\n    }\\n    DOMAIN\\_SEPARATOR = keccak256(\\n        abi.encode(\\n            keccak256(\\n                \"EIP712Domain(string name,string version,uint256 chainId,address verifyingContract)\"\\n            ),\\n            keccak256(bytes(\\_name)),\\n            keccak256(bytes(\"1\")),\\n            chainId,\\n            address(this)\\n        )\\n    );\\n}\\n```\\n
iETH.receive() does not support contracts executing during their constructorчlowч`iETH.receive()` requires that the caller is a contract:\\n```\\n/\\*\\*\\n \\* @notice receive ETH, used for flashloan repay.\\n \\*/\\nreceive() external payable {\\n    require(\\n        msg.sender.isContract(),\\n        \"receive: Only can call from a contract!\"\\n    );\\n}\\n```\\n\\nThis method uses the `extcodesize` of an account to check that the account belongs to a contract. However, contracts currently executing their constructor will have an `extcodesize` of 0, and will not be able to use this method.\\nThis is unlikely to cause significant issues, but dForce may want to consider supporting this edge case.чUse `msg.sender != tx.origin` as a more reliable method to detect use by a contract.чч```\\n/\\*\\*\\n \\* @notice receive ETH, used for flashloan repay.\\n \\*/\\nreceive() external payable {\\n    require(\\n        msg.sender.isContract(),\\n        \"receive: Only can call from a contract!\"\\n    );\\n}\\n```\\n
Token approvals can be stolen in DAOfiV1Router01.addLiquidity()чhighч`DAOfiV1Router01.addLiquidity()` creates the desired pair contract if it does not already exist, then transfers tokens into the pair and calls `DAOfiV1Pair.deposit()`. There is no validation of the address to transfer tokens from, so an attacker could pass in any address with nonzero token approvals to `DAOfiV1Router`. This could be used to add liquidity to a pair contract for which the attacker is the `pairOwner`, allowing the stolen funds to be retrieved using `DAOfiV1Pair.withdraw()`.\\n```\\nfunction addLiquidity(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint256 amountBase) {\\n    if (IDAOfiV1Factory(factory).getPair(\\n        lp.tokenBase,\\n        lp.tokenQuote,\\n        lp.slopeNumerator,\\n        lp.n,\\n        lp.fee\\n    ) == address(0)) {\\n        IDAOfiV1Factory(factory).createPair(\\n            address(this),\\n            lp.tokenBase,\\n            lp.tokenQuote,\\n            msg.sender,\\n            lp.slopeNumerator,\\n            lp.n,\\n            lp.fee\\n        );\\n    }\\n    address pair = DAOfiV1Library.pairFor(\\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\\n    );\\n\\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\\n}\\n```\\nчTransfer tokens from `msg.sender` instead of `lp.sender`.чч```\\nfunction addLiquidity(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint256 amountBase) {\\n    if (IDAOfiV1Factory(factory).getPair(\\n        lp.tokenBase,\\n        lp.tokenQuote,\\n        lp.slopeNumerator,\\n        lp.n,\\n        lp.fee\\n    ) == address(0)) {\\n        IDAOfiV1Factory(factory).createPair(\\n            address(this),\\n            lp.tokenBase,\\n            lp.tokenQuote,\\n            msg.sender,\\n            lp.slopeNumerator,\\n            lp.n,\\n            lp.fee\\n        );\\n    }\\n    address pair = DAOfiV1Library.pairFor(\\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\\n    );\\n\\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\\n}\\n```\\n
The deposit of a new pair can be stolenчhighчTo create a new pair, a user is expected to call the same `addLiquidity()` (or the addLiquidityETH()) function of the router contract seen above:\\n```\\nfunction addLiquidity(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint256 amountBase) {\\n    if (IDAOfiV1Factory(factory).getPair(\\n        lp.tokenBase,\\n        lp.tokenQuote,\\n        lp.slopeNumerator,\\n        lp.n,\\n        lp.fee\\n    ) == address(0)) {\\n        IDAOfiV1Factory(factory).createPair(\\n            address(this),\\n            lp.tokenBase,\\n            lp.tokenQuote,\\n            msg.sender,\\n            lp.slopeNumerator,\\n            lp.n,\\n            lp.fee\\n        );\\n    }\\n    address pair = DAOfiV1Library.pairFor(\\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\\n    );\\n\\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\\n}\\n```\\n\\nThis function checks if the pair already exists and creates a new one if it does not. After that, the first and only deposit is made to that pair.\\nThe attacker can front-run that call and create a pair with the same parameters (thus, with the same address) by calling the `createPair` function of the `DAOfiV1Factory` contract. By calling that function directly, the attacker does not have to make the deposit when creating a new pair. The initial user will make this deposit, whose funds can now be withdrawn by the attacker.чThere are a few factors/bugs that allowed this attack. All or some of them should be fixed:\\nThe `createPair` function of the `DAOfiV1Factory` contract can be called directly by anyone without depositing with any `router` address as the parameter. The solution could be to allow only the `router` to create a pair.\\nThe `addLiquidity` function checks that the pair does not exist yet. If the pair exists already, a deposit should only be made by the owner of the pair. But in general, a new pair shouldn't be deployed without depositing in the same transaction.\\nThe pair's address does not depend on the owner/creator. It might make sense to add that information to the salt.чч```\\nfunction addLiquidity(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint256 amountBase) {\\n    if (IDAOfiV1Factory(factory).getPair(\\n        lp.tokenBase,\\n        lp.tokenQuote,\\n        lp.slopeNumerator,\\n        lp.n,\\n        lp.fee\\n    ) == address(0)) {\\n        IDAOfiV1Factory(factory).createPair(\\n            address(this),\\n            lp.tokenBase,\\n            lp.tokenQuote,\\n            msg.sender,\\n            lp.slopeNumerator,\\n            lp.n,\\n            lp.fee\\n        );\\n    }\\n    address pair = DAOfiV1Library.pairFor(\\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\\n    );\\n\\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\\n}\\n```\\n
Incorrect token decimal conversions can lead to loss of fundsчhighчThe `_convert()` function in `DAOfiV1Pair` is used to accommodate tokens with varying `decimals()` values. There are three cases in which it implicitly returns 0 for any `amount`, the most notable of which is when `token.decimals() == resolution`.\\nAs a result of this, `getQuoteOut()` reverts any time either `baseToken` or `quoteToken` have `decimals == INTERNAL_DECIMALS` (currently hardcoded to 8).\\n`getBaseOut()` also reverts in most cases when either `baseToken` or `quoteToken` have `decimals() == INTERNAL_DECIMALS`. The exception is when `getBaseOut()` is called while `supply` is 0, as is the case in `deposit()`. This causes `getBaseOut()` to succeed, returning an incorrect value.\\nThe result of this is that no swaps can be performed in one of these pools, and the `deposit()` function will return an incorrect `amountBaseOut` of `baseToken` to the depositor, the balance of which can then be withdrawn by the `pairOwner`.\\n```\\nfunction \\_convert(address token, uint256 amount, uint8 resolution, bool to) private view returns (uint256 converted) {\\n    uint8 decimals = IERC20(token).decimals();\\n    uint256 diff = 0;\\n    uint256 factor = 0;\\n    converted = 0;\\n    if (decimals > resolution) {\\n        diff = uint256(decimals.sub(resolution));\\n        factor = 10 \\*\\* diff;\\n        if (to && amount >= factor) {\\n            converted = amount.div(factor);\\n        } else if (!to) {\\n            converted = amount.mul(factor);\\n        }\\n    } else if (decimals < resolution) {\\n        diff = uint256(resolution.sub(decimals));\\n        factor = 10 \\*\\* diff;\\n        if (to) {\\n            converted = amount.mul(factor);\\n        } else if (!to && amount >= factor) {\\n            converted = amount.div(factor);\\n        }\\n    }\\n}\\n```\\nчThe `_convert()` function should return `amount` when `token.decimals() == resolution`. Additionally, implicit return values should be avoided whenever possible, especially in functions that implement complex mathematical operations.\\n`BancorFormula.power(baseN, baseD, _, _)` does not support `baseN < baseD`, and checks should be added to ensure that any call to the `BancorFormula` conforms to the expected input ranges.чч```\\nfunction \\_convert(address token, uint256 amount, uint8 resolution, bool to) private view returns (uint256 converted) {\\n    uint8 decimals = IERC20(token).decimals();\\n    uint256 diff = 0;\\n    uint256 factor = 0;\\n    converted = 0;\\n    if (decimals > resolution) {\\n        diff = uint256(decimals.sub(resolution));\\n        factor = 10 \\*\\* diff;\\n        if (to && amount >= factor) {\\n            converted = amount.div(factor);\\n        } else if (!to) {\\n            converted = amount.mul(factor);\\n        }\\n    } else if (decimals < resolution) {\\n        diff = uint256(resolution.sub(decimals));\\n        factor = 10 \\*\\* diff;\\n        if (to) {\\n            converted = amount.mul(factor);\\n        } else if (!to && amount >= factor) {\\n            converted = amount.div(factor);\\n        }\\n    }\\n}\\n```\\n
The swapExactTokensForETH checks the wrong return valueчhighчThe following lines are intended to check that the amount of tokens received from a swap is greater than the minimum amount expected from this swap (sp.amountOut):\\n```\\nuint amountOut = IWETH10(WETH).balanceOf(address(this));\\nrequire(\\n    IWETH10(sp.tokenOut).balanceOf(address(this)).sub(balanceBefore) >= sp.amountOut,\\n    'DAOfiV1Router: INSUFFICIENT\\_OUTPUT\\_AMOUNT'\\n);\\n```\\n\\nInstead, it calculates the difference between the initial receiver's balance and the balance of the router.чCheck the intended value.чч```\\nuint amountOut = IWETH10(WETH).balanceOf(address(this));\\nrequire(\\n    IWETH10(sp.tokenOut).balanceOf(address(this)).sub(balanceBefore) >= sp.amountOut,\\n    'DAOfiV1Router: INSUFFICIENT\\_OUTPUT\\_AMOUNT'\\n);\\n```\\n
DAOfiV1Pair.deposit() accepts deposits of zero, blocking the poolчmediumч`DAOfiV1Pair.deposit()` is used to deposit liquidity into the pool. Only a single deposit can be made, so no liquidity can ever be added to a pool where `deposited == true`. The `deposit()` function does not check for a nonzero deposit amount in either token, so a malicious user that does not hold any of the `baseToken` or `quoteToken` can lock the pool by calling `deposit()` without first transferring any funds to the pool.\\n```\\nfunction deposit(address to) external override lock returns (uint256 amountBaseOut) {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\\n    require(deposited == false, 'DAOfiV1: DOUBLE\\_DEPOSIT');\\n    reserveBase = IERC20(baseToken).balanceOf(address(this));\\n    reserveQuote = IERC20(quoteToken).balanceOf(address(this));\\n    // this function is locked and the contract can not reset reserves\\n    deposited = true;\\n    if (reserveQuote > 0) {\\n        // set initial supply from reserveQuote\\n        supply = amountBaseOut = getBaseOut(reserveQuote);\\n        if (amountBaseOut > 0) {\\n            \\_safeTransfer(baseToken, to, amountBaseOut);\\n            reserveBase = reserveBase.sub(amountBaseOut);\\n        }\\n    }\\n    emit Deposit(msg.sender, reserveBase, reserveQuote, amountBaseOut, to);\\n}\\n```\\nчRequire a minimum deposit amount in both `baseToken` and `quoteToken`, and do not rely on any assumptions about the distribution of `baseToken` as part of the security model.чч```\\nfunction deposit(address to) external override lock returns (uint256 amountBaseOut) {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\\n    require(deposited == false, 'DAOfiV1: DOUBLE\\_DEPOSIT');\\n    reserveBase = IERC20(baseToken).balanceOf(address(this));\\n    reserveQuote = IERC20(quoteToken).balanceOf(address(this));\\n    // this function is locked and the contract can not reset reserves\\n    deposited = true;\\n    if (reserveQuote > 0) {\\n        // set initial supply from reserveQuote\\n        supply = amountBaseOut = getBaseOut(reserveQuote);\\n        if (amountBaseOut > 0) {\\n            \\_safeTransfer(baseToken, to, amountBaseOut);\\n            reserveBase = reserveBase.sub(amountBaseOut);\\n        }\\n    }\\n    emit Deposit(msg.sender, reserveBase, reserveQuote, amountBaseOut, to);\\n}\\n```\\n
Restricting DAOfiV1Pair functions to calls from router makes DAOfiV1Router01 security criticalчmediumчThe `DAOfiV1Pair` functions `deposit()`, `withdraw()`, and `swap()` are all restricted to calls from the router in order to avoid losses from user error. However, this means that any unidentified issue in the Router could render all pair contracts unusable, potentially locking the pair owner's funds.\\nAdditionally, `DAOfiV1Factory.createPair()` allows any nonzero address to be provided as the `router`, so pairs can be initialized with a malicious `router` that users would be forced to interact with to utilize the pair contract.\\n```\\nfunction deposit(address to) external override lock returns (uint256 amountBaseOut) {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\\n```\\n\\n```\\nfunction withdraw(address to) external override lock returns (uint256 amountBase, uint256 amountQuote) {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_WITHDRAW');\\n```\\n\\n```\\nfunction swap(address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, address to) external override lock {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_SWAP');\\n```\\nчDo not restrict `DAOfiV1Pair` functions to calls from `router`, but encourage users to use a trusted `router` to avoid losses from user error. If this restriction is kept, consider including the `router` address in the deployment salt for the pair or hardcoding the address of a trusted `router` in `DAOfiV1Factory` instead of taking the `router` as a parameter to `createPair()`.чч```\\nfunction deposit(address to) external override lock returns (uint256 amountBaseOut) {\\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\\n```\\n
Pair contracts can be easily blockedчlowчThe parameters used to define a unique pair are the `baseToken`, `quoteToken`, `slopeNumerator`, `n`, and `fee`. There is only one accepted value for `n`, and there are eleven accepted values for `fee`. This makes the number of possible “interesting” pools for each token pair somewhat limited, and pools can be easily blocked by front-running deployments and depositing zero liquidity or immediately withdrawing deposited liquidity. Because liquidity can only be added once, these pools are permanently blocked.\\nThe existing mitigation for this issue is to create a new pool with slightly different parameters. This creates significant cost for the creator of a pair, forces them to deploy a pair with sub-optimal parameters, and could potentially block all interesting pools for a token pair.\\nThe salt used to determine unique pair contracts in DAOfiV1Factory.createPair():\\n```\\nrequire(getPair(baseToken, quoteToken, slopeNumerator, n, fee) == address(0), 'DAOfiV1: PAIR\\_EXISTS'); // single check is sufficient\\nbytes memory bytecode = type(DAOfiV1Pair).creationCode;\\nbytes32 salt = keccak256(abi.encodePacked(baseToken, quoteToken, slopeNumerator, n, fee));\\nassembly {\\n    pair := create2(0, add(bytecode, 32), mload(bytecode), salt)\\n}\\nIDAOfiV1Pair(pair).initialize(router, baseToken, quoteToken, pairOwner, slopeNumerator, n, fee);\\npairs[salt] = pair;\\n```\\nчConsider adding additional parameters to the salt that defines a unique pair, such as the `pairOwner`. Modifying the parameters included in the salt can also be used to partially mitigate other security concerns raised in this report.чч```\\nrequire(getPair(baseToken, quoteToken, slopeNumerator, n, fee) == address(0), 'DAOfiV1: PAIR\\_EXISTS'); // single check is sufficient\\nbytes memory bytecode = type(DAOfiV1Pair).creationCode;\\nbytes32 salt = keccak256(abi.encodePacked(baseToken, quoteToken, slopeNumerator, n, fee));\\nassembly {\\n    pair := create2(0, add(bytecode, 32), mload(bytecode), salt)\\n}\\nIDAOfiV1Pair(pair).initialize(router, baseToken, quoteToken, pairOwner, slopeNumerator, n, fee);\\npairs[salt] = pair;\\n```\\n
DAOfiV1Router01.removeLiquidityETH() does not support tokens with no return valueчlowчWhile the rest of the system uses the `safeTransfer*` pattern, allowing tokens that do not return a boolean value on `transfer()` or `transferFrom()`, `DAOfiV1Router01.removeLiquidityETH()` throws and consumes all remaining gas if the base token does not return `true`.\\nNote that the deposit in this case can still be withdrawn without unwrapping the Eth using `removeLiquidity()`.\\n```\\nfunction removeLiquidityETH(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint amountToken, uint amountETH) {\\n    IDAOfiV1Pair pair = IDAOfiV1Pair(DAOfiV1Library.pairFor(factory, lp.tokenBase, WETH, lp.slopeNumerator, lp.n, lp.fee));\\n    require(msg.sender == pair.pairOwner(), 'DAOfiV1Router: FORBIDDEN');\\n    (amountToken, amountETH) = pair.withdraw(address(this));\\n    assert(IERC20(lp.tokenBase).transfer(lp.to, amountToken));\\n    IWETH10(WETH).withdraw(amountETH);\\n    TransferHelper.safeTransferETH(lp.to, amountETH);\\n}\\n```\\nчBe consistent with the use of `safeTransfer*`, and do not use `assert()` in cases where the condition can be false.чч```\\nfunction removeLiquidityETH(\\n    LiquidityParams calldata lp,\\n    uint deadline\\n) external override ensure(deadline) returns (uint amountToken, uint amountETH) {\\n    IDAOfiV1Pair pair = IDAOfiV1Pair(DAOfiV1Library.pairFor(factory, lp.tokenBase, WETH, lp.slopeNumerator, lp.n, lp.fee));\\n    require(msg.sender == pair.pairOwner(), 'DAOfiV1Router: FORBIDDEN');\\n    (amountToken, amountETH) = pair.withdraw(address(this));\\n    assert(IERC20(lp.tokenBase).transfer(lp.to, amountToken));\\n    IWETH10(WETH).withdraw(amountETH);\\n    TransferHelper.safeTransferETH(lp.to, amountETH);\\n}\\n```\\n
Users can withdraw their funds immediately when they are over-leveragedчhighч`Accounts.withdraw` makes two checks before processing a withdrawal.\\nFirst, the method checks that the amount requested for withdrawal is not larger than the user's balance for the asset in question:\\n```\\nfunction withdraw(address \\_accountAddr, address \\_token, uint256 \\_amount) external onlyAuthorized returns(uint256) {\\n\\n    // Check if withdraw amount is less than user's balance\\n    require(\\_amount <= getDepositBalanceCurrent(\\_token, \\_accountAddr), \"Insufficient balance.\");\\n    uint256 borrowLTV = globalConfig.tokenInfoRegistry().getBorrowLTV(\\_token);\\n```\\n\\nSecond, the method checks that the withdrawal will not over-leverage the user. The amount to be withdrawn is subtracted from the user's current “borrow power” at the current price. If the user's total value borrowed exceeds this new borrow power, the method fails, as the user no longer has sufficient collateral to support their borrow positions. However, this `require` is only checked if a user is not already over-leveraged:\\n```\\n// This if condition is to deal with the withdraw of collateral token in liquidation.\\n// As the amount if borrowed asset is already large than the borrow power, we don't\\n// have to check the condition here.\\nif(getBorrowETH(\\_accountAddr) <= getBorrowPower(\\_accountAddr))\\n    require(\\n        getBorrowETH(\\_accountAddr) <= getBorrowPower(\\_accountAddr).sub(\\n            \\_amount.mul(globalConfig.tokenInfoRegistry().priceFromAddress(\\_token))\\n            .mul(borrowLTV).div(Utils.getDivisor(address(globalConfig), \\_token)).div(100)\\n        ), \"Insufficient collateral when withdraw.\");\\n```\\n\\nIf the user has already borrowed more than their “borrow power” allows, they are allowed to withdraw regardless. This case may arise in several circumstances; the most common being price fluctuation.чDisallow withdrawals if the user is already over-leveraged.\\nFrom the comment included in the code sample above, this condition is included to support the `liquidate` method, but its inclusion creates an attack vector that may allow users to withdraw when they should not be able to do so. Consider adding an additional method to support `liquidate`, so that users may not exit without repaying debts.чч```\\nfunction withdraw(address \\_accountAddr, address \\_token, uint256 \\_amount) external onlyAuthorized returns(uint256) {\\n\\n    // Check if withdraw amount is less than user's balance\\n    require(\\_amount <= getDepositBalanceCurrent(\\_token, \\_accountAddr), \"Insufficient balance.\");\\n    uint256 borrowLTV = globalConfig.tokenInfoRegistry().getBorrowLTV(\\_token);\\n```\\n
Users can borrow funds, deposit them, then borrow more  Won't FixчhighчUsers may deposit and borrow funds denominated in any asset supported by the `TokenRegistry`. Each time a user deposits or borrows a token, they earn FIN according to the difference in deposit / borrow rate indices maintained by `Bank`.\\nBorrowing funds\\nWhen users borrow funds, they may only borrow up to a certain amount: the user's “borrow power.” As long as the user is not requesting to borrow an amount that would cause their resulting borrowed asset value to exceed their available borrow power, the borrow is successful and the user receives the assets immediately. A user's borrow power is calculated in the following function:\\n```\\n/\\*\\*\\n \\* Calculate an account's borrow power based on token's LTV\\n \\*/\\nfunction getBorrowPower(address \\_borrower) public view returns (uint256 power) {\\n    for(uint8 i = 0; i < globalConfig.tokenInfoRegistry().getCoinLength(); i++) {\\n        if (isUserHasDeposits(\\_borrower, i)) {\\n            address token = globalConfig.tokenInfoRegistry().addressFromIndex(i);\\n            uint divisor = INT\\_UNIT;\\n            if(token != ETH\\_ADDR) {\\n                divisor = 10\\*\\*uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));\\n            }\\n            // globalConfig.bank().newRateIndexCheckpoint(token);\\n            power = power.add(getDepositBalanceCurrent(token, \\_borrower)\\n                .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))\\n                .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)\\n                .div(divisor)\\n            );\\n        }\\n    }\\n    return power;\\n}\\n```\\n\\nFor each asset, borrow power is calculated from the user's deposit size, multiplied by the current chainlink price, multiplied and that asset's “borrow LTV.”\\nDepositing borrowed funds\\nAfter a user borrows tokens, they can then deposit those tokens, increasing their deposit balance for that asset. As a result, their borrow power increases, which allows the user to borrow again.\\nBy continuing to borrow, deposit, and borrow again, the user can repeatedly borrow assets. Essentially, this creates positions for the user where the collateral for their massive borrow position is entirely made up of borrowed assets.\\nConclusion\\nThere are several potential side-effects of this behavior.\\nFirst, as described in https://github.com/ConsenSys/definer-audit-2021-02/issues/3, the system is comprised of many different tokens, each of which is subject to price fluctuation. By borrowing and depositing repeatedly, a user may establish positions across all supported tokens. At this point, if price fluctuations cause the user's account to cross the liquidation threshold, their positions can be liquidated.\\nLiquidation is a complicated function of the protocol, but in essence, the liquidator purchases a target's collateral at a discount, and the resulting sale balances the account somewhat. However, when a user repeatedly deposits borrowed tokens, their collateral is made up of borrowed tokens: the system's liquidity! As a result, this may allow an attacker to intentionally create a massively over-leveraged account on purpose, liquidate it, and exit with a chunk of the system liquidity.\\nAnother potential problem with this behavior is FIN token mining. When users borrow and deposit, they earn FIN according to the size of the deposit / borrow, and the difference in deposit / borrow rate indices since the last deposit / borrow. By repeatedly depositing / borrowing, users are able to artificially deposit and borrow far more often than normal, which may allow them to generate FIN tokens at will. This additional strategy may make attacks like the one described above much more economically feasible.чDue to the limited time available during this engagement, these possibilities and potential mitigations were not fully explored. Definer is encouraged to investigate this behavior more carefully.чч```\\n/\\*\\*\\n \\* Calculate an account's borrow power based on token's LTV\\n \\*/\\nfunction getBorrowPower(address \\_borrower) public view returns (uint256 power) {\\n    for(uint8 i = 0; i < globalConfig.tokenInfoRegistry().getCoinLength(); i++) {\\n        if (isUserHasDeposits(\\_borrower, i)) {\\n            address token = globalConfig.tokenInfoRegistry().addressFromIndex(i);\\n            uint divisor = INT\\_UNIT;\\n            if(token != ETH\\_ADDR) {\\n                divisor = 10\\*\\*uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));\\n            }\\n            // globalConfig.bank().newRateIndexCheckpoint(token);\\n            power = power.add(getDepositBalanceCurrent(token, \\_borrower)\\n                .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))\\n                .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)\\n                .div(divisor)\\n            );\\n        }\\n    }\\n    return power;\\n}\\n```\\n
Stale Oracle prices might affect the ratesчhighчIt's possible that due to network congestion or other reasons, the price that the ChainLink oracle returns is old and not up to date. This is more extreme in lesser known tokens that have fewer ChainLink Price feeds to update the price frequently. The codebase as is, relies on `chainLink().getLatestAnswer()` and does not check the timestamp of the price.\\n```\\n    function priceFromAddress(address tokenAddress) public view returns(uint256) {\\n        if(Utils.\\_isETH(address(globalConfig), tokenAddress)) {\\n            return 1e18;\\n        }\\n        return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));\\n    }\\n```\\nчDo a sanity check on the price returned from the oracle. If the price is older than a threshold, revert or handle in other means.чч```\\n    function priceFromAddress(address tokenAddress) public view returns(uint256) {\\n        if(Utils.\\_isETH(address(globalConfig), tokenAddress)) {\\n            return 1e18;\\n        }\\n        return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));\\n    }\\n```\\n
Overcomplicated unit conversionsчmediumчThere are many instances of unit conversion in the system that are implemented in a confusing way. This could result in mistakes in the conversion and possibly failure in correct accounting. It's been seen in the ecosystem that these type of complicated unit conversions could result in calculation mistake and loss of funds.\\nHere are a few examples:\\n```\\n    function getBorrowRatePerBlock(address \\_token) public view returns(uint) {\\n        if(!globalConfig.tokenInfoRegistry().isSupportedOnCompound(\\_token))\\n        // If the token is NOT supported by the third party, borrowing rate = 3% + U \\* 15%.\\n            return getCapitalUtilizationRatio(\\_token).mul(globalConfig.rateCurveSlope()).div(INT\\_UNIT).add(globalConfig.rateCurveConstant()).div(BLOCKS\\_PER\\_YEAR);\\n\\n        // if the token is suppored in third party, borrowing rate = Compound Supply Rate \\* 0.4 + Compound Borrow Rate \\* 0.6\\n        return (compoundPool[\\_token].depositRatePerBlock).mul(globalConfig.compoundSupplyRateWeights()).\\n            add((compoundPool[\\_token].borrowRatePerBlock).mul(globalConfig.compoundBorrowRateWeights())).div(10);\\n    }\\n```\\n\\n```\\n                compoundPool[\\_token].depositRatePerBlock = cTokenExchangeRate.mul(UNIT).div(lastCTokenExchangeRate[cToken])\\n                    .sub(UNIT).div(blockNumber.sub(lastCheckpoint[\\_token]));\\n```\\n\\n```\\n        return lastDepositeRateIndex.mul(getBlockNumber().sub(lcp).mul(depositRatePerBlock).add(INT\\_UNIT)).div(INT\\_UNIT);\\n```\\nчSimplify the unit conversions in the system. This can be done either by using a function wrapper for units to convert all values to the same unit before including them in any calculation or by better documenting every line of unit conversionчч```\\n    function getBorrowRatePerBlock(address \\_token) public view returns(uint) {\\n        if(!globalConfig.tokenInfoRegistry().isSupportedOnCompound(\\_token))\\n        // If the token is NOT supported by the third party, borrowing rate = 3% + U \\* 15%.\\n            return getCapitalUtilizationRatio(\\_token).mul(globalConfig.rateCurveSlope()).div(INT\\_UNIT).add(globalConfig.rateCurveConstant()).div(BLOCKS\\_PER\\_YEAR);\\n\\n        // if the token is suppored in third party, borrowing rate = Compound Supply Rate \\* 0.4 + Compound Borrow Rate \\* 0.6\\n        return (compoundPool[\\_token].depositRatePerBlock).mul(globalConfig.compoundSupplyRateWeights()).\\n            add((compoundPool[\\_token].borrowRatePerBlock).mul(globalConfig.compoundBorrowRateWeights())).div(10);\\n    }\\n```\\n
Commented out code in the codebaseчmediumчThere are many instances of code lines (and functions) that are commented out in the code base. Having commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.\\nThe main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments.\\nHere's a few examples of such lines of code, note that there are more.\\n```\\n    struct LiquidationVars {\\n        // address token;\\n        // uint256 tokenPrice;\\n        // uint256 coinValue;\\n        uint256 borrowerCollateralValue;\\n        // uint256 tokenAmount;\\n        // uint256 tokenDivisor;\\n        uint256 msgTotalBorrow;\\n```\\n\\n```\\n                if(token != ETH\\_ADDR) {\\n                    divisor = 10\\*\\*uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));\\n                }\\n                // globalConfig.bank().newRateIndexCheckpoint(token);\\n                power = power.add(getDepositBalanceCurrent(token, \\_borrower)\\n```\\n\\nMany usage of `console.log()` and also the commented import on most of the contracts\\n```\\n        // require(\\n        // totalBorrow.mul(100) <= totalCollateral.mul(liquidationDiscountRatio),\\n        // \"Collateral is not sufficient to be liquidated.\"\\n        // );\\n```\\n\\n```\\n    // function \\_isETH(address \\_token) public view returns (bool) {\\n    // return globalConfig.constants().ETH\\_ADDR() == \\_token;\\n    // }\\n\\n    // function getDivisor(address \\_token) public view returns (uint256) {\\n    // if(\\_isETH(\\_token)) return INT\\_UNIT;\\n    // return 10 \\*\\* uint256(getTokenDecimals(\\_token));\\n    // }\\n```\\n\\n```\\n        // require(\\_borrowLTV != 0, \"Borrow LTV is zero\");\\n        require(\\_borrowLTV < SCALE, \"Borrow LTV must be less than Scale\");\\n        // require(liquidationThreshold > \\_borrowLTV, \"Liquidation threshold must be greater than Borrow LTV\");\\n```\\nчIn many of the above examples, it's not clear if the commented code is for testing or obsolete code (e.g. in the last example, can _borrowLTV ==0?) . All these instances should be reviewed and the system should be fully tested for all edge cases after the code changes.чч```\\n    struct LiquidationVars {\\n        // address token;\\n        // uint256 tokenPrice;\\n        // uint256 coinValue;\\n        uint256 borrowerCollateralValue;\\n        // uint256 tokenAmount;\\n        // uint256 tokenDivisor;\\n        uint256 msgTotalBorrow;\\n```\\n
Emergency withdrawal code presentчmediumчCode and functionality for emergency stop and withdrawal is present in this code base.\\n```\\n    // ============================================\\n    // EMERGENCY WITHDRAWAL FUNCTIONS\\n    // Needs to be removed when final version deployed\\n    // ============================================\\n    function emergencyWithdraw(GlobalConfig globalConfig, address \\_token) public {\\n        address cToken = globalConfig.tokenInfoRegistry().getCToken(\\_token);\\n// rest of code\\n```\\n\\n```\\n    function emergencyWithdraw(address \\_token) external onlyEmergencyAddress {\\n        SavingLib.emergencyWithdraw(globalConfig, \\_token);\\n    }\\n```\\n\\n```\\n// rest of code\\n    address payable public constant EMERGENCY\\_ADDR = 0xc04158f7dB6F9c9fFbD5593236a1a3D69F92167c;\\n// rest of code\\n```\\nчTo remove the emergency code and fully test all the affected contracts.чч```\\n    // ============================================\\n    // EMERGENCY WITHDRAWAL FUNCTIONS\\n    // Needs to be removed when final version deployed\\n    // ============================================\\n    function emergencyWithdraw(GlobalConfig globalConfig, address \\_token) public {\\n        address cToken = globalConfig.tokenInfoRegistry().getCToken(\\_token);\\n// rest of code\\n```\\n
Accounts contains expensive loopingчmediumч`Accounts.getBorrowETH` performs multiple external calls to `GlobalConfig` and `TokenRegistry` within a for loop:\\n```\\nfunction getBorrowETH(\\n    address \\_accountAddr\\n) public view returns (uint256 borrowETH) {\\n    uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();\\n    //console.log(\"tokenNum\", tokenNum);\\n    for(uint i = 0; i < tokenNum; i++) {\\n        if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\\n            address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);\\n            uint divisor = INT\\_UNIT;\\n            if(tokenAddress != ETH\\_ADDR) {\\n                divisor = 10 \\*\\* uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));\\n            }\\n            borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));\\n        }\\n    }\\n    return borrowETH;\\n}\\n```\\n\\nThe loop also makes additional external calls and delegatecalls from:\\nTokenRegistry.priceFromIndex:\\n```\\nfunction priceFromIndex(uint index) public view returns(uint256) {\\n    require(index < tokens.length, \"coinIndex must be smaller than the coins length.\");\\n    address tokenAddress = tokens[index];\\n    // Temp fix\\n    if(Utils.\\_isETH(address(globalConfig), tokenAddress)) {\\n        return 1e18;\\n    }\\n    return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));\\n}\\n```\\n\\nAccounts.getBorrowBalanceCurrent:\\n```\\nfunction getBorrowBalanceCurrent(\\n    address \\_token,\\n    address \\_accountAddr\\n) public view returns (uint256 borrowBalance) {\\n    AccountTokenLib.TokenInfo storage tokenInfo = accounts[\\_accountAddr].tokenInfos[\\_token];\\n    uint accruedRate;\\n    if(tokenInfo.getBorrowPrincipal() == 0) {\\n        return 0;\\n    } else {\\n        if(globalConfig.bank().borrowRateIndex(\\_token, tokenInfo.getLastBorrowBlock()) == 0) {\\n            accruedRate = INT\\_UNIT;\\n        } else {\\n            accruedRate = globalConfig.bank().borrowRateIndexNow(\\_token)\\n            .mul(INT\\_UNIT)\\n            .div(globalConfig.bank().borrowRateIndex(\\_token, tokenInfo.getLastBorrowBlock()));\\n        }\\n        return tokenInfo.getBorrowBalance(accruedRate);\\n    }\\n}\\n```\\n\\nIn a worst case scenario, each iteration may perform a maximum of 25+ calls/delegatecalls. Assuming a maximum `tokenNum` of 128 (TokenRegistry.MAX_TOKENS), the gas cost for this method may reach upwards of 2 million for external calls alone.\\nGiven that this figure would only be a portion of the total transaction gas cost, `getBorrowETH` may represent a DoS risk within the `Accounts` contract.чAvoid for loops unless absolutely necessary\\nWhere possible, consolidate multiple subsequent calls to the same contract to a single call, and store the results of calls in local variables for re-use. For example,\\nInstead of this:\\n```\\nuint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();\\nfor(uint i = 0; i < tokenNum; i++) {\\n  if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\\n    address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);\\n    uint divisor = INT\\_UNIT;\\n    if(tokenAddress != ETH\\_ADDR) {\\n      divisor = 10 \\*\\* uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));\\n    }\\n    borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));\\n  }\\n}\\n```\\n\\nModify `TokenRegistry` to support a single call, and cache intermediate results like this:\\n```\\nTokenRegistry registry = globalConfig.tokenInfoRegistry();\\nuint tokenNum = registry.getCoinLength();\\nfor(uint i = 0; i < tokenNum; i++) {\\n  if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\\n    // here, getPriceFromIndex(i) performs all of the steps as the code above, but with only 1 ext call\\n    borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(registry.getPriceFromIndex(i)).div(divisor));\\n  }\\n}\\n```\\nчч```\\nfunction getBorrowETH(\\n    address \\_accountAddr\\n) public view returns (uint256 borrowETH) {\\n    uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();\\n    //console.log(\"tokenNum\", tokenNum);\\n    for(uint i = 0; i < tokenNum; i++) {\\n        if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\\n            address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);\\n            uint divisor = INT\\_UNIT;\\n            if(tokenAddress != ETH\\_ADDR) {\\n                divisor = 10 \\*\\* uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));\\n            }\\n            borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));\\n        }\\n    }\\n    return borrowETH;\\n}\\n```\\n
Naming inconsistencyчlowчThere are some inconsistencies in the naming of some functions with what they do.\\n```\\n    function getCoinLength() public view returns (uint256 length) { //@audit-info coin vs token\\n        return tokens.length;\\n    }\\n```\\nчReview the code for the naming inconsistencies.чч```\\n    function getCoinLength() public view returns (uint256 length) { //@audit-info coin vs token\\n        return tokens.length;\\n    }\\n```\\n
TokenFaucet refill can have an unexpected outcomeчmediumчThe `TokenFaucet` contract can only disburse tokens to the users if it has enough balance. When the contract is running out of tokens, it stops dripping.\\n```\\nuint256 assetTotalSupply = asset.balanceOf(address(this));\\nuint256 availableTotalSupply = assetTotalSupply.sub(totalUnclaimed);\\nuint256 newSeconds = currentTimestamp.sub(lastDripTimestamp);\\nuint256 nextExchangeRateMantissa = exchangeRateMantissa;\\nuint256 newTokens;\\nuint256 measureTotalSupply = measure.totalSupply();\\n\\nif (measureTotalSupply > 0 && availableTotalSupply > 0 && newSeconds > 0) {\\n  newTokens = newSeconds.mul(dripRatePerSecond);\\n  if (newTokens > availableTotalSupply) {\\n    newTokens = availableTotalSupply;\\n  }\\n  uint256 indexDeltaMantissa = measureTotalSupply > 0 ? FixedPoint.calculateMantissa(newTokens, measureTotalSupply) : 0;\\n  nextExchangeRateMantissa = nextExchangeRateMantissa.add(indexDeltaMantissa);\\n\\n  emit Dripped(\\n    newTokens\\n  );\\n}\\n```\\n\\nThe owners of the faucet can decide to refill the contract so it can disburse tokens again. If there's been a lot of time since the faucet was drained, the `lastDripTimestamp` value can be far behind the `currentTimestamp`. In that case, the users can instantly withdraw some amount (up to all the balance) right after the refill.чTo avoid uncertainty, it's essential to call the `drip` function before the refill. If this call is made in a separate transaction, the owner should make sure that this transaction was successfully mined before sending tokens for the refill.чч```\\nuint256 assetTotalSupply = asset.balanceOf(address(this));\\nuint256 availableTotalSupply = assetTotalSupply.sub(totalUnclaimed);\\nuint256 newSeconds = currentTimestamp.sub(lastDripTimestamp);\\nuint256 nextExchangeRateMantissa = exchangeRateMantissa;\\nuint256 newTokens;\\nuint256 measureTotalSupply = measure.totalSupply();\\n\\nif (measureTotalSupply > 0 && availableTotalSupply > 0 && newSeconds > 0) {\\n  newTokens = newSeconds.mul(dripRatePerSecond);\\n  if (newTokens > availableTotalSupply) {\\n    newTokens = availableTotalSupply;\\n  }\\n  uint256 indexDeltaMantissa = measureTotalSupply > 0 ? FixedPoint.calculateMantissa(newTokens, measureTotalSupply) : 0;\\n  nextExchangeRateMantissa = nextExchangeRateMantissa.add(indexDeltaMantissa);\\n\\n  emit Dripped(\\n    newTokens\\n  );\\n}\\n```\\n
Gas Optimization on transfersчlowчIn TokenFaucet, on every transfer `_captureNewTokensForUser` is called twice. This function does a few calculations and writes the latest UserState to the storage. However, if `lastExchangeRateMantissa == exchangeRateMantissa`, or in other words, two transfers happen in the same block, there are no changes in the newToken amounts, so there is an extra storage store with the same values.\\n`deltaExchangeRateMantissa` will be 0 in case two transfers ( no matter from or to) are in the same block for a user.\\n```\\n uint256 deltaExchangeRateMantissa = uint256(exchangeRateMantissa).sub(userState.lastExchangeRateMantissa);\\n    uint128 newTokens = FixedPoint.multiplyUintByMantissa(userMeasureBalance, deltaExchangeRateMantissa).toUint128();\\n    userStates[user] = UserState({\\n      lastExchangeRateMantissa: exchangeRateMantissa,\\n      balance: uint256(userState.balance).add(newTokens).toUint128()\\n    });\\n```\\nчReturn without storage update if `lastExchangeRateMantissa == exchangeRateMantissa`, or by another method if `deltaExchangeRateMantissa == 0`. This reduces the gas cost for active users (high number of transfers that might be in the same block)чч```\\n uint256 deltaExchangeRateMantissa = uint256(exchangeRateMantissa).sub(userState.lastExchangeRateMantissa);\\n    uint128 newTokens = FixedPoint.multiplyUintByMantissa(userMeasureBalance, deltaExchangeRateMantissa).toUint128();\\n    userStates[user] = UserState({\\n      lastExchangeRateMantissa: exchangeRateMantissa,\\n      balance: uint256(userState.balance).add(newTokens).toUint128()\\n    });\\n```\\n
Handle transfer tokens where from == toчlowчIn TokenFaucet, when calling `beforeTokenTransfer` it should also be optimized when `to == from`. This is to prevent any possible issues with internal accounting and token drip calculations.\\n```\\n// rest of code\\n if (token == address(measure) && from != address(0)) {  //add && from != to\\n      drip();\\n// rest of code\\n```\\nчAs ERC20 standard, `from == to` can be allowed but check in `beforeTokenTransfer` that if `to == from`, then do not call `_captureNewTokensForUser(from);` again.чч```\\n// rest of code\\n if (token == address(measure) && from != address(0)) {  //add && from != to\\n      drip();\\n// rest of code\\n```\\n
Redundant/Duplicate checksчlowчThere are a few checks (require) in TokenFaucet that are redundant and/or checked twice.\\n```\\n    require(\\_dripRatePerSecond > 0, \"TokenFaucet/dripRate-gt-zero\");\\n    asset = \\_asset;\\n    measure = \\_measure;\\n    setDripRatePerSecond(\\_dripRatePerSecond);\\n```\\n\\n```\\n  function setDripRatePerSecond(uint256 \\_dripRatePerSecond) public onlyOwner {\\n    require(\\_dripRatePerSecond > 0, \"TokenFaucet/dripRate-gt-zero\");\\n```\\n\\n\\n```\\n  function drip() public returns (uint256) {\\n    uint256 currentTimestamp = \\_currentTime();\\n\\n    // this should only run once per block.\\n    if (lastDripTimestamp == uint32(currentTimestamp)) {\\n      return 0;\\n    }\\n// rest of code\\n    uint256 newSeconds = currentTimestamp.sub(lastDripTimestamp);\\n// rest of code\\n    if (measureTotalSupply > 0 && availableTotalSupply > 0 && newSeconds > 0) {\\n// rest of code\\n        uint256 indexDeltaMantissa = measureTotalSupply > 0 ? FixedPoint.calculateMantissa(newTokens, measureTotalSupply) : 0; \\n```\\nчRemove the redundant checks to reduce the code size and complexity.чч```\\n    require(\\_dripRatePerSecond > 0, \"TokenFaucet/dripRate-gt-zero\");\\n    asset = \\_asset;\\n    measure = \\_measure;\\n    setDripRatePerSecond(\\_dripRatePerSecond);\\n```\\n
GenesisGroup.commit overwrites previously-committed valuesчhighч`commit` allows anyone to `commit` purchased FGEN to a swap that will occur once the genesis group is launched. This commitment may be performed on behalf of other users, as long as the calling account has sufficient allowance:\\n```\\nfunction commit(address from, address to, uint amount) external override onlyGenesisPeriod {\\n burnFrom(from, amount);\\n\\n committedFGEN[to] = amount;\\n totalCommittedFGEN += amount;\\n\\n emit Commit(from, to, amount);\\n}\\n```\\n\\nThe `amount` stored in the recipient's `committedFGEN` balance overwrites any previously-committed value. Additionally, this also allows anyone to commit an `amount` of “0” to any account, deleting their commitment entirely.чEnsure the committed amount is added to the existing commitment.чч```\\nfunction commit(address from, address to, uint amount) external override onlyGenesisPeriod {\\n burnFrom(from, amount);\\n\\n committedFGEN[to] = amount;\\n totalCommittedFGEN += amount;\\n\\n emit Commit(from, to, amount);\\n}\\n```\\n
UniswapIncentive overflow on pre-transfer hooksчhighчBefore a token transfer is performed, `Fei` performs some combination of mint/burn operations via UniswapIncentive.incentivize:\\n```\\nfunction incentivize(\\n address sender,\\n address receiver, \\n address operator,\\n uint amountIn\\n) external override onlyFei {\\n    updateOracle();\\n\\n if (isPair(sender)) {\\n  incentivizeBuy(receiver, amountIn);\\n }\\n\\n if (isPair(receiver)) {\\n        require(isSellAllowlisted(sender) || isSellAllowlisted(operator), \"UniswapIncentive: Blocked Fei sender or operator\");\\n  incentivizeSell(sender, amountIn);\\n }\\n}\\n```\\n\\nBoth `incentivizeBuy` and `incentivizeSell` calculate buy/sell incentives using overflow-prone math, then mint / burn from the target according to the results. This may have unintended consequences, like allowing a caller to mint tokens before transferring them, or burn tokens from their recipient.\\n`incentivizeBuy` calls `getBuyIncentive` to calculate the final minted value:\\n```\\nfunction incentivizeBuy(address target, uint amountIn) internal ifMinterSelf {\\n if (isExemptAddress(target)) {\\n  return;\\n }\\n\\n    (uint incentive, uint32 weight,\\n    Decimal.D256 memory initialDeviation,\\n    Decimal.D256 memory finalDeviation) = getBuyIncentive(amountIn);\\n\\n    updateTimeWeight(initialDeviation, finalDeviation, weight);\\n    if (incentive != 0) {\\n        fei().mint(target, incentive);        \\n    }\\n}\\n```\\n\\n`getBuyIncentive` calculates price deviations after casting `amount` to an `int256`, which may overflow:\\n```\\nfunction getBuyIncentive(uint amount) public view override returns(\\n    uint incentive,\\n    uint32 weight,\\n    Decimal.D256 memory initialDeviation,\\n    Decimal.D256 memory finalDeviation\\n) {\\n    (initialDeviation, finalDeviation) = getPriceDeviations(-1 \\* int256(amount));\\n```\\nчResolution\\nThis was addressed in fei-protocol/fei-protocol-core#15.\\nEnsure casts in `getBuyIncentive` and `getSellPenalty` do not overflow.чч```\\nfunction incentivize(\\n address sender,\\n address receiver, \\n address operator,\\n uint amountIn\\n) external override onlyFei {\\n    updateOracle();\\n\\n if (isPair(sender)) {\\n  incentivizeBuy(receiver, amountIn);\\n }\\n\\n if (isPair(receiver)) {\\n        require(isSellAllowlisted(sender) || isSellAllowlisted(operator), \"UniswapIncentive: Blocked Fei sender or operator\");\\n  incentivizeSell(sender, amountIn);\\n }\\n}\\n```\\n
BondingCurve allows users to acquire FEI before launchчmediumч`BondingCurve.allocate` allocates the protocol's held PCV, then calls `_incentivize`, which rewards the caller with FEI if a certain amount of time has passed:\\n```\\n/// @notice if window has passed, reward caller and reset window\\nfunction \\_incentivize() internal virtual {\\n    if (isTimeEnded()) {\\n        \\_initTimed(); // reset window\\n        fei().mint(msg.sender, incentiveAmount);\\n    }\\n}\\n```\\n\\n`allocate` can be called before genesis launch, as long as the contract holds some nonzero PCV. By force-sending the contract 1 wei, anyone can bypass the majority of checks and actions in `allocate`, and mint themselves FEI each time the timer expires.чPrevent `allocate` from being called before genesis launch.чч```\\n/// @notice if window has passed, reward caller and reset window\\nfunction \\_incentivize() internal virtual {\\n    if (isTimeEnded()) {\\n        \\_initTimed(); // reset window\\n        fei().mint(msg.sender, incentiveAmount);\\n    }\\n}\\n```\\n
Overflow/underflow protectionчmediumчHaving overflow/underflow vulnerabilities is very common for smart contracts. It is usually mitigated by using `SafeMath` or using solidity version ^0.8 (after solidity 0.8 arithmetical operations already have default overflow/underflow protection).\\nIn this code, many arithmetical operations are used without the ‘safe' version. The reasoning behind it is that all the values are derived from the actual ETH values, so they can't overflow.\\nOn the other hand, some operations can't be checked for overflow/underflow without going much deeper into the codebase that is out of scope:\\n```\\nuint totalGenesisTribe = tribeBalance() - totalCommittedTribe;\\n```\\nчResolution\\nThis was partially addressed in fei-protocol/fei-protocol-core#17 by using `SafeMath` for the specific example given in the description.\\nIn our opinion, it is still safer to have these operations in a safe mode. So we recommend using `SafeMath` or solidity version ^0.8 compiler.чч```\\nuint totalGenesisTribe = tribeBalance() - totalCommittedTribe;\\n```\\n
Unchecked return value for IWETH.transfer callчmediumчIn `EthUniswapPCVController`, there is a call to `IWETH.transfer` that does not check the return value:\\n```\\nweth.transfer(address(pair), amount);\\n```\\n\\nIt is usually good to add a require-statement that checks the return value or to use something like safeTransfer; unless one is sure the given token reverts in case of a failure.чConsider adding a require-statement or using `safeTransfer`.чч```\\nweth.transfer(address(pair), amount);\\n```\\n
GenesisGroup.emergencyExit remains functional after launchчmediumч`emergencyExit` is intended as an escape mechanism for users in the event the genesis `launch` method fails or is frozen. `emergencyExit` becomes callable 3 days after `launch` is callable. These two methods are intended to be mutually-exclusive, but are not: either method remains callable after a successful call to the other.\\nThis may result in accounting edge cases. In particular, `emergencyExit` fails to decrease `totalCommittedFGEN` by the exiting user's commitment:\\n```\\nburnFrom(from, amountFGEN);\\ncommittedFGEN[from] = 0;\\n\\npayable(to).transfer(total);\\n```\\n\\nAs a result, calling launch after a user performs an exit will incorrectly calculate the amount of FEI to swap:\\n```\\nuint amountFei = feiBalance() \\* totalCommittedFGEN / (totalSupply() + totalCommittedFGEN);\\nif (amountFei != 0) {\\n totalCommittedTribe = ido.swapFei(amountFei);\\n}\\n```\\nчEnsure `launch` cannot be called if `emergencyExit` has been called\\nEnsure `emergencyExit` cannot be called if `launch` has been called\\nIn `emergencyExit`, reduce `totalCommittedFGEN` by the exiting user's committed amountчч```\\nburnFrom(from, amountFGEN);\\ncommittedFGEN[from] = 0;\\n\\npayable(to).transfer(total);\\n```\\n
Unchecked return value for transferFrom callsчmediumчThere are two `transferFrom` calls that do not check the return value (some tokens signal failure by returning false):\\n```\\nstakedToken.transferFrom(from, address(this), amount);\\n```\\n\\n```\\nfei().transferFrom(msg.sender, address(pair), amountFei);\\n```\\n\\nIt is usually good to add a require-statement that checks the return value or to use something like safeTransferFrom; unless one is sure the given token reverts in case of a failure.чConsider adding a require-statement or using `safeTransferFrom`.чч```\\nstakedToken.transferFrom(from, address(this), amount);\\n```\\n
Pool: claiming to the pool itself causes accounting issuesчlowч```\\nfunction \\_claim(address from, address to) internal returns (uint256) {\\n    (uint256 amountReward, uint256 amountPool) = redeemableReward(from);\\n    require(amountPool != 0, \"Pool: User has no redeemable pool tokens\");\\n\\n    \\_burnFrom(from, amountPool);\\n    \\_incrementClaimed(amountReward);\\n\\n    rewardToken.transfer(to, amountReward);\\n    return amountReward;\\n}\\n```\\n\\nIf the destination address `to` is the pool itself, the pool will burn tokens and increment the amount of tokens claimed, then transfer the reward tokens `to` itself.чResolution\\nThis was addressed in fei-protocol/fei-protocol-core#57\\nPrevent claims from specifying the pool as a destination.чч```\\nfunction \\_claim(address from, address to) internal returns (uint256) {\\n    (uint256 amountReward, uint256 amountPool) = redeemableReward(from);\\n    require(amountPool != 0, \"Pool: User has no redeemable pool tokens\");\\n\\n    \\_burnFrom(from, amountPool);\\n    \\_incrementClaimed(amountReward);\\n\\n    rewardToken.transfer(to, amountReward);\\n    return amountReward;\\n}\\n```\\n
Assertions that can failчlowчIn `UniswapSingleEthRouter` there are two assert-statements that may fail:\\n```\\nassert(msg.sender == address(WETH)); // only accept ETH via fallback from the WETH contract\\n```\\n\\n```\\nassert(IWETH(WETH).transfer(address(PAIR), amountIn));\\n```\\n\\nSince they do some sort of input validation it might be good to replace them with require-statements. I would only use asserts for checks that should never fail and failure would constitute a bug in the code.чConsider replacing the assert-statements with require-statements. An additional benefit is that this will not result in consuming all the gas in case of a violation.чч```\\nassert(msg.sender == address(WETH)); // only accept ETH via fallback from the WETH contract\\n```\\n
Simplify API of GenesisGroup.purchaseчlowчThe API of `GenesisGroup.purchase` could be simplified by not including the `value` parameter that is required to be equivalent to msg.value:\\n```\\nrequire(msg.value == value, \"GenesisGroup: value mismatch\");\\n```\\n\\nUsing `msg.value` might make the API more explicit and avoid requiring `msg.value == value`. It can also save some gas due to fewer inputs and fewer checks.чConsider dropping the `value` parameter and changing the code to use `msg.value` instead.чч```\\nrequire(msg.value == value, \"GenesisGroup: value mismatch\");\\n```\\n
[Out of Scope] ReferralFeeReceiver - anyone can steal all the funds that belong to ReferralFeeReceiverчhighчNote: This issue was raised in components that were being affected by the scope reduction as outlined in the section “Scope” and are, therefore, only shallowly validated. Nevertheless, we find it important to communicate such potential findings and ask the client to further investigate.\\nThe `ReferralFeeReceiver` receives pool shares when users `swap()` tokens in the pool. A `ReferralFeeReceiver` may be used with multiple pools and, therefore, be a lucrative target as it is holding pool shares.\\nAny token or `ETH` that belongs to the `ReferralFeeReceiver` is at risk and can be drained by any user by providing a custom `mooniswap` pool contract that references existing token holdings.\\nIt should be noted that none of the functions in `ReferralFeeReceiver` verify that the user-provided `mooniswap` pool address was actually deployed by the linked `MooniswapFactory`. The factory provides certain security guarantees about `mooniswap` pool contracts (e.g. valid `mooniswap` contract, token deduplication, tokenA!=tokenB, enforced token sorting, …), however, since the `ReferralFeeReceiver` does not verify the user-provided `mooniswap` address they are left unchecked.\\nAdditional Notes\\n`freezeEpoch` - (callable by anyone) performs a `pool.withdraw()` with the `minAmounts` check being disabled. This may allow someone to call this function at a time where the contract actually gets a bad deal.\\n`trade` - (callable by anyone) can intentionally be used to perform bad trades (front-runnable)\\n`trade` - (callable by anyone) appears to implement inconsistent behavior when sending out `availableBalance`. `ETH` is sent to `tx.origin` (the caller) while tokens are sent to the user-provided `mooniswap` address.\\n```\\nif (path[0].isETH()) {\\n    tx.origin.transfer(availableBalance);  // solhint-disable-line avoid-tx-origin\\n} else {\\n    path[0].safeTransfer(address(mooniswap), availableBalance);\\n}\\n```\\n\\nmultiple methods - since `mooniswap` is a user-provided address there are a lot of opportunities to reenter the contract. Consider adding reentrancy guards as another security layer (e.g. `claimCurrentEpoch` and others).\\nmultiple methods - do not validate the amount of tokens that are returned, causing an evm assertion due to out of bounds index access.\\n```\\nIERC20[] memory tokens = mooniswap.getTokens();\\nuint256 token0Balance = tokens[0].uniBalanceOf(address(this));\\nuint256 token1Balance = tokens[1].uniBalanceOf(address(this));\\n```\\n\\nin `GovernanceFeeReceiver` anyone can intentionally force unwrapping of pool tokens or perform swaps in the worst time possible. e.g. The checks for `withdraw(..., minAmounts)` is disabled.\\n```\\nfunction unwrapLPTokens(Mooniswap mooniswap) external validSpread(mooniswap) {\\n    mooniswap.withdraw(mooniswap.balanceOf(address(this)), new uint256[](0));\\n}\\n\\nfunction swap(IERC20[] memory path) external validPath(path) {\\n    (uint256 amount,) = \\_maxAmountForSwap(path, path[0].uniBalanceOf(address(this)));\\n    uint256 result = \\_swap(path, amount, payable(address(rewards)));\\n    rewards.notifyRewardAmount(result);\\n}\\n```\\n\\nA malicious user can drain all token by calling `claimFrozenEpoch` with a custom contract as `mooniswap` that returns a token address the `ReferralFeeReceiver` contracts holds token from in `IERC20[] memory tokens = mooniswap.getTokens();`. A subsequent call to `_transferTokenShare()` will then send out any amount of token requested by the attacker to the attacker-controlled address (msg.sender).\\nLet's assume the following scenario:\\n`ReferralFeeReceiver` holds `DAI` token and we want to steal them.\\nAn attacker may be able to drain the contract from `DAI` token via `claimFrozenToken` if\\nthey control the `mooniswap` address argument and provide a malicious contract\\n`user.share[mooniswap][firstUnprocessedEpoch] > 0` - this can be arbitrarily set in `updateReward`\\n`token.epochBalance[currentEpoch].token0Balance > 0` - this can be manipulated in `freezeEpoch` by providing a malicious `mooniswap` contract\\nthey own a worthless `ERC20` token e.g. named `ATTK`\\nThe following steps outline the attack:\\nThe attacker calls into `updateReward` to set `user.share[mooniswap][currentEpoch]` to a value that is greater than zero to make sure that `share` in `claimFrozenEpoch` takes the `_transferTokenShare` path.\\n```\\nfunction updateReward(address referral, uint256 amount) external override {\\n    Mooniswap mooniswap = Mooniswap(msg.sender);\\n    TokenInfo storage token = tokenInfo[mooniswap];\\n    UserInfo storage user = userInfo[referral];\\n    uint256 currentEpoch = token.currentEpoch;\\n\\n    // Add new reward to current epoch\\n    user.share[mooniswap][currentEpoch] = user.share[mooniswap][currentEpoch].add(amount);\\n    token.epochBalance[currentEpoch].totalSupply = token.epochBalance[currentEpoch].totalSupply.add(amount);\\n\\n    // Collect all processed epochs and advance user token epoch\\n    \\_collectProcessedEpochs(user, token, mooniswap, currentEpoch);\\n}\\n```\\n\\nThe attacker then calls `freezeEpoch()` providing the malicious `mooniswap` contract address controlled by the attacker.\\nThe malicious contract returns token that is controlled by the attacker (e.g. ATTK) in a call to `mooniswap.getTokens();`\\nThe contract then stores the current balance of the attacker-controlled token in `token0Balance/token1Balance`. Note that the token being returned here by the malicious contract can be different from the one we're checking out in the last step (balance manipulation via `ATTK`, checkout of `DAI` in the last step).\\nThen the contract calls out to the malicious `mooniswap` contract. This gives the malicious contract an easy opportunity to send some attacker-controlled token (ATTK) to the `ReferralFeeReceiver` in order to freely manipulate the frozen tokenbalances (tokens[0].uniBalanceOf(address(this)).sub(token0Balance);).\\nNote that the used token addresses are never stored anywhere. The balances recorded here are for an attacker-controlled token (ATTK), not the actual one that we're about to steal (e.g. DAI)\\nThe token balances are now set-up for checkout in the last step (claimFrozenEpoch).\\n```\\nfunction freezeEpoch(Mooniswap mooniswap) external validSpread(mooniswap) {\\n    TokenInfo storage token = tokenInfo[mooniswap];\\n    uint256 currentEpoch = token.currentEpoch;\\n    require(token.firstUnprocessedEpoch == currentEpoch, \"Previous epoch is not finalized\");\\n\\n    IERC20[] memory tokens = mooniswap.getTokens();\\n    uint256 token0Balance = tokens[0].uniBalanceOf(address(this));\\n    uint256 token1Balance = tokens[1].uniBalanceOf(address(this));\\n    mooniswap.withdraw(mooniswap.balanceOf(address(this)), new uint256[](0));\\n    token.epochBalance[currentEpoch].token0Balance = tokens[0].uniBalanceOf(address(this)).sub(token0Balance);\\n    token.epochBalance[currentEpoch].token1Balance = tokens[1].uniBalanceOf(address(this)).sub(token1Balance);\\n    token.currentEpoch = currentEpoch.add(1);\\n}\\n```\\n\\nA call to `claimFrozenEpoch` checks-out the previously frozen token balance.\\nThe `claim > 0` requirement was fulfilled in step 1.\\nThe token balance was prepared for the attacker-controlled token (ATTK) in step 2, but we're now checking out `DAI`.\\nWhen the contract calls out to the attackers `mooniswap` contract the call to `IERC20[] memory tokens = mooniswap.getTokens();` returns the address of the token to be stolen (e.g. DAI) instead of the attacker-controlled token (ATTK) that was used to set-up the balance records.\\nSubsequently, the valuable target tokens (DAI) are sent out to the caller in `_transferTokenShare`.\\n```\\nif (share > 0) {\\n    EpochBalance storage epochBalance = token.epochBalance[firstUnprocessedEpoch];\\n    uint256 totalSupply = epochBalance.totalSupply;\\n    user.share[mooniswap][firstUnprocessedEpoch] = 0;\\n    epochBalance.totalSupply = totalSupply.sub(share);\\n\\n    IERC20[] memory tokens = mooniswap.getTokens();\\n    epochBalance.token0Balance = \\_transferTokenShare(tokens[0], epochBalance.token0Balance, share, totalSupply);\\n    epochBalance.token1Balance = \\_transferTokenShare(tokens[1], epochBalance.token1Balance, share, totalSupply);\\n    epochBalance.inchBalance = \\_transferTokenShare(inchToken, epochBalance.inchBalance, share, totalSupply);\\n```\\nчResolution\\nAccording to the client, this issue is addressed in 1inch-exchange/1inch-liquidity-protocol#2 and the reentrancy in `FeeReceiver` in 1inch-exchange/[email protected]e9c6a03\\n(This fix is as reported by the developer team, but has not been verified by Diligence).\\nEnforce that the user-provided `mooniswap` contract was actually deployed by the linked factory. Other contracts cannot be trusted. Consider implementing token sorting and de-duplication (tokenA!=tokenB) in the pool contract constructor as well. Consider employing a reentrancy guard to safeguard the contract from reentrancy attacks.\\nImprove testing. The methods mentioned here are not covered at all. Improve documentation and provide a specification that outlines how this contract is supposed to be used.\\nReview the “additional notes” provided with this issue.чч```\\nif (path[0].isETH()) {\\n    tx.origin.transfer(availableBalance);  // solhint-disable-line avoid-tx-origin\\n} else {\\n    path[0].safeTransfer(address(mooniswap), availableBalance);\\n}\\n```\\n
GovernanceMothership - notifyFor allows to arbitrarily create new or override other users stake in governance modulesчhighчThe `notify*` methods are called to update linked governance modules when an accounts stake changes in the Mothership. The linked modules then update their own balances of the user to accurately reflect the account's real stake in the Mothership.\\nBesides `notify` there's also a method named `notifyFor` which is publicly accessible. It is assumed that the method should be used similar to `notify` to force an update for another account's balance.\\nHowever, invoking the method forces an update in the linked modules for the provided address, but takes `balanceOf(msg.sender)` instead of `balanceOf(account)`. This allows malicious actors to:\\nArbitrarily change other accounts stake in linked governance modules (e.g. zeroing stake, increasing stake) based on the callers stake in the mothership\\nDuplicate stake out of thin air to arbitrary addresses (e.g. staking in mothership once and calling `notifyFor` many other account addresses)\\npublicly accessible method allows forcing stake updates for arbitrary users\\n```\\nfunction notifyFor(address account) external {\\n    \\_notifyFor(account, balanceOf(msg.sender));\\n}\\n```\\n\\nthe method calls the linked governance modules\\n```\\nfunction \\_notifyFor(address account, uint256 balance) private {\\n    uint256 modulesLength = \\_modules.length();\\n    for (uint256 i = 0; i < modulesLength; ++i) {\\n        IGovernanceModule(\\_modules.at(i)).notifyStakeChanged(account, balance);\\n    }\\n}\\n```\\n\\nwhich will arbitrarily `mint` or `burn` stake in the `BalanceAccounting` of `Factory` or `Reward` (or other linked governance modules)\\n```\\nfunction notifyStakeChanged(address account, uint256 newBalance) external override onlyMothership {\\n    \\_notifyStakeChanged(account, newBalance);\\n}\\n```\\n\\n```\\nfunction \\_notifyStakeChanged(address account, uint256 newBalance) internal override {\\n    uint256 balance = balanceOf(account);\\n    if (newBalance > balance) {\\n        \\_mint(account, newBalance.sub(balance));\\n    } else if (newBalance < balance) {\\n        \\_burn(account, balance.sub(newBalance));\\n    } else {\\n        return;\\n    }\\n    uint256 newTotalSupply = totalSupply();\\n\\n    \\_defaultFee.updateBalance(account, \\_defaultFee.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_FEE, \\_emitDefaultFeeVoteUpdate);\\n    \\_defaultSlippageFee.updateBalance(account, \\_defaultSlippageFee.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_SLIPPAGE\\_FEE, \\_emitDefaultSlippageFeeVoteUpdate);\\n    \\_defaultDecayPeriod.updateBalance(account, \\_defaultDecayPeriod.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_DECAY\\_PERIOD, \\_emitDefaultDecayPeriodVoteUpdate);\\n    \\_referralShare.updateBalance(account, \\_referralShare.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_REFERRAL\\_SHARE, \\_emitReferralShareVoteUpdate);\\n    \\_governanceShare.updateBalance(account, \\_governanceShare.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_GOVERNANCE\\_SHARE, \\_emitGovernanceShareVoteUpdate);\\n}\\n```\\n\\n```\\nfunction \\_notifyStakeChanged(address account, uint256 newBalance) internal override updateReward(account) {\\n    uint256 balance = balanceOf(account);\\n    if (newBalance > balance) {\\n        \\_mint(account, newBalance.sub(balance));\\n    } else if (newBalance < balance) {\\n        \\_burn(account, balance.sub(newBalance));\\n    }\\n}\\n```\\nчRemove `notifyFor` or change it to take the balance of the correct account `_notifyFor(account, balanceOf(msg.sender))`.\\nIt is questionable whether the public `notify*()` family of methods is actually needed as stake should only change - and thus an update of linked modules should only be required - if an account calls `stake()` or `unstake()`. It should therefore be considered to remove `notify()`, `notifyFor` and `batchNotifyFor`.чч```\\nfunction notifyFor(address account) external {\\n    \\_notifyFor(account, balanceOf(msg.sender));\\n}\\n```\\n
The uniTransferFrom function can potentially be used with invalid paramsчmediumчThe system is using the `UniERC20` contract to incapsulate transfers of both ERC-20 tokens and ETH. This contract has `uniTransferFrom` function that can be used for any ERC-20 or ETH:\\n```\\nfunction uniTransferFrom(IERC20 token, address payable from, address to, uint256 amount) internal {\\n    if (amount > 0) {\\n        if (isETH(token)) {\\n            require(msg.value >= amount, \"UniERC20: not enough value\");\\n            if (msg.value > amount) {\\n                // Return remainder if exist\\n                from.transfer(msg.value.sub(amount));\\n            }\\n        } else {\\n            token.safeTransferFrom(from, to, amount);\\n        }\\n    }\\n}\\n```\\n\\nIn case if the function is called for the normal ERC-20 token, everything works as expected. The tokens are transferred `from` the `from` address `to` the `to` address. If the token is ETH - the transfer is expected `to` be `from` the `msg.sender` `to` `this` contract. Even if the `to` and `from` parameters are different.\\nThis issue's severity is not high because the function is always called with the proper parameters in the current codebase.чResolution\\nAccording to the client, this issue is addressed in 1inch-exchange/[email protected]d0ffb6f.\\n(This fix is as reported by the developer team, but has not been verified by Diligence).\\nMake sure that the `uniTransferFrom` function is always called with expected parameters.чч```\\nfunction uniTransferFrom(IERC20 token, address payable from, address to, uint256 amount) internal {\\n    if (amount > 0) {\\n        if (isETH(token)) {\\n            require(msg.value >= amount, \"UniERC20: not enough value\");\\n            if (msg.value > amount) {\\n                // Return remainder if exist\\n                from.transfer(msg.value.sub(amount));\\n            }\\n        } else {\\n            token.safeTransferFrom(from, to, amount);\\n        }\\n    }\\n}\\n```\\n
MooniswapGovernance - votingpower is not accurately reflected when minting pool tokensчmediumчWhen a user provides liquidity to the pool, pool-tokens are minted. The minting event triggers the `_beforeTokenTransfer` callback in `MooniswapGovernance` which updates voting power reflecting the newly minted stake for the user.\\nThere seems to be a copy-paste error in the way `balanceTo` is determined that sets `balanceTo` to zero if new token were minted (from==address(0)). This means, that in a later call to `_updateOnTransfer` only the newly minted amount is considered when adjusting voting power.\\nIf tokens are newly minted `from==address(0)` and therefore `balanceTo -> 0`.\\n```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\\n    uint256 newTotalSupply = totalSupply()\\n        .add(from == address(0) ? amount : 0)\\n        .sub(to == address(0) ? amount : 0);\\n\\n    ParamsHelper memory params = ParamsHelper({\\n        from: from,\\n        to: to,\\n        amount: amount,\\n        balanceFrom: balanceFrom,\\n        balanceTo: balanceTo,\\n        newTotalSupply: newTotalSupply\\n    });\\n```\\n\\nnow, `balanceTo` is zero which would adjust voting power to `amount` instead of the user's actual balance + the newly minted token.\\n```\\nif (params.to != address(0)) {\\n    votingData.updateBalance(params.to, voteTo, params.balanceTo, params.balanceTo.add(params.amount), params.newTotalSupply, defaultValue, emitEvent);\\n}\\n```\\nч`balanceTo` should be zero when burning (to == address(0)) and `balanceOf(to)` when minting.\\ne.g. like this:\\n```\\nuint256 balanceTo = (to != address(0)) ? balanceOf(to) : 0;\\n```\\nчч```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\\n    uint256 newTotalSupply = totalSupply()\\n        .add(from == address(0) ? amount : 0)\\n        .sub(to == address(0) ? amount : 0);\\n\\n    ParamsHelper memory params = ParamsHelper({\\n        from: from,\\n        to: to,\\n        amount: amount,\\n        balanceFrom: balanceFrom,\\n        balanceTo: balanceTo,\\n        newTotalSupply: newTotalSupply\\n    });\\n```\\n
MooniswapGovernance - _beforeTokenTransfer should not update voting power on transfers to selfчmediumчMooniswap governance is based on the liquidity voting system that is also employed by the mothership or for factory governance. In contrast to traditional voting systems where users vote for discrete values, the liquidity voting system derives a continuous weighted averaged “consensus” value from all the votes. Thus it is required that whenever stake changes in the system, all the parameters that can be voted upon are updated with the new weights for a specific user.\\nThe Mooniswap pool is governed by liquidity providers and liquidity tokens are the stake that gives voting rights in `MooniswapGovernance`. Thus whenever liquidity tokens are transferred to another address, stake and voting values need to be updated. This is handled by `MooniswapGovernance._beforeTokenTransfer()`.\\nIn the special case where someone triggers a token transfer where the `from` address equals the `to` address, effectively sending the token `to` themselves, no update on voting power should be performed. Instead, voting power is first updated with `balance - amount` and then with `balance + amount` which in the worst case means it is updating first `to` a zero balance and then `to` 2x the balance.\\nUltimately this should not have an effect on the overall outcome but is unnecessary and wasting gas.\\n`beforeTokenTransfer` callback in `Mooniswap` does not check for the NOP case where `from==to`\\n```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\\n    uint256 newTotalSupply = totalSupply()\\n        .add(from == address(0) ? amount : 0)\\n        .sub(to == address(0) ? amount : 0);\\n\\n    ParamsHelper memory params = ParamsHelper({\\n        from: from,\\n        to: to,\\n        amount: amount,\\n        balanceFrom: balanceFrom,\\n        balanceTo: balanceTo,\\n        newTotalSupply: newTotalSupply\\n    });\\n\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultFee, \\_emitFeeVoteUpdate, \\_fee);\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultSlippageFee, \\_emitSlippageFeeVoteUpdate, \\_slippageFee);\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultDecayPeriod, \\_emitDecayPeriodVoteUpdate, \\_decayPeriod);\\n}\\n```\\n\\nwhich leads to `updateBalance` being called on the same address twice, first with `currentBalance - amountTransferred` and then with `currentBalance + amountTransferred`.\\n```\\nif (params.from != address(0)) {\\n    votingData.updateBalance(params.from, voteFrom, params.balanceFrom, params.balanceFrom.sub(params.amount), params.newTotalSupply, defaultValue, emitEvent);\\n}\\n\\nif (params.to != address(0)) {\\n    votingData.updateBalance(params.to, voteTo, params.balanceTo, params.balanceTo.add(params.amount), params.newTotalSupply, defaultValue, emitEvent);\\n}\\n```\\nчDo not update voting power on LP token transfers where `from == to`.чч```\\nfunction \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\\n    uint256 newTotalSupply = totalSupply()\\n        .add(from == address(0) ? amount : 0)\\n        .sub(to == address(0) ? amount : 0);\\n\\n    ParamsHelper memory params = ParamsHelper({\\n        from: from,\\n        to: to,\\n        amount: amount,\\n        balanceFrom: balanceFrom,\\n        balanceTo: balanceTo,\\n        newTotalSupply: newTotalSupply\\n    });\\n\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultFee, \\_emitFeeVoteUpdate, \\_fee);\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultSlippageFee, \\_emitSlippageFeeVoteUpdate, \\_slippageFee);\\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultDecayPeriod, \\_emitDecayPeriodVoteUpdate, \\_decayPeriod);\\n}\\n```\\n
Unpredictable behavior for users due to admin front running or general bad timingчmediumчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.\\nIn general users of the system should have assurances about the behavior of the action they're about to take.\\nMooniswapFactoryGovernance - Admin opportunity to lock `swapFor` with a referral when setting an invalid `referralFeeReceiver`\\n`setReferralFeeReceiver` and `setGovernanceFeeReceiver` takes effect immediately.\\n```\\nfunction setReferralFeeReceiver(address newReferralFeeReceiver) external onlyOwner {\\n    referralFeeReceiver = newReferralFeeReceiver;\\n    emit ReferralFeeReceiverUpdate(newReferralFeeReceiver);\\n}\\n```\\n\\n`setReferralFeeReceiver` can be used to set an invalid receiver address (or one that reverts on every call) effectively rendering `Mooniswap.swapFor` unusable if a referral was specified in the swap.\\n```\\nif (referral != address(0)) {\\n    referralShare = invIncrease.mul(referralShare).div(\\_FEE\\_DENOMINATOR);\\n    if (referralShare > 0) {\\n        if (referralFeeReceiver != address(0)) {\\n            \\_mint(referralFeeReceiver, referralShare);\\n            IReferralFeeReceiver(referralFeeReceiver).updateReward(referral, referralShare);\\n```\\n\\nLocking staked token\\nAt any point in time and without prior notice to users an admin may accidentally or intentionally add a broken governance sub-module to the system that blocks all users from unstaking their `1INCH` token. An admin can recover from this by removing the broken sub-module, however, with malicious intent tokens may be locked forever.\\nSince `1INCH` token gives voting power in the system, tokens are considered to hold value for other users and may be traded on exchanges. This raises concerns if tokens can be locked in a contract by one actor.\\nAn admin adds an invalid address or a malicious sub-module to the governance contract that always `reverts` on calls to `notifyStakeChanged`.\\n```\\nfunction addModule(address module) external onlyOwner {\\n    require(\\_modules.add(module), \"Module already registered\");\\n    emit AddModule(module);\\n}\\n```\\n\\n```\\nfunction \\_notifyFor(address account, uint256 balance) private {\\n    uint256 modulesLength = \\_modules.length();\\n    for (uint256 i = 0; i < modulesLength; ++i) {\\n        IGovernanceModule(\\_modules.at(i)).notifyStakeChanged(account, balance);\\n    }\\n}\\n```\\n\\nAdmin front-running to prevent user stake sync\\nAn admin may front-run users while staking in an attempt to prevent submodules from being notified of the stake update. This is unlikely to happen as it incurs costs for the attacker (front-back-running) to normal users but may be an interesting attack scenario to exclude a whale's stake from voting.\\nFor example, an admin may front-run `stake()` or `notoify*()` by briefly removing all governance submodules from the mothership and re-adding them after the users call succeeded. The stake-update will not be propagated to the sub-modules. A user may only detect this when they are voting (if they had no stake before) or when they actually check their stake. Such an attack might likely stay unnoticed unless someone listens for `addmodule` `removemodule` events on the contract.\\nAn admin front-runs a transaction by removing all modules and re-adding them afterwards to prevent the stake from propagating to the submodules.\\n```\\nfunction removeModule(address module) external onlyOwner {\\n    require(\\_modules.remove(module), \"Module was not registered\");\\n    emit RemoveModule(module);\\n}\\n```\\n\\nAdmin front-running to prevent unstake from propagating\\nAn admin may choose to front-run their own `unstake()`, temporarily removing all governance sub-modules, preventing `unstake()` from syncing the action to sub-modules while still getting their previously staked tokens out. The governance sub-modules can be re-added right after unstaking. Due to double-accounting of the stake (in governance and in every sub-module) their stake will still be exercisable in the sub-module even though it was removed from the mothership. Users can only prevent this by manually calling a state-sync on the affected account(s).чThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.\\nFurthermore, users should be guaranteed to be able to redeem their staked tokens. An entity - even though trusted - in the system should not be able to lock tokens indefinitely.чч```\\nfunction setReferralFeeReceiver(address newReferralFeeReceiver) external onlyOwner {\\n    referralFeeReceiver = newReferralFeeReceiver;\\n    emit ReferralFeeReceiverUpdate(newReferralFeeReceiver);\\n}\\n```\\n
The owner can borrow token0/token1 in the rescueFundsчlowчIf some random tokens/funds are accidentally transferred to the pool, the `owner` can call the `rescueFunds` function to withdraw any funds manually:\\n```\\nfunction rescueFunds(IERC20 token, uint256 amount) external nonReentrant onlyOwner {\\n    uint256 balance0 = token0.uniBalanceOf(address(this));\\n    uint256 balance1 = token1.uniBalanceOf(address(this));\\n\\n    token.uniTransfer(msg.sender, amount);\\n\\n    require(token0.uniBalanceOf(address(this)) >= balance0, \"Mooniswap: access denied\");\\n    require(token1.uniBalanceOf(address(this)) >= balance1, \"Mooniswap: access denied\");\\n    require(balanceOf(address(this)) >= \\_BASE\\_SUPPLY, \"Mooniswap: access denied\");\\n}\\n```\\n\\nThere's no restriction on which funds the `owner` can try to withdraw and which token to call. It's theoretically possible to transfer pool tokens and then return them to the contract (e.g. in the case of ERC-777). That action would be similar to a free flash loan.чExplicitly check that the `token` is not equal to any of the pool tokens.чч```\\nfunction rescueFunds(IERC20 token, uint256 amount) external nonReentrant onlyOwner {\\n    uint256 balance0 = token0.uniBalanceOf(address(this));\\n    uint256 balance1 = token1.uniBalanceOf(address(this));\\n\\n    token.uniTransfer(msg.sender, amount);\\n\\n    require(token0.uniBalanceOf(address(this)) >= balance0, \"Mooniswap: access denied\");\\n    require(token1.uniBalanceOf(address(this)) >= balance1, \"Mooniswap: access denied\");\\n    require(balanceOf(address(this)) >= \\_BASE\\_SUPPLY, \"Mooniswap: access denied\");\\n}\\n```\\n
Ether temporarily held during transactions can be stolen via reentrancyчhighчThe exchange proxy typically holds no ether balance, but it can temporarily hold a balance during a transaction. This balance is vulnerable to theft if the following conditions are met:\\nNo check at the end of the transaction reverts if ether goes missing,\\nreentrancy is possible during the transaction, and\\na mechanism exists to spend ether held by the exchange proxy.\\nWe found one example where these conditions are met, but it's possible that more exist.\\nExample\\n`MetaTransactionsFeature.executeMetaTransaction()` accepts ether, which is used to pay protocol fees. It's possible for less than the full amount in `msg.value` to be consumed, which is why the function uses the `refundsAttachedEth` modifier to return any remaining ether to the caller:\\n```\\n/// @dev Refunds up to `msg.value` leftover ETH at the end of the call.\\nmodifier refundsAttachedEth() {\\n    \\_;\\n    uint256 remainingBalance =\\n        LibSafeMathV06.min256(msg.value, address(this).balance);\\n    if (remainingBalance > 0) {\\n        msg.sender.transfer(remainingBalance);\\n    }\\n}\\n```\\n\\nNotice that this modifier just returns the remaining ether balance (up to msg.value). It does not check for a specific amount of remaining ether. This meets condition (1) above.\\nIt's impossible to reenter the system with a second metatransaction because `executeMetaTransaction()` uses the modifier `nonReentrant`, but there's nothing preventing reentrancy via a different feature. We can achieve reentrancy by trading a token that uses callbacks (e.g. ERC777's hooks) during transfers. This meets condition (2).\\nTo find a full exploit, we also need a way to extract the ether held by the exchange proxy. `LiquidityProviderFeature.sellToLiquidityProvider()` provides such a mechanism. By passing `ETH_TOKEN_ADDRESS` as the `inputToken` and an address in the attacker's control as the `provider`, an attacker can transfer out any ether held by the exchange proxy. Note that `sellToLiquidityProvider()` can transfer any amount of ether, not limited to the amount sent via msg.value:\\n```\\nif (inputToken == ETH\\_TOKEN\\_ADDRESS) {\\n    provider.transfer(sellAmount);\\n```\\n\\nThis meets condition (3).\\nThe full steps to exploit this vulnerability are as follows:\\nA maker/attacker signs a trade where one of the tokens will invoke a callback during the trade.\\nA taker signs a metatransaction to take this trade.\\nA relayer sends in the metatransaction, providing more ether than is necessary to pay the protocol fee. (It's unclear how likely this situation is.)\\nDuring the token callback, the attacker invokes `LiquidityProviderFeature.sellToLiquidityProvider()` to transfer the excess ether to their account.\\nThe metatransaction feature returns the remaining ether balance, which is now zero.чIn general, we recommend using strict accounting of ether throughout the system. If there's ever a temporary balance, it should be accurately resolved at the end of the transaction, after any potential reentrancy opportunities.\\nFor the example we specifically found, we recommend doing strict accounting in the metatransactions feature. This means features called via a metatransaction would need to return how much ether was consumed. The metatransactions feature could then refund exactly `msg.value - <consumed ether>`. The transaction should be reverted if this fails because it means ether went missing during the transaction.\\nWe also recommend limiting `sellToLiquidityProvider()` to only transfer up to `msg.value`. This is a form of defense in depth in case other vectors for a similar attack exist.чч```\\n/// @dev Refunds up to `msg.value` leftover ETH at the end of the call.\\nmodifier refundsAttachedEth() {\\n    \\_;\\n    uint256 remainingBalance =\\n        LibSafeMathV06.min256(msg.value, address(this).balance);\\n    if (remainingBalance > 0) {\\n        msg.sender.transfer(remainingBalance);\\n    }\\n}\\n```\\n
UniswapFeature: Non-static call to ERC20.allowance()чlowчIn the case where a token is possibly “greedy” (consumes all gas on failure), `UniswapFeature` makes a call to the token's `allowance()` function to check whether the user has provided a token allowance to the protocol proxy or to the `AllowanceTarget`. This call is made using `call()`, potentially allowing state-changing operations to take place before control of the execution returns to `UniswapFeature`.\\n```\\n// `token.allowance()``\\nmstore(0xB00, ALLOWANCE\\_CALL\\_SELECTOR\\_32)\\nmstore(0xB04, caller())\\nmstore(0xB24, address())\\nlet success := call(gas(), token, 0, 0xB00, 0x44, 0xC00, 0x20)\\n```\\nчReplace the `call()` with a `staticcall()`.чч```\\n// `token.allowance()``\\nmstore(0xB00, ALLOWANCE\\_CALL\\_SELECTOR\\_32)\\nmstore(0xB04, caller())\\nmstore(0xB24, address())\\nlet success := call(gas(), token, 0, 0xB00, 0x44, 0xC00, 0x20)\\n```\\n
UniswapFeature: Unchecked returndatasize in low-level external callsчlowч`UniswapFeature` makes a number of external calls from low-level assembly code. Two of these calls rely on the `CALL` opcode to copy the returndata to memory without checking that the call returned the expected amount of data. Because the `CALL` opcode does not zero memory if the call returns less data than expected, this can lead to usage of dirty memory under the assumption that it is data returned from the most recent call.\\nCall to `UniswapV2Pair.getReserves()`\\n```\\n// Call pair.getReserves(), store the results at `0xC00`\\nmstore(0xB00, UNISWAP\\_PAIR\\_RESERVES\\_CALL\\_SELECTOR\\_32)\\nif iszero(staticcall(gas(), pair, 0xB00, 0x4, 0xC00, 0x40)) {\\n    bubbleRevert()\\n}\\n```\\n\\nCall to `ERC20.allowance()`\\n```\\n// Check if we have enough direct allowance by calling\\n// `token.allowance()``\\nmstore(0xB00, ALLOWANCE\\_CALL\\_SELECTOR\\_32)\\nmstore(0xB04, caller())\\nmstore(0xB24, address())\\nlet success := call(gas(), token, 0, 0xB00, 0x44, 0xC00, 0x20)\\n```\\nчInstead of providing a memory range for `call()` to write returndata to, explicitly check `returndatasize()` after the call is made and then copy the data into memory using `returndatacopy()`.\\n```\\nif lt(returndatasize(), EXPECTED\\_SIZE) {\\n    revert(0, 0) \\n}\\nreturndatacopy(0xC00, 0x00, EXPECTED\\_SIZE)\\n```\\nчч```\\n// Call pair.getReserves(), store the results at `0xC00`\\nmstore(0xB00, UNISWAP\\_PAIR\\_RESERVES\\_CALL\\_SELECTOR\\_32)\\nif iszero(staticcall(gas(), pair, 0xB00, 0x4, 0xC00, 0x40)) {\\n    bubbleRevert()\\n}\\n```\\n
PeriodicPrizeStrategy - RNG failure can lock user fundsчhighчTo prevent manipulation of the `SortitionSumTree` after a requested random number enters the mempool, users are unable to withdraw funds while the strategy contract waits on a random number request between execution of `startAward()` and `completeAward()`.\\nIf an rng request fails, however, there is no way to exit this locked state. After an rng request times out, only `startAward()` can be called, which will make another rng request and re-enter the same locked state. The rng provider can also not be updated while the contract is in this state. If the rng provider fails permanently, user funds are permanently locked.\\n`requireNotLocked()` prevents transfers, deposits, or withdrawals when there is a pending award.\\n```\\nfunction beforeTokenTransfer(address from, address to, uint256 amount, address controlledToken) external override onlyPrizePool {\\n  if (controlledToken == address(ticket)) {\\n    \\_requireNotLocked();\\n  }\\n```\\n\\n```\\nfunction \\_requireNotLocked() internal view {\\n  uint256 currentBlock = \\_currentBlock();\\n  require(rngRequest.lockBlock == 0 || currentBlock < rngRequest.lockBlock, \"PeriodicPrizeStrategy/rng-in-flight\");\\n}\\n```\\n\\n`setRngService()` reverts if there is a pending or timed-out rng request\\n```\\nfunction setRngService(RNGInterface rngService) external onlyOwner {\\n  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");\\n```\\nчInstead of forcing the pending award phase to be re-entered in the event of an rng request time-out, provide an `exitAwardPhase()` function that ends the award phase without paying out the award. This will at least allow users to withdraw their funds in the event of a catastrophic failure of the rng service. It may also be prudent to allow the rng service to be updated in the event of an rng request time out.чч```\\nfunction beforeTokenTransfer(address from, address to, uint256 amount, address controlledToken) external override onlyPrizePool {\\n  if (controlledToken == address(ticket)) {\\n    \\_requireNotLocked();\\n  }\\n```\\n
LootBox - Unprotected selfdestruct in proxy implementationчhighчWhen the `LootBoxController` is deployed, it also deploys an instance of `LootBox`. When someone calls `LootBoxController.plunder()` or `LootBoxController.executeCall()` the controller actually deploys a temporary proxy contract to a deterministic address using `create2`, then calls out to it to collect the loot.\\nThe `LootBox` implementation contract is completely unprotected, exposing all its functionality to any actor on the blockchain. The most critical functionality is actually the `LootBox.destroy()` method that calls `selfdestruct()` on the implementation contract.\\nTherefore, an unauthenticated user can `selfdestruct` the `LootBox` proxy implementation and cause the complete system to become dysfunctional. As an effect, none of the AirDrops that were delivered based on this contract will be redeemable (Note: `create2` deploy address is calculated from the current contract address and salt). Funds may be lost.\\n```\\nconstructor () public {\\n  lootBoxActionInstance = new LootBox();\\n  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));\\n}\\n```\\n\\n```\\n/// @notice Destroys this contract using `selfdestruct`\\n/// @param to The address to send remaining Ether to\\nfunction destroy(address payable to) external {\\n  selfdestruct(to);\\n}\\n```\\n\\nnot in scope but listed for completeness\\n```\\ncontract CounterfactualAction {\\n  function depositTo(address payable user, PrizePool prizePool, address output, address referrer) external {\\n    IERC20 token = IERC20(prizePool.token());\\n    uint256 amount = token.balanceOf(address(this));\\n    token.approve(address(prizePool), amount);\\n    prizePool.depositTo(user, amount, output, referrer);\\n    selfdestruct(user);\\n  }\\n\\n  function cancel(address payable user, PrizePool prizePool) external {\\n    IERC20 token = IERC20(prizePool.token());\\n    token.transfer(user, token.balanceOf(address(this)));\\n    selfdestruct(user);\\n  }\\n```\\nчEnforce that only the deployer of the contract can call functionality in the contract. Make sure that nobody can destroy the implementation of proxy contracts.чч```\\nconstructor () public {\\n  lootBoxActionInstance = new LootBox();\\n  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));\\n}\\n```\\n
PeriodicPriceStrategy - trustedForwarder can impersonate any msg.senderчhighчThe `trustedForwarder` undermines the trust assumptions in the system. For example, one would assume that the access control modifier `onlyPrizePool` would only allow the configured `PrizePool` to call certain methods. However, in reality, the `trustedForwarder` can assume this position as well. The same is true for the `onlyOwnerOrListener` modifier. One would assume `msg.sender` must either be `periodicPrizeStrategyListener` or `owner` (the initial deployer) while the `trustedForwarder` can assume any of the administrative roles.\\nThe centralization of power to allow one account to impersonate other components and roles (owner, `listener`, prizePool) in the system is a concern by itself and may give users pause when deciding whether to trust the contract system. The fact that the `trustedForwarder` can spoof events for any `msg.sender` may also make it hard to keep an accurate log trail of events in case of a security incident.\\nNote: The same functionality seems to be used in `ControlledToken` and other contracts which allows the `trustedForwarder` to assume any tokenholder in `ERC20UpgradeSafe`. There is practically no guarantee to `ControlledToken` holders.\\nNote: The trustedForwarder/msgSender() pattern is used in multiple contracts, many of which are not in the scope of this assessment.\\naccess control modifiers that can be impersonated\\n```\\nmodifier onlyPrizePool() {\\n  require(\\_msgSender() == address(prizePool), \"PeriodicPrizeStrategy/only-prize-pool\");\\n  \\_;\\n}\\n```\\n\\n```\\nmodifier onlyOwnerOrListener() {\\n  require(\\_msgSender() == owner() || \\_msgSender() == address(periodicPrizeStrategyListener), \"PeriodicPrizeStrategy/only-owner-or-listener\");\\n  \\_;\\n}\\n```\\n\\nevent `msg.sender` that can be spoofed because the actual `msg.sender` can be `trustedForwarder`\\n```\\nemit PrizePoolOpened(\\_msgSender(), prizePeriodStartedAt);\\n```\\n\\n```\\nemit PrizePoolAwardStarted(\\_msgSender(), address(prizePool), requestId, lockBlock);\\n```\\n\\n```\\nemit PrizePoolAwarded(\\_msgSender(), randomNumber);\\nemit PrizePoolOpened(\\_msgSender(), prizePeriodStartedAt);\\n```\\n\\n`_msgSender()` implementation allows the `trustedForwarder` to impersonate any `msg.sender` address\\n```\\n/// @dev Provides information about the current execution context for GSN Meta-Txs.\\n/// @return The payable address of the message sender\\nfunction \\_msgSender()\\n  internal\\n  override(BaseRelayRecipient, ContextUpgradeSafe)\\n  virtual\\n  view\\n  returns (address payable)\\n{\\n  return BaseRelayRecipient.\\_msgSender();\\n}\\n```\\nчRemove the `trustedForwarder` or restrict the type of actions the forwarder can perform and don't allow it to impersonate other components in the system. Make sure users understand the trust assumptions and who has what powers in the system. Make sure to keep an accurate log trail of who performed which action on whom's behalf.чч```\\nmodifier onlyPrizePool() {\\n  require(\\_msgSender() == address(prizePool), \"PeriodicPrizeStrategy/only-prize-pool\");\\n  \\_;\\n}\\n```\\n
Unpredictable behavior for users due to admin front running or general bad timingчhighчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.\\nIn general users of the system should have assurances about the behavior of the action they're about to take.\\nAn administrator (deployer) of `MultipleWinners` can change the number of winners in the system without warning. This has the potential to violate a security goal of the system.\\nadmin can change the number of winners during a prize-draw period\\n```\\nfunction setNumberOfWinners(uint256 count) external onlyOwner {\\n  \\_\\_numberOfWinners = count;\\n\\n  emit NumberOfWinnersSet(count);\\n}\\n```\\n\\n`PeriodicPriceStrategy` - admin may switch-out RNG service at any time (when RNG is not in inflight or timed-out)\\n```\\nfunction setRngService(RNGInterface rngService) external onlyOwner {\\n  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");\\n\\n  rng = rngService;\\n  emit RngServiceUpdated(address(rngService));\\n}\\n```\\n\\n`PeriodicPriceStrategy` - admin can effectively disable the rng request timeout by setting a high value during a prize-draw (e.g. to indefinitely block payouts)\\n```\\nfunction setRngRequestTimeout(uint32 \\_rngRequestTimeout) external onlyOwner {\\n  \\_setRngRequestTimeout(\\_rngRequestTimeout);\\n}\\n```\\n\\n`PeriodicPriceStrategy` - admin may set new tokenListener which might intentionally block token-transfers\\n```\\nfunction setTokenListener(TokenListenerInterface \\_tokenListener) external onlyOwner {\\n  tokenListener = \\_tokenListener;\\n\\n  emit TokenListenerUpdated(address(tokenListener));\\n}\\n```\\n\\n```\\nfunction setPeriodicPrizeStrategyListener(address \\_periodicPrizeStrategyListener) external onlyOwner {\\n  periodicPrizeStrategyListener = PeriodicPrizeStrategyListener(\\_periodicPrizeStrategyListener);\\n\\n  emit PeriodicPrizeStrategyListenerSet(\\_periodicPrizeStrategyListener);\\n}\\n```\\n\\nout of scope but mentioned as a relevant example: `PrizePool` owner can set new `PrizeStrategy` at any time\\n```\\n/// @notice Sets the prize strategy of the prize pool. Only callable by the owner.\\n/// @param \\_prizeStrategy The new prize strategy\\nfunction setPrizeStrategy(address \\_prizeStrategy) external override onlyOwner {\\n  \\_setPrizeStrategy(TokenListenerInterface(\\_prizeStrategy));\\n}\\n```\\n\\na malicious admin may remove all external ERC20/ERC721 token awards prior to the user claiming them (admin front-running opportunity)\\n```\\nfunction removeExternalErc20Award(address \\_externalErc20, address \\_prevExternalErc20) external onlyOwner {\\n  externalErc20s.removeAddress(\\_prevExternalErc20, \\_externalErc20);\\n  emit ExternalErc20AwardRemoved(\\_externalErc20);\\n}\\n```\\n\\n```\\nfunction removeExternalErc721Award(address \\_externalErc721, address \\_prevExternalErc721) external onlyOwner {\\n  externalErc721s.removeAddress(\\_prevExternalErc721, \\_externalErc721);\\n  delete externalErc721TokenIds[\\_externalErc721];\\n  emit ExternalErc721AwardRemoved(\\_externalErc721);\\n}\\n```\\n\\nthe `PeriodicPrizeStrategy` `owner` (also see concerns outlined in issue 5.4) can transfer external ERC20 at any time to avoid them being awarded to users. there is no guarantee to the user.\\n```\\nfunction transferExternalERC20(\\n  address to,\\n  address externalToken,\\n  uint256 amount\\n)\\n  external\\n  onlyOwner\\n{\\n  prizePool.transferExternalERC20(to, externalToken, amount);\\n}\\n```\\nчThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.чч```\\nfunction setNumberOfWinners(uint256 count) external onlyOwner {\\n  \\_\\_numberOfWinners = count;\\n\\n  emit NumberOfWinnersSet(count);\\n}\\n```\\n
PeriodicPriceStrategy - addExternalErc721Award duplicate or invalid tokenIds may block award phaseчmediumчThe prize-strategy owner (or a listener) can add `ERC721` token awards by calling `addExternalErc721Award` providing the `ERC721` token address and a list of `tokenIds` owned by the prizePool.\\nThe method does not check if duplicate `tokenIds` or `tokenIds` that are not owned by the contract are provided. This may cause an exception when `_awardExternalErc721s` calls `prizePool.awardExternalERC721` to transfer an invalid or previously transferred token, blocking the award phase.\\nNote: An admin can recover from this situation by removing and re-adding the `ERC721` token from the awards list.\\nadding `tokenIds`\\n```\\n/// @notice Adds an external ERC721 token as an additional prize that can be awarded\\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\\n/// and they must be approved by the Prize-Pool\\n/// NOTE: The NFT must already be owned by the Prize-Pool\\n/// @param \\_externalErc721 The address of an ERC721 token to be awarded\\n/// @param \\_tokenIds An array of token IDs of the ERC721 to be awarded\\nfunction addExternalErc721Award(address \\_externalErc721, uint256[] calldata \\_tokenIds) external onlyOwnerOrListener {\\n  // require(\\_externalErc721.isContract(), \"PeriodicPrizeStrategy/external-erc721-not-contract\");\\n  require(prizePool.canAwardExternal(\\_externalErc721), \"PeriodicPrizeStrategy/cannot-award-external\");\\n \\n  if (!externalErc721s.contains(\\_externalErc721)) {\\n    externalErc721s.addAddress(\\_externalErc721);\\n  }\\n\\n  for (uint256 i = 0; i < \\_tokenIds.length; i++) {\\n    uint256 tokenId = \\_tokenIds[i];\\n    require(IERC721(\\_externalErc721).ownerOf(tokenId) == address(prizePool), \"PeriodicPrizeStrategy/unavailable-token\");\\n    externalErc721TokenIds[\\_externalErc721].push(tokenId);\\n  }\\n\\n  emit ExternalErc721AwardAdded(\\_externalErc721, \\_tokenIds);\\n}\\n```\\n\\nawarding tokens\\n```\\n/// @notice Awards all external ERC721 tokens to the given user.\\n/// The external tokens must be held by the PrizePool contract.\\n/// @dev The list of ERC721s is reset after every award\\n/// @param winner The user to transfer the tokens to\\nfunction \\_awardExternalErc721s(address winner) internal {\\n  address currentToken = externalErc721s.start();\\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\\n    if (balance > 0) {\\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\\n      delete externalErc721TokenIds[currentToken];\\n    }\\n    currentToken = externalErc721s.next(currentToken);\\n  }\\n  externalErc721s.clearAll();\\n}\\n```\\n\\ntransferring the tokens\\n```\\n/// @notice Called by the prize strategy to award external ERC721 prizes\\n/// @dev Used to award any arbitrary NFTs held by the Prize Pool\\n/// @param to The address of the winner that receives the award\\n/// @param externalToken The address of the external NFT token being awarded\\n/// @param tokenIds An array of NFT Token IDs to be transferred\\nfunction awardExternalERC721(\\n  address to,\\n  address externalToken,\\n  uint256[] calldata tokenIds\\n)\\n  external override\\n  onlyPrizeStrategy\\n{\\n  require(\\_canAwardExternal(externalToken), \"PrizePool/invalid-external-token\");\\n\\n  if (tokenIds.length == 0) {\\n    return;\\n  }\\n\\n  for (uint256 i = 0; i < tokenIds.length; i++) {\\n    IERC721(externalToken).transferFrom(address(this), to, tokenIds[i]);\\n  }\\n\\n  emit AwardedExternalERC721(to, externalToken, tokenIds);\\n}\\n```\\nчEnsure that no duplicate token-ids were provided or skip over token-ids that are not owned by prize-pool (anymore).чч```\\n/// @notice Adds an external ERC721 token as an additional prize that can be awarded\\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\\n/// and they must be approved by the Prize-Pool\\n/// NOTE: The NFT must already be owned by the Prize-Pool\\n/// @param \\_externalErc721 The address of an ERC721 token to be awarded\\n/// @param \\_tokenIds An array of token IDs of the ERC721 to be awarded\\nfunction addExternalErc721Award(address \\_externalErc721, uint256[] calldata \\_tokenIds) external onlyOwnerOrListener {\\n  // require(\\_externalErc721.isContract(), \"PeriodicPrizeStrategy/external-erc721-not-contract\");\\n  require(prizePool.canAwardExternal(\\_externalErc721), \"PeriodicPrizeStrategy/cannot-award-external\");\\n \\n  if (!externalErc721s.contains(\\_externalErc721)) {\\n    externalErc721s.addAddress(\\_externalErc721);\\n  }\\n\\n  for (uint256 i = 0; i < \\_tokenIds.length; i++) {\\n    uint256 tokenId = \\_tokenIds[i];\\n    require(IERC721(\\_externalErc721).ownerOf(tokenId) == address(prizePool), \"PeriodicPrizeStrategy/unavailable-token\");\\n    externalErc721TokenIds[\\_externalErc721].push(tokenId);\\n  }\\n\\n  emit ExternalErc721AwardAdded(\\_externalErc721, \\_tokenIds);\\n}\\n```\\n
PeriodicPrizeStrategy - Token with callback related warnings (ERC777 a.o.)чmediumчThis issue is highly dependent on the configuration of the system. If an admin decides to allow callback enabled token (e.g. `ERC20` compliant `ERC777` or other ERC721/ERC20 extensions) as awards then one recipient may be able to\\nblock the payout for everyone by forcing a revert in the callback when accepting token awards\\nuse the callback to siphon gas, mint gas token, or similar activities\\npotentially re-enter the `PrizeStrategy` contract in an attempt to manipulate the payout (e.g. by immediately withdrawing from the pool to manipulate the 2nd ticket.draw())\\n```\\nfunction \\_awardExternalErc721s(address winner) internal {\\n  address currentToken = externalErc721s.start();\\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\\n    if (balance > 0) {\\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\\n      delete externalErc721TokenIds[currentToken];\\n    }\\n    currentToken = externalErc721s.next(currentToken);\\n  }\\n  externalErc721s.clearAll();\\n}\\n```\\nчIt is highly recommended to not allow tokens with callback functionality into the system. Document and/or implement safeguards that disallow the use of callback enabled tokens. Consider implementing means for the “other winners” to withdraw their share of the rewards independently from others.чч```\\nfunction \\_awardExternalErc721s(address winner) internal {\\n  address currentToken = externalErc721s.start();\\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\\n    if (balance > 0) {\\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\\n      delete externalErc721TokenIds[currentToken];\\n    }\\n    currentToken = externalErc721s.next(currentToken);\\n  }\\n  externalErc721s.clearAll();\\n}\\n```\\n
PeriodicPrizeStrategy - unbounded external tokens linked list may be used to force a gas DoSчmediumчThe size of the linked list of ERC20/ERC721 token awards is not limited. This fact may be exploited by an administrative account by adding an excessive number of external token addresses.\\nThe winning user might want to claim their win by calling `completeAward()` which fails in one of the `_distribute() -> _awardAllExternalTokens() -> _awardExternalErc20s/_awardExternalErc721s` while loops if too many token addresses are configured and gas consumption hits the block gas limit (or it just gets too expensive for the user to call).\\nNote: an admin can recover from this situation by removing items from the list.\\n```\\n/// @notice Adds an external ERC20 token type as an additional prize that can be awarded\\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\\n/// and they must be approved by the Prize-Pool\\n/// @param \\_externalErc20 The address of an ERC20 token to be awarded\\nfunction addExternalErc20Award(address \\_externalErc20) external onlyOwnerOrListener {\\n  \\_addExternalErc20Award(\\_externalErc20);\\n}\\n\\nfunction \\_addExternalErc20Award(address \\_externalErc20) internal {\\n  require(prizePool.canAwardExternal(\\_externalErc20), \"PeriodicPrizeStrategy/cannot-award-external\");\\n  externalErc20s.addAddress(\\_externalErc20);\\n  emit ExternalErc20AwardAdded(\\_externalErc20);\\n}\\n```\\n\\n```\\n/// @param newAddress The address to shift to the front of the list\\nfunction addAddress(Mapping storage self, address newAddress) internal {\\n  require(newAddress != SENTINEL && newAddress != address(0), \"Invalid address\");\\n  require(self.addressMap[newAddress] == address(0), \"Already added\");\\n  self.addressMap[newAddress] = self.addressMap[SENTINEL];\\n  self.addressMap[SENTINEL] = newAddress;\\n  self.count = self.count + 1;\\n}\\n```\\n\\nawarding the tokens loops through the linked list of configured tokens\\n```\\n/// @notice Awards all external ERC721 tokens to the given user.\\n/// The external tokens must be held by the PrizePool contract.\\n/// @dev The list of ERC721s is reset after every award\\n/// @param winner The user to transfer the tokens to\\nfunction \\_awardExternalErc721s(address winner) internal {\\n  address currentToken = externalErc721s.start();\\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\\n    if (balance > 0) {\\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\\n      delete externalErc721TokenIds[currentToken];\\n    }\\n    currentToken = externalErc721s.next(currentToken);\\n  }\\n  externalErc721s.clearAll();\\n}\\n```\\nчLimit the number of tokens an admin can add. Consider implementing an interface that allows the user to claim tokens one-by-one or in user-configured batches.чч```\\n/// @notice Adds an external ERC20 token type as an additional prize that can be awarded\\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\\n/// and they must be approved by the Prize-Pool\\n/// @param \\_externalErc20 The address of an ERC20 token to be awarded\\nfunction addExternalErc20Award(address \\_externalErc20) external onlyOwnerOrListener {\\n  \\_addExternalErc20Award(\\_externalErc20);\\n}\\n\\nfunction \\_addExternalErc20Award(address \\_externalErc20) internal {\\n  require(prizePool.canAwardExternal(\\_externalErc20), \"PeriodicPrizeStrategy/cannot-award-external\");\\n  externalErc20s.addAddress(\\_externalErc20);\\n  emit ExternalErc20AwardAdded(\\_externalErc20);\\n}\\n```\\n
MultipleWinners - setNumberOfWinners does not enforce count>0чmediumчThe constructor of `MultipleWinners` enforces that the argument `_numberOfWinners > 0` while `setNumberOfWinners` does not. A careless or malicious admin might set `__numberOfWinners` to zero to cause the `distribute()` method to throw and not pay out any winners.\\nenforced in the constructor\\n```\\nrequire(\\_numberOfWinners > 0, \"MultipleWinners/num-gt-zero\");\\n```\\n\\nnot enforced when updating the value at a later stage\\n```\\nfunction setNumberOfWinners(uint256 count) external onlyOwner {\\n  \\_\\_numberOfWinners = count;\\n\\n  emit NumberOfWinnersSet(count);\\n}\\n```\\nчRequire that `numberOfWinners > 0`.чч```\\nrequire(\\_numberOfWinners > 0, \"MultipleWinners/num-gt-zero\");\\n```\\n
LootBox - plunder should disallow plundering to address(0)чmediumчAnyone can call `LootboxController.plunder()` to plunder on behalf of a `tokenId` owner. If a `LootBox` received an AirDrop but no `NFT` was issued to an owner (yet) this might open up an opportunity for a malicious actor to call `plunder()` in an attempt to burn the ETH and any airdropped tokens that allow transfers to `address(0)`.\\nNote:\\nDepending on the token implementation, transfers may or may not revert if the `toAddress == address(0)`, while burning the `ETH` will succeed.\\nThis might allow anyone to forcefully burn received `ETH` that would otherwise be available to the future beneficiary\\nIf the airdrop and transfer of `LootBox` ownership are not done within one transaction, this might open up a front-running window that allows a third party to burn air-dropped `ETH` before it can be claimed by the `owner`.\\nconsider one component issues the airdrop in one transaction (or block) and setting the `owner` in a later transaction (or block). The `owner` is unset for a short duration of time which might allow anyone to burn `ETH` held by the `LootBox` proxy instance.\\n`plunder()` receiving the `owner` of an `ERC721.tokenId`\\n```\\nfunction plunder(\\n  address erc721,\\n  uint256 tokenId,\\n  IERC20[] calldata erc20s,\\n  LootBox.WithdrawERC721[] calldata erc721s,\\n  LootBox.WithdrawERC1155[] calldata erc1155s\\n) external {\\n  address payable owner = payable(IERC721(erc721).ownerOf(tokenId));\\n```\\n\\nThe modified `ERC721` returns `address(0)` if the owner is not known\\n```\\n \\* @dev See {IERC721-ownerOf}.\\n \\*/\\nfunction ownerOf(uint256 tokenId) public view override returns (address) {\\n    return \\_tokenOwners[tokenId];\\n}\\n```\\n\\nWhile `withdraw[ERC20|ERC721|ERC1155]` fail with `to == address(0)`, `transferEther()` succeeds and burns the eth by sending it to `address(0)`\\n```\\nfunction plunder(\\n  IERC20[] memory erc20,\\n  WithdrawERC721[] memory erc721,\\n  WithdrawERC1155[] memory erc1155,\\n  address payable to\\n) external {\\n  \\_withdrawERC20(erc20, to);\\n  \\_withdrawERC721(erc721, to);\\n  \\_withdrawERC1155(erc1155, to);\\n  transferEther(to, address(this).balance);\\n}\\n```\\nчRequire that the destination address `to` in `plunder()` and `transferEther()` is not `address(0)`.чч```\\nfunction plunder(\\n  address erc721,\\n  uint256 tokenId,\\n  IERC20[] calldata erc20s,\\n  LootBox.WithdrawERC721[] calldata erc721s,\\n  LootBox.WithdrawERC1155[] calldata erc1155s\\n) external {\\n  address payable owner = payable(IERC721(erc721).ownerOf(tokenId));\\n```\\n
PeriodicPrizeStrategy - Inconsistent behavior between award-phase modifiers and view functionsчlowчThe logic in the `canStartAward()` function is inconsistent with that of the `requireCanStartAward` modifier, and the logic in the `canCompleteAward()` function is inconsistent with that of the `requireCanCompleteAward` modifier. Neither of these view functions appear to be used elsewhere in the codebase, but the similarities between the function names and the corresponding modifiers is highly misleading.\\n`canStartAward()` is inconsistent with `requireCanStartAward`\\n```\\nfunction canStartAward() external view returns (bool) {\\n  return \\_isPrizePeriodOver() && !isRngRequested();\\n}\\n```\\n\\n```\\nmodifier requireCanStartAward() {\\n  require(\\_isPrizePeriodOver(), \"PeriodicPrizeStrategy/prize-period-not-over\");\\n  require(!isRngRequested() || isRngTimedOut(), \"PeriodicPrizeStrategy/rng-already-requested\");\\n  \\_;\\n}\\n```\\n\\n`canCompleteAward()` is inconsistent with `requireCanCompleteAward`\\n```\\nfunction canCompleteAward() external view returns (bool) {\\n  return isRngRequested() && isRngCompleted();\\n}\\n```\\n\\n```\\nmodifier requireCanCompleteAward() {\\n  require(\\_isPrizePeriodOver(), \"PeriodicPrizeStrategy/prize-period-not-over\");\\n  require(isRngRequested(), \"PeriodicPrizeStrategy/rng-not-requested\");\\n  require(isRngCompleted(), \"PeriodicPrizeStrategy/rng-not-complete\");\\n  \\_;\\n}\\n```\\nчMake the logic consistent between the view functions and the modifiers of the same name or remove the functions.чч```\\nfunction canStartAward() external view returns (bool) {\\n  return \\_isPrizePeriodOver() && !isRngRequested();\\n}\\n```\\n
MultipleWinners - Awards can be guaranteed with a set number of ticketsчlowчBecause additional award drawings are distributed at a constant interval in the `SortitionSumTree` by `MultipleWinners._distribute()`, any user that holds a number of tickets `>= floor(totalSupply / __numberOfWinners)` can guarantee at least one award regardless of the initial drawing.\\nMultipleWinners._distribute():\\n```\\nuint256 ticketSplit = totalSupply.div(\\_\\_numberOfWinners);\\nuint256 nextRandom = randomNumber.add(ticketSplit);\\n// the other winners receive their prizeShares\\nfor (uint256 winnerCount = 1; winnerCount < \\_\\_numberOfWinners; winnerCount++) {\\n  winners[winnerCount] = ticket.draw(nextRandom);\\n  nextRandom = nextRandom.add(ticketSplit);\\n}\\n```\\nчDo not distribute awards at fixed intervals from the initial drawing, but instead randomize the additional drawings as well.чч```\\nuint256 ticketSplit = totalSupply.div(\\_\\_numberOfWinners);\\nuint256 nextRandom = randomNumber.add(ticketSplit);\\n// the other winners receive their prizeShares\\nfor (uint256 winnerCount = 1; winnerCount < \\_\\_numberOfWinners; winnerCount++) {\\n  winners[winnerCount] = ticket.draw(nextRandom);\\n  nextRandom = nextRandom.add(ticketSplit);\\n}\\n```\\n
MultipleWinners - Inconsistent behavior compared to SingleRandomWinnerчlowчThe `MultipleWinners` strategy carries out award distribution to the zero address if `ticket.draw()` returns `address(0)` (indicating an error condition) while `SingleRandomWinner` does not.\\n`SingleRandomWinner` silently skips award distribution if `ticket.draw()` returns `address(0)`.\\n```\\ncontract SingleRandomWinner is PeriodicPrizeStrategy {\\n  function \\_distribute(uint256 randomNumber) internal override {\\n    uint256 prize = prizePool.captureAwardBalance();\\n    address winner = ticket.draw(randomNumber);\\n    if (winner != address(0)) {\\n      \\_awardTickets(winner, prize);\\n      \\_awardAllExternalTokens(winner);\\n    }\\n  }\\n}\\n```\\n\\n`MultipleWinners` still attempts to distribute awards if `ticket.draw()` returns `address(0)`. This may or may not succeed depending on the implementation of the tokens included in the `externalErc20s` and `externalErc721s` linked lists.\\n```\\nfunction \\_distribute(uint256 randomNumber) internal override {\\n  uint256 prize = prizePool.captureAwardBalance();\\n\\n  // main winner gets all external tokens\\n  address mainWinner = ticket.draw(randomNumber);\\n  \\_awardAllExternalTokens(mainWinner);\\n\\n  address[] memory winners = new address[](\\_\\_numberOfWinners);\\n  winners[0] = mainWinner;\\n```\\nчImplement consistent behavior. Avoid hiding error conditions and consider throwing an exception instead.чч```\\ncontract SingleRandomWinner is PeriodicPrizeStrategy {\\n  function \\_distribute(uint256 randomNumber) internal override {\\n    uint256 prize = prizePool.captureAwardBalance();\\n    address winner = ticket.draw(randomNumber);\\n    if (winner != address(0)) {\\n      \\_awardTickets(winner, prize);\\n      \\_awardAllExternalTokens(winner);\\n    }\\n  }\\n}\\n```\\n
Initialize implementations for proxy contracts and protect initialization methodsчlowчAny situation where the implementation of proxy contracts can be initialized by third parties should be avoided. This can be the case if the `initialize` function is unprotected or not initialized immediately after deployment. Since the implementation contract is not meant to be used directly without a proxy delegate-calling to it, it is recommended to protect the initialization method of the implementation by initializing on deployment.\\nThis affects all proxy implementations (the delegatecall target contract) deployed in the system.\\nThe implementation for `MultipleWinners` is not initialized. Even though not directly used by the system it may be initialized by a third party.\\n```\\nconstructor () public {\\n  instance = new MultipleWinners();\\n}\\n```\\n\\nThe deployed `ERC721Contract` is not initialized.\\n```\\nconstructor () public {\\n  erc721ControlledInstance = new ERC721Controlled();\\n  erc721ControlledBytecode = MinimalProxyLibrary.minimalProxy(address(erc721ControlledInstance));\\n}\\n```\\n\\nThe deployed `LootBox` is not initialized.\\n```\\nconstructor () public {\\n  lootBoxActionInstance = new LootBox();\\n  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));\\n}\\n```\\nчInitialize unprotected implementation contracts in the implementation's constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction.чч```\\nconstructor () public {\\n  instance = new MultipleWinners();\\n}\\n```\\n
LootBox - transferEther should be internalчlowч`LootBox.transferEther()` can be `internal` as it is only called from `LootBox.plunder()` and the LootBox(proxy) instances are generally very short-living (created and destroyed within one transaction).\\n```\\nfunction transferEther(address payable to, uint256 amount) public {\\n  to.transfer(amount);\\n\\n  emit TransferredEther(to, amount);\\n}\\n```\\nчRestrict transferEther()'s visibility to `internal`.чч```\\nfunction transferEther(address payable to, uint256 amount) public {\\n  to.transfer(amount);\\n\\n  emit TransferredEther(to, amount);\\n}\\n```\\n
LootBox - executeCalls can be misused to relay callsчlowч`LootBox` is deployed with `LootBoxController` and serves as the implementation for individual `create2` lootbox proxy contracts. None of the methods of the `LootBox` implementation contract are access restricted. A malicious actor may therefore use the `executeCalls()` method to relay arbitrary calls to other contracts on the blockchain in an attempt to disguise the origin or misuse the reputation of the `LootBox` contract (as it belongs to the PoolTogether project).\\nNote: allows non-value and value calls (deposits can be forces via selfdestruct)\\n```\\nfunction executeCalls(Call[] calldata calls) external returns (bytes[] memory) {\\n  bytes[] memory response = new bytes[](calls.length);\\n  for (uint256 i = 0; i < calls.length; i++) {\\n    response[i] = \\_executeCall(calls[i].to, calls[i].value, calls[i].data);\\n  }\\n  return response;\\n}\\n```\\nчRestrict access to call forwarding functionality to trusted entities. Consider implementing the `Ownable` pattern allowing access to functionality to the owner only.чч```\\nfunction executeCalls(Call[] calldata calls) external returns (bytes[] memory) {\\n  bytes[] memory response = new bytes[](calls.length);\\n  for (uint256 i = 0; i < calls.length; i++) {\\n    response[i] = \\_executeCall(calls[i].to, calls[i].value, calls[i].data);\\n  }\\n  return response;\\n}\\n```\\n
ERC20 tokens with no return value will fail to transferчhighчAlthough the ERC20 standard suggests that a transfer should return `true` on success, many tokens are non-compliant in this regard.\\nIn that case, the `.transfer()` call here will revert even if the transfer is successful, because solidity will check that the RETURNDATASIZE matches the ERC20 interface.\\n```\\nif (!instance.transfer(getSendAddress(), forwarderBalance)) {\\n    revert('Could not gather ERC20');\\n}\\n```\\nчConsider using OpenZeppelin's SafeERC20.чч```\\nif (!instance.transfer(getSendAddress(), forwarderBalance)) {\\n    revert('Could not gather ERC20');\\n}\\n```\\n
Delegated transactions can be executed for multiple accountsчhighчThe `Gateway` contract allows users to create meta transactions triggered by the system's backend. To do so, one of the owners of the account should sign the message in the following format:\\n```\\naddress sender = \\_hashPrimaryTypedData(\\n \\_hashTypedData(\\n nonce,\\n to,\\n data\\n )\\n).recoverAddress(senderSignature);\\n```\\n\\nThe message includes a nonce, destination address, and call data. The problem is that this message does not include the `account` address. So if the `sender` is the owner of multiple accounts, this meta transaction can be called for multiple accounts.чResolution\\nComment from the client: The issue has been solved\\nAdd the `account` field in the signed message or make sure that any address can be the owner of only one `account`.чч```\\naddress sender = \\_hashPrimaryTypedData(\\n \\_hashTypedData(\\n nonce,\\n to,\\n data\\n )\\n).recoverAddress(senderSignature);\\n```\\n
Removing an owner does not work in PersonalAccountRegistryчhighчAn owner of a personal account can be added/removed by other owners. When removing the owner, only `removedAtBlockNumber` value is updated. `accounts[account].owners[owner].added` remains true:\\n```\\naccounts[account].owners[owner].removedAtBlockNumber = block.number;\\n\\nemit AccountOwnerRemoved(\\n account,\\n owner\\n);\\n```\\n\\nBut when the account is checked whether this account is the owner, only `accounts[account].owners[owner].added` is actually checked:\\n```\\nfunction \\_verifySender(\\n address account\\n)\\n private\\n returns (address)\\n{\\n address sender = \\_getContextSender();\\n\\n if (!accounts[account].owners[sender].added) {\\n require(\\n accounts[account].salt == 0\\n );\\n\\n bytes32 salt = keccak256(\\n abi.encodePacked(sender)\\n );\\n\\n require(\\n account == \\_computeAccountAddress(salt)\\n );\\n\\n accounts[account].salt = salt;\\n accounts[account].owners[sender].added = true;\\n\\n emit AccountOwnerAdded(\\n account,\\n sender\\n );\\n }\\n\\n return sender;\\n}\\n```\\n\\nSo the owner will never be removed, because `accounts[account].owners[owner].added` will always be `true.чProperly check if the account is still the owner in the `_verifySender` function.чч```\\naccounts[account].owners[owner].removedAtBlockNumber = block.number;\\n\\nemit AccountOwnerRemoved(\\n account,\\n owner\\n);\\n```\\n
The withdrawal mechanism is overcomplicatedчmediumчTo withdraw the funds, anyone who has the account in `PaymentRegistry` should call the `withdrawDeposit` function and go through the withdrawal process. After the lockdown period (30 days), the user will withdraw all the funds from the account.\\n```\\nfunction withdrawDeposit(\\n address token\\n)\\n external\\n{\\n address owner = \\_getContextAccount();\\n uint256 lockedUntil = deposits[owner].withdrawalLockedUntil[token];\\n\\n /\\* solhint-disable not-rely-on-time \\*/\\n\\n if (lockedUntil != 0 && lockedUntil <= now) {\\n deposits[owner].withdrawalLockedUntil[token] = 0;\\n\\n address depositAccount = deposits[owner].account;\\n uint256 depositValue;\\n\\n if (token == address(0)) {\\n depositValue = depositAccount.balance;\\n } else {\\n depositValue = ERC20Token(token).balanceOf(depositAccount);\\n }\\n\\n \\_transferFromDeposit(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n\\n emit DepositWithdrawn(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n } else {\\n \\_deployDepositAccount(owner);\\n\\n lockedUntil = now.add(depositWithdrawalLockPeriod);\\n\\n deposits[owner].withdrawalLockedUntil[token] = lockedUntil;\\n\\n emit DepositWithdrawalRequested(\\n deposits[owner].account,\\n owner,\\n token,\\n lockedUntil\\n );\\n }\\n /\\* solhint-enable not-rely-on-time \\*/\\n}\\n```\\n\\nDuring that period, everyone who has a channel with the user is forced to commit their channels or lose money from that channel. When doing so, every user will reset the initial lockdown period and the withdrawer should start the process again.\\n```\\nif (deposits[sender].withdrawalLockedUntil[token] > 0) {\\n deposits[sender].withdrawalLockedUntil[token] = 0;\\n```\\n\\nThere is no way for the withdrawer to close the channel by himself. If the withdrawer has N channels, it's theoretically possible to wait for up to N*(30 days) period and make N+2 transactions.чThere may be some minor recommendations on how to improve that without major changes:\\nWhen committing a payment channel, do not reset the lockdown period to zero. Two better option would be either not change it at all or extend to `now + depositWithdrawalLockPeriod`чч```\\nfunction withdrawDeposit(\\n address token\\n)\\n external\\n{\\n address owner = \\_getContextAccount();\\n uint256 lockedUntil = deposits[owner].withdrawalLockedUntil[token];\\n\\n /\\* solhint-disable not-rely-on-time \\*/\\n\\n if (lockedUntil != 0 && lockedUntil <= now) {\\n deposits[owner].withdrawalLockedUntil[token] = 0;\\n\\n address depositAccount = deposits[owner].account;\\n uint256 depositValue;\\n\\n if (token == address(0)) {\\n depositValue = depositAccount.balance;\\n } else {\\n depositValue = ERC20Token(token).balanceOf(depositAccount);\\n }\\n\\n \\_transferFromDeposit(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n\\n emit DepositWithdrawn(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n } else {\\n \\_deployDepositAccount(owner);\\n\\n lockedUntil = now.add(depositWithdrawalLockPeriod);\\n\\n deposits[owner].withdrawalLockedUntil[token] = lockedUntil;\\n\\n emit DepositWithdrawalRequested(\\n deposits[owner].account,\\n owner,\\n token,\\n lockedUntil\\n );\\n }\\n /\\* solhint-enable not-rely-on-time \\*/\\n}\\n```\\n
The lockdown period shouldn't be extended when called multiple timesчlowчIn order to withdraw a deposit from the `PaymentRegistry`, the account owner should call the `withdrawDeposit` function and wait for `depositWithdrawalLockPeriod` (30 days) before actually transferring all the tokens from the account.\\nThe issue is that if the withdrawer accidentally calls it for the second time before these 30 days pass, the waiting period gets extended for 30 days again.\\n```\\nif (lockedUntil != 0 && lockedUntil <= now) {\\n deposits[owner].withdrawalLockedUntil[token] = 0;\\n\\n address depositAccount = deposits[owner].account;\\n uint256 depositValue;\\n\\n if (token == address(0)) {\\n depositValue = depositAccount.balance;\\n } else {\\n depositValue = ERC20Token(token).balanceOf(depositAccount);\\n }\\n\\n \\_transferFromDeposit(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n\\n emit DepositWithdrawn(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n} else {\\n \\_deployDepositAccount(owner);\\n\\n lockedUntil = now.add(depositWithdrawalLockPeriod);\\n```\\nчResolution\\nComment from the client: The issue has been solved\\nOnly extend the waiting period when a withdrawal is requested for the first time.чч```\\nif (lockedUntil != 0 && lockedUntil <= now) {\\n deposits[owner].withdrawalLockedUntil[token] = 0;\\n\\n address depositAccount = deposits[owner].account;\\n uint256 depositValue;\\n\\n if (token == address(0)) {\\n depositValue = depositAccount.balance;\\n } else {\\n depositValue = ERC20Token(token).balanceOf(depositAccount);\\n }\\n\\n \\_transferFromDeposit(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n\\n emit DepositWithdrawn(\\n depositAccount,\\n owner,\\n token,\\n depositValue\\n );\\n} else {\\n \\_deployDepositAccount(owner);\\n\\n lockedUntil = now.add(depositWithdrawalLockPeriod);\\n```\\n
Gateway can call any contract  AcknowledgedчlowчResolution\\nComment from the client: That's right Gateway can call any contract, we want to keep it open for any external contract.\\nThe `Gateway` contract is used as a gateway for meta transactions and batched transactions. It can currently call any contract, while is only intended to call specific contracts in the system that implemented `GatewayRecipient` interface:\\n```\\n for (uint256 i = 0; i < data.length; i++) {\\n require(\\n to[i] != address(0)\\n );\\n\\n // solhint-disable-next-line avoid-low-level-calls\\n (succeeded,) = to[i].call(abi.encodePacked(data[i], account, sender));\\n\\n require(\\n succeeded\\n );\\n }\\n}\\n```\\n\\nThere are currently no restrictions for `to` value.чMake sure, only intended contracts can be called by the `Gateway` : `PersonalAccountRegistry`, `PaymentRegistry`, `ENSController`.чч```\\n for (uint256 i = 0; i < data.length; i++) {\\n require(\\n to[i] != address(0)\\n );\\n\\n // solhint-disable-next-line avoid-low-level-calls\\n (succeeded,) = to[i].call(abi.encodePacked(data[i], account, sender));\\n\\n require(\\n succeeded\\n );\\n }\\n}\\n```\\n
Remove unused codeчlowч```\\n return \\_deployAccount(\\n salt,\\n 0\\n );\\n}\\n\\nfunction \\_deployAccount(\\n bytes32 salt,\\n uint256 value\\n)\\n internal\\n returns (address)\\n{\\n return address(new Account{salt: salt, value: value}());\\n}\\n```\\nчIt is recommended to remove this value as there are no use cases for it at the moment, however if it is planned to be used in the future, it should be well documented in the code to prevent confusion.чч```\\n return \\_deployAccount(\\n salt,\\n 0\\n );\\n}\\n\\nfunction \\_deployAccount(\\n bytes32 salt,\\n uint256 value\\n)\\n internal\\n returns (address)\\n{\\n return address(new Account{salt: salt, value: value}());\\n}\\n```\\n
Every node gets a full validator's bountyчhighчResolution\\nThis issue is addressed in Bug/skale 3273 formula fix 435 and SKALE-3273 Fix BountyV2 populating error 438.\\nThe main change is related to how bounties are calculated for each validator. Below are a few notes on these pull requests:\\n`nodesByValidator` mapping is no longer used in the codebase and the non-zero values are deleted when `calculateBounty()` is called for a specific validator. The mapping is kept in the code for compatible storage layout in upgradable proxies.\\nSome functions such as `populate()` was developed for the transition to the upgraded contracts (rewrite `_effectiveDelegatedSum` values based on the new calculation formula). This function is not part of this review and will be removed in the future updates.\\nUnlike the old architecture, `nodesByValidator[validatorId]` is no longer used within the system to calculate `_effectiveDelegatedSum` and bounties. This is replaced by using overall staked amount and duration.\\nIf a validator does not claim their bounty during a month, it is considered as a misbehave and her bounty goes to the bounty pool for the next month.\\nTo get the bounty, every node calls the `getBounty` function of the `SkaleManager` contract. This function can be called once per month. The size of the bounty is defined in the `BountyV2` contract in the `_calculateMaximumBountyAmount` function:\\n```\\nreturn epochPoolSize\\n    .add(\\_bountyWasPaidInCurrentEpoch)\\n    .mul(\\n        delegationController.getAndUpdateEffectiveDelegatedToValidator(\\n            nodes.getValidatorId(nodeIndex),\\n            currentMonth\\n        )\\n    )\\n    .div(effectiveDelegatedSum);\\n```\\n\\nThe problem is that this amount actually represents the amount that should be paid to the validator of that node. But each node will get this amount. Additionally, the amount of validator's bounty should also correspond to the number of active nodes, while this formula only uses the amount of delegated funds.чEvery node should get only their parts of the bounty.чч```\\nreturn epochPoolSize\\n    .add(\\_bountyWasPaidInCurrentEpoch)\\n    .mul(\\n        delegationController.getAndUpdateEffectiveDelegatedToValidator(\\n            nodes.getValidatorId(nodeIndex),\\n            currentMonth\\n        )\\n    )\\n    .div(effectiveDelegatedSum);\\n```\\n
A node exit prevents some other nodes from exiting for some period  PendingчmediumчWhen a node wants to exit, the `nodeExit` function should be called as many times, as there are schains in the node. Each time one schain is getting removed from the node. During every call, all the active schains are getting frozen for 12 hours.\\n```\\nfunction freezeSchains(uint nodeIndex) external allow(\"SkaleManager\") {\\n    SchainsInternal schainsInternal = SchainsInternal(contractManager.getContract(\"SchainsInternal\"));\\n    bytes32[] memory schains = schainsInternal.getActiveSchains(nodeIndex);\\n    for (uint i = 0; i < schains.length; i++) {\\n        Rotation memory rotation = rotations[schains[i]];\\n        if (rotation.nodeIndex == nodeIndex && now < rotation.freezeUntil) {\\n            continue;\\n        }\\n        string memory schainName = schainsInternal.getSchainName(schains[i]);\\n        string memory revertMessage = \"Node cannot rotate on Schain \";\\n        revertMessage = revertMessage.strConcat(schainName);\\n        revertMessage = revertMessage.strConcat(\", occupied by Node \");\\n        revertMessage = revertMessage.strConcat(rotation.nodeIndex.uint2str());\\n        string memory dkgRevert = \"DKG process did not finish on schain \";\\n        ISkaleDKG skaleDKG = ISkaleDKG(contractManager.getContract(\"SkaleDKG\"));\\n        require(\\n            skaleDKG.isLastDKGSuccessful(keccak256(abi.encodePacked(schainName))),\\n            dkgRevert.strConcat(schainName));\\n        require(rotation.freezeUntil < now, revertMessage);\\n        \\_startRotation(schains[i], nodeIndex);\\n    }\\n}\\n```\\n\\nBecause of that, no other node that is running one of these schains can exit during that period. In the worst-case scenario, one malicious node has 128 Schains and calls `nodeExit` every 12 hours. That means that some nodes will not be able to exit for 64 days.чMake node exiting process less synchronous.чч```\\nfunction freezeSchains(uint nodeIndex) external allow(\"SkaleManager\") {\\n    SchainsInternal schainsInternal = SchainsInternal(contractManager.getContract(\"SchainsInternal\"));\\n    bytes32[] memory schains = schainsInternal.getActiveSchains(nodeIndex);\\n    for (uint i = 0; i < schains.length; i++) {\\n        Rotation memory rotation = rotations[schains[i]];\\n        if (rotation.nodeIndex == nodeIndex && now < rotation.freezeUntil) {\\n            continue;\\n        }\\n        string memory schainName = schainsInternal.getSchainName(schains[i]);\\n        string memory revertMessage = \"Node cannot rotate on Schain \";\\n        revertMessage = revertMessage.strConcat(schainName);\\n        revertMessage = revertMessage.strConcat(\", occupied by Node \");\\n        revertMessage = revertMessage.strConcat(rotation.nodeIndex.uint2str());\\n        string memory dkgRevert = \"DKG process did not finish on schain \";\\n        ISkaleDKG skaleDKG = ISkaleDKG(contractManager.getContract(\"SkaleDKG\"));\\n        require(\\n            skaleDKG.isLastDKGSuccessful(keccak256(abi.encodePacked(schainName))),\\n            dkgRevert.strConcat(schainName));\\n        require(rotation.freezeUntil < now, revertMessage);\\n        \\_startRotation(schains[i], nodeIndex);\\n    }\\n}\\n```\\n
Removing a node require multiple transactions and may be very expensive  PendingчmediumчWhen removing a node from the network, the owner should redistribute all the schains that are currently on that node to the other nodes. To do so, the validator should call the `nodeExit` function of the `SkaleManager` contract. In this function, only one schain is going to be removed from the node. So the node would have to call the `nodeExit` function as many times as there are schains in the node. Every call iterates over every potential node that can be used as a replacement (like in https://github.com/ConsenSys/skale-network-audit-2020-10/issues/3).\\nIn addition to that, the first call will iterate over all schains in the node, make 4 SSTORE operations and external calls for each schain:\\n```\\nfunction \\_startRotation(bytes32 schainIndex, uint nodeIndex) private {\\n    ConstantsHolder constants = ConstantsHolder(contractManager.getContract(\"ConstantsHolder\"));\\n    rotations[schainIndex].nodeIndex = nodeIndex;\\n    rotations[schainIndex].newNodeIndex = nodeIndex;\\n    rotations[schainIndex].freezeUntil = now.add(constants.rotationDelay());\\n    waitForNewNode[schainIndex] = true;\\n}\\n```\\n\\nThis may hit the block gas limit even easier than issue 5.4.\\nIf the first transaction does not hit the block's gas limit, the maximum price of deleting a node would be BLOCK_GAS_COST * 128. At the moment, it's around $50,000.чOptimize the process of deleting a node, so it can't hit the gas limit in one transaction, and the overall price should be cheaper.чч```\\nfunction \\_startRotation(bytes32 schainIndex, uint nodeIndex) private {\\n    ConstantsHolder constants = ConstantsHolder(contractManager.getContract(\"ConstantsHolder\"));\\n    rotations[schainIndex].nodeIndex = nodeIndex;\\n    rotations[schainIndex].newNodeIndex = nodeIndex;\\n    rotations[schainIndex].freezeUntil = now.add(constants.rotationDelay());\\n    waitForNewNode[schainIndex] = true;\\n}\\n```\\n
Adding a new schain may potentially hit the gas limit  PendingчmediumчWhen adding a new schain, a group of random 16 nodes is randomly selected to run that schain. In order to do so, the `_generateGroup` function iterates over all the nodes that can be used for that purpose:\\n```\\nfunction \\_generateGroup(bytes32 schainId, uint numberOfNodes) private returns (uint[] memory nodesInGroup) {\\n    Nodes nodes = Nodes(contractManager.getContract(\"Nodes\"));\\n    uint8 space = schains[schainId].partOfNode;\\n    nodesInGroup = new uint[](numberOfNodes);\\n\\n    uint[] memory possibleNodes = isEnoughNodes(schainId);\\n    require(possibleNodes.length >= nodesInGroup.length, \"Not enough nodes to create Schain\");\\n    uint ignoringTail = 0;\\n    uint random = uint(keccak256(abi.encodePacked(uint(blockhash(block.number.sub(1))), schainId)));\\n    for (uint i = 0; i < nodesInGroup.length; ++i) {\\n        uint index = random % (possibleNodes.length.sub(ignoringTail));\\n        uint node = possibleNodes[index];\\n        nodesInGroup[i] = node;\\n        \\_swap(possibleNodes, index, possibleNodes.length.sub(ignoringTail).sub(1));\\n        ++ignoringTail;\\n\\n        \\_exceptionsForGroups[schainId][node] = true;\\n        addSchainForNode(node, schainId);\\n        require(nodes.removeSpaceFromNode(node, space), \"Could not remove space from Node\");\\n    }\\n```\\n\\nIf the total number of nodes exceeds around a few thousands, adding a schain may hit the block gas limit.чAvoid iterating over all nodes when selecting a random node for a schain.чч```\\nfunction \\_generateGroup(bytes32 schainId, uint numberOfNodes) private returns (uint[] memory nodesInGroup) {\\n    Nodes nodes = Nodes(contractManager.getContract(\"Nodes\"));\\n    uint8 space = schains[schainId].partOfNode;\\n    nodesInGroup = new uint[](numberOfNodes);\\n\\n    uint[] memory possibleNodes = isEnoughNodes(schainId);\\n    require(possibleNodes.length >= nodesInGroup.length, \"Not enough nodes to create Schain\");\\n    uint ignoringTail = 0;\\n    uint random = uint(keccak256(abi.encodePacked(uint(blockhash(block.number.sub(1))), schainId)));\\n    for (uint i = 0; i < nodesInGroup.length; ++i) {\\n        uint index = random % (possibleNodes.length.sub(ignoringTail));\\n        uint node = possibleNodes[index];\\n        nodesInGroup[i] = node;\\n        \\_swap(possibleNodes, index, possibleNodes.length.sub(ignoringTail).sub(1));\\n        ++ignoringTail;\\n\\n        \\_exceptionsForGroups[schainId][node] = true;\\n        addSchainForNode(node, schainId);\\n        require(nodes.removeSpaceFromNode(node, space), \"Could not remove space from Node\");\\n    }\\n```\\n
Re-entrancy attacks with ERC-777чlowчSome tokens may allow users to perform re-entrancy while calling the `transferFrom` function. For example, it would be possible for an attacker to “borrow” a large amount of ERC-777 tokens from the lending pool by re-entering the `deposit` function from within `transferFrom`.\\n```\\nfunction deposit(\\n  address asset,\\n  uint256 amount,\\n  address onBehalfOf,\\n  uint16 referralCode\\n) external override {\\n  \\_whenNotPaused();\\n  ReserveLogic.ReserveData storage reserve = \\_reserves[asset];\\n\\n  ValidationLogic.validateDeposit(reserve, amount);\\n\\n  address aToken = reserve.aTokenAddress;\\n\\n  reserve.updateState();\\n  reserve.updateInterestRates(asset, aToken, amount, 0);\\n\\n  bool isFirstDeposit = IAToken(aToken).balanceOf(onBehalfOf) == 0;\\n  if (isFirstDeposit) {\\n    \\_usersConfig[onBehalfOf].setUsingAsCollateral(reserve.id, true);\\n  }\\n\\n  IAToken(aToken).mint(onBehalfOf, amount, reserve.liquidityIndex);\\n\\n  //transfer to the aToken contract\\n  IERC20(asset).safeTransferFrom(msg.sender, aToken, amount);\\n\\n  emit Deposit(asset, msg.sender, onBehalfOf, amount, referralCode);\\n}\\n```\\n\\nBecause the `safeTransferFrom` call is happening at the end of the `deposit` function, the `deposit` will be fully processed before the tokens are actually transferred.\\nSo at the beginning of the transfer, the attacker can re-enter the call to withdraw their deposit. The withdrawal will succeed even though the attacker's tokens have not yet been transferred to the lending pool. Essentially, the attacker is granted a flash-loan but without paying fees.\\nAdditionally, after these calls, interest rates will be skewed because interest rate update relies on the actual current balance.\\nRemediation\\nDo not whitelist ERC-777 or other re-entrable tokens to prevent this kind of attack.чResolution\\nThe issue was partially mitigated in `deposit` function by minting AToken before the transfer of the `deposit` token.чч```\\nfunction deposit(\\n  address asset,\\n  uint256 amount,\\n  address onBehalfOf,\\n  uint16 referralCode\\n) external override {\\n  \\_whenNotPaused();\\n  ReserveLogic.ReserveData storage reserve = \\_reserves[asset];\\n\\n  ValidationLogic.validateDeposit(reserve, amount);\\n\\n  address aToken = reserve.aTokenAddress;\\n\\n  reserve.updateState();\\n  reserve.updateInterestRates(asset, aToken, amount, 0);\\n\\n  bool isFirstDeposit = IAToken(aToken).balanceOf(onBehalfOf) == 0;\\n  if (isFirstDeposit) {\\n    \\_usersConfig[onBehalfOf].setUsingAsCollateral(reserve.id, true);\\n  }\\n\\n  IAToken(aToken).mint(onBehalfOf, amount, reserve.liquidityIndex);\\n\\n  //transfer to the aToken contract\\n  IERC20(asset).safeTransferFrom(msg.sender, aToken, amount);\\n\\n  emit Deposit(asset, msg.sender, onBehalfOf, amount, referralCode);\\n}\\n```\\n
Attacker can abuse swapLiquidity function to drain users' fundsчmediumчThe `swapLiquidity` function allows liquidity providers to atomically swap their collateral. The function takes a receiverAddressargument that normally points to an `ISwapAdapter` implementation trusted by the user.\\n```\\nvars.fromReserveAToken.burn(\\n msg.sender,\\n receiverAddress,\\n amountToSwap,\\n fromReserve.liquidityIndex\\n);\\n// Notifies the receiver to proceed, sending as param the underlying already transferred\\nISwapAdapter(receiverAddress).executeOperation(\\n fromAsset,\\n toAsset,\\n amountToSwap,\\n address(this),\\n params\\n);\\n\\nvars.amountToReceive = IERC20(toAsset).balanceOf(receiverAddress);\\nif (vars.amountToReceive != 0) {\\n IERC20(toAsset).transferFrom(\\n receiverAddress,\\n address(vars.toReserveAToken),\\n vars.amountToReceive\\n );\\n\\n if (vars.toReserveAToken.balanceOf(msg.sender) == 0) {\\n \\_usersConfig[msg.sender].setUsingAsCollateral(toReserve.id, true);\\n }\\n\\n vars.toReserveAToken.mint(msg.sender, vars.amountToReceive, toReserve.liquidityIndex);\\n```\\n\\nHowever, since an attacker can pass any address as the `receiverAddress`, they can arbitrarily transfer funds from other contracts that have given allowances to the `LendingPool` contract (for example, another ISwapAdapter).\\nThe `amountToSwap` is defined by the caller and can be very small. The attacker gets the difference between `IERC20(toAsset).balanceOf(receiverAddress)` value of `toAsset` and the `amountToSwap` of `fromToken`.\\nRemediation\\nEnsure that no funds can be stolen from contracts that have granted allowances to the `LendingPool` contract.чResolution\\nSolved by removing `swapLiquidity` functionality.чч```\\nvars.fromReserveAToken.burn(\\n msg.sender,\\n receiverAddress,\\n amountToSwap,\\n fromReserve.liquidityIndex\\n);\\n// Notifies the receiver to proceed, sending as param the underlying already transferred\\nISwapAdapter(receiverAddress).executeOperation(\\n fromAsset,\\n toAsset,\\n amountToSwap,\\n address(this),\\n params\\n);\\n\\nvars.amountToReceive = IERC20(toAsset).balanceOf(receiverAddress);\\nif (vars.amountToReceive != 0) {\\n IERC20(toAsset).transferFrom(\\n receiverAddress,\\n address(vars.toReserveAToken),\\n vars.amountToReceive\\n );\\n\\n if (vars.toReserveAToken.balanceOf(msg.sender) == 0) {\\n \\_usersConfig[msg.sender].setUsingAsCollateral(toReserve.id, true);\\n }\\n\\n vars.toReserveAToken.mint(msg.sender, vars.amountToReceive, toReserve.liquidityIndex);\\n```\\n
VotingMachine - tryToMoveToValidating can lock up proposalsчhighчAfter a vote was received, the proposal can move to a validating state if any of the votes pass the proposal's `precReq` value, referred to as the minimum threshold.\\n```\\ntryToMoveToValidating(\\_proposalId);\\n```\\n\\nInside the method `tryToMoveToValidating` each of the vote options are checked to see if they pass `precReq`. In case that happens, the proposal goes into the next stage, specifically `Validating`.\\n```\\n/// @notice Function to move to Validating the proposal in the case the last vote action\\n/// was done before the required votingBlocksDuration passed\\n/// @param \\_proposalId The id of the proposal\\nfunction tryToMoveToValidating(uint256 \\_proposalId) public {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"VOTING\\_STATUS\\_REQUIRED\");\\n    if (\\_proposal.currentStatusInitBlock.add(\\_proposal.votingBlocksDuration) <= block.number) {\\n        for (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\\n            if (\\_proposal.votes[i] > \\_proposal.precReq) {\\n                internalMoveToValidating(\\_proposalId);\\n            }\\n        }\\n    }\\n}\\n```\\n\\nThe method `internalMoveToValidating` checks the proposal's status to be `Voting` and proceeds to moving the proposal into `Validating` state.\\n```\\n/// @notice Internal function to change proposalStatus from Voting to Validating\\n/// @param \\_proposalId The id of the proposal\\nfunction internalMoveToValidating(uint256 \\_proposalId) internal {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\\n    \\_proposal.proposalStatus = ProposalStatus.Validating;\\n    \\_proposal.currentStatusInitBlock = block.number;\\n    emit StatusChangeToValidating(\\_proposalId);\\n}\\n```\\n\\nThe problem appears if multiple vote options go past the minimum threshold. This is because the loop does not stop after the first found option and the loop will fail when the method `internalMoveToValidating` is called a second time.\\n```\\nfor (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\\n    if (\\_proposal.votes[i] > \\_proposal.precReq) {\\n        internalMoveToValidating(\\_proposalId);\\n    }\\n}\\n```\\n\\nThe method `internalMoveToValidating` fails the second time because the first time it is called, the proposal goes into the `Validating` state and the second time it is called, the require check fails.\\n```\\nrequire(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\\n\\_proposal.proposalStatus = ProposalStatus.Validating;\\n```\\n\\nThis can lead to proposal lock-ups if there are enough votes to at least one option that pass the minimum threshold.чAfter moving to the `Validating` state return successfully.\\n```\\nfunction tryToMoveToValidating(uint256 \\_proposalId) public {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"VOTING\\_STATUS\\_REQUIRED\");\\n    if (\\_proposal.currentStatusInitBlock.add(\\_proposal.votingBlocksDuration) <= block.number) {\\n        for (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\\n            if (\\_proposal.votes[i] > \\_proposal.precReq) {\\n                internalMoveToValidating(\\_proposalId);\\n                return; // <- this was added\\n            }\\n        }\\n    }\\n}\\n```\\n\\nAn additional change can be done to `internalMoveToValidating` because it is called only in `tryToMoveToValidating` and the parent method already does the check.\\n```\\n/// @notice Internal function to change proposalStatus from Voting to Validating\\n/// @param \\_proposalId The id of the proposal\\nfunction internalMoveToValidating(uint256 \\_proposalId) internal {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    // The line below can be removed\\n    // require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\\n    \\_proposal.proposalStatus = ProposalStatus.Validating;\\n    \\_proposal.currentStatusInitBlock = block.number;\\n    emit StatusChangeToValidating(\\_proposalId);\\n}\\n```\\nчч```\\ntryToMoveToValidating(\\_proposalId);\\n```\\n
VotingMachine - verifyNonce should only allow the next nonceчhighчWhen a relayer calls `submitVoteByRelayer` they also need to provide a nonce. This nonce is cryptographicly checked against the provided signature. It is also checked again to be higher than the previous nonce saved for that voter.\\n```\\n/// @notice Verifies the nonce of a voter on a proposal\\n/// @param \\_proposalId The id of the proposal\\n/// @param \\_voter The address of the voter\\n/// @param \\_relayerNonce The nonce submitted by the relayer\\nfunction verifyNonce(uint256 \\_proposalId, address \\_voter, uint256 \\_relayerNonce) public view {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    require(\\_proposal.voters[\\_voter].nonce < \\_relayerNonce, \"INVALID\\_NONCE\");\\n}\\n```\\n\\nWhen the vote is saved, the previous nonce is incremented.\\n```\\nvoter.nonce = voter.nonce.add(1);\\n```\\n\\nThis leaves the opportunity to use the same signature to vote multiple times, as long as the provided nonce is higher than the incremented nonce.чThe check should be more restrictive and make sure the consecutive nonce was provided.\\n```\\nrequire(\\_proposal.voters[\\_voter].nonce + 1 == \\_relayerNonce, \"INVALID\\_NONCE\");\\n```\\nчч```\\n/// @notice Verifies the nonce of a voter on a proposal\\n/// @param \\_proposalId The id of the proposal\\n/// @param \\_voter The address of the voter\\n/// @param \\_relayerNonce The nonce submitted by the relayer\\nfunction verifyNonce(uint256 \\_proposalId, address \\_voter, uint256 \\_relayerNonce) public view {\\n    Proposal storage \\_proposal = proposals[\\_proposalId];\\n    require(\\_proposal.voters[\\_voter].nonce < \\_relayerNonce, \"INVALID\\_NONCE\");\\n}\\n```\\n
VoteMachine - Cancelling vote does not increase the nonceчlowчA vote can be cancelled by calling `cancelVoteByRelayer` with the proposal ID, nonce, voter's address, signature and a hash of the sent params.\\nThe parameters are hashed and checked against the signature correctly.\\nThe nonce is part of these parameters and it is checked to be valid.\\n```\\nrequire(\\_proposal.voters[\\_voter].nonce < \\_relayerNonce, \"INVALID\\_NONCE\");\\n```\\n\\nOnce the vote is cancelled, the data is cleared but the nonce is not increased.\\n```\\nif (\\_cachedVoter.balance > 0) {\\n    \\_proposal.votes[\\_cachedVoter.vote] = \\_proposal.votes[\\_cachedVoter.vote].sub(\\_cachedVoter.balance.mul(\\_cachedVoter.weight));\\n    \\_proposal.totalVotes = \\_proposal.totalVotes.sub(1);\\n    voter.weight = 0;\\n    voter.balance = 0;\\n    voter.vote = 0;\\n    voter.asset = address(0);\\n    emit VoteCancelled(\\n        \\_proposalId,\\n        \\_voter,\\n        \\_cachedVoter.vote,\\n        \\_cachedVoter.asset,\\n        \\_cachedVoter.weight,\\n        \\_cachedVoter.balance,\\n        uint256(\\_proposal.proposalStatus)\\n    );\\n}\\n```\\n\\nThis means that in the future, the same signature can be used as long as the nonce is still higher than the current one.чConsidering the recommendation from issue https://github.com/ConsenSys/aave-governance-dao-audit-2020-01/issues/4 is implemented, the nonce should also increase when the vote is cancelled. Otherwise the same signature can be replayed again.чч```\\nrequire(\\_proposal.voters[\\_voter].nonce < \\_relayerNonce, \"INVALID\\_NONCE\");\\n```\\n
Possible lock ups with SafeMath multiplication  AcknowledgedчlowчIn some cases using SafeMath can lead to a situation where a contract is locked up due to an unavoidable overflow.\\nIt is theoretically possible that both the `internalSubmitVote()` and `internalCancelVote()` functions could become unusable by voters with a high enough balance, if the asset weighting is set extremely high.\\nThis line in `internalSubmitVote()` could overflow if the voter's balance and the asset weight were sufficiently high:\\n```\\nuint256 \\_votingPower = \\_voterAssetBalance.mul(\\_assetWeight);\\n```\\n\\nA similar situation occurs in internalCancelVote():\\n```\\n\\_proposal.votes[\\_cachedVoter.vote] = \\_proposal.votes[\\_cachedVoter.vote].sub(\\_cachedVoter.balance.mul(\\_cachedVoter.weight));\\n\\_proposal.totalVotes = \\_proposal.totalVotes.sub(1);\\n```\\nчThis could be protected against by setting a maximum value for asset weights. In practice it is very unlikely to occur in this situation, but it could be introduced at some point in the future.чч```\\nuint256 \\_votingPower = \\_voterAssetBalance.mul(\\_assetWeight);\\n```\\n
Reentrancy vulnerability in MetaSwap.swap()чhighч`MetaSwap.swap()` should have a reentrancy guard.\\nThe adapters use this general process:\\nCollect the from token (or ether) from the user.\\nExecute the trade.\\nTransfer the contract's balance of tokens (from and to) and ether to the user.\\nIf an attacker is able to reenter `swap()` before step 3, they can execute their own trade using the same tokens and get all the tokens for themselves.\\nThis is partially mitigated by the check against `amountTo` in `CommonAdapter`, but note that the `amountTo` typically allows for slippage, so it may still leave room for an attacker to siphon off some amount while still returning the required minimum to the user.\\n```\\n// Transfer remaining balance of tokenTo to sender\\nif (address(tokenTo) != Constants.ETH) {\\n    uint256 balance = tokenTo.balanceOf(address(this));\\n    require(balance >= amountTo, \"INSUFFICIENT\\_AMOUNT\");\\n    \\_transfer(tokenTo, balance, recipient);\\n} else {\\n```\\n\\nAs an example of how this could be exploited, 0x supports an “EIP1271Wallet” signature type, which invokes an external contract to check whether a trade is allowed. A malicious maker might front run the swap to reduce their inventory. This way, the taker is sending more of the taker asset than necessary to `MetaSwap`. The excess can be stolen by the maker during the EIP1271 call.чUse a simple reentrancy guard, such as OpenZeppelin's `ReentrancyGuard` to prevent reentrancy in `MetaSwap.swap()`. It might seem more obvious to put this check in `Spender.swap()`, but the `Spender` contract intentionally does not use any storage to avoid interference between different adapters.чч```\\n// Transfer remaining balance of tokenTo to sender\\nif (address(tokenTo) != Constants.ETH) {\\n    uint256 balance = tokenTo.balanceOf(address(this));\\n    require(balance >= amountTo, \"INSUFFICIENT\\_AMOUNT\");\\n    \\_transfer(tokenTo, balance, recipient);\\n} else {\\n```\\n
Simplify fee calculation in WethAdapterчlowч`WethAdapter` does some arithmetic to keep track of how much ether is being provided as a fee versus as funds that should be transferred into WETH:\\n```\\n// Some aggregators require ETH fees\\nuint256 fee = msg.value;\\n\\nif (address(tokenFrom) == Constants.ETH) {\\n    // If tokenFrom is ETH, msg.value = fee + amountFrom (total fee could be 0)\\n    require(amountFrom <= fee, \"MSG\\_VAL\\_INSUFFICIENT\");\\n    fee -= amountFrom;\\n    // Can't deal with ETH, convert to WETH\\n    IWETH weth = getWETH();\\n    weth.deposit{value: amountFrom}();\\n    \\_approveSpender(weth, spender, amountFrom);\\n} else {\\n    // Otherwise capture tokens from sender\\n    // tokenFrom.safeTransferFrom(recipient, address(this), amountFrom);\\n    \\_approveSpender(tokenFrom, spender, amountFrom);\\n}\\n\\n// Perform the swap\\naggregator.functionCallWithValue(abi.encodePacked(method, data), fee);\\n```\\n\\nThis code can be simplified by using `address(this).balance` instead.чResolution\\nConsenSys/[email protected]93bf5c6.\\nConsider something like the following code instead:\\n```\\nif (address(tokenFrom) == Constants.ETH) {\\n    getWETH().deposit{value: amountFrom}(); // will revert if the contract has an insufficient balance\\n    \\_approveSpender(weth, spender, amountFrom);\\n} else {\\n    tokenFrom.safeTransferFrom(recipient, address(this), amountFrom);\\n    \\_approveSpender(tokenFrom, spender, amountFrom);\\n}\\n\\n// Send the remaining balance as the fee.\\naggregator.functionCallWithValue(abi.encodePacked(method, data), address(this).balance);\\n```\\n\\nAside from being a little simpler, this way of writing the code makes it obvious that the full balance is being properly consumed. Part is traded, and the rest is sent as a fee.чч```\\n// Some aggregators require ETH fees\\nuint256 fee = msg.value;\\n\\nif (address(tokenFrom) == Constants.ETH) {\\n    // If tokenFrom is ETH, msg.value = fee + amountFrom (total fee could be 0)\\n    require(amountFrom <= fee, \"MSG\\_VAL\\_INSUFFICIENT\");\\n    fee -= amountFrom;\\n    // Can't deal with ETH, convert to WETH\\n    IWETH weth = getWETH();\\n    weth.deposit{value: amountFrom}();\\n    \\_approveSpender(weth, spender, amountFrom);\\n} else {\\n    // Otherwise capture tokens from sender\\n    // tokenFrom.safeTransferFrom(recipient, address(this), amountFrom);\\n    \\_approveSpender(tokenFrom, spender, amountFrom);\\n}\\n\\n// Perform the swap\\naggregator.functionCallWithValue(abi.encodePacked(method, data), fee);\\n```\\n
Consider checking adapter existence in MetaSwapчlowч`MetaSwap` doesn't check that an adapter exists before calling into Spender:\\n```\\nfunction swap(\\n    string calldata aggregatorId,\\n    IERC20 tokenFrom,\\n    uint256 amount,\\n    bytes calldata data\\n) external payable whenNotPaused nonReentrant {\\n    Adapter storage adapter = adapters[aggregatorId];\\n\\n    if (address(tokenFrom) != Constants.ETH) {\\n        tokenFrom.safeTransferFrom(msg.sender, address(spender), amount);\\n    }\\n\\n    spender.swap{value: msg.value}(\\n        adapter.addr,\\n```\\n\\nThen `Spender` performs the check and reverts if it receives `address(0)`.\\n```\\nfunction swap(address adapter, bytes calldata data) external payable {\\n    require(adapter != address(0), \"ADAPTER\\_NOT\\_SUPPORTED\");\\n```\\n\\nIt can be difficult to decide where to put a check like this, especially when the operation spans multiple contracts. Arguments can be made for either choice (or even duplicating the check), but as a general rule it's a good idea to avoid passing invalid parameters internally. Checking for adapter existence in `MetaSwap.swap()` is a natural place to do input validation, and it means `Spender` can have a simpler model where it trusts its inputs (which always come from MetaSwap).чDrop the check from `Spender.swap()` and perform the check instead in `MetaSwap.swap()`.чч```\\nfunction swap(\\n    string calldata aggregatorId,\\n    IERC20 tokenFrom,\\n    uint256 amount,\\n    bytes calldata data\\n) external payable whenNotPaused nonReentrant {\\n    Adapter storage adapter = adapters[aggregatorId];\\n\\n    if (address(tokenFrom) != Constants.ETH) {\\n        tokenFrom.safeTransferFrom(msg.sender, address(spender), amount);\\n    }\\n\\n    spender.swap{value: msg.value}(\\n        adapter.addr,\\n```\\n
Swap fees can be bypassed using redeemMassetчhighчPart of the value proposition for liquidity providers is earning fees incurred for swapping between assets. However, traders can perform fee-less swaps by providing liquidity in one bAsset, followed by calling `redeemMasset()` to convert the resulting mAssets back into a proportional amount of bAssets. Since removing liquidity via `redeemMasset()` does not incur a fee this is equivalent to doing a swap with zero fees.\\nAs a very simple example, assuming a pool with 2 bAssets (say, DAI and USDT), it would be possible to swap 10 DAI to USDT as follows:\\nAdd 20 DAI to the pool, receive 20 mUSD\\ncall redeemMasset() to redeem 10 DAI and 10 USDT\\nThe boolean argument `applyFee` is set to `false` in _redeemMasset:\\n```\\n\\_settleRedemption(\\_recipient, \\_mAssetQuantity, props.bAssets, bAssetQuantities, props.indexes, props.integrators, false);\\n```\\nчResolution\\nThis issue was reported independently via the bug bounty program and was fixed early during the audit. The fix has already been deployed on mainnet using the upgrade mechanism\\nCharge a small redemption fee in `redeemMasset()`.чч```\\n\\_settleRedemption(\\_recipient, \\_mAssetQuantity, props.bAssets, bAssetQuantities, props.indexes, props.integrators, false);\\n```\\n
Users can collect interest from SavingsContract by only staking mTokens momentarilyчhighчThe SAVE contract allows users to deposit mAssets in return for lending yield and swap fees. When depositing mAsset, users receive a “credit” tokens at the momentary credit/mAsset exchange rate which is updated at every deposit. However, the smart contract enforces a minimum timeframe of 30 minutes in which the interest rate will not be updated. A user who deposits shortly before the end of the timeframe will receive credits at the stale interest rate and can immediately trigger and update of the rate and withdraw at the updated (more favorable) rate after the 30 minutes window. As a result, it would be possible for users to benefit from interest payouts by only staking mAssets momentarily and using them for other purposes the rest of the time.\\n```\\n// 1. Only collect interest if it has been 30 mins\\nuint256 timeSinceLastCollection = now.sub(previousCollection);\\nif(timeSinceLastCollection > THIRTY\\_MINUTES) {\\n```\\nчRemove the 30 minutes window such that every deposit also updates the exchange rate between credits and tokens. Note that this issue was reported independently during the bug bounty program and a fix is currently being worked on.чч```\\n// 1. Only collect interest if it has been 30 mins\\nuint256 timeSinceLastCollection = now.sub(previousCollection);\\nif(timeSinceLastCollection > THIRTY\\_MINUTES) {\\n```\\n
Internal accounting of vault balance may diverge from actual token balance in lending pool  Won't FixчmediumчIt is possible that the vault balance for a given bAsset is greater than the corresponding balance in the lending pool. This violates one of the correctness properties stated in the audit brief. Our Harvey fuzzer was able to generate a transaction that mints a small amount (0xf500) of mAsset. Due to the way that the lending pool integration (Compound in this case) updates the vault balance it ends up greater than the available balance in the lending pool.\\nMore specifically, the integration contract assumes that the amount deposited into the pool is equal to the amount received by the mAsset contract for the case where no transaction fees are charged for token transfers:\\n```\\nquantityDeposited = \\_amount;\\n\\nif(\\_isTokenFeeCharged) {\\n    // If we charge a fee, account for it\\n    uint256 prevBal = \\_checkBalance(cToken);\\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\\n    uint256 newBal = \\_checkBalance(cToken);\\n    quantityDeposited = \\_min(quantityDeposited, newBal.sub(prevBal));\\n} else {\\n    // Else just execute the mint\\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\\n}\\n\\nemit Deposit(\\_bAsset, address(cToken), quantityDeposited);\\n```\\n\\nFor illustration, consider the following scenario: assume your current balance in a lending pool is 0. When you deposit some amount X into the lending pool your balance after the deposit may be less than X (even if the underlying token does not charge transfer fees). One reason for this is rounding, but, in theory, a lending pool could also charge fees, etc.\\nThe vault balance is updated in function `Masset._mintTo` based on the amount returned by the integration.\\n```\\nbasketManager.increaseVaultBalance(bInfo.index, integrator, quantityDeposited);\\n```\\n\\n```\\nuint256 deposited = IPlatformIntegration(\\_integrator).deposit(\\_bAsset, quantityTransferred, \\_erc20TransferFeeCharged);\\n```\\n\\nThis violation of the correctness property is temporary since the vault balance is readjusted when interest is collected. However, the time frame of ca. 30 minutes between interest collections (may be longer if no continuous interest is distributed) means that it may be violated for substantial periods of time.\\n```\\nuint256 balance = IPlatformIntegration(integrations[i]).checkBalance(b.addr);\\nuint256 oldVaultBalance = b.vaultBalance;\\n\\n// accumulate interest (ratioed bAsset)\\nif(balance > oldVaultBalance && b.status == BassetStatus.Normal) {\\n    // Update balance\\n    basket.bassets[i].vaultBalance = balance;\\n```\\n\\nThe regular updates due to interest collection should ensure that the difference stays relatively small. However, note that the following scenarios is feasible: assuming there is 0 DAI in the basket, a user mints X mUSD by depositing X DAI. While the interest collection hasn't been triggered yet, the user tries to redeem X mUSD for DAI. This may fail since the amount of DAI in the lending pool is smaller than X.чIt seems like this issue could be fixed by using the balance increase from the lending pool to update the vault balance (much like for the scenario where transfer fees are charged) instead of using the amount received.чч```\\nquantityDeposited = \\_amount;\\n\\nif(\\_isTokenFeeCharged) {\\n    // If we charge a fee, account for it\\n    uint256 prevBal = \\_checkBalance(cToken);\\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\\n    uint256 newBal = \\_checkBalance(cToken);\\n    quantityDeposited = \\_min(quantityDeposited, newBal.sub(prevBal));\\n} else {\\n    // Else just execute the mint\\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\\n}\\n\\nemit Deposit(\\_bAsset, address(cToken), quantityDeposited);\\n```\\n
Missing validation in Masset._redeemTo  AcknowledgedчmediumчIn function `_redeemTo` the collateralisation ratio is not taken into account unlike in _redeemMasset:\\n```\\nuint256 colRatio = StableMath.min(props.colRatio, StableMath.getFullScale());\\n\\n// Ensure payout is related to the collateralised mAsset quantity\\nuint256 collateralisedMassetQuantity = \\_mAssetQuantity.mulTruncate(colRatio);\\n```\\n\\nIt seems like `_redeemTo` should not be executed if the collateralisation ratio is below 100%. However, the contracts (that is, `Masset` and ForgeValidator) themselves don't seem to enforce this explicitly. Instead, the governor needs to ensure that the collateralisation ratio is only set to a value below 100% when the basket is not “healthy” (for instance, if it is considered “failed”). Failing to ensure this may allow an attacker to redeem a disproportionate amount of assets. Note that the functionality for setting the collateralisation ratio is not currently implemented in the audited code.чConsider enforcing the intended use of `_redeemTo` more explicitly. For instance, it might be possible to introduce additional input validation by requiring that the collateralisation ratio is not below 100%.чч```\\nuint256 colRatio = StableMath.min(props.colRatio, StableMath.getFullScale());\\n\\n// Ensure payout is related to the collateralised mAsset quantity\\nuint256 collateralisedMassetQuantity = \\_mAssetQuantity.mulTruncate(colRatio);\\n```\\n
Removing a bAsset might leave some tokens stuck in the vault  AcknowledgedчlowчIn function `_removeBasset` there is existing validation to make sure only “empty” vaults are removed:\\n```\\nrequire(bAsset.vaultBalance == 0, \"bAsset vault must be empty\");\\n```\\n\\nHowever, this is not necessarily sufficient since the lending pool balance may be higher than the vault balance. The reason is that the vault balance is usually slightly out-of-date due to the 30 minutes time span between interest collections. Consider the scenario: (1) a user swaps out an asset 29 minutes after the last interest collection to reduce its vault balance from 100 USD to 0, and (2) the governor subsequently remove the asset. During those 29 minutes the asset was collecting interest (according to the lending pool the balance was higher than 100 USD at the time of the swap) that is now “stuck” in the vault.чConsider adding additional input validation (for instance, by requiring that the lending pool balance to be 0) or triggering a swap directly when removing an asset from the basket.чч```\\nrequire(bAsset.vaultBalance == 0, \"bAsset vault must be empty\");\\n```\\n
Unused parameter in BasketManager._addBasset  Won't FixчlowчIt seems like the `_measurementMultiple` parameter is always `StableMath.getRatioScale()` (1e8). There is also some range validation code that seems unnecessary if the parameter is always 1e8.\\n```\\nrequire(\\_measurementMultiple >= 1e6 && \\_measurementMultiple <= 1e10, \"MM out of range\");\\n```\\nчConsider removing the parameter and the input validation to improve the readability of the code.чч```\\nrequire(\\_measurementMultiple >= 1e6 && \\_measurementMultiple <= 1e10, \"MM out of range\");\\n```\\n
Assumptions are made about interest distribution  Won't FixчlowчThere is a mechanism that prevents interest collection if the extrapolated APY exceeds a threshold (MAX_APY).\\n```\\nrequire(extrapolatedAPY < MAX\\_APY, \"Interest protected from inflating past maxAPY\");\\n```\\n\\nThe extrapolation seems to assume that the interest is payed out frequently and continuously. It seems like a less frequent payout (for instance, once a month/year) could be rejected since the extrapolation considers the interest since the last time that `collectAndDistributeInterest` was called (potentially without interest being collected).чConsider revisiting or documenting this assumption. For instance, one could consider extrapolating between the current time and the last time that (non-zero) interest was actually collected.чч```\\nrequire(extrapolatedAPY < MAX\\_APY, \"Interest protected from inflating past maxAPY\");\\n```\\n
Assumptions are made about Aave and Compound integrations  AcknowledgedчlowчThe code makes several assumptions about the Aave and Compound integrations. A malicious or malfunctioning integration (or lending pool) might violate those assumptions. This might lead to unintended behavior in the system. Below are three such assumptions:\\nfunction `checkBalance` reverts if the token hasn't been added:\\n```\\nIPlatformIntegration(\\_integration).checkBalance(\\_bAsset);\\n```\\n\\nfunction `withdraw` is trusted to not fail when it shouldn't:\\n```\\nIPlatformIntegration(\\_integrators[i]).withdraw(\\_recipient, bAsset, q, \\_bAssets[i].isTransferFeeCharged);\\n```\\n\\nthe mapping from mAssets to pTokens is fixed:\\n```\\nrequire(bAssetToPToken[\\_bAsset] == address(0), \"pToken already set\");\\n```\\n\\nThe first assumption could be avoided by adding a designated function to check if the token was added.\\nThe second assumption is more difficult to avoid, but should be considered when adding new integrations. The system needs to trust the lending pools to work properly; for instance, if the lending pool would blacklist the integration contract the system may behave in unintended ways.\\nThe third assumption could be avoided, but it comes at a cost.чConsider revisiting or avoiding these assumptions. For any assumptions that are there by design it would be good to document them to facilitate future changes. One should also be careful to avoid coupling between external systems. For instance, if withdrawing from Aave fails this should not prevent withdrawing from Compound.чч```\\nIPlatformIntegration(\\_integration).checkBalance(\\_bAsset);\\n```\\n
Assumptions are made about bAssets  AcknowledgedчlowчThe code makes several assumptions about the bAssets that can be used. A malicious or malfunctioning asset contract might violate those assumptions. This might lead to unintended behavior in the system. Below there are several such assumptions:\\nDecimals of a bAsset are constant where the decimals are used to derive the asset's ratio:\\n```\\nuint256 bAsset\\_decimals = CommonHelpers.getDecimals(\\_bAsset);\\n```\\n\\nDecimals must be in a range from 4 to 18:\\n```\\nrequire(decimals >= 4 && decimals <= 18, \"Token must have sufficient decimal places\");\\n```\\n\\nThe governor is able to foresee when transfer fees are charged (which needs to be called if anything changes); in theory, assets could be much more flexible in when transfer fees are charged (for instance, during certain periods or for certain users)\\n```\\nfunction setTransferFeesFlag(address \\_bAsset, bool \\_flag)\\n```\\n\\nIt seems like some of these assumptions could be avoided, but there might be a cost. For instance, one could retrieve the decimals directly instead of “caching” them and one could always enable the setting where transfer fees may be charged.чConsider revisiting or avoiding these assumptions. For any assumptions that are there by design it would be good to document them to facilitate future changes.чч```\\nuint256 bAsset\\_decimals = CommonHelpers.getDecimals(\\_bAsset);\\n```\\n
Unused field in ForgePropsMulti struct  Won't FixчlowчThe `ForgePropsMulti` struct defines the field `isValid` which always seems to be true:\\n```\\n/\\*\\* @dev All details needed to Forge with multiple bAssets \\*/\\nstruct ForgePropsMulti {\\n    bool isValid; // Flag to signify that forge bAssets have passed validity check\\n    Basset[] bAssets;\\n    address[] integrators;\\n    uint8[] indexes;\\n}\\n```\\n\\nIf it is indeed always true, one could remove the following line:\\n```\\nif(!props.isValid) return 0;\\n```\\nчIf the field is indeed always true please consider removing it to simplify the code.чч```\\n/\\*\\* @dev All details needed to Forge with multiple bAssets \\*/\\nstruct ForgePropsMulti {\\n    bool isValid; // Flag to signify that forge bAssets have passed validity check\\n    Basset[] bAssets;\\n    address[] integrators;\\n    uint8[] indexes;\\n}\\n```\\n
BassetStatus enum defines multiple unused states  Won't FixчlowчThe `BassetStatus` enum defines several values that do not seem to be assigned in the code:\\nDefault (different from “Normal”?)\\nBlacklisted\\nLiquidating\\nLiquidated\\nFailed\\n```\\n/\\*\\* @dev Status of the Basset - has it broken its peg? \\*/\\nenum BassetStatus {\\n    Default,\\n    Normal,\\n    BrokenBelowPeg,\\n    BrokenAbovePeg,\\n    Blacklisted,\\n    Liquidating,\\n    Liquidated,\\n    Failed\\n}\\n```\\n\\nSince some of these are used in the code there might be some dead code that can be removed as a result. For example:\\n```\\n\\_bAsset.status == BassetStatus.Liquidating ||\\n\\_bAsset.status == BassetStatus.Blacklisted\\n```\\nчIf those values are indeed never used please consider removing them to simplify the code.чч```\\n/\\*\\* @dev Status of the Basset - has it broken its peg? \\*/\\nenum BassetStatus {\\n    Default,\\n    Normal,\\n    BrokenBelowPeg,\\n    BrokenAbovePeg,\\n    Blacklisted,\\n    Liquidating,\\n    Liquidated,\\n    Failed\\n}\\n```\\n
Potential gas savings by terminating early  AcknowledgedчlowчIf a function invocation is bound to revert, one should try to revert as soon as possible to save gas. In `ForgeValidator.validateRedemption` it is possible to terminate more early:\\n```\\nif(atLeastOneBecameOverweight) return (false, \"bAssets must remain below max weight\", false);\\n```\\nчConsider moving the require-statement a few lines up (for instance, after assigning to atLeastOneBecameOverweight).чч```\\nif(atLeastOneBecameOverweight) return (false, \"bAssets must remain below max weight\", false);\\n```\\n
Discrepancy between code and commentsчlowчThere is a discrepancy between the code at:\\n```\\nrequire(weightSum >= 1e18 && weightSum <= 4e18, \"Basket weight must be >= 100 && <= 400%\");\\n```\\n\\nAnd the comment at:\\n```\\n\\* @dev Throws if the total Basket weight does not sum to 100\\n```\\nчUpdate the code or the comment to be consistent.чч```\\nrequire(weightSum >= 1e18 && weightSum <= 4e18, \"Basket weight must be >= 100 && <= 400%\");\\n```\\n
Loss of the liquidity pool is not equally distributedчhighчAll stakeholders in the liquidity pool should be able to withdraw the same amount as they staked plus a share of fees that the converter earned during their staking period.\\n```\\n        IPoolTokensContainer(anchor).burn(\\_poolToken, msg.sender, \\_amount);\\n\\n        // calculate how much liquidity to remove\\n        // if the entire supply is liquidated, the entire staked amount should be sent, otherwise\\n        // the price is based on the ratio between the pool token supply and the staked balance\\n        uint256 reserveAmount = 0;\\n        if (\\_amount == initialPoolSupply)\\n            reserveAmount = balance;\\n        else\\n            reserveAmount = \\_amount.mul(balance).div(initialPoolSupply);\\n\\n        // sync the reserve balance / staked balance\\n        reserves[reserveToken].balance = reserves[reserveToken].balance.sub(reserveAmount);\\n        uint256 newStakedBalance = stakedBalances[reserveToken].sub(reserveAmount);\\n        stakedBalances[reserveToken] = newStakedBalance;\\n```\\n\\nThe problem is that sometimes there might not be enough funds in reserve (for example, due to this issue https://github.com/ConsenSys/bancor-audit-2020-06/issues/4). So the first ones who withdraw their stakes receive all the tokens they own. But the last stakeholders might not be able to get their funds back because the pool is empty already.\\nSo under some circumstances, there is a chance that users can lose all of their staked funds.\\nThis issue also has the opposite side: if the liquidity pool makes an extra profit, the stakers do not owe this profit and cannot withdraw it.чResolution\\nThe issue was addressed by adding a new fee mechanism called ‘adjusted fees'. This mechanism aims to decrease the deficit of the reserves over time. If there is a deficit of reserves, it is usually present on the secondary token side, because there is a strong incentive to bring the primary token to the balanced state. Roughly speaking, the idea is that if the secondary token has a deficit in reserves, there are additional fees for trading that token. These fees are not distributed across the liquidity providers like the regular fees. Instead, they are just populating the reserve, decreasing the existing deficit.\\nLoss is still not distributed across the liquidity providers, and there is a possibility that there are not enough funds for everyone to withdraw them. In the case of a run on reserves, LPs will be able to withdraw funds on a first-come-first-serve basis.\\nDistribute losses evenly across the liquidity providers.чч```\\n        IPoolTokensContainer(anchor).burn(\\_poolToken, msg.sender, \\_amount);\\n\\n        // calculate how much liquidity to remove\\n        // if the entire supply is liquidated, the entire staked amount should be sent, otherwise\\n        // the price is based on the ratio between the pool token supply and the staked balance\\n        uint256 reserveAmount = 0;\\n        if (\\_amount == initialPoolSupply)\\n            reserveAmount = balance;\\n        else\\n            reserveAmount = \\_amount.mul(balance).div(initialPoolSupply);\\n\\n        // sync the reserve balance / staked balance\\n        reserves[reserveToken].balance = reserves[reserveToken].balance.sub(reserveAmount);\\n        uint256 newStakedBalance = stakedBalances[reserveToken].sub(reserveAmount);\\n        stakedBalances[reserveToken] = newStakedBalance;\\n```\\n
Use of external calls with a fixed amount of gas  Won't FixчmediumчThe converter smart contract uses the Solidity transfer() function to transfer Ether.\\n.transfer() and .send() forward exactly 2,300 gas to the recipient. The goal of this hardcoded gas stipend was to prevent reentrancy vulnerabilities, but this only makes sense under the assumption that gas costs are constant. Recently EIP 1884 was included in the Istanbul hard fork. One of the changes included in EIP 1884 is an increase to the gas cost of the SLOAD operation, causing a contract's fallback function to cost more than 2300 gas.\\n```\\n\\_to.transfer(address(this).balance);\\n```\\n\\n```\\nif (\\_targetToken == ETH\\_RESERVE\\_ADDRESS)\\n```\\n\\n```\\nmsg.sender.transfer(reserveAmount);\\n```\\nчResolution\\nIt was decided to accept this minor risk as the usage of .call() might introduce other unexpected behavior.\\nIt's recommended to stop using .transfer() and .send() and instead use .call(). Note that .call() does nothing to mitigate reentrancy attacks, so other precautions must be taken. To prevent reentrancy attacks, it is recommended that you use the checks-effects-interactions pattern.чч```\\n\\_to.transfer(address(this).balance);\\n```\\n
Use of assert statement for input validationчlowчSolidity assertion should only be used to assert invariants, i.e. statements that are expected to always hold if the code behaves correctly. Note that all available gas is consumed when an assert-style exception occurs.\\nIt appears that assert() is used in one location within the test scope to catch invalid user inputs:\\n```\\nassert(amount < targetReserveBalance);\\n```\\nчUsing `require()` instead of `assert()`.чч```\\nassert(amount < targetReserveBalance);\\n```\\n
Certain functions lack input validation routinesчhighчThe functions should first check if the passed arguments are valid first. The checks-effects-interactions pattern should be implemented throughout the code.\\nThese checks should include, but not be limited to:\\n`uint` should be larger than `0` when `0` is considered invalid\\n`uint` should be within constraints\\n`int` should be positive in some cases\\nlength of arrays should match if more arrays are sent as arguments\\naddresses should not be `0x0`\\nThe function `includeAsset` does not do any checks before changing the contract state.\\n```\\nfunction includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\\n}\\n```\\n\\nThe internal function called by the public method `includeAsset` again doesn't check any of the data.\\n```\\nfunction includeAsset (Shells.Shell storage shell, address \\_numeraire, address \\_numeraireAssim, address \\_reserve, address \\_reserveAssim, uint256 \\_weight) internal {\\n\\n    Assimilators.Assimilator storage \\_numeraireAssimilator = shell.assimilators[\\_numeraire];\\n\\n    \\_numeraireAssimilator.addr = \\_numeraireAssim;\\n\\n    \\_numeraireAssimilator.ix = uint8(shell.numeraires.length);\\n\\n    shell.numeraires.push(\\_numeraireAssimilator);\\n\\n    Assimilators.Assimilator storage \\_reserveAssimilator = shell.assimilators[\\_reserve];\\n\\n    \\_reserveAssimilator.addr = \\_reserveAssim;\\n\\n    \\_reserveAssimilator.ix = uint8(shell.reserves.length);\\n\\n    shell.reserves.push(\\_reserveAssimilator);\\n\\n    shell.weights.push(\\_weight.divu(1e18).add(uint256(1).divu(1e18)));\\n\\n}\\n```\\n\\nSimilar with `includeAssimilator`.\\n```\\nfunction includeAssimilator (address \\_numeraire, address \\_derivative, address \\_assimilator) public onlyOwner {\\n    shell.includeAssimilator(\\_numeraire, \\_derivative, \\_assimilator);\\n}\\n```\\n\\nAgain no checks are done in any function.\\n```\\nfunction includeAssimilator (Shells.Shell storage shell, address \\_numeraire, address \\_derivative, address \\_assimilator) internal {\\n\\n    Assimilators.Assimilator storage \\_numeraireAssim = shell.assimilators[\\_numeraire];\\n\\n    shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\\n    // shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix, 0, 0);\\n\\n}\\n```\\n\\nNot only does the administrator functions not have any checks, but also user facing functions do not check the arguments.\\nFor example `swapByOrigin` does not check any of the arguments if you consider it calls `MainnetDaiToDaiAssimilator`.\\n```\\nfunction swapByOrigin (address \\_o, address \\_t, uint256 \\_oAmt, uint256 \\_mTAmt, uint256 \\_dline) public notFrozen returns (uint256 tAmt\\_) {\\n\\n    return transferByOrigin(\\_o, \\_t, \\_dline, \\_mTAmt, \\_oAmt, msg.sender);\\n\\n}\\n```\\n\\nIt calls `transferByOrigin` and we simplify this example and consider we have `_o.ix == _t.ix`\\n```\\nfunction transferByOrigin (address \\_origin, address \\_target, uint256 \\_dline, uint256 \\_mTAmt, uint256 \\_oAmt, address \\_rcpnt) public notFrozen nonReentrant returns (uint256 tAmt\\_) {\\n\\n    Assimilators.Assimilator memory \\_o = shell.assimilators[\\_origin];\\n    Assimilators.Assimilator memory \\_t = shell.assimilators[\\_target];\\n\\n    // TODO: how to include min target amount\\n    if (\\_o.ix == \\_t.ix) return \\_t.addr.outputNumeraire(\\_rcpnt, \\_o.addr.intakeRaw(\\_oAmt));\\n```\\n\\nIn which case it can call 2 functions on an assimilatior such as `MainnetDaiToDaiAssimilator`.\\nThe first called function is `intakeRaw`.\\n```\\n// transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount\\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_, int128 balance\\_) {\\n\\n    dai.transferFrom(msg.sender, address(this), \\_amount);\\n\\n    amount\\_ = \\_amount.divu(1e18);\\n\\n}\\n```\\n\\nAnd its result is used in `outputNumeraire` that again does not have any checks.\\n```\\n// takes numeraire amount of dai, unwraps corresponding amount of cDai, transfers that out, returns numeraire amount\\nfunction outputNumeraire (address \\_dst, int128 \\_amount) public returns (uint256 amount\\_) {\\n\\n    amount\\_ = \\_amount.mulu(1e18);\\n\\n    dai.transfer(\\_dst, amount\\_);\\n\\n    return amount\\_;\\n\\n}\\n```\\nчResolution\\nComment from the development team:\\nNow all functions in the Orchestrator revert on incorrect arguments.\\nAll functions in Loihi in general revert on incorrect arguments.\\nImplement the `checks-effects-interactions` as a pattern to write code. Add tests that check if all of the arguments have been validated.\\nConsider checking arguments as an important part of writing code and developing the system.чч```\\nfunction includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\\n}\\n```\\n
Remove Loihi methods that can be used as backdoors by the administratorчhighчThere are several functions in `Loihi` that give extreme powers to the shell administrator. The most dangerous set of those is the ones granting the capability to add assimilators.\\nSince assimilators are essentially a proxy architecture to delegate code to several different implementations of the same interface, the administrator could, intentionally or unintentionally, deploy malicious or faulty code in the implementation of an assimilator. This means that the administrator is essentially totally trusted to not run code that, for example, drains the whole pool or locks up the users' and LPs' tokens.\\nIn addition to these, the function `safeApprove` allows the administrator to move any of the tokens the contract holds to any address regardless of the balances any of the users have.\\nThis can also be used by the owner as a backdoor to completely drain the contract.\\n```\\nfunction safeApprove(address \\_token, address \\_spender, uint256 \\_value) public onlyOwner {\\n\\n    (bool success, bytes memory returndata) = \\_token.call(abi.encodeWithSignature(\"approve(address,uint256)\", \\_spender, \\_value));\\n\\n    require(success, \"SafeERC20: low-level call failed\");\\n\\n}\\n```\\nчRemove the `safeApprove` function and, instead, use a trustless escape-hatch mechanism like the one suggested in issue 6.1.\\nFor the assimilator addition functions, our recommendation is that they are made completely internal, only callable in the constructor, at deploy time.\\nEven though this is not a big structural change (in fact, it reduces the attack surface), it is, indeed, a feature loss. However, this is the only way to make each shell a time-invariant system.\\nThis would not only increase Shell's security but also would greatly improve the trust the users have in the protocol since, after deployment, the code is now static and auditable.чч```\\nfunction safeApprove(address \\_token, address \\_spender, uint256 \\_value) public onlyOwner {\\n\\n    (bool success, bytes memory returndata) = \\_token.call(abi.encodeWithSignature(\"approve(address,uint256)\", \\_spender, \\_value));\\n\\n    require(success, \"SafeERC20: low-level call failed\");\\n\\n}\\n```\\n
Assimilators should implement an interfaceчhighчThe Assimilators are one of the core components within the application. They are used to move the tokens and can be thought of as a “middleware” between the Shell Protocol application and any other supported tokens.\\nThe methods attached to the assimilators are called throughout the application and they are a critical component of the whole system. Because of this fact, it is extremely important that they behave correctly.\\nA suggestion to restrict the possibility of errors when implementing them and when using them is to make all of the assimilators implement a unique specific interface. This way, any deviation would be immediately observed, right when the compilation happens.\\nConsider this example. The user calls `swapByOrigin`.\\n```\\nfunction swapByOrigin (address \\_o, address \\_t, uint256 \\_oAmt, uint256 \\_mTAmt, uint256 \\_dline) public notFrozen returns (uint256 tAmt\\_) {\\n\\n    return transferByOrigin(\\_o, \\_t, \\_dline, \\_mTAmt, \\_oAmt, msg.sender);\\n\\n}\\n```\\n\\nWhich calls `transferByOrigin`. In `transferByOrigin`, if the origin index matches the target index, a different execution branch is activated.\\n```\\nif (\\_o.ix == \\_t.ix) return \\_t.addr.outputNumeraire(\\_rcpnt, \\_o.addr.intakeRaw(\\_oAmt));\\n```\\n\\nIn this case we need the output of `_o.addr.intakeRaw(_oAmt)`.\\nIf we pick a random assimilator and check the implementation, we see the function `intakeRaw` needs to return the transferred amount.\\n```\\n// takes raw cdai amount, transfers it in, calculates corresponding numeraire amount and returns it\\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_) {\\n\\n    bool success = cdai.transferFrom(msg.sender, address(this), \\_amount);\\n\\n    if (!success) revert(\"CDai/transferFrom-failed\");\\n\\n    uint256 \\_rate = cdai.exchangeRateStored();\\n\\n    \\_amount = ( \\_amount \\* \\_rate ) / 1e18;\\n\\n    cdai.redeemUnderlying(\\_amount);\\n\\n    amount\\_ = \\_amount.divu(1e18);\\n\\n}\\n```\\n\\nHowever, with other implementations, the returns do not match. In the case of `MainnetDaiToDaiAssimilator`, it returns 2 values, which will make the `Loihi` contract work in this case but can misbehave in other cases, or even fail.\\n```\\n// transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount\\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_, int128 balance\\_) {\\n\\n    dai.transferFrom(msg.sender, address(this), \\_amount);\\n\\n    amount\\_ = \\_amount.divu(1e18);\\n\\n}\\n```\\n\\nMaking all the assimilators implement one unique interface will enforce the functions to look the same from the outside.чCreate a unique interface for the assimilators and make all the contracts implement that interface.чч```\\nfunction swapByOrigin (address \\_o, address \\_t, uint256 \\_oAmt, uint256 \\_mTAmt, uint256 \\_dline) public notFrozen returns (uint256 tAmt\\_) {\\n\\n    return transferByOrigin(\\_o, \\_t, \\_dline, \\_mTAmt, \\_oAmt, msg.sender);\\n\\n}\\n```\\n
Assimilators do not conform to the ERC20 specificationчmediumчThe assimilators in the codebase make heavy usage of both the `transfer` and `transferFrom` methods in the ERC20 standard.\\nQuoting the relevant parts of the specification of the standard:\\nTransfers _value amount of tokens to address _to, and MUST fire the Transfer event. The function SHOULD throw if the message caller's account balance does not have enough tokens to spend.\\nThe transferFrom method is used for a withdraw workflow, allowing contracts to transfer tokens on your behalf. This can be used for example to allow a contract to transfer tokens on your behalf and/or to charge fees in sub-currencies. The function SHOULD throw unless the _from account has deliberately authorized the sender of the message via some mechanism.\\nWe can see that, even though it is suggested that ERC20-compliant tokens do `throw` on the lack of authorization from the sender or lack of funds to complete the transfer, the standard does not enforce it.\\nThis means that, in order to make the system both more resilient and future-proof, code in each implementation of current and future assimilators should check for the return value of both `transfer` and `transferFrom` call instead of just relying on the external contract to revert execution.\\nThe extent of this issue is only mitigated by the fact that new assets are only added by the shell administrator and could, therefore, be audited prior to their addition.\\nNon-exhaustive Examples\\n```\\ndai.transferFrom(msg.sender, address(this), \\_amount);\\n```\\n\\n```\\ndai.transfer(\\_dst, \\_amount);\\n```\\nчAdd a check for the return boolean of the function.\\nExample:\\n`require(dai.transferFrom(msg.sender, address(this), _amount) == true);`чч```\\ndai.transferFrom(msg.sender, address(this), \\_amount);\\n```\\n
Access to assimilators does not check for existence and allows delegation to the zeroth addressчmediumчFor every method that allows to selectively withdraw, deposit, or swap tokens in `Loihi`, the user is allowed to specify addresses for the assimilators of said tokens (by inputting the addresses of the tokens themselves).\\nThe shell then performs a lookup on a mapping called `assimilators` inside its main structure and uses the result of that lookup to delegate call the assimilator deployed by the shell administrator.\\nHowever, there are no checks for prior instantiation of a specific, supported token, effectively meaning that we can do a lookup on an all-zeroed-out member of that mapping and delegate call execution to the zeroth address.\\nFor example, the 32 bytes expected as a result of this call:\\n```\\nfunction viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\\n\\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\\n\\n}\\n```\\n\\nThis is definitely an insufficient check since the interface for the assimilators might change in the future to include functions that have no return values.чCheck for the prior instantiation of assimilators by including the following requirement:\\n`require(shell.assimilators[<TOKEN_ADDRESS>].ix != 0);`\\nIn all the functions that access the `assimilators` mapping and change the indexes to be 1-based instead pf 0-based.чч```\\nfunction viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\\n\\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\\n\\n}\\n```\\n
Math library's fork has problematic changesчmediumчThe math library ABDK Libraries for Solidity was forked and modified to add a few `unsafe_*` functions.\\n`unsafe_add`\\n`unsafe_sub`\\n`unsafe_mul`\\n`unsafe_div`\\n`unsafe_abs`\\nThe problem which was introduced is that `unsafe_add` ironically is not really unsafe, it is as safe as the original `add` function. It is, in fact, identical to the safe `add` function.\\n```\\n/\\*\\*\\n \\* Calculate x + y. Revert on overflow.\\n \\*\\n \\* @param x signed 64.64-bit fixed point number\\n \\* @param y signed 64.64-bit fixed point number\\n \\* @return signed 64.64-bit fixed point number\\n \\*/\\nfunction add (int128 x, int128 y) internal pure returns (int128) {\\n  int256 result = int256(x) + y;\\n  require (result >= MIN\\_64x64 && result <= MAX\\_64x64);\\n  return int128 (result);\\n}\\n```\\n\\n```\\n/\\*\\*\\n \\* Calculate x + y. Revert on overflow.\\n \\*\\n \\* @param x signed 64.64-bit fixed point number\\n \\* @param y signed 64.64-bit fixed point number\\n \\* @return signed 64.64-bit fixed point number\\n \\*/\\nfunction unsafe\\_add (int128 x, int128 y) internal pure returns (int128) {\\n  int256 result = int256(x) + y;\\n  require (result >= MIN\\_64x64 && result <= MAX\\_64x64);\\n  return int128 (result);\\n}\\n```\\n\\nFortunately, `unsafe_add` is not used anywhere in the code.\\nHowever, `unsafe_abs` was changed from this:\\n```\\n/\\*\\*\\n \\* Calculate |x|. Revert on overflow.\\n \\*\\n \\* @param x signed 64.64-bit fixed point number\\n \\* @return signed 64.64-bit fixed point number\\n \\*/\\nfunction abs (int128 x) internal pure returns (int128) {\\n  require (x != MIN\\_64x64);\\n  return x < 0 ? -x : x;\\n}\\n```\\n\\nTo this:\\n```\\n/\\*\\*\\n \\* Calculate |x|. Revert on overflow.\\n \\*\\n \\* @param x signed 64.64-bit fixed point number\\n \\* @return signed 64.64-bit fixed point number\\n \\*/\\nfunction unsafe\\_abs (int128 x) internal pure returns (int128) {\\n  return x < 0 ? -x : x;\\n}\\n```\\n\\nThe check that was removed, is actually an important check:\\n```\\nrequire (x != MIN\\_64x64);\\n```\\n\\n```\\nint128 private constant MIN\\_64x64 = -0x80000000000000000000000000000000;\\n```\\n\\nThe problem is that for an `int128` variable that is equal to `-0x80000000000000000000000000000000`, there is no absolute value within the constraints of `int128`.\\nStarting from int128 `n` = `-0x80000000000000000000000000000000`, the absolute value should be int128 `abs_n` = -n, however `abs_n` is equal to the initial value of `n`. The final value of `abs_n` is still `-0x80000000000000000000000000000000`. It's still not a positive or zero value. The operation `0 - n` wraps back to the same initial value.чRemove unused `unsafe_*` functions and try to find other ways of doing unsafe math (if it is fundamentally important) without changing existing, trusted, already audited code.чч```\\n/\\*\\*\\n \\* Calculate x + y. Revert on overflow.\\n \\*\\n \\* @param x signed 64.64-bit fixed point number\\n \\* @param y signed 64.64-bit fixed point number\\n \\* @return signed 64.64-bit fixed point number\\n \\*/\\nfunction add (int128 x, int128 y) internal pure returns (int128) {\\n  int256 result = int256(x) + y;\\n  require (result >= MIN\\_64x64 && result <= MAX\\_64x64);\\n  return int128 (result);\\n}\\n```\\n
Use one file for each contract or libraryчmediumчThe repository contains a lot of contracts and libraries that are added in the same file as another contract or library.\\nOrganizing the code in this manner makes it hard to navigate, develop and audit. It is a best practice to have each contract or library in its own file. The file also needs to bear the name of the hosted contract or library.\\n```\\nlibrary SafeERC20Arithmetic {\\n```\\n\\n```\\nlibrary Shells {\\n```\\n\\n```\\ncontract ERC20Approve {\\n    function approve (address spender, uint256 amount) public returns (bool);\\n}\\n```\\n\\n```\\ncontract Loihi is LoihiRoot {\\n```\\n\\n```\\nlibrary Delegate {\\n```\\n\\n```\\nlibrary Assimilators {\\n```\\nчSplit up contracts and libraries in single files.чч```\\nlibrary SafeERC20Arithmetic {\\n```\\n
Remove debugging code from the repositoryчmediumчThroughout the repository, there is source code from the development stage that was used for debugging the functionality and was not removed.\\nThis should not be present in the source code and even if they are used while functionality is developed, they should be removed after the functionality was implemented.\\n```\\nevent log(bytes32);\\nevent log\\_int(bytes32, int256);\\nevent log\\_ints(bytes32, int256[]);\\nevent log\\_uint(bytes32, uint256);\\nevent log\\_uints(bytes32, uint256[]);\\n```\\n\\n```\\nevent log(bytes32);\\nevent log\\_uint(bytes32, uint256);\\nevent log\\_int(bytes32, int256);\\n```\\n\\n```\\nevent log(bytes32);\\nevent log\\_int(bytes32, int128);\\nevent log\\_int(bytes32, int);\\nevent log\\_uint(bytes32, uint);\\nevent log\\_addr(bytes32, address);\\n```\\n\\n```\\nevent log(bytes32);\\n```\\n\\n```\\nevent log(bytes32);\\nevent log\\_int(bytes32, int256);\\nevent log\\_ints(bytes32, int256[]);\\nevent log\\_uint(bytes32, uint256);\\nevent log\\_uints(bytes32, uint256[]);\\n```\\n\\n```\\nevent log\\_int(bytes32, int);\\nevent log\\_ints(bytes32, int128[]);\\nevent log\\_uint(bytes32, uint);\\nevent log\\_uints(bytes32, uint[]);\\nevent log\\_addrs(bytes32, address[]);\\n```\\n\\n```\\nevent log\\_uint(bytes32, uint256);\\nevent log\\_int(bytes32, int256);\\n```\\n\\n```\\nevent log\\_uint(bytes32, uint256);\\n```\\n\\n```\\nshell.testHalts = true;\\n```\\n\\n```\\nfunction setTestHalts (bool \\_testOrNotToTest) public {\\n\\n    shell.testHalts = \\_testOrNotToTest;\\n\\n}\\n```\\n\\n```\\nbool testHalts;\\n```\\nчRemove the debug functionality at the end of the development cycle of each functionality.чч```\\nevent log(bytes32);\\nevent log\\_int(bytes32, int256);\\nevent log\\_ints(bytes32, int256[]);\\nevent log\\_uint(bytes32, uint256);\\nevent log\\_uints(bytes32, uint256[]);\\n```\\n
Remove commented out code from the repositoryчmediumчHaving commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.\\nThere is no code that is important enough to be left commented out in a repository. Git branching should take care of having different code versions or diffs should show what was before.\\nIf there is commented out code, this also has to be maintained; it will be out of date if other parts of the system are changed, and the tests will not pick that up.\\nThe main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments.\\nCommented out code should be removed or dealt with in a separate branch that is later included in the master branch.\\n```\\nfunction viewRawAmount (address \\_assim, int128 \\_amt) internal returns (uint256 amount\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewRawAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewRawAmount.selector, \\_amt.abs()); // for development\\n\\n    amount\\_ = abi.decode(\\_assim.delegate(data), (uint256)); // for development\\n\\n}\\n```\\n\\n```\\nfunction viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\\n\\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\\n\\n}\\n```\\n\\n```\\nfunction viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\\n\\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\\n\\n}\\n```\\n\\n```\\nfunction includeAssimilator (Shells.Shell storage shell, address \\_numeraire, address \\_derivative, address \\_assimilator) internal {\\n\\n    Assimilators.Assimilator storage \\_numeraireAssim = shell.assimilators[\\_numeraire];\\n\\n    shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\\n    // shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix, 0, 0);\\n\\n}\\n```\\n\\n```\\nfunction transfer (address \\_recipient, uint256 \\_amount) public nonReentrant returns (bool) {\\n    // return shell.transfer(\\_recipient, \\_amount);\\n}\\n\\nfunction transferFrom (address \\_sender, address \\_recipient, uint256 \\_amount) public nonReentrant returns (bool) {\\n    // return shell.transferFrom(\\_sender, \\_recipient, \\_amount);\\n}\\n\\nfunction approve (address \\_spender, uint256 \\_amount) public nonReentrant returns (bool success\\_) {\\n    // return shell.approve(\\_spender, \\_amount);\\n}\\n\\nfunction increaseAllowance(address \\_spender, uint256 \\_addedValue) public returns (bool success\\_) {\\n    // return shell.increaseAllowance(\\_spender, \\_addedValue);\\n}\\n\\nfunction decreaseAllowance(address \\_spender, uint256 \\_subtractedValue) public returns (bool success\\_) {\\n    // return shell.decreaseAllowance(\\_spender, \\_subtractedValue);\\n}\\n\\nfunction balanceOf (address \\_account) public view returns (uint256) {\\n    // return shell.balances[\\_account];\\n}\\n```\\n\\n```\\n// function test\\_s1\\_selectiveDeposit\\_noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_NO\\_HACK () public logs\\_gas {\\n\\n// uint256 newShells = super.noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD();\\n\\n// assertEq(newShells, 32499999216641686631);\\n\\n// }\\n\\n// function test\\_s1\\_selectiveDeposit\\_noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK () public logs\\_gas {\\n\\n// uint256 newShells = super.noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK();\\n\\n// assertEq(newShells, 32499999216641686631);\\n\\n// }\\n```\\n\\n```\\n// function noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK () public returns (uint256 shellsMinted\\_) {\\n\\n// uint256 startingShells = l.proportionalDeposit(300e18);\\n\\n// uint256 gas = gasleft();\\n\\n// shellsMinted\\_ = l.depositHack(\\n// address(dai), 10e18,\\n// address(usdc), 10e6,\\n// address(usdt), 10e6,\\n// address(susd), 2.5e18\\n// );\\n\\n// emit log\\_uint(\"gas for deposit\", gas - gasleft());\\n\\n\\n// }\\n```\\nчRemove all the commented out code or transform it into comments.чч```\\nfunction viewRawAmount (address \\_assim, int128 \\_amt) internal returns (uint256 amount\\_) {\\n\\n    // amount\\_ = IAssimilator(\\_assim).viewRawAmount(\\_amt); // for production\\n\\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewRawAmount.selector, \\_amt.abs()); // for development\\n\\n    amount\\_ = abi.decode(\\_assim.delegate(data), (uint256)); // for development\\n\\n}\\n```\\n
Should check if the asset already exists when adding a new assetчmediumчThe public function `includeAsset`\\n```\\nfunction includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\\n}\\n```\\n\\nCalls the internal `includeAsset` implementation\\n```\\nfunction includeAsset (Shells.Shell storage shell, address \\_numeraire, address \\_numeraireAssim, address \\_reserve, address \\_reserveAssim, uint256 \\_weight) internal {\\n```\\n\\nBut there is no check to see if the asset already exists in the list. Because the check was not done, `shell.numeraires` can contain multiple identical instances.\\n```\\nshell.numeraires.push(\\_numeraireAssimilator);\\n```\\nчCheck if the `_numeraire` already exists before invoking `includeAsset`.чч```\\nfunction includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\\n}\\n```\\n
Check return values for both internal and external callsчlowчThere are some cases where functions which return values are called throughout the source code but the return values are not processed, nor checked.\\nThe returns should in principle be handled and checked for validity to provide more robustness to the code.\\nThe function `intakeNumeraire` receives a number of tokens and returns how many tokens were transferred to the contract.\\n```\\n// transfers numeraire amount of dai in, wraps it in cDai, returns raw amount\\nfunction intakeNumeraire (int128 \\_amount) public returns (uint256 amount\\_) {\\n\\n    // truncate stray decimals caused by conversion\\n    amount\\_ = \\_amount.mulu(1e18) / 1e3 \\* 1e3;\\n\\n    dai.transferFrom(msg.sender, address(this), amount\\_);\\n\\n}\\n```\\n\\nSimilarly, the function `outputNumeraire` receives a destination address and an amount of token for withdrawal and returns a number of transferred tokens to the specified address.\\n```\\n// takes numeraire amount of dai, unwraps corresponding amount of cDai, transfers that out, returns numeraire amount\\nfunction outputNumeraire (address \\_dst, int128 \\_amount) public returns (uint256 amount\\_) {\\n\\n    amount\\_ = \\_amount.mulu(1e18);\\n\\n    dai.transfer(\\_dst, amount\\_);\\n\\n    return amount\\_;\\n\\n}\\n```\\n\\nHowever, the results are not handled in the main contract.\\n```\\nshell.numeraires[i].addr.intakeNumeraire(\\_shells.mul(shell.weights[i]));\\n```\\n\\n```\\nshell.numeraires[i].addr.intakeNumeraire(\\_oBals[i].mul(\\_multiplier));\\n```\\n\\n```\\nshell.reserves[i].addr.outputNumeraire(msg.sender, \\_oBals[i].mul(\\_multiplier));\\n```\\n\\nA sanity check can be done to make sure that more than 0 tokens were transferred to the contract.\\n```\\nunit intakeAmount = shell.numeraires[i].addr.intakeNumeraire(\\_shells.mul(shell.weights[i]));\\nrequire(intakeAmount > 0, \"Must intake a positive number of tokens\");\\n```\\nчHandle all return values everywhere returns exist and add checks to make sure an expected value was returned.\\nIf the return values are never used, consider not returning them at all.чч```\\n// transfers numeraire amount of dai in, wraps it in cDai, returns raw amount\\nfunction intakeNumeraire (int128 \\_amount) public returns (uint256 amount\\_) {\\n\\n    // truncate stray decimals caused by conversion\\n    amount\\_ = \\_amount.mulu(1e18) / 1e3 \\* 1e3;\\n\\n    dai.transferFrom(msg.sender, address(this), amount\\_);\\n\\n}\\n```\\n
Interfaces do not need to be implemented for the compiler to access their selectors.чlowч```\\nIAssimilator constant iAsmltr = IAssimilator(address(0));\\n```\\n\\nThis pattern is unneeded since you can reference selectors by using the imported interface directly without any implementation. It hinders both gas costs and readability of the code.ч```\\nbytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\\n```\\n\\nuse the expression:\\n`IAssimilator.viewRawAmount.selector`чч```\\nIAssimilator constant iAsmltr = IAssimilator(address(0));\\n```\\n
Use consistent interfaces for functions in the same groupчlowчThis library has 2 functions.\\n`add` which receives 2 arguments, `x` and `y`.\\n```\\nfunction add(uint x, uint y) internal pure returns (uint z) {\\n    require((z = x + y) >= x, \"add-overflow\");\\n}\\n```\\n\\n`sub` which receives 3 arguments `x`, `y` and `_errorMessage`.\\n```\\nfunction sub(uint x, uint y, string memory \\_errorMessage) internal pure returns (uint z) {\\n    require((z = x - y) <= x, \\_errorMessage);\\n}\\n```\\n\\nIn order to reduce the cognitive load on the auditors and developers alike, somehow-related functions should have coherent logic and interfaces. Both of the functions either need to have 2 arguments, with an implied error message passed to `require`, or both functions need to have 3 arguments, with an error message that can be specified.чUpdate the functions to be coherent with other related functions.чч```\\nfunction add(uint x, uint y) internal pure returns (uint z) {\\n    require((z = x + y) >= x, \"add-overflow\");\\n}\\n```\\n
Consider emitting an event when changing the frozen state of the contractчlowчThe function `freeze` allows the owner to `freeze` and unfreeze the contract.\\n```\\nfunction freeze (bool \\_freeze) public onlyOwner {\\n    frozen = \\_freeze;\\n}\\n```\\n\\nThe common pattern when doing actions important for the outside of the blockchain is to emit an event when the action is successful.\\nIt's probably a good idea to emit an event stating the contract was frozen or unfrozen.чCreate an event that displays the current state of the contract.\\n```\\nevent Frozen(bool frozen);\\n```\\n\\nAnd emit the event when `frozen` is called.\\n```\\nfunction freeze (bool \\_freeze) public onlyOwner {\\n    frozen = \\_freeze;\\n    emit Frozen(\\_freeze);\\n}\\n```\\nчч```\\nfunction freeze (bool \\_freeze) public onlyOwner {\\n    frozen = \\_freeze;\\n}\\n```\\n
Function supportsInterface can be restricted to pureчlowчThe function `supportsInterface` returns a `bool` stating that the contract supports one of the defined interfaces.\\n```\\nfunction supportsInterface (bytes4 interfaceID) public returns (bool) {\\n    return interfaceID == ERC20ID || interfaceID == ERC165ID;\\n}\\n```\\n\\nThe function does not access or change the state of the contract, this is why it can be restricted to `pure`.чRestrict the function definition to `pure`.\\n```\\nfunction supportsInterface (bytes4 interfaceID) public pure returns (bool) {\\n```\\nчч```\\nfunction supportsInterface (bytes4 interfaceID) public returns (bool) {\\n    return interfaceID == ERC20ID || interfaceID == ERC165ID;\\n}\\n```\\n
Use more consistent function naming (includeAssimilator / excludeAdapter)чlowчThe function `includeAssimilator` adds a new assimilator to the list\\n```\\nshell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\\n```\\n\\nThe function `excludeAdapter` removes the specified assimilator from the list\\n```\\ndelete shell.assimilators[\\_assimilator];\\n```\\nчConsider renaming the function `excludeAdapter` to `removeAssimilator` and moving the logic of adding and removing in the same source file.чч```\\nshell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\\n```\\n
Eliminate assembly code by using ABI decodeчhighчThere are several locations where assembly code is used to access and decode byte arrays (including uses inside loops). Even though assembly code was used for gas optimization, it reduces the readability (and future updatability) of the code.\\n```\\nassembly {\\n    flag := mload(add(\\_data, 32))\\n}\\nif (flag == CHANGE\\_PARTITION\\_FLAG) {\\n    assembly {\\n        toPartition := mload(add(\\_data, 64))\\n```\\n\\n```\\nassembly {\\n    toPartition := mload(add(\\_data, 64))\\n```\\n\\n```\\nfor (uint256 i = 116; i <= \\_operatorData.length; i = i + 32) {\\n    bytes32 temp;\\n    assembly {\\n        temp := mload(add(\\_operatorData, i))\\n    }\\n    proof[index] = temp;\\n    index++;\\n}\\n```\\nчAs discussed in the mid-audit meeting, it is a good solution to use ABI decode since all uses of assembly simply access 32-byte chunks of data from user input. This should eliminate all assembly code and make the code significantly more clean. In addition, it might allow for more compact encoding in some cases (for instance, by eliminating or reducing the size of the flags).\\nThis suggestion can be also applied to Merkle Root verifications/calculation code, which can reduce the for loops and complexity of these functions.чч```\\nassembly {\\n    flag := mload(add(\\_data, 32))\\n}\\nif (flag == CHANGE\\_PARTITION\\_FLAG) {\\n    assembly {\\n        toPartition := mload(add(\\_data, 64))\\n```\\n
Ignored return value for transferFrom callчhighчWhen burning swap tokens the return value of the `transferFrom` call is ignored. Depending on the token's implementation this could allow an attacker to mint an arbitrary amount of Amp tokens.\\nNote that the severity of this issue could have been Critical if Flexa token was any arbitrarily tokens. We quickly verified that Flexa token implementation would revert if the amount exceeds the allowance, however it might not be the case for other token implementations.\\n```\\nswapToken.transferFrom(\\_from, swapTokenGraveyard, amount);\\n```\\nчThe code should be changed like this:\\n```\\nrequire(swapToken.transferFrom(_from, swapTokenGraveyard, amount));\\n```\\nчч```\\nswapToken.transferFrom(\\_from, swapTokenGraveyard, amount);\\n```\\n
Potentially insufficient validation for operator transfersчmediumчFor operator transfers, the current validation does not require the sender to be an operator (as long as the transferred value does not exceed the allowance):\\n```\\nrequire(\\n    \\_isOperatorForPartition(\\_partition, msg.sender, \\_from) ||\\n        (\\_value <= \\_allowedByPartition[\\_partition][\\_from][msg.sender]),\\n    EC\\_53\\_INSUFFICIENT\\_ALLOWANCE\\n);\\n```\\n\\nIt is unclear if this is the intention `or` whether the logical `or` should be a logical `and`.чResolution\\nremoving `operatorTransferByPartition` and simplifying the interfaces to only `tranferByPartition`\\nThis removes the existing tranferByPartition, converting operatorTransferByPartition to it. The reason for this is to make the client interface simpler, where there is one method to transfer by partition, and that method can be called by either a sender wanting to transfer from their own address, or an operator wanting to transfer from a different token holder address. We found that it was redundant to have multiple methods, and the client convenience wasn't worth the confusion.\\nConfirm that the code matches the intention. If so, consider documenting the behavior (for instance, by changing the name of function `operatorTransferByPartition`.чч```\\nrequire(\\n    \\_isOperatorForPartition(\\_partition, msg.sender, \\_from) ||\\n        (\\_value <= \\_allowedByPartition[\\_partition][\\_from][msg.sender]),\\n    EC\\_53\\_INSUFFICIENT\\_ALLOWANCE\\n);\\n```\\n
Potentially missing nonce check  AcknowledgedчmediumчWhen executing withdrawals in the collateral manager the per-address withdrawal nonce is simply updated without checking that the new nonce is one greater than the previous one (see Examples). It seems like without such a check it might be easy to make mistakes and causing issues with ordering of withdrawals.\\n```\\naddressToWithdrawalNonce[\\_partition][supplier] = withdrawalRootNonce;\\n```\\n\\n```\\naddressToWithdrawalNonce[\\_partition][supplier] = maxWithdrawalRootNonce;\\n```\\n\\n```\\nmaxWithdrawalRootNonce = \\_nonce;\\n```\\nчConsider adding more validation and sanity checks for nonces on per-address withdrawals.чч```\\naddressToWithdrawalNonce[\\_partition][supplier] = withdrawalRootNonce;\\n```\\n
Unbounded loop when validating Merkle proofsчmediumчIt seems like the loop for validating Merkle proofs is unbounded. If possible it would be good to have an upper bound to prevent DoS-like attacks. It seems like the depth of the tree, and thus, the length of the proof could be bounded.\\nThis could also simplify the decoding and make it more robust. For instance, in `_decodeWithdrawalOperatorData` it is unclear what happens if the data length is not a multiple of 32. It seems like it might result in out-of-bound reads.\\n```\\nuint256 proofNb = (\\_operatorData.length - 84) / 32;\\nbytes32[] memory proof = new bytes32[](proofNb);\\nuint256 index = 0;\\nfor (uint256 i = 116; i <= \\_operatorData.length; i = i + 32) {\\n    bytes32 temp;\\n    assembly {\\n        temp := mload(add(\\_operatorData, i))\\n    }\\n    proof[index] = temp;\\n    index++;\\n}\\n```\\nчConsider enforcing a bound on the length of Merkle proofs.\\nAlso note that if similar mitigation method as issue 5.1 is used, this method can be replaced by a simpler function using ABI Decode, which does not have any unbounded issues as the sizes of the hashes are fixed (or can be indicated in the passed objects)чч```\\nuint256 proofNb = (\\_operatorData.length - 84) / 32;\\nbytes32[] memory proof = new bytes32[](proofNb);\\nuint256 index = 0;\\nfor (uint256 i = 116; i <= \\_operatorData.length; i = i + 32) {\\n    bytes32 temp;\\n    assembly {\\n        temp := mload(add(\\_operatorData, i))\\n    }\\n    proof[index] = temp;\\n    index++;\\n}\\n```\\n
Mitigation for possible reentrancy in token transfersчmediumчERC777 adds significant features to the token implementation, however there are some known risks associated with this token, such as possible reentrancy attack vector. Given that the Amp token uses hooks to communicate to Collateral manager, it seems that the environment is trusted and safe. However, a minor modification to the implementation can result in safer implementation of the token transfer.\\n```\\nrequire(\\n    \\_balanceOfByPartition[\\_from][\\_fromPartition] >= \\_value,\\n    EC\\_52\\_INSUFFICIENT\\_BALANCE\\n);\\n\\nbytes32 toPartition = \\_fromPartition;\\nif (\\_data.length >= 64) {\\n    toPartition = \\_getDestinationPartition(\\_fromPartition, \\_data);\\n}\\n\\n\\_callPreTransferHooks(\\n    \\_fromPartition,\\n    \\_operator,\\n    \\_from,\\n    \\_to,\\n    \\_value,\\n    \\_data,\\n    \\_operatorData\\n);\\n\\n\\_removeTokenFromPartition(\\_from, \\_fromPartition, \\_value);\\n\\_transfer(\\_from, \\_to, \\_value);\\n\\_addTokenToPartition(\\_to, toPartition, \\_value);\\n\\n\\_callPostTransferHooks(\\n    toPartition,\\n```\\nчIt is suggested to move any condition check that is checking the balance to after the external call. However `_callPostTransferHooks` needs to be called after the state changes, so the suggested mitigation here is to move the require at line 1152 to after `_callPreTransferHooks()` function (e.g. line 1171).чч```\\nrequire(\\n    \\_balanceOfByPartition[\\_from][\\_fromPartition] >= \\_value,\\n    EC\\_52\\_INSUFFICIENT\\_BALANCE\\n);\\n\\nbytes32 toPartition = \\_fromPartition;\\nif (\\_data.length >= 64) {\\n    toPartition = \\_getDestinationPartition(\\_fromPartition, \\_data);\\n}\\n\\n\\_callPreTransferHooks(\\n    \\_fromPartition,\\n    \\_operator,\\n    \\_from,\\n    \\_to,\\n    \\_value,\\n    \\_data,\\n    \\_operatorData\\n);\\n\\n\\_removeTokenFromPartition(\\_from, \\_fromPartition, \\_value);\\n\\_transfer(\\_from, \\_to, \\_value);\\n\\_addTokenToPartition(\\_to, toPartition, \\_value);\\n\\n\\_callPostTransferHooks(\\n    toPartition,\\n```\\n
Potentially inconsistent input validationчmediumчThere are some functions that might require additional input validation (similar to other functions):\\nAmp.transferWithData: `require(_isOperator(msg.sender, _from), EC_58_INVALID_OPERATOR);` like in\\n```\\nrequire(\\_isOperator(msg.sender, \\_from), EC\\_58\\_INVALID\\_OPERATOR);\\n```\\n\\nAmp.authorizeOperatorByPartition: `require(_operator != msg.sender);` like in\\n```\\nrequire(\\_operator != msg.sender);\\n```\\n\\nAmp.revokeOperatorByPartition: `require(_operator != msg.sender);` like in\\n```\\nrequire(\\_operator != msg.sender);\\n```\\nчConsider adding additional input validation.чч```\\nrequire(\\_isOperator(msg.sender, \\_from), EC\\_58\\_INVALID\\_OPERATOR);\\n```\\n
ERC20 compatibility of Amp token using defaultPartitionчmediumчIt is somewhat unclear how the Amp token ensures ERC20 compatibility. While the `default` partition is used in some places (for instance, in function balanceOf) there are also separate fields for (aggregated) balances/allowances. This seems to introduce some redundancy and raises certain questions about when which fields are relevant.\\n`_allowed` is used in function `allowance` instead of `_allowedByPartition` with the default partition\\nAn `Approval` event should be emitted when approving the default partition\\n```\\nemit ApprovalByPartition(\\_partition, \\_tokenHolder, \\_spender, \\_amount);\\n```\\n\\n`increaseAllowance()` vs. `increaseAllowanceByPartition()`чAfter the mid-audit discussion, it was clear that the general `balanceOf` method (with no partition) is not needed and can be replaced with a `balanceOf` function that returns balance of the default partition, similarly for allowance, the general `increaseAllowance` function can simply call `increaseAllowanceByPartition` using default partition (same for decreaseAllowance).чч```\\nemit ApprovalByPartition(\\_partition, \\_tokenHolder, \\_spender, \\_amount);\\n```\\n
Additional validation for canReceiveчlowчFor `FlexaCollateralManager.tokensReceived` there is validation to ensure that only the Amp calls the function. In contrast, there is no such validation for `canReceive` and it is unclear if this is the intention.\\n```\\nrequire(msg.sender == amp, \"Invalid sender\");\\n```\\nчConsider adding a conjunct `msg.sender == amp` in function `_canReceive`.\\n```\\nfunction \\_canReceive(address \\_to, bytes32 \\_destinationPartition) internal view returns (bool) {\\n    return \\_to == address(this) && partitions[\\_destinationPartition];\\n}\\n```\\nчч```\\nrequire(msg.sender == amp, \"Invalid sender\");\\n```\\n
Discrepancy between code and commentsчlowчThere are some discrepancies between (uncommented) code and the documentations comment:\\n```\\n// Indicate token verifies Amp, ERC777 and ERC20 interfaces\\nERC1820Implementer.\\_setInterface(AMP\\_INTERFACE\\_NAME);\\nERC1820Implementer.\\_setInterface(ERC20\\_INTERFACE\\_NAME);\\n// ERC1820Implementer.\\_setInterface(ERC777\\_INTERFACE\\_NAME);\\n```\\n\\n```\\n/\\*\\*\\n \\* @notice Indicates a supply refund was executed\\n \\* @param supplier Address whose refund authorization was executed\\n \\* @param partition Partition from which the tokens were transferred\\n \\* @param amount Amount of tokens transferred\\n \\*/\\nevent SupplyRefund(\\n    address indexed supplier,\\n    bytes32 indexed partition,\\n    uint256 amount,\\n    uint256 indexed nonce\\n);\\n```\\nчConsider updating either the code or the comment.чч```\\n// Indicate token verifies Amp, ERC777 and ERC20 interfaces\\nERC1820Implementer.\\_setInterface(AMP\\_INTERFACE\\_NAME);\\nERC1820Implementer.\\_setInterface(ERC20\\_INTERFACE\\_NAME);\\n// ERC1820Implementer.\\_setInterface(ERC777\\_INTERFACE\\_NAME);\\n```\\n
Several fields could potentially be private  AcknowledgedчlowчSeveral fields in `Amp` could possibly be private:\\nswapToken:\\n```\\nISwapToken public swapToken;\\n```\\n\\nswapTokenGraveyard:\\n```\\naddress public constant swapTokenGraveyard = 0x000000000000000000000000000000000000dEaD;\\n```\\n\\ncollateralManagers:\\n```\\naddress[] public collateralManagers;\\n```\\n\\npartitionStrategies:\\n```\\nbytes4[] public partitionStrategies;\\n```\\n\\nThe same hold for several fields in `FlexaCollateralManager`. For instance:\\npartitions:\\n```\\nmapping(bytes32 => bool) public partitions;\\n```\\n\\nnonceToSupply:\\n```\\nmapping(uint256 => Supply) public nonceToSupply;\\n```\\n\\nwithdrawalRootToNonce:\\n```\\nmapping(bytes32 => uint256) public withdrawalRootToNonce;\\n```\\nчDouble-check that you really want to expose those fields.чч```\\nISwapToken public swapToken;\\n```\\n
Several fields could be declared immutable  AcknowledgedчlowчSeveral fields could be declared immutable to make clear that they never change after construction:\\nAmp._name:\\n```\\nstring internal \\_name;\\n```\\n\\nAmp._symbol:\\n```\\nstring internal \\_symbol;\\n```\\n\\nAmp.swapToken:\\n```\\nISwapToken public swapToken;\\n```\\n\\nFlexaCollateralManager.amp:\\n```\\naddress public amp;\\n```\\nчUse the `immutable` annotation in Solidity (see Immutable).чч```\\nstring internal \\_name;\\n```\\n
A reverting fallback function will lock up all payoutsчhighч```\\nfunction \\_transferETH(address \\_recipient, uint256 \\_amount) private {\\n    (bool success, ) = \\_recipient.call{value: \\_amount}(\\n        abi.encodeWithSignature(\"\")\\n    );\\n    require(success, \"Transfer Failed\");\\n}\\n```\\n\\nThe `_payment()` function processes a list of transfers to settle the transactions in an `ExchangeBox`. If any of the recipients of an Eth transfer is a smart contract that reverts, then the entire payout will fail and will be unrecoverable.чImplement a queuing mechanism to allow buyers/sellers to initiate the withdrawal on their own using a ‘pull-over-push pattern.'\\nIgnore a failed transfer and leave the responsibility up to users to receive them properly.чч```\\nfunction \\_transferETH(address \\_recipient, uint256 \\_amount) private {\\n    (bool success, ) = \\_recipient.call{value: \\_amount}(\\n        abi.encodeWithSignature(\"\")\\n    );\\n    require(success, \"Transfer Failed\");\\n}\\n```\\n
Force traders to mint gas tokenчhighчAttack scenario:\\nAlice makes a large trade via the Fairswap_iDOLvsEth exchange. This will tie up her iDOL until the box is executed.\\nMallory makes a small trades to buy ETH immediately afterwards, the trades are routed through an attack contract.\\nAlice needs to execute the box to get her iDOL out.\\nBecause the gas amount is unlimited, when you Mallory's ETH is paid out to her attack contract, mint a lot of GasToken.\\nIf Alice has $100 worth of ETH tied up in the exchange, you can basically ransom her for $99 of gas token or else she'll never see her funds again.\\n```\\nfunction \\_transferETH(address \\_recipient, uint256 \\_amount) private {\\n```\\nчWhen sending ETH, a pull-payment model is generally preferable.\\nThis would require setting up a queue, allowing users to call a function to initiate a withdrawal.чч```\\nfunction \\_transferETH(address \\_recipient, uint256 \\_amount) private {\\n```\\n
Missing Proper Access ControlчhighчSome functions do not have proper access control and are `public`, meaning that anyone can call them. This will result in system take over depending on how critical those functionalities are.\\n```\\n \\*/\\nfunction setIDOLContract(address contractAddress) public {\\n    require(address(\\_IDOLContract) == address(0), \"IDOL contract is already registered\");\\n    \\_setStableCoinContract(contractAddress);\\n}\\n```\\nчMake the `setIDOLContract()` function `internal` and call it from the constructor, or only allow the `deployer` to set the value.чч```\\n \\*/\\nfunction setIDOLContract(address contractAddress) public {\\n    require(address(\\_IDOLContract) == address(0), \"IDOL contract is already registered\");\\n    \\_setStableCoinContract(contractAddress);\\n}\\n```\\n
Code is not production-readyчhighчSimilar to other discussed issues, several areas of the code suggest that the system is not production-ready. This results in narrow test scenarios that do not cover production code flow.\\nisNotStartedAuction\\ninAcceptingBidsPeriod\\ninRevealingValuationPeriod\\ninReceivingBidsPeriod\\n```\\n/\\*\\n// Indicates any auction has never held for a specified BondID\\nfunction isNotStartedAuction(bytes32 auctionID) public virtual override returns (bool) {\\n uint256 closingTime = \\_auctionClosingTime[auctionID];\\n return closingTime == 0;\\n}\\n\\n// Indicates if the auctionID is in bid acceptance status\\nfunction inAcceptingBidsPeriod(bytes32 auctionID) public virtual override returns (bool) {\\n uint256 closingTime = \\_auctionClosingTime[auctionID];\\n```\\n\\n```\\n// TEST\\nfunction isNotStartedAuction(bytes32 auctionID)\\n    public\\n    virtual\\n    override\\n    returns (bool)\\n{\\n    return true;\\n}\\n\\n// TEST\\nfunction inAcceptingBidsPeriod(bytes32 auctionID)\\n```\\n\\nThese commented-out functions contain essential functionality for the Auction contract. For example, `inRevealingValuationPeriod` is used to allow revealing of the bid price publicly:\\n```\\nrequire(\\n    inRevealingValuationPeriod(auctionID),\\n    \"it is not the time to reveal the value of bids\"\\n);\\n```\\nчRemove the test functions and use the production code for testing. The tests must have full coverage of the production code to be considered complete.чч```\\n/\\*\\n// Indicates any auction has never held for a specified BondID\\nfunction isNotStartedAuction(bytes32 auctionID) public virtual override returns (bool) {\\n uint256 closingTime = \\_auctionClosingTime[auctionID];\\n return closingTime == 0;\\n}\\n\\n// Indicates if the auctionID is in bid acceptance status\\nfunction inAcceptingBidsPeriod(bytes32 auctionID) public virtual override returns (bool) {\\n uint256 closingTime = \\_auctionClosingTime[auctionID];\\n```\\n
Unreachable code due to checked conditionsчmediumч```\\nfunction revealBid(\\n    bytes32 auctionID,\\n    uint256 price,\\n    uint256 targetSBTAmount,\\n    uint256 random\\n) public override {\\n    require(\\n        inRevealingValuationPeriod(auctionID),\\n        \"it is not the time to reveal the value of bids\"\\n    );\\n```\\n\\nHowever, later in the same function, code exists to introduce “Penalties for revealing too early.” This checks to see if the function was called before closing, which should not be possible given the previous check.\\n```\\n/\\*\\*\\n \\* @dev Penalties for revealing too early.\\n \\* Some participants may not follow the rule and publicate their bid information before the reveal process.\\n \\* In such a case, the bid price is overwritten by the bid with the strike price (slightly unfavored price).\\n \\*/\\nuint256 bidPrice = price;\\n\\n/\\*\\*\\n \\* @dev FOR TEST CODE RUNNING: The following if statement in L533 should be replaced by the comment out\\n \\*/\\nif (inAcceptingBidsPeriod(auctionID)) {\\n    // if (false) {\\n    (, , uint256 solidStrikePriceE4, ) = \\_getBondFromAuctionID(auctionID);\\n    bidPrice = \\_exchangeSBT2IDOL(solidStrikePriceE4.mul(10\\*\\*18));\\n}\\n```\\nчResolution\\nComment from Lien Protocol:\\nDouble-check the logic in these functions. If revealing should be allowed (but penalized in the earlier stage), the first check should be changed. However, based on our understanding, the first check is correct, and the second check for early reveal is redundant and should be removed.чч```\\nfunction revealBid(\\n    bytes32 auctionID,\\n    uint256 price,\\n    uint256 targetSBTAmount,\\n    uint256 random\\n) public override {\\n    require(\\n        inRevealingValuationPeriod(auctionID),\\n        \"it is not the time to reveal the value of bids\"\\n    );\\n```\\n
Fairswap: inconsistent checks on _executionOrder()чlowчThe `_executionOrder()` function should only be called under specific conditions. However, these conditions are not always consistently defined.\\n```\\nif (nextBoxNumber > 1 && nextBoxNumber > nextExecuteBoxNumber) {\\n```\\n\\n```\\nif (nextBoxNumber > 1 && nextBoxNumber > nextExecuteBoxNumber) {\\n```\\n\\n```\\nif (nextBoxNumber > 1 && nextBoxNumber >= nextExecuteBoxNumber) {\\n```\\nчResolution\\nComment from Lien Protocol:\\nReduce duplicate code by defining an internal function to perform this check. A clear, descriptive name will help to clarify the intention.чч```\\nif (nextBoxNumber > 1 && nextBoxNumber > nextExecuteBoxNumber) {\\n```\\n
Inconsistency in DecimalSafeMath implementationsчlowчThere are two different implementations of `DecimalSafeMath` in the 3 FairSwap repositories.\\n```\\nlibrary DecimalSafeMath {\\n    function decimalDiv(uint256 a, uint256 b)internal pure returns (uint256) {\\n        // assert(b > 0); // Solidity automatically throws when dividing by 0\\n        uint256 a\\_ = a \\* 1000000000000000000;\\n        uint256 c = a\\_ / b;\\n        // assert(a == b \\* c + a % b); // There is no case in which this doesn't hold\\n        return c;\\n    }\\n```\\n\\n```\\nlibrary DecimalSafeMath {\\n\\n    function decimalDiv(uint256 a, uint256 b)internal pure returns (uint256) {\\n        // assert(b > 0); // Solidity automatically throws when dividing by 0\\n      \\n        uint256 c = (a \\* 1000000000000000000) / b;\\n        // assert(a == b \\* c + a % b); // There is no case in which this doesn't hold\\n        return c;\\n    }\\n```\\nчTry removing duplicate code/libraries and using a better inheritance model to include one file in all FairSwaps.чч```\\nlibrary DecimalSafeMath {\\n    function decimalDiv(uint256 a, uint256 b)internal pure returns (uint256) {\\n        // assert(b > 0); // Solidity automatically throws when dividing by 0\\n        uint256 a\\_ = a \\* 1000000000000000000;\\n        uint256 c = a\\_ / b;\\n        // assert(a == b \\* c + a % b); // There is no case in which this doesn't hold\\n        return c;\\n    }\\n```\\n
Exchange - CancelOrder has no effect  PendingчhighчThe exchange provides means for the `trader` or `broker` to cancel the order. The `cancelOrder` method, however, only stores the hash of the canceled order in mapping but the mapping is never checked. It is therefore effectively impossible for a `trader` to cancel an order.\\n```\\nfunction cancelOrder(LibOrder.Order memory order) public {\\n    require(msg.sender == order.trader || msg.sender == order.broker, \"invalid caller\");\\n\\n    bytes32 orderHash = order.getOrderHash();\\n    cancelled[orderHash] = true;\\n\\n    emit Cancel(orderHash);\\n}\\n```\\nч`matchOrders*` or `validateOrderParam` should check if `cancelled[orderHash] == true` and abort fulfilling the order.\\nVerify the order params (Signature) before accepting it as canceled.чч```\\nfunction cancelOrder(LibOrder.Order memory order) public {\\n    require(msg.sender == order.trader || msg.sender == order.broker, \"invalid caller\");\\n\\n    bytes32 orderHash = order.getOrderHash();\\n    cancelled[orderHash] = true;\\n\\n    emit Cancel(orderHash);\\n}\\n```\\n
Perpetual - withdraw should only be available in NORMAL state  PendingчhighчAccording to the specification `withdraw` can only be called in `NORMAL` state. However, the implementation allows it to be called in `NORMAL` and `SETTLED` mode.\\nWithdraw only checks for `!SETTLING` state which resolves to `NORMAL` and `SETTLED`.\\n```\\nfunction withdraw(uint256 amount) public {\\n    withdrawFromAccount(msg.sender, amount);\\n}\\n```\\n\\n```\\nfunction withdrawFromAccount(address payable guy, uint256 amount) private {\\n    require(guy != address(0), \"invalid guy\");\\n    require(status != LibTypes.Status.SETTLING, \"wrong perpetual status\");\\n\\n    uint256 currentMarkPrice = markPrice();\\n    require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe before withdraw\");\\n    remargin(guy, currentMarkPrice);\\n    address broker = currentBroker(guy);\\n    bool forced = broker == address(amm.perpetualProxy()) || broker == address(0);\\n    withdraw(guy, amount, forced);\\n\\n    require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe after withdraw\");\\n    require(availableMarginWithPrice(guy, currentMarkPrice) >= 0, \"withdraw margin\");\\n}\\n```\\n\\nIn contrast, `withdrawFor` requires the state to be NORMAL:\\n```\\nfunction withdrawFor(address payable guy, uint256 amount) public onlyWhitelisted {\\n    require(status == LibTypes.Status.NORMAL, \"wrong perpetual status\");\\n    withdrawFromAccount(guy, amount);\\n}\\n```\\nчResolution\\nThis issue was resolved by requiring `status == LibTypes.Status.NORMAL`.\\n`withdraw` should only be available in the `NORMAL` operation mode.чч```\\nfunction withdraw(uint256 amount) public {\\n    withdrawFromAccount(msg.sender, amount);\\n}\\n```\\n
Perpetual - withdrawFromInsuranceFund should check wadAmount instead of rawAmount  Pendingчhighч`withdrawFromInsurance` checks that enough funds are in the insurance fund before allowing withdrawal by an admin by checking the provided `rawAmount <= insuranceFundBalance.toUint256()`. `rawAmount` is the `ETH` (18 digit precision) or collateral token amount (can be less than 18 digit precision) to be withdrawn while `insuranceFundBalance` is a WAD-denominated value (18 digit precision).\\nThe check does not hold if the configured collateral has different precision and may have unwanted consequences, e.g. the withdrawal of more funds than expected.\\nNote: there is another check for `insuranceFundBalance` staying positive after the potential external call to collateral.\\n```\\nfunction withdrawFromInsuranceFund(uint256 rawAmount) public onlyWhitelistAdmin {\\n    require(rawAmount > 0, \"invalid amount\");\\n    require(insuranceFundBalance > 0, \"insufficient funds\");\\n    require(rawAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");\\n\\n    int256 wadAmount = toWad(rawAmount);\\n    insuranceFundBalance = insuranceFundBalance.sub(wadAmount);\\n    withdrawFromProtocol(msg.sender, rawAmount);\\n\\n    require(insuranceFundBalance >= 0, \"negtive insurance fund\");\\n\\n    emit UpdateInsuranceFund(insuranceFundBalance);\\n}\\n```\\n\\nWhen looking at the test-cases there seems to be a misconception about what unit of amount `withdrawFromInsuranceFund` is taking. For example, the insurance fund withdrawal and deposit are not tested for collateral that specifies a precision that is not 18. The test-cases falsely assume that the input to `withdrawFromInsuranceFund` is a WAD value, while it is taking the collateral's `rawAmount` which is then converted to a WAD number.\\ncode/test/test_perpetual.js:L471-L473\\n```\\nawait perpetual.withdrawFromInsuranceFund(toWad(10.111));\\nfund = await perpetual.insuranceFundBalance();\\nassert.equal(fund.toString(), 0);\\n```\\nчCheck that `require(wadAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");`, add a test-suite testing the insurance fund with collaterals with different precision and update existing tests that properly provide the expected input to `withdraFromInsurance`.чч```\\nfunction withdrawFromInsuranceFund(uint256 rawAmount) public onlyWhitelistAdmin {\\n    require(rawAmount > 0, \"invalid amount\");\\n    require(insuranceFundBalance > 0, \"insufficient funds\");\\n    require(rawAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");\\n\\n    int256 wadAmount = toWad(rawAmount);\\n    insuranceFundBalance = insuranceFundBalance.sub(wadAmount);\\n    withdrawFromProtocol(msg.sender, rawAmount);\\n\\n    require(insuranceFundBalance >= 0, \"negtive insurance fund\");\\n\\n    emit UpdateInsuranceFund(insuranceFundBalance);\\n}\\n```\\n
Perpetual - liquidateFrom should not have public visibility  Pendingчhighч`Perpetual.liquidate` is used to liquidate an account that is “unsafe,” determined by the relative sizes of `marginBalanceWithPrice` and maintenanceMarginWithPrice:\\n```\\n// safe for liquidation\\nfunction isSafeWithPrice(address guy, uint256 currentMarkPrice) public returns (bool) {\\n    return\\n        marginBalanceWithPrice(guy, currentMarkPrice) >=\\n        maintenanceMarginWithPrice(guy, currentMarkPrice).toInt256();\\n}\\n```\\n\\n`Perpetual.liquidate` allows the caller to assume the liquidated account's position, as well as a small amount of “penalty collateral.” The steps to liquidate are, roughly:\\nClose the liquidated account's position\\nPerform a trade on the liquidated assets with the liquidator acting as counter-party\\nGrant the liquidator a portion of the liquidated assets as a reward. An additional portion is added to the insurance fund.\\nHandle any losses\\nWe found several issues in Perpetual.liquidate:\\n`liquidateFrom` has `public` visibility:\\n```\\nfunction liquidateFrom(address from, address guy, uint256 maxAmount) public returns (uint256, uint256) {\\n```\\n\\nGiven that `liquidate` only calls `liquidateFrom` after checking the current contract's status, this oversight allows anyone to call `liquidateFrom` during the `SETTLED` stage:\\n```\\nfunction liquidate(address guy, uint256 maxAmount) public returns (uint256, uint256) {\\n    require(status != LibTypes.Status.SETTLED, \"wrong perpetual status\");\\n    return liquidateFrom(msg.sender, guy, maxAmount);\\n}\\n```\\n\\nAdditionally, directly calling `liquidateFrom` allows anyone to liquidate on behalf of other users, forcing other accounts to assume liquidated positions.\\nFinally, neither `liquidate` nor `liquidateFrom` check that the liquidated account and liquidator are the same. Though the liquidation accounting process is hard to follow, we believe this is unintended and could lead to large errors in internal contract accounting.чMake `liquidateFrom` an `internal` function\\nIn `liquidate` or `liquidateFrom`, check that `msg.sender != guy`чч```\\n// safe for liquidation\\nfunction isSafeWithPrice(address guy, uint256 currentMarkPrice) public returns (bool) {\\n    return\\n        marginBalanceWithPrice(guy, currentMarkPrice) >=\\n        maintenanceMarginWithPrice(guy, currentMarkPrice).toInt256();\\n}\\n```\\n
Unpredictable behavior due to front running or general bad timing  PendingчhighчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.\\nSome instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they're about to take.\\nThe deployer of the `PerpetualGovernance`, `AMMGovernance`, and `GlobalConfig` contracts are set as administrators for the contracts through `WhitelistedRole`. The `WhitelistedAdminRole` can whitelist other accounts at any time and allow them to perform actions protected by the `onlyWhitelisted` decorator.\\nUpdating governance and global configuration parameters are not protected by a time-lock and take effect immediately. This, therefore, creates an opportunity for administrators to front-run users on the exchange by changing parameters for orders. It may also allow an administrator to temporarily lift restrictions for themselves (e.g. withdrawalLockBlockCount).\\n`GlobalConfig`\\n`withdrawalLockBlockCount` is queried when applying for withdrawal. This value can be set zero enabling allowing immediate withdrawal.\\n`brokerLockBlockCount` is queried when setting a new broker. This value can e set to zero effectively enabling immediate broker changes.\\n```\\nfunction setGlobalParameter(bytes32 key, uint256 value) public onlyWhitelistAdmin {\\n    if (key == \"withdrawalLockBlockCount\") {\\n        withdrawalLockBlockCount = value;\\n    } else if (key == \"brokerLockBlockCount\") {\\n        brokerLockBlockCount = value;\\n    } else {\\n        revert(\"key not exists\");\\n    }\\n    emit UpdateGlobalParameter(key, value);\\n}\\n```\\n\\n`PerpetualGovernance`\\ne.g. Admin can front-run specific `matchOrder` calls and set arbitrary dev fees or curve parameters…\\n```\\nfunction setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {\\n    if (key == \"initialMarginRate\") {\\n        governance.initialMarginRate = value.toUint256();\\n        require(governance.initialMarginRate > 0, \"require im > 0\");\\n        require(governance.initialMarginRate < 10\\*\\*18, \"require im < 1\");\\n        require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");\\n    } else if (key == \"maintenanceMarginRate\") {\\n        governance.maintenanceMarginRate = value.toUint256();\\n        require(governance.maintenanceMarginRate > 0, \"require mm > 0\");\\n        require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");\\n        require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");\\n        require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");\\n    } else if (key == \"liquidationPenaltyRate\") {\\n        governance.liquidationPenaltyRate = value.toUint256();\\n        require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");\\n    } else if (key == \"penaltyFundRate\") {\\n        governance.penaltyFundRate = value.toUint256();\\n        require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");\\n    } else if (key == \"takerDevFeeRate\") {\\n        governance.takerDevFeeRate = value;\\n    } else if (key == \"makerDevFeeRate\") {\\n        governance.makerDevFeeRate = value;\\n    } else if (key == \"lotSize\") {\\n        require(\\n            governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,\\n            \"require tls % ls == 0\"\\n        );\\n        governance.lotSize = value.toUint256();\\n    } else if (key == \"tradingLotSize\") {\\n        require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");\\n        governance.tradingLotSize = value.toUint256();\\n    } else if (key == \"longSocialLossPerContracts\") {\\n        require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\\n        socialLossPerContracts[uint256(LibTypes.Side.LONG)] = value;\\n    } else if (key == \"shortSocialLossPerContracts\") {\\n        require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\\n        socialLossPerContracts[uint256(LibTypes.Side.SHORT)] = value;\\n    } else {\\n        revert(\"key not exists\");\\n    }\\n    emit UpdateGovernanceParameter(key, value);\\n}\\n```\\n\\nAdmin can set `devAddress` or even update to a new `amm` and `globalConfig`\\n```\\nfunction setGovernanceAddress(bytes32 key, address value) public onlyWhitelistAdmin {\\n    require(value != address(0x0), \"invalid address\");\\n    if (key == \"dev\") {\\n        devAddress = value;\\n    } else if (key == \"amm\") {\\n        amm = IAMM(value);\\n    } else if (key == \"globalConfig\") {\\n        globalConfig = IGlobalConfig(value);\\n    } else {\\n        revert(\"key not exists\");\\n    }\\n    emit UpdateGovernanceAddress(key, value);\\n}\\n```\\n\\n`AMMGovernance`\\n```\\nfunction setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {\\n    if (key == \"poolFeeRate\") {\\n        governance.poolFeeRate = value.toUint256();\\n    } else if (key == \"poolDevFeeRate\") {\\n        governance.poolDevFeeRate = value.toUint256();\\n    } else if (key == \"emaAlpha\") {\\n        require(value > 0, \"alpha should be > 0\");\\n        governance.emaAlpha = value;\\n        emaAlpha2 = 10\\*\\*18 - governance.emaAlpha;\\n        emaAlpha2Ln = emaAlpha2.wln();\\n    } else if (key == \"updatePremiumPrize\") {\\n        governance.updatePremiumPrize = value.toUint256();\\n    } else if (key == \"markPremiumLimit\") {\\n        governance.markPremiumLimit = value;\\n    } else if (key == \"fundingDampener\") {\\n        governance.fundingDampener = value;\\n    } else {\\n        revert(\"key not exists\");\\n    }\\n    emit UpdateGovernanceParameter(key, value);\\n}\\n```\\nчThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all updates to system parameters or upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.\\nAdditionally, users should verify the whitelist setup before using the contract system and monitor it for new additions to the whitelist. Documentation should clearly outline what roles are owned by whom to support suitability. Sane parameter bounds should be enforced (e.g. min. disallow block delay of zero )чч```\\nfunction setGlobalParameter(bytes32 key, uint256 value) public onlyWhitelistAdmin {\\n    if (key == \"withdrawalLockBlockCount\") {\\n        withdrawalLockBlockCount = value;\\n    } else if (key == \"brokerLockBlockCount\") {\\n        brokerLockBlockCount = value;\\n    } else {\\n        revert(\"key not exists\");\\n    }\\n    emit UpdateGlobalParameter(key, value);\\n}\\n```\\n
AMM - Governance is able to set an invalid alpha value  PendingчmediumчAccording to https://en.wikipedia.org/wiki/Moving_average\\nThe coefficient α represents the degree of weighting decrease, a constant smoothing factor between 0 and 1. A higher α discounts older observations faster.\\nHowever, the code does not check upper bounds. An admin may, therefore, set an invalid alpha that puts `emaAlpha2` out of bounds or negative.\\n```\\n} else if (key == \"emaAlpha\") {\\n    require(value > 0, \"alpha should be > 0\");\\n    governance.emaAlpha = value;\\n    emaAlpha2 = 10\\*\\*18 - governance.emaAlpha;\\n    emaAlpha2Ln = emaAlpha2.wln();\\n```\\nчEnsure that the system configuration is always within safe bounds. Document expected system variable types and their safe operating ranges. Enforce that bounds are checked every time a value is set. Enforce safe defaults when deploying contracts.\\nEnsure `emaAlpha` is `0 < value < 1 WAD`чч```\\n} else if (key == \"emaAlpha\") {\\n    require(value > 0, \"alpha should be > 0\");\\n    governance.emaAlpha = value;\\n    emaAlpha2 = 10\\*\\*18 - governance.emaAlpha;\\n    emaAlpha2Ln = emaAlpha2.wln();\\n```\\n
Exchange - insufficient input validation in matchOrders  Pendingчmediumч`matchOrders` does not check that that the sender has provided the same number of `amounts` as `makerOrderParams`. When fewer `amounts` exist than `makerOrderParams`, the method will revert because of an out-of-bounds array access. When fewer `makerOrderParams` exist than `amounts`, the method will succeed, and the additional values in `amounts` will be ignored.\\nAdditionally, the method allows the sender to provide no `makerOrderParams` at all, resulting in no state changes.\\n`matchOrders` also does not reject trades with an amount set to zero. Such orders should be rejected because they do not comply with the minimum `tradingLotSize` configured for the system. As a side-effect, events may be emitted for zero-amount trades and unexpected state changes may occur.\\n```\\nfunction matchOrders(\\n    LibOrder.OrderParam memory takerOrderParam,\\n    LibOrder.OrderParam[] memory makerOrderParams,\\n    address \\_perpetual,\\n    uint256[] memory amounts\\n) public {\\n```\\n\\n```\\nfunction matchOrderWithAMM(LibOrder.OrderParam memory takerOrderParam, address \\_perpetual, uint256 amount) public {\\n```\\nчResolution\\nThis issue was addressed by following the recommendation to verify that `amounts.length > 0 && makerOrderParams.length == amounts.length`. However, the code does not abort if one of the `amounts` is zero which should never happen and therefore raise an exception due to it likely being an erroneous call. Additionally, the method now enforces that only a broker can interact with the interface.\\nRequire `makerOrderParams.length > 0 && amounts.length == makerOrderParams.length`\\nRequire that `amount` or any of the `amounts[i]` provided to `matchOrders` is `>=tradingLotSize`.чч```\\nfunction matchOrders(\\n    LibOrder.OrderParam memory takerOrderParam,\\n    LibOrder.OrderParam[] memory makerOrderParams,\\n    address \\_perpetual,\\n    uint256[] memory amounts\\n) public {\\n```\\n
AMM - Liquidity provider may lose up to lotSize when removing liquidity  AcknowledgedчmediumчWhen removing liquidity, the amount of collateral received is calculated from the `shareAmount` (ShareToken) of the liquidity provider. The liquidity removal process registers a trade on the amount, with the liquidity provider and `AMM` taking opposite sides. Because trading only accepts multiple of the `lotSize`, the leftover is discarded. The amount discarded may be up to `lotSize - 1`.\\nThe expectation is that this value should not be too high, but as `lotSize` can be set to arbitrary values by an admin, it is possible that this step discards significant value. Additionally, see issue 6.6 for how this can be exploited by an admin.\\nNote that similar behavior is present in `Perpetual.liquidateFrom`, where the `liquidatableAmount` calculated undergoes a similar modulo operation:\\n```\\nuint256 liquidatableAmount = totalPositionSize.sub(totalPositionSize.mod(governance.lotSize));\\nliquidationAmount = liquidationAmount.ceil(governance.lotSize).min(maxAmount).min(liquidatableAmount);\\n```\\n\\n`lotSize` can arbitrarily be set up to `pos_int256_max` as long as `tradingLotSize % `lotSize` == 0`\\n```\\n} else if (key == \"lotSize\") {\\n    require(\\n        governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,\\n        \"require tls % ls == 0\"\\n    );\\n    governance.lotSize = value.toUint256();\\n} else if (key == \"tradingLotSize\") {\\n    require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");\\n    governance.tradingLotSize = value.toUint256();\\n```\\n\\n`amount` is derived from `shareAmount` rounded down to the next multiple of the `lotSize`. The leftover is discarded.\\n```\\nuint256 amount = shareAmount.wmul(oldPoolPositionSize).wdiv(shareToken.totalSupply());\\namount = amount.sub(amount.mod(perpetualProxy.lotSize()));\\n\\nperpetualProxy.transferBalanceOut(trader, price.wmul(amount).mul(2));\\nburnShareTokenFrom(trader, shareAmount);\\nuint256 opened = perpetualProxy.trade(trader, LibTypes.Side.LONG, price, amount);\\n```\\nчEnsure that documentation makes users aware of the fact that they may lose up to `lotsize-1` in value.\\nAlternatively, track accrued value and permit trades on values that exceed `lotSize`. Note that this may add significant complexity.\\nEnsure that similar system behavior, like the `liquidatableAmount` calculated in `Perpetual.liquidateFrom`, is also documented and communicated clearly to users.чч```\\nuint256 liquidatableAmount = totalPositionSize.sub(totalPositionSize.mod(governance.lotSize));\\nliquidationAmount = liquidationAmount.ceil(governance.lotSize).min(maxAmount).min(liquidatableAmount);\\n```\\n
Oracle - Unchecked oracle response timestamp and integer over/underflowчmediumчThe external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations of the AMM. Oracle reliance has historically resulted in crippled on-chain systems, and complications that lead to these outcomes can arise from things as simple as network congestion.\\nEnsuring that unexpected oracle return values are properly handled will reduce reliance on off-chain components and increase the resiliency of the smart contract system that depends on them.\\nThe `ChainlinkAdapter` and `InversedChainlinkAdapter` take the oracle's (int256) `latestAnswer` and convert the result using `chainlinkDecimalsAdapter`. This arithmetic operation can underflow/overflow if the Oracle provides a large enough answer:\\n```\\nint256 public constant chainlinkDecimalsAdapter = 10\\*\\*10;\\n\\nconstructor(address \\_feeder) public {\\n    feeder = IChainlinkFeeder(\\_feeder);\\n}\\n\\nfunction price() public view returns (uint256 newPrice, uint256 timestamp) {\\n    newPrice = (feeder.latestAnswer() \\* chainlinkDecimalsAdapter).toUint256();\\n    timestamp = feeder.latestTimestamp();\\n}\\n```\\n\\n```\\nint256 public constant chainlinkDecimalsAdapter = 10\\*\\*10;\\n\\nconstructor(address \\_feeder) public {\\n    feeder = IChainlinkFeeder(\\_feeder);\\n}\\n\\nfunction price() public view returns (uint256 newPrice, uint256 timestamp) {\\n    newPrice = ONE.wdiv(feeder.latestAnswer() \\* chainlinkDecimalsAdapter).toUint256();\\n    timestamp = feeder.latestTimestamp();\\n}\\n```\\n\\nThe oracle provides a timestamp for the `latestAnswer` that is not validated and may lead to old oracle timestamps being accepted (e.g. caused by congestion on the blockchain or a directed censorship attack).\\n```\\n    timestamp = feeder.latestTimestamp();\\n}\\n```\\nчUse `SafeMath` for mathematical computations\\nVerify `latestAnswer` is within valid bounds (!=0)\\nVerify `latestTimestamp` is within accepted bounds (not in the future, was updated within a reasonable amount of time)\\nDeduplicate code by combining both Adapters into one as the only difference is that the `InversedChainlinkAdapter` returns `ONE.wdiv(price)`.чч```\\nint256 public constant chainlinkDecimalsAdapter = 10\\*\\*10;\\n\\nconstructor(address \\_feeder) public {\\n    feeder = IChainlinkFeeder(\\_feeder);\\n}\\n\\nfunction price() public view returns (uint256 newPrice, uint256 timestamp) {\\n    newPrice = (feeder.latestAnswer() \\* chainlinkDecimalsAdapter).toUint256();\\n    timestamp = feeder.latestTimestamp();\\n}\\n```\\n
Perpetual - Administrators can put the system into emergency mode indefinitely  PendingчmediumчThere is no limitation on how long an administrator can put the `Perpetual` contract into emergency mode. Users cannot trade or withdraw funds in emergency mode and are effectively locked out until the admin chooses to put the contract in `SETTLED` mode.\\n```\\nfunction beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {\\n    require(status != LibTypes.Status.SETTLED, \"already settled\");\\n    settlementPrice = price;\\n    status = LibTypes.Status.SETTLING;\\n    emit BeginGlobalSettlement(price);\\n}\\n```\\n\\n```\\nfunction endGlobalSettlement() public onlyWhitelistAdmin {\\n    require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\\n\\n    address guy = address(amm.perpetualProxy());\\n    settleFor(guy);\\n    status = LibTypes.Status.SETTLED;\\n\\n    emit EndGlobalSettlement();\\n}\\n```\\nчResolution\\nThe client provided the following statement addressing the issue:\\nIt should be solved by voting. Moreover, we add two roles who is able to disable withdrawing /pause the system.\\nThe duration of the emergency phase is still unrestricted.\\nSet a time-lock when entering emergency mode that allows anyone to set the system to `SETTLED` after a fixed amount of time.чч```\\nfunction beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {\\n    require(status != LibTypes.Status.SETTLED, \"already settled\");\\n    settlementPrice = price;\\n    status = LibTypes.Status.SETTLING;\\n    emit BeginGlobalSettlement(price);\\n}\\n```\\n
Signed data may be usable cross-chainчmediumчSigned order data may be re-usable cross-chain as the chain-id is not explicitly part of the signed data.\\nIt is also recommended to further harden the signature verification and validate that `v` and `s` are within expected bounds. `ecrecover()` returns `0x0` to indicate an error condition, therefore, a `signerAddress` or `recovered` address of `0x0` should explicitly be disallowed.\\nThe signed order data currently includes the EIP712 Domain Name `Mai Protocol` and the following information:\\n```\\nstruct Order {\\n    address trader;\\n    address broker;\\n    address perpetual;\\n    uint256 amount;\\n    uint256 price;\\n    /\\*\\*\\n \\* Data contains the following values packed into 32 bytes\\n \\* ╔════════════════════╤═══════════════════════════════════════════════════════════╗\\n \\* ║ │ length(bytes) desc ║\\n \\* ╟────────────────────┼───────────────────────────────────────────────────────────╢\\n \\* ║ version │ 1 order version ║\\n \\* ║ side │ 1 0: buy (long), 1: sell (short) ║\\n \\* ║ isMarketOrder │ 1 0: limitOrder, 1: marketOrder ║\\n \\* ║ expiredAt │ 5 order expiration time in seconds ║\\n \\* ║ asMakerFeeRate │ 2 maker fee rate (base 100,000) ║\\n \\* ║ asTakerFeeRate │ 2 taker fee rate (base 100,000) ║\\n \\* ║ (d) makerRebateRate│ 2 rebate rate for maker (base 100) ║\\n \\* ║ salt │ 8 salt ║\\n \\* ║ isMakerOnly │ 1 is maker only ║\\n \\* ║ isInversed │ 1 is inversed contract ║\\n \\* ║ │ 8 reserved ║\\n \\* ╚════════════════════╧═══════════════════════════════════════════════════════════╝\\n \\*/\\n    bytes32 data;\\n}\\n```\\n\\nSignature verification:\\n```\\nfunction isValidSignature(OrderSignature memory signature, bytes32 hash, address signerAddress)\\n    internal\\n    pure\\n    returns (bool)\\n{\\n    uint8 method = uint8(signature.config[1]);\\n    address recovered;\\n    uint8 v = uint8(signature.config[0]);\\n\\n    if (method == uint8(SignatureMethod.ETH\\_SIGN)) {\\n        recovered = ecrecover(\\n            keccak256(abi.encodePacked(\"\\x19Ethereum Signed Message:\\n32\", hash)),\\n            v,\\n            signature.r,\\n            signature.s\\n        );\\n    } else if (method == uint8(SignatureMethod.EIP712)) {\\n        recovered = ecrecover(hash, v, signature.r, signature.s);\\n    } else {\\n        revert(\"invalid sign method\");\\n    }\\n\\n    return signerAddress == recovered;\\n}\\n```\\nчInclude the `chain-id` in the signature to avoid cross-chain validity of signatures\\nverify `s` is within valid bounds to avoid signature malleability\\n```\\nif (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {\\n      revert(\"ECDSA: invalid signature 's' value\");\\n }\\n```\\n\\nverify `v` is within valid bounds\\n```\\nif (v != 27 && v != 28) {\\n     revert(\"ECDSA: invalid signature 'v' value\");\\n}\\n```\\n\\nreturn invalid if the result of `ecrecover()` is `0x0`чч```\\nstruct Order {\\n    address trader;\\n    address broker;\\n    address perpetual;\\n    uint256 amount;\\n    uint256 price;\\n    /\\*\\*\\n \\* Data contains the following values packed into 32 bytes\\n \\* ╔════════════════════╤═══════════════════════════════════════════════════════════╗\\n \\* ║ │ length(bytes) desc ║\\n \\* ╟────────────────────┼───────────────────────────────────────────────────────────╢\\n \\* ║ version │ 1 order version ║\\n \\* ║ side │ 1 0: buy (long), 1: sell (short) ║\\n \\* ║ isMarketOrder │ 1 0: limitOrder, 1: marketOrder ║\\n \\* ║ expiredAt │ 5 order expiration time in seconds ║\\n \\* ║ asMakerFeeRate │ 2 maker fee rate (base 100,000) ║\\n \\* ║ asTakerFeeRate │ 2 taker fee rate (base 100,000) ║\\n \\* ║ (d) makerRebateRate│ 2 rebate rate for maker (base 100) ║\\n \\* ║ salt │ 8 salt ║\\n \\* ║ isMakerOnly │ 1 is maker only ║\\n \\* ║ isInversed │ 1 is inversed contract ║\\n \\* ║ │ 8 reserved ║\\n \\* ╚════════════════════╧═══════════════════════════════════════════════════════════╝\\n \\*/\\n    bytes32 data;\\n}\\n```\\n
Exchange - validateOrderParam does not check against SUPPORTED_ORDER_VERSIONчmediumч`validateOrderParam` verifies the signature and version of a provided order. Instead of checking against the contract constant `SUPPORTED_ORDER_VERSION` it, however, checks against a hardcoded version `2` in the method itself.\\nThis might be a problem if `SUPPORTED_ORDER_VERSION` is seen as the configuration parameter for the allowed version. Changing it would not change the allowed order version for `validateOrderParam` as this constant literal is never used.\\nAt the time of this audit, however, the `SUPPORTED_ORDER_VERSION` value equals the hardcoded value in the `validateOrderParam` method.\\n```\\nfunction validateOrderParam(IPerpetual perpetual, LibOrder.OrderParam memory orderParam)\\n    internal\\n    view\\n    returns (bytes32)\\n{\\n    address broker = perpetual.currentBroker(orderParam.trader);\\n    require(broker == msg.sender, \"invalid broker\");\\n    require(orderParam.getOrderVersion() == 2, \"unsupported version\");\\n    require(orderParam.getExpiredAt() >= block.timestamp, \"order expired\");\\n\\n    bytes32 orderHash = orderParam.getOrderHash(address(perpetual), broker);\\n    require(orderParam.signature.isValidSignature(orderHash, orderParam.trader), \"invalid signature\");\\n    require(filled[orderHash] < orderParam.amount, \"fullfilled order\");\\n\\n    return orderHash;\\n}\\n```\\nчCheck against `SUPPORTED_ORDER_VERSION` instead of the hardcoded value `2`.чч```\\nfunction validateOrderParam(IPerpetual perpetual, LibOrder.OrderParam memory orderParam)\\n    internal\\n    view\\n    returns (bytes32)\\n{\\n    address broker = perpetual.currentBroker(orderParam.trader);\\n    require(broker == msg.sender, \"invalid broker\");\\n    require(orderParam.getOrderVersion() == 2, \"unsupported version\");\\n    require(orderParam.getExpiredAt() >= block.timestamp, \"order expired\");\\n\\n    bytes32 orderHash = orderParam.getOrderHash(address(perpetual), broker);\\n    require(orderParam.signature.isValidSignature(orderHash, orderParam.trader), \"invalid signature\");\\n    require(filled[orderHash] < orderParam.amount, \"fullfilled order\");\\n\\n    return orderHash;\\n}\\n```\\n
LibMathSigned - wpowi returns an invalid result for a negative exponent  Pendingчmediumч`LibMathSigned.wpowi(x,n)` calculates Wad value `x` (base) to the power of `n` (exponent). The exponent is declared as a signed int, however, the method returns wrong results when calculating `x` ^(-n).\\nThe comment for the `wpowi` method suggests that `n` is a normal integer instead of a Wad-denominated value. This, however, is not being enforced.\\n`LibMathSigned.wpowi(8000000000000000000, 2) = 64000000000000000000`\\n(wrong) `LibMathSigned.wpowi(8000000000000000000, -2) = 64000000000000000000`\\n```\\n// x ^ n\\n// NOTE: n is a normal integer, do not shift 18 decimals\\n// solium-disable-next-line security/no-assign-params\\nfunction wpowi(int256 x, int256 n) internal pure returns (int256 z) {\\n    z = n % 2 != 0 ? x : \\_WAD;\\n\\n    for (n /= 2; n != 0; n /= 2) {\\n        x = wmul(x, x);\\n\\n        if (n % 2 != 0) {\\n            z = wmul(z, x);\\n        }\\n    }\\n}\\n```\\nчMake `wpowi` support negative exponents or use the proper type for `n` (uint) and reject negative values.\\nEnforce that the exponent bounds are within sane ranges and less than a Wad to detect potential misuse where someone accidentally provides a Wad value as `n`.\\nAdd positive and negative unit-tests to fully cover this functionality.чч```\\n// x ^ n\\n// NOTE: n is a normal integer, do not shift 18 decimals\\n// solium-disable-next-line security/no-assign-params\\nfunction wpowi(int256 x, int256 n) internal pure returns (int256 z) {\\n    z = n % 2 != 0 ? x : \\_WAD;\\n\\n    for (n /= 2; n != 0; n /= 2) {\\n        x = wmul(x, x);\\n\\n        if (n % 2 != 0) {\\n            z = wmul(z, x);\\n        }\\n    }\\n}\\n```\\n
Outdated solidity version and floating pragma  PendingчmediumчUsing an outdated compiler version can be problematic especially if there are publicly disclosed bugs and issues (see also https://github.com/ethereum/solidity/releases) that affect the current compiler version.\\nThe codebase specifies a floating version of `^0.5.2` and makes use of the experimental feature `ABIEncoderV2`.\\nIt should be noted, that `ABIEncoderV2` was subject to multiple bug-fixes up until the latest 0.6.xversion and contracts compiled with earlier versions are - for example - susceptible to the following issues:\\nImplicitConstructorCallvalueCheck\\nTupleAssignmentMultiStackSlotComponents\\nMemoryArrayCreationOverflow\\nprivateCanBeOverridden\\nYulOptimizerRedundantAssignmentBreakContinue0.5\\nABIEncoderV2CalldataStructsWithStaticallySizedAndDynamicallyEncodedMembers\\nSignedArrayStorageCopy\\nABIEncoderV2StorageArrayWithMultiSlotElement\\nDynamicConstructorArgumentsClippedABIV2\\nCodebase declares compiler version ^0.5.2:\\n```\\npragma solidity ^0.5.2;\\npragma experimental ABIEncoderV2; // to enable structure-type parameters\\n```\\n\\nAccording to etherscan.io, the currently deployed main-net `AMM` contract is compiled with solidity version 0.5.8:\\nhttps://etherscan.io/address/0xb95B9fb0539Ec84DeD2855Ed1C9C686Af9A4e8b3#codeчIt is recommended to settle on the latest stable 0.6.x or 0.5.x version of the Solidity compiler and lock the pragma version to a specifically tested compiler release.чч```\\npragma solidity ^0.5.2;\\npragma experimental ABIEncoderV2; // to enable structure-type parameters\\n```\\n
AMM - ONE_WAD_U is never usedчlowчThe const `ONE_WAD_U` is declared but never used. Avoid re-declaring the same constants in multiple source-units (and unit-test cases) as this will be hard to maintain.\\n```\\nuint256 private constant ONE\\_WAD\\_U = 10\\*\\*18;\\n```\\nчRemove unused code. Import the value from a shared resource. E.g.ONE_WAD is declared multiple times in `LibMathSigned`, `LibMathUnsigned`, `AMM`, hardcoded in checks in `PerpetualGovernance.setGovernanceParameter`, `AMMGovernance.setGovernanceParameter`.чч```\\nuint256 private constant ONE\\_WAD\\_U = 10\\*\\*18;\\n```\\n
Perpetual - Variable shadowing in constructorчlowч`Perpetual` inherits from `PerpetualGovernance` and `Collateral`, which declare state variables that are shadowed in the `Perpetual` constructor.\\nLocal constructor argument shadows `PerpetualGovernance.globalConfig`, `PerpetualGovernance.devAddress`, `Collateral.collateral`\\nNote: Confusing name: `Collateral` is an inherited contract and a state variable.\\n```\\nconstructor(address globalConfig, address devAddress, address collateral, uint256 collateralDecimals)\\n    public\\n    Position(collateral, collateralDecimals)\\n{\\n    setGovernanceAddress(\"globalConfig\", globalConfig);\\n    setGovernanceAddress(\"dev\", devAddress);\\n    emit CreatePerpetual();\\n}\\n```\\nчRename the parameter or state variable.чч```\\nconstructor(address globalConfig, address devAddress, address collateral, uint256 collateralDecimals)\\n    public\\n    Position(collateral, collateralDecimals)\\n{\\n    setGovernanceAddress(\"globalConfig\", globalConfig);\\n    setGovernanceAddress(\"dev\", devAddress);\\n    emit CreatePerpetual();\\n}\\n```\\n
Perpetual - The specified decimals for the collateral may not reflect the token's actual decimals  AcknowledgedчlowчWhen initializing the `Perpetual` contract, the deployer can decide to use either `ETH`, or an ERC20-compliant collateral. In the latter case, the deployer must provide a nonzero address for the token, as well as the number of `decimals` used by the token:\\n```\\nconstructor(address \\_collateral, uint256 decimals) public {\\n    require(decimals <= MAX\\_DECIMALS, \"decimals out of range\");\\n    require(\\_collateral != address(0x0) || (\\_collateral == address(0x0) && decimals == 18), \"invalid decimals\");\\n\\n    collateral = \\_collateral;\\n    scaler = (decimals == MAX\\_DECIMALS ? 1 : 10\\*\\*(MAX\\_DECIMALS - decimals)).toInt256();\\n}\\n```\\n\\nThe provided `decimals` value is not checked for validity and can differ from the actual token's `decimals`.чEnsure to establish documentation that makes users aware of the fact that the decimals configured are not enforced to match the actual tokens decimals. This is to allow users to audit the system configuration and decide whether they want to participate in it.чч```\\nconstructor(address \\_collateral, uint256 decimals) public {\\n    require(decimals <= MAX\\_DECIMALS, \"decimals out of range\");\\n    require(\\_collateral != address(0x0) || (\\_collateral == address(0x0) && decimals == 18), \"invalid decimals\");\\n\\n    collateral = \\_collateral;\\n    scaler = (decimals == MAX\\_DECIMALS ? 1 : 10\\*\\*(MAX\\_DECIMALS - decimals)).toInt256();\\n}\\n```\\n
AMM - Unchecked return value in ShareToken.mint  Pendingчlowч`ShareToken` is an extension of the Openzeppelin ERC20Mintable pattern which exposes a method called `mint()` that allows accounts owning the minter role to mint new tokens. The return value of `ShareToken.mint()` is not checked.\\nSince the ERC20 standard does not define whether this method should return a value or revert it may be problematic to assume that all tokens revert. If, for example, an implementation is used that does not revert on error but returns a boolean error indicator instead the caller might falsely continue without the token minted.\\nWe would like to note that the functionality is intended to be used with the provided `ShareToken` and therefore the contract is safe to use assuming `ERC20Mintable.mint` reverts on error. The issue arises if the system is used with a different `ShareToken` implementation that is not implemented in the same way.\\nOpenzeppelin implementation\\n```\\nfunction mint(address account, uint256 amount) public onlyMinter returns (bool) {\\n    \\_mint(account, amount);\\n    return true;\\n}\\n```\\n\\nCall with unchecked return value\\n```\\nfunction mintShareTokenTo(address guy, uint256 amount) internal {\\n    shareToken.mint(guy, amount);\\n}\\n```\\nчConsider wrapping the `mint` statement in a `require` clause, however, this way only tokens that are returning a boolean error indicator are supported. Document the specification requirements for the `ShareToken` and clearly state if the token is expected to revert or return an error indicator.\\nIt should also be documented that the Token exposes a `burn` method that does not adhere to the Openzeppelin `ERC20Burnable` implementation. The `ERC20Burnable` import is unused as noted in issue 6.23.чч```\\nfunction mint(address account, uint256 amount) public onlyMinter returns (bool) {\\n    \\_mint(account, amount);\\n    return true;\\n}\\n```\\n
Perpetual - beginGlobalSettlement can be called multiple times  AcknowledgedчlowчThe system can be put into emergency mode by an admin calling `beginGlobalSettlement` and providing a fixed `settlementPrice`. The method can be invoked even when the contract is already in `SETTLING` (emergency) mode, allowing an admin to selectively adjust the settlement price again. This does not seem to be the intended behavior as calling the method again re-sets the status to `SETTLING`. Furthermore, it may affect users' behavior during the `SETTLING` phase.\\n```\\nfunction beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {\\n    require(status != LibTypes.Status.SETTLED, \"already settled\");\\n    settlementPrice = price;\\n    status = LibTypes.Status.SETTLING;\\n    emit BeginGlobalSettlement(price);\\n}\\n```\\nчEmergency mode should only be allowed to be set onceчч```\\nfunction beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {\\n    require(status != LibTypes.Status.SETTLED, \"already settled\");\\n    settlementPrice = price;\\n    status = LibTypes.Status.SETTLING;\\n    emit BeginGlobalSettlement(price);\\n}\\n```\\n
Exchange - OrderStatus is never usedчlowчThe enum `OrderStatus` is declared but never used.\\n```\\nenum OrderStatus {EXPIRED, CANCELLED, FILLABLE, FULLY\\_FILLED}\\n```\\nчResolution\\nThis issue was resolved by removing the unused code.\\nRemove unused code.чч```\\nenum OrderStatus {EXPIRED, CANCELLED, FILLABLE, FULLY\\_FILLED}\\n```\\n
LibMath - Inaccurate declaration of _UINT256_MAXчlowч`LibMathUnsigned` declares `_UINT256_MAX` as `2^255-1` while this value actually represents `_INT256_MAX`. This appears to just be a naming issue.\\n(UINT256_MAX/2-1 => pos INT256_MAX; 2**256/2-1==2**255-1)\\n```\\nlibrary LibMathUnsigned {\\n    uint256 private constant \\_WAD = 10\\*\\*18;\\n    uint256 private constant \\_UINT256\\_MAX = 2\\*\\*255 - 1;\\n```\\nчRename `_UINT256_MAX` to `_INT256MAX` or `_SIGNED_INT256MAX`.чч```\\nlibrary LibMathUnsigned {\\n    uint256 private constant \\_WAD = 10\\*\\*18;\\n    uint256 private constant \\_UINT256\\_MAX = 2\\*\\*255 - 1;\\n```\\n
LibMath - inconsistent assertion text and improve representation of literals with many digits  AcknowledgedчlowчThe assertion below states that `logE only accepts v <= 1e22 * 1e18` while the argument name is `x`. In addition to that we suggest representing large literals in scientific notation.\\n```\\nfunction wln(int256 x) internal pure returns (int256) {\\n    require(x > 0, \"logE of negative number\");\\n    require(x <= 10000000000000000000000000000000000000000, \"logE only accepts v <= 1e22 \\* 1e18\"); // in order to prevent using safe-math\\n    int256 r = 0;\\n    uint8 extra\\_digits = longer\\_digits - fixed\\_digits;\\n```\\nчUpdate the inconsistent assertion text `v` -> `x` and represent large literals in scientific notation as they are otherwise difficult to read and review.чч```\\nfunction wln(int256 x) internal pure returns (int256) {\\n    require(x > 0, \"logE of negative number\");\\n    require(x <= 10000000000000000000000000000000000000000, \"logE only accepts v <= 1e22 \\* 1e18\"); // in order to prevent using safe-math\\n    int256 r = 0;\\n    uint8 extra\\_digits = longer\\_digits - fixed\\_digits;\\n```\\n
LibMath - roundHalfUp returns unfinished resultчlowчThe method `LibMathSigned.roundHalfUp(int `x`, int y)` returns the value `x` rounded up to the base `y`. The method suggests that the result is the rounded value while that's not actually true. The result for a positive `x` is `x` + base/2 and `x - base/2` for negative values. The rounding is not yet finished as this would require a final division by base `y` to manifest the rounding.\\nIt is assumed that the final rounding step is not executed for performance reasons. However, this might easily introduce errors when the caller assumes the result is rounded for base while it is not.\\n`roundHalfUp(-4700, 1000) = -4700` instead of `5000`\\n`roundHalfUp(4700, 1000) = 4700` instead of `5000`\\n```\\n// ROUND\\_HALF\\_UP rule helper. 0.5 ≈ 1, 0.4 ≈ 0, -0.5 ≈ -1, -0.4 ≈ 0\\nfunction roundHalfUp(int256 x, int256 y) internal pure returns (int256) {\\n    require(y > 0, \"roundHalfUp only supports y > 0\");\\n    if (x >= 0) {\\n        return add(x, y / 2);\\n    }\\n    return sub(x, y / 2);\\n}\\n```\\nчWe have verified the current code-base and the callers for `roundHalfUp` are correctly finishing the rounding step. However, it is recommended to finish the rounding within the method or document this behavior to prevent errors caused by code that falsely assumes that the returned value finished rounding.чч```\\n// ROUND\\_HALF\\_UP rule helper. 0.5 ≈ 1, 0.4 ≈ 0, -0.5 ≈ -1, -0.4 ≈ 0\\nfunction roundHalfUp(int256 x, int256 y) internal pure returns (int256) {\\n    require(y > 0, \"roundHalfUp only supports y > 0\");\\n    if (x >= 0) {\\n        return add(x, y / 2);\\n    }\\n    return sub(x, y / 2);\\n}\\n```\\n
LibMath/LibOrder - unused named return valueчlowчThe following methods declare a named return value but explicitly return a value instead. The named return value is not used.\\n`LibMathSigned.min()`\\n`LibMathSigned.max()`\\n`LibMathUnsigned.min()`\\n`LibMathUnsigned.max()`\\n`LibOrder.getOrderHash()`\\n`LibOrder.hashOrder()`\\n```\\nfunction min(int256 x, int256 y) internal pure returns (int256 z) {\\n    return x <= y ? x : y;\\n}\\n\\nfunction max(int256 x, int256 y) internal pure returns (int256 z) {\\n    return x >= y ? x : y;\\n}\\n```\\n\\n```\\nfunction min(uint256 x, uint256 y) internal pure returns (uint256 z) {\\n    return x <= y ? x : y;\\n}\\n\\nfunction max(uint256 x, uint256 y) internal pure returns (uint256 z) {\\n    return x >= y ? x : y;\\n}\\n```\\n\\n```\\nfunction getOrderHash(Order memory order) internal pure returns (bytes32 orderHash) {\\n    orderHash = LibEIP712.hashEIP712Message(hashOrder(order));\\n    return orderHash;\\n}\\n```\\n\\n```\\nfunction hashOrder(Order memory order) internal pure returns (bytes32 result) {\\n    bytes32 orderType = EIP712\\_ORDER\\_TYPE;\\n    // solium-disable-next-line security/no-inline-assembly\\n    assembly {\\n        let start := sub(order, 32)\\n        let tmp := mload(start)\\n        mstore(start, orderType)\\n        result := keccak256(start, 224)\\n        mstore(start, tmp)\\n    }\\n    return result;\\n}\\n```\\nчRemove the named return value and explicitly return the value.чч```\\nfunction min(int256 x, int256 y) internal pure returns (int256 z) {\\n    return x <= y ? x : y;\\n}\\n\\nfunction max(int256 x, int256 y) internal pure returns (int256 z) {\\n    return x >= y ? x : y;\\n}\\n```\\n
Commented code exists in BMathчlowч```\\nuint tokenInRatio = bdiv(newTokenBalanceIn, tokenBalanceIn);\\n\\n// uint newPoolSupply = (ratioTi ^ weightTi) \\* poolSupply;\\nuint poolRatio = bpow(tokenInRatio, normalizedWeight);\\n```\\n\\n```\\nuint normalizedWeight = bdiv(tokenWeightOut, totalWeight);\\n// charge exit fee on the pool token side\\n// pAiAfterExitFee = pAi\\*(1-exitFee)\\nuint poolAmountInAfterExitFee = bmul(poolAmountIn, bsub(BONE, EXIT\\_FEE));\\n```\\n\\nAnd many more examples.чRemove the commented code, or address them properly. If the code is related to exit fee, which is considered to be 0 in this version, this style should be persistent in other contracts as well.чч```\\nuint tokenInRatio = bdiv(newTokenBalanceIn, tokenBalanceIn);\\n\\n// uint newPoolSupply = (ratioTi ^ weightTi) \\* poolSupply;\\nuint poolRatio = bpow(tokenInRatio, normalizedWeight);\\n```\\n
Max weight requirement in rebind is inaccurateчlowч`BPool.rebind` enforces `MIN_WEIGHT` and `MAX_WEIGHT` bounds on the passed-in `denorm` value:\\n```\\nfunction rebind(address token, uint balance, uint denorm)\\n    public\\n    \\_logs\\_\\n    \\_lock\\_\\n{\\n\\n    require(msg.sender == \\_controller, \"ERR\\_NOT\\_CONTROLLER\");\\n    require(\\_records[token].bound, \"ERR\\_NOT\\_BOUND\");\\n    require(!\\_finalized, \"ERR\\_IS\\_FINALIZED\");\\n\\n    require(denorm >= MIN\\_WEIGHT, \"ERR\\_MIN\\_WEIGHT\");\\n    require(denorm <= MAX\\_WEIGHT, \"ERR\\_MAX\\_WEIGHT\");\\n    require(balance >= MIN\\_BALANCE, \"ERR\\_MIN\\_BALANCE\");\\n```\\n\\n`MIN_WEIGHT` is `1 BONE`, and `MAX_WEIGHT` is `50 BONE`.\\nThough a token weight of `50 BONE` may make sense in a single-token system, `BPool` is intended to be used with two to eight tokens. The sum of the weights of all tokens must not be greater than `50 BONE`.\\nThis implies that a weight of `50 BONE` for any single token is incorrect, given that at least one other token must be present.ч`MAX_WEIGHT` for any single token should be `MAX_WEIGHT` - MIN_WEIGHT, or `49 BONE`.чч```\\nfunction rebind(address token, uint balance, uint denorm)\\n    public\\n    \\_logs\\_\\n    \\_lock\\_\\n{\\n\\n    require(msg.sender == \\_controller, \"ERR\\_NOT\\_CONTROLLER\");\\n    require(\\_records[token].bound, \"ERR\\_NOT\\_BOUND\");\\n    require(!\\_finalized, \"ERR\\_IS\\_FINALIZED\");\\n\\n    require(denorm >= MIN\\_WEIGHT, \"ERR\\_MIN\\_WEIGHT\");\\n    require(denorm <= MAX\\_WEIGHT, \"ERR\\_MAX\\_WEIGHT\");\\n    require(balance >= MIN\\_BALANCE, \"ERR\\_MIN\\_BALANCE\");\\n```\\n
Test code present in the code baseчmediumчTest code are present in the code base. This is mainly a reminder to fix those before production.\\n`rescuerAddress` and `freezerAddress` are not even in the function arguments.\\n```\\nwhitelistingAddress = \\_whitelistingAddress;\\nprojectAddress = \\_projectAddress;\\nfreezerAddress = \\_projectAddress; // TODO change, here only for testing\\nrescuerAddress = \\_projectAddress; // TODO change, here only for testing\\n```\\nчResolution\\nFixed in lukso-network/[email protected]edb880c.\\nMake sure all the variable assignments are ready for production before deployment to production.чч```\\nwhitelistingAddress = \\_whitelistingAddress;\\nprojectAddress = \\_projectAddress;\\nfreezerAddress = \\_projectAddress; // TODO change, here only for testing\\nrescuerAddress = \\_projectAddress; // TODO change, here only for testing\\n```\\n
frozenPeriod is subtracted twice for calculating the current priceчmediumчIf the contract had been frozen, the current stage price will calculate the price by subtracting the `frozenPeriod` twice and result in wrong calculation.\\n`getCurrentBlockNumber()` subtracts `frozenPeriod` once, and then `getStageAtBlock()` will also subtract the same number again.\\n```\\nfunction getCurrentStage() public view returns (uint8) {\\n    return getStageAtBlock(getCurrentBlockNumber());\\n}\\n```\\n\\n```\\nfunction getCurrentBlockNumber() public view returns (uint256) {\\n    return uint256(block.number)\\n    .sub(frozenPeriod); // make sure we deduct any frozenPeriod from calculations\\n}\\n```\\n\\n```\\nfunction getStageAtBlock(uint256 \\_blockNumber) public view returns (uint8) {\\n\\n    uint256 blockNumber = \\_blockNumber.sub(frozenPeriod); // adjust the block by the frozen period\\n```\\nчResolution\\nFound in parallel to the audit team and has been mitigated in lukso-network/[email protected]ebc4bce . The issue was further simplified by adding `getCurrentEffectiveBlockNumber()` in lukso-network/[email protected]e4c9ed5 to remove ambiguity when calculating current block number.\\nMake sure `frozenPeriod` calculation is done correctly. It could be solved by renaming `getCurrentBlockNumber()` to reflect the calculation done inside the function.\\ne.g. :\\n`getCurrentBlockNumber()` : gets current block number\\n`getCurrentEffectiveBlockNumber()` : calculates the effective block number deducting `frozenPeriod`чч```\\nfunction getCurrentStage() public view returns (uint8) {\\n    return getStageAtBlock(getCurrentBlockNumber());\\n}\\n```\\n
Gold order size should be limitedчhighчWhen a user submits an order to buy gold cards, it's possible to buy a huge amount of cards. `_commit` function uses less gas than `mineGolds`, which means that the user can successfully commit to buying this amount of cards and when it's time to collect them, `mineGolds` function may run out of gas because it iterates over all card IDs and mints them:\\n```\\n// Mint gold cards\\nskyweaverAssets.batchMint(\\_order.cardRecipient, \\_ids, amounts, \"\");\\n```\\nчResolution\\nAddressed in horizon-games/SkyWeaver-contracts#9 by adding a limit for cold cards amount in one order.\\nLimit a maximum gold card amount in one order.чч```\\n// Mint gold cards\\nskyweaverAssets.batchMint(\\_order.cardRecipient, \\_ids, amounts, \"\");\\n```\\n
Price and refund changes may cause failuresчhighчPrice and refund for gold cards are used in 3 different places: commit, mint, refund.\\nWeave tokens spent during the commit phase\\n```\\nfunction \\_commit(uint256 \\_weaveAmount, GoldOrder memory \\_order)\\n  internal\\n{\\n  // Check if weave sent is sufficient for order\\n  uint256 total\\_cost = \\_order.cardAmount.mul(goldPrice).add(\\_order.feeAmount);\\n  uint256 refund\\_amount = \\_weaveAmount.sub(total\\_cost); // Will throw if insufficient amount received\\n```\\n\\nbut they are burned `rngDelay` blocks after\\n```\\n// Burn the non-refundable weave\\nuint256 weave\\_to\\_burn = (\\_order.cardAmount.mul(goldPrice)).sub(\\_order.cardAmount.mul(goldRefund));\\nweaveContract.burn(weaveID, weave\\_to\\_burn);\\n```\\n\\nIf the price is increased between these transactions, mining cards may fail because it should burn more `weave` tokens than there are tokens in the smart contract. Even if there are enough tokens during this particular transaction, someone may fail to melt a gold card later.\\nIf the price is decreased, some `weave` tokens will be stuck in the contract forever without being burned.чStore `goldPrice` and `goldRefund` in `GoldOrder`.чч```\\nfunction \\_commit(uint256 \\_weaveAmount, GoldOrder memory \\_order)\\n  internal\\n{\\n  // Check if weave sent is sufficient for order\\n  uint256 total\\_cost = \\_order.cardAmount.mul(goldPrice).add(\\_order.feeAmount);\\n  uint256 refund\\_amount = \\_weaveAmount.sub(total\\_cost); // Will throw if insufficient amount received\\n```\\n
Re-entrancy attack allows to buy EternalHeroes cheaperчhighчWhen buying eternal heroes in `_buy` function of `EternalHeroesFactory` contract, a buyer can do re-entracy before items are minted.\\n```\\nuint256 refundAmount = \\_arcAmount.sub(total\\_cost);\\nif (refundAmount > 0) {\\n  arcadeumCoin.safeTransferFrom(address(this), \\_recipient, arcadeumCoinID, refundAmount, \"\");\\n}\\n\\n// Mint tokens to recipient\\nfactoryManager.batchMint(\\_recipient, \\_ids, amounts\\_to\\_mint, \"\");\\n```\\n\\nSince price should increase after every `N` items are minted, it's possible to buy more items with the old price.чAdd re-entrancy protection or mint items before sending the refund.чч```\\nuint256 refundAmount = \\_arcAmount.sub(total\\_cost);\\nif (refundAmount > 0) {\\n  arcadeumCoin.safeTransferFrom(address(this), \\_recipient, arcadeumCoinID, refundAmount, \"\");\\n}\\n\\n// Mint tokens to recipient\\nfactoryManager.batchMint(\\_recipient, \\_ids, amounts\\_to\\_mint, \"\");\\n```\\n
Supply limitation misbehaviorsчmediumчIn `SWSupplyManager` contract, the `owner` can limit supply for any token ID by setting maxSupply:\\n```\\nfunction setMaxSupplies(uint256[] calldata \\_ids, uint256[] calldata \\_newMaxSupplies) external onlyOwner() {\\n  require(\\_ids.length == \\_newMaxSupplies.length, \"SWSupplyManager#setMaxSupply: INVALID\\_ARRAYS\\_LENGTH\");\\n\\n  // Can only \\*decrease\\* a max supply\\n  // Can't set max supply back to 0\\n  for (uint256 i = 0; i < \\_ids.length; i++ ) {\\n    if (maxSupply[\\_ids[i]] > 0) {\\n      require(\\n        0 < \\_newMaxSupplies[i] && \\_newMaxSupplies[i] < maxSupply[\\_ids[i]],\\n        \"SWSupplyManager#setMaxSupply: INVALID\\_NEW\\_MAX\\_SUPPLY\"\\n      );\\n    }\\n    maxSupply[\\_ids[i]] = \\_newMaxSupplies[i];\\n  }\\n\\n  emit MaxSuppliesChanged(\\_ids, \\_newMaxSupplies);\\n}\\n```\\n\\nThe problem is that you can set `maxSupply` that is lower than `currentSupply`, which would be an unexpected state to have.\\nAlso, if some tokens are burned, their `currentSupply` is not decreasing:\\n```\\nfunction burn(\\n  uint256 \\_id,\\n  uint256 \\_amount)\\n  external\\n{\\n  \\_burn(msg.sender, \\_id, \\_amount);\\n}\\n```\\n\\nThis unexpected behaviour may lead to burning all of the tokens without being able to mint more.чProperly track `currentSupply` by modifying it in `burn` function. Consider having a following restriction `require(_newMaxSupplies[i] > currentSupply[_ids[i]])` in `setMaxSupplies` function.чч```\\nfunction setMaxSupplies(uint256[] calldata \\_ids, uint256[] calldata \\_newMaxSupplies) external onlyOwner() {\\n  require(\\_ids.length == \\_newMaxSupplies.length, \"SWSupplyManager#setMaxSupply: INVALID\\_ARRAYS\\_LENGTH\");\\n\\n  // Can only \\*decrease\\* a max supply\\n  // Can't set max supply back to 0\\n  for (uint256 i = 0; i < \\_ids.length; i++ ) {\\n    if (maxSupply[\\_ids[i]] > 0) {\\n      require(\\n        0 < \\_newMaxSupplies[i] && \\_newMaxSupplies[i] < maxSupply[\\_ids[i]],\\n        \"SWSupplyManager#setMaxSupply: INVALID\\_NEW\\_MAX\\_SUPPLY\"\\n      );\\n    }\\n    maxSupply[\\_ids[i]] = \\_newMaxSupplies[i];\\n  }\\n\\n  emit MaxSuppliesChanged(\\_ids, \\_newMaxSupplies);\\n}\\n```\\n
importScore() in IexecMaintenanceDelegate can be used to wrongfully reset worker scores  AcknowledgedчmediumчThe import of worker scores from the previous PoCo system deployed on chain is made to be asynchronous. And, even though the pull pattern usually makes a system much more resilient, in this case, it opens up the possibility for an attack that undermines the trust-based game-theoretical balance the PoCo system relies on. As can be seen in the following function:\\n```\\nfunction importScore(address \\_worker)\\nexternal override\\n{\\n require(!m\\_v3\\_scoreImported[\\_worker], \"score-already-imported\");\\n m\\_workerScores[\\_worker] = m\\_workerScores[\\_worker].max(m\\_v3\\_iexecHub.viewScore(\\_worker));\\n m\\_v3\\_scoreImported[\\_worker] = true;\\n}\\n```\\n\\nA motivated attacker could attack the system providing bogus results for computation tasks therefore reducing his own reputation (mirrored by the low worker score that would follow).\\nAfter the fact, the attacker could reset its score to the previous high value attained in the previously deployed PoCo system (v3) and undo all the wrongdoings he had done at no reputational cost.чResolution\\nUpdate from the iExec team:\\nIn order to perform this attack, one would first have to gain reputation on the new version, and lose it. They would then be able to restore its score from the old version.\\nWe feel the risk is acceptable for a few reasons:\\nIt can only be done once per worker\\nConsidering the score dynamics discussed in the “Trust in the PoCo” document, it is more interesting for a worker to import its reputation in the beginning rather then creating a new one, since bad contributions only remove part of the reputation\\nOnly a handful of workers have reputation in the old system (180), and their score is low (average 7, max 22)\\nWe might force the import all 180 workers with reputation >0. A script to identify the relevant addresses is already available.\\nCheck that each worker interacting with the PoCo system has already imported his score. Otherwise import it synchronously with a call at the time of their first interaction.чч```\\nfunction importScore(address \\_worker)\\nexternal override\\n{\\n require(!m\\_v3\\_scoreImported[\\_worker], \"score-already-imported\");\\n m\\_workerScores[\\_worker] = m\\_workerScores[\\_worker].max(m\\_v3\\_iexecHub.viewScore(\\_worker));\\n m\\_v3\\_scoreImported[\\_worker] = true;\\n}\\n```\\n
Domain separator in iExecMaintenanceDelegate has a wrong version field  AcknowledgedчmediumчThe domain separator used to comply with the EIP712 standard in `iExecMaintenanceDelegate` has a wrong version field.\\n```\\nfunction \\_domain()\\ninternal view returns (IexecLibOrders\\_v5.EIP712Domain memory)\\n{\\n return IexecLibOrders\\_v5.EIP712Domain({\\n  name:              \"iExecODB\"\\n , version:           \"3.0-alpha\"\\n , chainId:           \\_chainId()\\n , verifyingContract: address(this)\\n });\\n}\\n```\\n\\nIn the above snippet we can see the code is still using the version field from an old version of the PoCo protocol, `\"3.0-alpha\"`.чResolution\\nIssue was fixed in iExecBlockchainComputing/[email protected]ebee370\\nChange the version field to: `\"5.0-alpha\"`чч```\\nfunction \\_domain()\\ninternal view returns (IexecLibOrders\\_v5.EIP712Domain memory)\\n{\\n return IexecLibOrders\\_v5.EIP712Domain({\\n  name:              \"iExecODB\"\\n , version:           \"3.0-alpha\"\\n , chainId:           \\_chainId()\\n , verifyingContract: address(this)\\n });\\n}\\n```\\n
The updateContract() method in ERC1538UpdateDelegate is incorrectly implementedчlowчThe `updateContract()` method in `ERC1538UpdateDelegate` does not behave as intended for some specific streams of bytes (meant to be parsed as function signatures).\\nThe mentioned function takes as input, among other things, a `string` (which is, canonically, a dynamically-sized `bytes` array) and tries to parse it as a conjunction of function signatures.\\nAs is evident in:\\n```\\nif (char == 0x3B) // 0x3B = ';'\\n```\\n\\nInside the function, `;` is being used as a “reserved” character, serving as a delimiter between each function signature.\\nHowever, if two semicolons are used in succession, the second one will not be checked and will be made part of the function signature being sent into the `_setFunc()` method.\\nExample of faulty input\\n`someFunc;;someOtherFuncWithSemiColon;`чResolution\\nIssue was fixed in iExecBlockchainComputing/[email protected]e6be083\\nReplace the line that increases the `pos` counter at the end of the function:\\n```\\nstart = ++pos;\\n```\\n\\nWIth this line of code:\\n`start = pos + 1;`чч```\\nif (char == 0x3B) // 0x3B = ';'\\n```\\n
TokenStaking.recoverStake allows instant stake undelegationчhighч`TokenStaking.recoverStake` is used to recover stake that has been designated to be undelegated. It contains a single check to ensure that the undelegation period has passed:\\n```\\nfunction recoverStake(address \\_operator) public {\\n    uint256 operatorParams = operators[\\_operator].packedParams;\\n    require(\\n        block.number > operatorParams.getUndelegationBlock().add(undelegationPeriod),\\n        \"Can not recover stake before undelegation period is over.\"\\n    );\\n```\\n\\nHowever, if an undelegation period is never set, this will always return true, allowing any operator to instantly undelegate stake at any time.чRequire that the undelegation period is nonzero before allowing an operator to recover stake.чч```\\nfunction recoverStake(address \\_operator) public {\\n    uint256 operatorParams = operators[\\_operator].packedParams;\\n    require(\\n        block.number > operatorParams.getUndelegationBlock().add(undelegationPeriod),\\n        \"Can not recover stake before undelegation period is over.\"\\n    );\\n```\\n
tbtc - No access control in TBTCSystem.requestNewKeepчhighч`TBTCSystem.requestNewKeep` is used by each new `Deposit` contract on creation. It calls `BondedECDSAKeepFactory.openKeep`, which sets the `Deposit` contract as the “owner,” a permissioned role within the created keep. `openKeep` also automatically allocates bonds from members registered to the application. The “application” from which member bonds are allocated is the tbtc system itself.\\nBecause `requestNewKeep` has no access controls, anyone can request that a keep be opened with `msg.sender` as the “owner,” and arbitrary signing threshold values:\\n```\\n/// @notice Request a new keep opening.\\n/// @param \\_m Minimum number of honest keep members required to sign.\\n/// @param \\_n Number of members in the keep.\\n/// @return Address of a new keep.\\nfunction requestNewKeep(uint256 \\_m, uint256 \\_n, uint256 \\_bond)\\n    external\\n    payable\\n    returns (address)\\n{\\n    IBondedECDSAKeepVendor \\_keepVendor = IBondedECDSAKeepVendor(keepVendor);\\n    IBondedECDSAKeepFactory \\_keepFactory = IBondedECDSAKeepFactory(\\_keepVendor.selectFactory());\\n    return \\_keepFactory.openKeep.value(msg.value)(\\_n, \\_m, msg.sender, \\_bond);\\n}\\n```\\n\\nGiven that the owner of a keep is able to seize signer bonds, close the keep, and more, having control of this role could be detrimental to group members.чResolution\\nIssue addressed in keep-network/tbtc#514. Each call to `requestNewKeep` makes a check that `uint(msg.sender)` is an existing `TBTCDepositToken`. Because these tokens are only minted in `DepositFactory`, `msg.sender` would have to be one of the cloned deposit contracts.\\nAdd access control to `requestNewKeep`, so that it can only be called as a part of the `Deposit` creation and initialization process.чч```\\n/// @notice Request a new keep opening.\\n/// @param \\_m Minimum number of honest keep members required to sign.\\n/// @param \\_n Number of members in the keep.\\n/// @return Address of a new keep.\\nfunction requestNewKeep(uint256 \\_m, uint256 \\_n, uint256 \\_bond)\\n    external\\n    payable\\n    returns (address)\\n{\\n    IBondedECDSAKeepVendor \\_keepVendor = IBondedECDSAKeepVendor(keepVendor);\\n    IBondedECDSAKeepFactory \\_keepFactory = IBondedECDSAKeepFactory(\\_keepVendor.selectFactory());\\n    return \\_keepFactory.openKeep.value(msg.value)(\\_n, \\_m, msg.sender, \\_bond);\\n}\\n```\\n
Unpredictable behavior due to front running or general bad timingчhighчIn a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.\\nSpecifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.\\nSome instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they're about to take.\\nSystem Parameters\\nThe owner of the `TBTCSystem` contract can change system parameters at any time with changes taking effect immediately.\\n`setSignerFeeDivisor` - stored in the deposit contract when creating a new deposit. emits an event.\\n`setLotSizes` - stored in the deposit contract when creating a new deposit. emits an event.\\n`setCollateralizationThresholds` - stored in the deposit contract when creating a new deposit. emits an event.\\nThis also opens up an opportunity for malicious owner to:\\ninterfere with other participants deposit creation attempts (front-running transactions)\\ncraft a series of transactions that allow the owner to set parameters that are more beneficial to them, then create a deposit and reset the parameters to the systems' initial settings.\\n```\\n/// @notice Set the system signer fee divisor.\\n/// @param \\_signerFeeDivisor The signer fee divisor.\\nfunction setSignerFeeDivisor(uint256 \\_signerFeeDivisor)\\n    external onlyOwner\\n{\\n    require(\\_signerFeeDivisor > 9, \"Signer fee divisor must be greater than 9, for a signer fee that is <= 10%.\");\\n    signerFeeDivisor = \\_signerFeeDivisor;\\n    emit SignerFeeDivisorUpdated(\\_signerFeeDivisor);\\n}\\n```\\n\\nUpgradables\\nThe proxy pattern used in many places throughout the system allows the operator to set a new implementation which takes effect immediately.\\n```\\n/\\*\\*\\n \\* @dev Upgrade current implementation.\\n \\* @param \\_implementation Address of the new implementation contract.\\n \\*/\\nfunction upgradeTo(address \\_implementation)\\n    public\\n    onlyOwner\\n{\\n    address currentImplementation = implementation();\\n    require(\\_implementation != address(0), \"Implementation address can't be zero.\");\\n    require(\\_implementation != currentImplementation, \"Implementation address must be different from the current one.\");\\n    setImplementation(\\_implementation);\\n    emit Upgraded(\\_implementation);\\n}\\n```\\n\\n```\\n/// @notice Upgrades the current vendor implementation.\\n/// @param \\_implementation Address of the new vendor implementation contract.\\nfunction upgradeTo(address \\_implementation) public onlyOwner {\\n    address currentImplementation = implementation();\\n    require(\\n        \\_implementation != address(0),\\n        \"Implementation address can't be zero.\"\\n    );\\n    require(\\n        \\_implementation != currentImplementation,\\n        \"Implementation address must be different from the current one.\"\\n    );\\n    setImplementation(\\_implementation);\\n    emit Upgraded(\\_implementation);\\n}\\n```\\n\\nRegistry\\n```\\nfunction registerFactory(address payable \\_factory) external onlyOperatorContractUpgrader {\\n    require(\\_factory != address(0), \"Incorrect factory address\");\\n    require(\\n        registry.isApprovedOperatorContract(\\_factory),\\n        \"Factory contract is not approved\"\\n    );\\n    keepFactory = \\_factory;\\n}\\n```\\nчThe underlying issue is that users of the system can't be sure what the behavior of a function call will be, and this is because the behavior can change at any time.\\nWe recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.чч```\\n/// @notice Set the system signer fee divisor.\\n/// @param \\_signerFeeDivisor The signer fee divisor.\\nfunction setSignerFeeDivisor(uint256 \\_signerFeeDivisor)\\n    external onlyOwner\\n{\\n    require(\\_signerFeeDivisor > 9, \"Signer fee divisor must be greater than 9, for a signer fee that is <= 10%.\");\\n    signerFeeDivisor = \\_signerFeeDivisor;\\n    emit SignerFeeDivisorUpdated(\\_signerFeeDivisor);\\n}\\n```\\n
keep-core - reportRelayEntryTimeout creates an incentive for nodes to race for rewards potentially wasting gas and it creates an opportunity for front-runningчhighчThe incentive on `reportRelayEntryTimeout` for being rewarded with 5% of the seized amount creates an incentive to call the method but might also kick off a race for front-running this call. This method is being called from the keep node which is unlikely to adjust the gasPrice and might always lose the race against a front-running bot collecting rewards for all timeouts and fraud proofs (issue 5.7)\\n```\\n/\\*\\*\\n \\* @dev Function used to inform about the fact the currently ongoing\\n \\* new relay entry generation operation timed out. As a result, the group\\n \\* which was supposed to produce a new relay entry is immediately\\n \\* terminated and a new group is selected to produce a new relay entry.\\n \\* All members of the group are punished by seizing minimum stake of\\n \\* their tokens. The submitter of the transaction is rewarded with a\\n \\* tattletale reward which is limited to min(1, 20 / group\\_size) of the\\n \\* maximum tattletale reward.\\n \\*/\\nfunction reportRelayEntryTimeout() public {\\n    require(hasEntryTimedOut(), \"Entry did not time out\");\\n    groups.reportRelayEntryTimeout(signingRequest.groupIndex, groupSize, minimumStake);\\n\\n    // We could terminate the last active group. If that's the case,\\n    // do not try to execute signing again because there is no group\\n    // which can handle it.\\n    if (numberOfGroups() > 0) {\\n        signRelayEntry(\\n            signingRequest.relayRequestId,\\n            signingRequest.previousEntry,\\n            signingRequest.serviceContract,\\n            signingRequest.entryVerificationAndProfitFee,\\n            signingRequest.callbackFee\\n        );\\n    }\\n}\\n```\\nчMake sure that `reportRelayEntryTimeout` throws as early as possible if the group was previously terminated (isGroupTerminated) to avoid that keep-nodes spend gas on a call that will fail. Depending on the reward for calling out the timeout this might create a front-running opportunity that cannot be resolved.чч```\\n/\\*\\*\\n \\* @dev Function used to inform about the fact the currently ongoing\\n \\* new relay entry generation operation timed out. As a result, the group\\n \\* which was supposed to produce a new relay entry is immediately\\n \\* terminated and a new group is selected to produce a new relay entry.\\n \\* All members of the group are punished by seizing minimum stake of\\n \\* their tokens. The submitter of the transaction is rewarded with a\\n \\* tattletale reward which is limited to min(1, 20 / group\\_size) of the\\n \\* maximum tattletale reward.\\n \\*/\\nfunction reportRelayEntryTimeout() public {\\n    require(hasEntryTimedOut(), \"Entry did not time out\");\\n    groups.reportRelayEntryTimeout(signingRequest.groupIndex, groupSize, minimumStake);\\n\\n    // We could terminate the last active group. If that's the case,\\n    // do not try to execute signing again because there is no group\\n    // which can handle it.\\n    if (numberOfGroups() > 0) {\\n        signRelayEntry(\\n            signingRequest.relayRequestId,\\n            signingRequest.previousEntry,\\n            signingRequest.serviceContract,\\n            signingRequest.entryVerificationAndProfitFee,\\n            signingRequest.callbackFee\\n        );\\n    }\\n}\\n```\\n
keep-core - reportUnauthorizedSigning fraud proof is not bound to reporter and can be front-runчhighчAn attacker can monitor `reportUnauthorizedSigning()` for fraud reports and attempt to front-run the original call in an effort to be the first one reporting the fraud and be rewarded 5% of the total seized amount.\\n```\\n/\\*\\*\\n \\* @dev Reports unauthorized signing for the provided group. Must provide\\n \\* a valid signature of the group address as a message. Successful signature\\n \\* verification means the private key has been leaked and all group members\\n \\* should be punished by seizing their tokens. The submitter of this proof is\\n \\* rewarded with 5% of the total seized amount scaled by the reward adjustment\\n \\* parameter and the rest 95% is burned.\\n \\*/\\nfunction reportUnauthorizedSigning(\\n    uint256 groupIndex,\\n    bytes memory signedGroupPubKey\\n) public {\\n    groups.reportUnauthorizedSigning(groupIndex, signedGroupPubKey, minimumStake);\\n}\\n```\\nчRequire the reporter to include `msg.sender` in the signature proving the fraud or implement a two-step commit/reveal scheme to counter front-running opportunities by forcing a reporter to secretly commit the fraud parameters in one block and reveal them in another.чч```\\n/\\*\\*\\n \\* @dev Reports unauthorized signing for the provided group. Must provide\\n \\* a valid signature of the group address as a message. Successful signature\\n \\* verification means the private key has been leaked and all group members\\n \\* should be punished by seizing their tokens. The submitter of this proof is\\n \\* rewarded with 5% of the total seized amount scaled by the reward adjustment\\n \\* parameter and the rest 95% is burned.\\n \\*/\\nfunction reportUnauthorizedSigning(\\n    uint256 groupIndex,\\n    bytes memory signedGroupPubKey\\n) public {\\n    groups.reportUnauthorizedSigning(groupIndex, signedGroupPubKey, minimumStake);\\n}\\n```\\n
keep-core - operator contracts disabled via panic button can be re-enabled by RegistryKeeperчhighчThe Registry contract defines three administrative accounts: `Governance`, `registryKeeper`, and `panicButton`. All permissions are initially assigned to the deployer when the contract is created. The account acting like a super-admin, being allowed to re-assign administrative accounts - is `Governance`. `registryKeeper` is a lower privileged account maintaining the registry and `panicButton` is an emergency account that can disable operator contracts.\\nThe keep specification states the following:\\nPanic Button The Panic Button can disable malicious or malfunctioning contracts that have been previously approved by the Registry Keeper. When a contract is disabled by the Panic Button, its status on the registry changes to reflect this, and it becomes ineligible to penalize operators. Contracts disabled by the Panic Button can not be reactivated. The Panic Button can be rekeyed by Governance.\\nIt is assumed that the permissions are `Governance` > `panicButton` > `registryKeeper`, meaning that `panicButton` should be able to overrule `registryKeeper`, while `registryKeeper` cannot overrule `panicButton`.\\nWith the current implementation of the Registry the `registryKeeper` account can re-enable an operator contract that has previously been disabled by the `panicButton` account.\\nWe would also like to note the following:\\nThe contract should use enums instead of integer literals when working with contract states.\\nChanges to the contract take effect immediately, allowing an administrative account to selectively front-run calls to the Registry ACL and interfere with user activity.\\nThe operator contract state can be set to the current value without raising an error.\\nThe panic button can be called for operator contracts that are not yet active.\\n```\\nfunction approveOperatorContract(address operatorContract) public onlyRegistryKeeper {\\n    operatorContracts[operatorContract] = 1;\\n}\\n\\nfunction disableOperatorContract(address operatorContract) public onlyPanicButton {\\n    operatorContracts[operatorContract] = 2;\\n}\\n```\\nчThe keep specification states:\\nThe Panic Button can be used to set the status of an APPROVED contract to DISABLED. Operator Contracts disabled with the Panic Button cannot be re-enabled, and disabled contracts may not punish operators nor be selected by service contracts to perform work.\\nAll three accounts are typically trusted. We recommend requiring the `Governance` or `paniceButton` accounts to reset the contract operator state before `registryKeeper` can change the state or disallow re-enabling of disabled operator contracts as stated in the specification.чч```\\nfunction approveOperatorContract(address operatorContract) public onlyRegistryKeeper {\\n    operatorContracts[operatorContract] = 1;\\n}\\n\\nfunction disableOperatorContract(address operatorContract) public onlyPanicButton {\\n    operatorContracts[operatorContract] = 2;\\n}\\n```\\n
tbtc - State transitions are not always enforcedчhighчA deposit follows a complex state-machine that makes sure it is correctly funded before `TBTC` Tokens are minted. The deposit lifecycle starts with a set of states modeling a funding flow that - if successful - ultimately leads to the deposit being active, meaning that corresponding `TBTC` tokens exist for the deposits. A redemption flow allows to redeem `TBTC` for `BTC` and a liquidation flow handles fraud and abort conditions. Fraud cases in the funding flow are handled separately.\\nState transitions from one deposit state to another require someone calling the corresponding transition method on the deposit and actually spend gas on it. The incentive to call a transition varies and is analyzed in more detail in the security-specification section of this report.\\nThis issue assumes that participants are not always pushing forward through the state machine as soon as a new state becomes available, opening up the possibility of having multiple state transitions being a valid option for a deposit (e.g. pushing a deposit to active state even though a timeout should have been called on it).\\nA TDT holder can choose not to call out `notifySignerSetupFailure` hoping that the signing group still forms after the signer setup timeout passes.\\nthere is no incentive for the TDT holder to terminate its own deposit after a timeout.\\nthe deposit might end up never being in a final error state.\\nthere is no incentive for the signing group to terminate the deposit.\\nThis affects all states that can time out.\\nThe deposit can be pushed to active state even after `notifySignerSetupFailure`, `notifyFundingTimeout` have passed but nobody called it out.\\nThere is no timeout check in `retrieveSignerPubkey`, `provideBTCFundingProof`.\\n```\\n/// @notice we poll the Keep contract to retrieve our pubkey\\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\\n/// @param \\_d deposit storage pointer\\n/// @return True if successful, otherwise revert\\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\\n\\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\\n```\\n\\n```\\nfunction provideBTCFundingProof(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes4 \\_txVersion,\\n    bytes memory \\_txInputVector,\\n    bytes memory \\_txOutputVector,\\n    bytes4 \\_txLocktime,\\n    uint8 \\_fundingOutputIndex,\\n    bytes memory \\_merkleProof,\\n    uint256 \\_txIndexInBlock,\\n    bytes memory \\_bitcoinHeaders\\n) public returns (bool) {\\n\\n    require(\\_d.inAwaitingBTCFundingProof(), \"Not awaiting funding\");\\n\\n    bytes8 \\_valueBytes;\\n    bytes memory  \\_utxoOutpoint;\\n```\\n\\nMembers of the signing group might decide to call `notifyFraudFundingTimeout` in a race to avoid late submissions for `provideFraudBTCFundingProof` to succeed in order to contain funds lost due to fraud.\\nIt should be noted that even after the fraud funding timeout passed the TDT holder could `provideFraudBTCFundingProof` as it does not check for the timeout.\\nA malicious signing group observes BTC funding on the bitcoin chain in an attempt to commit fraud at the time the `provideBTCFundingProof` transition becomes available to front-run `provideFundingECDSAFraudProof` forcing the deposit into active state.\\nThe malicious users of the signing group can then try to report fraud, set themselves as `liquidationInitiator` to be awarded part of the signer bond (in addition to taking control of the BTC collateral).\\nThe TDT holders fraud-proof can be front-run, see issue 5.15\\nIf oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition.\\nFor severe oracle errors deposits might be liquidated by calling `notifyUndercollateralizedLiquidation`. The TDT holder cannot exit liquidation in this case.\\nFor non-severe under collateralization someone could call `notifyCourtesyCall` to impose extra effort on TDT holders to `exitCourtesyCall` deposits.\\nA deposit term expiration courtesy call can be exit in the rare case where `_d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp`\\n```\\n/// @notice Goes from courtesy call to active\\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\\n/// @param \\_d deposit storage pointer\\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\\n    \\_d.setActive();\\n    \\_d.logExitedCourtesyCall();\\n}\\n```\\n\\n```\\n/// @notice Notifies the contract that its term limit has been reached\\n/// @dev This initiates a courtesy call\\n/// @param \\_d deposit storage pointer\\nfunction notifyDepositExpiryCourtesyCall(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inActive(), \"Deposit is not active\");\\n    require(block.timestamp >= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit term not elapsed\");\\n    \\_d.setCourtesyCall();\\n    \\_d.logCourtesyCalled();\\n    \\_d.courtesyCallInitiated = block.timestamp;\\n}\\n```\\n\\nAllow exiting the courtesy call only if the deposit is not expired: `block.timestamp < _d.fundedAt + TBTCConstants.getDepositTerm()`чEnsure that there are no competing interests between participants of the system to favor one transition over the other, causing race conditions, front-running opportunities or stale deposits that are not pushed to end-states.\\nNote: Please find an analysis of incentives to call state transitions in the security section of this document.чч```\\n/// @notice we poll the Keep contract to retrieve our pubkey\\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\\n/// @param \\_d deposit storage pointer\\n/// @return True if successful, otherwise revert\\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\\n\\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\\n```\\n
tbtc - Funder loses payment to keep if signing group is not established in time  PendingчhighчTo create a new deposit, the funder has to pay for the creation of a keep. If establishing the keep does not succeed in time, fails or the signing group decides not to return a public key when `retrieveSignerPubkey` is called to transition from `awaiting_signer_setup` to `awaiting_btc_funding_proof` the signer setup fails. After a timeout of 3 hrs, anyone can force the deposit to transition from `awaiting_signer_setup` to `failed_setup` by calling `notifySignerSetupFailure`.\\nThe funder had to provide payment for the keep but the signing group failed to establish. Payment for the keep is not returned even though one could assume that the signing group tried to play unfairly. The signing group might intentionally try to cause this scenario to interfere with the system.\\n`retrieveSignerPubkey` fails if keep provided pubkey is empty or of an unexpected length\\n```\\n/// @notice we poll the Keep contract to retrieve our pubkey\\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\\n/// @param \\_d deposit storage pointer\\n/// @return True if successful, otherwise revert\\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\\n\\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\\n\\n    \\_d.signingGroupPubkeyX = \\_publicKey.slice(0, 32).toBytes32();\\n    \\_d.signingGroupPubkeyY = \\_publicKey.slice(32, 32).toBytes32();\\n    require(\\_d.signingGroupPubkeyY != bytes32(0) && \\_d.signingGroupPubkeyX != bytes32(0), \"Keep returned bad pubkey\");\\n    \\_d.fundingProofTimerStart = block.timestamp;\\n\\n    \\_d.setAwaitingBTCFundingProof();\\n    \\_d.logRegisteredPubkey(\\n        \\_d.signingGroupPubkeyX,\\n        \\_d.signingGroupPubkeyY);\\n}\\n```\\n\\n`notifySignerSetupFailure` can be called by anyone after a timeout of 3hrs\\n```\\n/// @notice Anyone may notify the contract that signing group setup has timed out\\n/// @dev We rely on the keep system punishes the signers in this case\\n/// @param \\_d deposit storage pointer\\nfunction notifySignerSetupFailure(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inAwaitingSignerSetup(), \"Not awaiting setup\");\\n    require(\\n        block.timestamp > \\_d.signingGroupRequestedAt + TBTCConstants.getSigningGroupFormationTimeout(),\\n        \"Signing group formation timeout not yet elapsed\"\\n    );\\n    \\_d.setFailedSetup();\\n    \\_d.logSetupFailed();\\n\\n    fundingTeardown(\\_d);\\n}\\n```\\nчIt should be ensured that a keep group always establishes or otherwise the funder is refunded the fee for the keep.чч```\\n/// @notice we poll the Keep contract to retrieve our pubkey\\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\\n/// @param \\_d deposit storage pointer\\n/// @return True if successful, otherwise revert\\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\\n\\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\\n\\n    \\_d.signingGroupPubkeyX = \\_publicKey.slice(0, 32).toBytes32();\\n    \\_d.signingGroupPubkeyY = \\_publicKey.slice(32, 32).toBytes32();\\n    require(\\_d.signingGroupPubkeyY != bytes32(0) && \\_d.signingGroupPubkeyX != bytes32(0), \"Keep returned bad pubkey\");\\n    \\_d.fundingProofTimerStart = block.timestamp;\\n\\n    \\_d.setAwaitingBTCFundingProof();\\n    \\_d.logRegisteredPubkey(\\n        \\_d.signingGroupPubkeyX,\\n        \\_d.signingGroupPubkeyY);\\n}\\n```\\n
bitcoin-spv - SPV proofs do not support transactions with larger numbers of inputs and outputs  PendingчhighчThere is no explicit restriction on the number of inputs and outputs a Bitcoin transaction can have - as long as the transaction fits into a block. The number of inputs and outputs in a transaction is denoted by a leading “varint” - a variable length integer. In `BTCUtils.validateVin` and `BTCUtils.validateVout`, the value of this varint is restricted to under `0xFD`, or 253:\\n```\\n/// @notice Checks that the vin passed up is properly formatted\\n/// @dev Consider a vin with a valid vout in its scriptsig\\n/// @param \\_vin Raw bytes length-prefixed input vector\\n/// @return True if it represents a validly formatted vin\\nfunction validateVin(bytes memory \\_vin) internal pure returns (bool) {\\n    uint256 \\_offset = 1;\\n    uint8 \\_nIns = uint8(\\_vin.slice(0, 1)[0]);\\n\\n    // Not valid if it says there are too many or no inputs\\n    if (\\_nIns >= 0xfd || \\_nIns == 0) {\\n        return false;\\n    }\\n```\\n\\nTransactions that include more than 252 inputs or outputs will not pass this validation, leading to some legitimate deposits being rejected by the tBTC system.\\nThe 252-item limit exists in a few forms throughout the system, outside of the aforementioned `BTCUtils.validateVin` and BTCUtils.validateVout:\\nBTCUtils.determineOutputLength:\\n```\\n/// @notice Determines the length of an output\\n/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\\n/// @param \\_output The output\\n/// @return The length indicated by the prefix, error if invalid length\\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\\n\\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\\n}\\n```\\n\\nDepositUtils.findAndParseFundingOutput:\\n```\\nfunction findAndParseFundingOutput(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes memory \\_txOutputVector,\\n    uint8 \\_fundingOutputIndex\\n) public view returns (bytes8) {\\n```\\n\\nDepositUtils.validateAndParseFundingSPVProof:\\n```\\nfunction validateAndParseFundingSPVProof(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes4 \\_txVersion,\\n    bytes memory \\_txInputVector,\\n    bytes memory \\_txOutputVector,\\n    bytes4 \\_txLocktime,\\n    uint8 \\_fundingOutputIndex,\\n    bytes memory \\_merkleProof,\\n    uint256 \\_txIndexInBlock,\\n    bytes memory \\_bitcoinHeaders\\n) public view returns (bytes8 \\_valueBytes, bytes memory \\_utxoOutpoint){\\n```\\n\\nDepositFunding.provideFraudBTCFundingProof:\\n```\\nfunction provideFraudBTCFundingProof(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes4 \\_txVersion,\\n    bytes memory \\_txInputVector,\\n    bytes memory \\_txOutputVector,\\n    bytes4 \\_txLocktime,\\n    uint8 \\_fundingOutputIndex,\\n    bytes memory \\_merkleProof,\\n    uint256 \\_txIndexInBlock,\\n    bytes memory \\_bitcoinHeaders\\n) public returns (bool) {\\n```\\n\\nDepositFunding.provideBTCFundingProof:\\n```\\nfunction provideBTCFundingProof(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes4 \\_txVersion,\\n    bytes memory \\_txInputVector,\\n    bytes memory \\_txOutputVector,\\n    bytes4 \\_txLocktime,\\n    uint8 \\_fundingOutputIndex,\\n    bytes memory \\_merkleProof,\\n    uint256 \\_txIndexInBlock,\\n    bytes memory \\_bitcoinHeaders\\n) public returns (bool) {\\n```\\n\\nDepositLiquidation.provideSPVFraudProof:\\n```\\nfunction provideSPVFraudProof(\\n    DepositUtils.Deposit storage \\_d,\\n    bytes4 \\_txVersion,\\n    bytes memory \\_txInputVector,\\n    bytes memory \\_txOutputVector,\\n    bytes4 \\_txLocktime,\\n    bytes memory \\_merkleProof,\\n    uint256 \\_txIndexInBlock,\\n    uint8 \\_targetInputIndex,\\n    bytes memory \\_bitcoinHeaders\\n) public {\\n```\\nчResolution\\nThe client provided the following statement:\\nBenchmarks and takeaways are being tracked in issue https://github.com/keep-network/tbtc/issues/556.\\nIncorporate varint parsing in `BTCUtils.validateVin` and `BTCUtils.validateVout`. Ensure that other components of the system reflect the removal of the 252-item limit.чч```\\n/// @notice Checks that the vin passed up is properly formatted\\n/// @dev Consider a vin with a valid vout in its scriptsig\\n/// @param \\_vin Raw bytes length-prefixed input vector\\n/// @return True if it represents a validly formatted vin\\nfunction validateVin(bytes memory \\_vin) internal pure returns (bool) {\\n    uint256 \\_offset = 1;\\n    uint8 \\_nIns = uint8(\\_vin.slice(0, 1)[0]);\\n\\n    // Not valid if it says there are too many or no inputs\\n    if (\\_nIns >= 0xfd || \\_nIns == 0) {\\n        return false;\\n    }\\n```\\n
bitcoin-spv - multiple integer under-/overflowsчhighчThe bitcoin-spv library allows for multiple integer under-/overflows while processing or converting potentially untrusted or user-provided data.\\n`uint8` underflow `uint256(uint8(_e - 3))`\\nNote: `_header[75]` will throw consuming all gas if out of bounds while the majority of the library usually uses `slice(start, 1)` to handle this more gracefully.\\n```\\n/// @dev Target is a 256 bit number encoded as a 3-byte mantissa and 1 byte exponent\\n/// @param \\_header The header\\n/// @return The target threshold\\nfunction extractTarget(bytes memory \\_header) internal pure returns (uint256) {\\n    bytes memory \\_m = \\_header.slice(72, 3);\\n    uint8 \\_e = uint8(\\_header[75]);\\n    uint256 \\_mantissa = bytesToUint(reverseEndianness(\\_m));\\n    uint \\_exponent = \\_e - 3;\\n\\n    return \\_mantissa \\* (256 \\*\\* \\_exponent);\\n}\\n```\\n\\n`uint8` overflow `uint256(uint8(_len + 8 + 1))`\\nNote: might allow a specially crafted output to return an invalid determineOutputLength <= 9.\\nNote: while type `VarInt` is implemented for inputs, it is not for the output length.\\n```\\n/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\\n/// @param \\_output The output\\n/// @return The length indicated by the prefix, error if invalid length\\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\\n\\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\\n}\\n```\\n\\n`uint8` underflow `uint256(uint8(extractOutputScriptLen(_output)[0]) - 2)`\\n```\\n/// @dev Determines type by the length prefix and validates format\\n/// @param \\_output The output\\n/// @return The hash committed to by the pk\\_script, or null for errors\\nfunction extractHash(bytes memory \\_output) internal pure returns (bytes memory) {\\n    if (uint8(\\_output.slice(9, 1)[0]) == 0) {\\n        uint256 \\_len = uint8(extractOutputScriptLen(\\_output)[0]) - 2;\\n        // Check for maliciously formatted witness outputs\\n        if (uint8(\\_output.slice(10, 1)[0]) != uint8(\\_len)) {\\n            return hex\"\";\\n        }\\n        return \\_output.slice(11, \\_len);\\n    } else {\\n        bytes32 \\_tag = \\_output.keccak256Slice(8, 3);\\n```\\n\\n`BytesLib` input validation multiple start+length overflow\\nNote: multiple occurrences. should check `start+length > start && bytes.length >= start+length`\\n```\\nfunction slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\\n```\\n\\n`BytesLib` input validation multiple start overflow\\n```\\nfunction toUint(bytes memory \\_bytes, uint \\_start) internal  pure returns (uint256) {\\n    require(\\_bytes.length >= (\\_start + 32), \"Uint conversion out of bounds.\");\\n```\\n\\n```\\nfunction toAddress(bytes memory \\_bytes, uint \\_start) internal  pure returns (address) {\\n    require(\\_bytes.length >= (\\_start + 20), \"Address conversion out of bounds.\");\\n```\\n\\n```\\nfunction slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\\n```\\n\\n```\\nfunction keccak256Slice(bytes memory \\_bytes, uint \\_start, uint \\_length) pure internal returns (bytes32 result) {\\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\\n```\\nчWe believe that a general-purpose parsing and verification library for bitcoin payments should be very strict when processing untrusted user input. With strict we mean, that it should rigorously validate provided input data and only proceed with the processing of the data if it is within a safe-to-use range for the method to return valid results. Relying on the caller to provide pre-validate data can be unsafe especially if the caller assumes that proper input validation is performed by the library.\\nGiven the risk profile for this library, we recommend a conservative approach that balances security instead of gas efficiency without relying on certain calls or instructions to throw on invalid input.\\nFor this issue specifically, we recommend proper input validation and explicit type expansion where necessary to prevent values from wrapping or processing data for arguments that are not within a safe-to-use range.чч```\\n/// @dev Target is a 256 bit number encoded as a 3-byte mantissa and 1 byte exponent\\n/// @param \\_header The header\\n/// @return The target threshold\\nfunction extractTarget(bytes memory \\_header) internal pure returns (uint256) {\\n    bytes memory \\_m = \\_header.slice(72, 3);\\n    uint8 \\_e = uint8(\\_header[75]);\\n    uint256 \\_mantissa = bytesToUint(reverseEndianness(\\_m));\\n    uint \\_exponent = \\_e - 3;\\n\\n    return \\_mantissa \\* (256 \\*\\* \\_exponent);\\n}\\n```\\n
tbtc - Unreachable state LIQUIDATION_IN_PROGRESSчhighчAccording to the specification (overview, states, version 2020-02-06), a deposit can be in one of two liquidation_in_progress states.\\nLIQUIDATION_IN_PROGRESS\\nLIQUIDATION_IN_PROGRESS Liquidation due to undercollateralization or an abort has started Automatic (on-chain) liquidation was unsuccessful\\nFRAUD_LIQUIDATION_IN_PROGRESS\\nFRAUD_LIQUIDATION_IN_PROGRESS Liquidation due to fraud has started Automatic (on-chain) liquidation was unsuccessful\\nHowever, `LIQUIDATION_IN_PROGRESS` is unreachable and instead, `FRAUD_LIQUIDATION_IN_PROGRESS` is always called. This means that all non-fraud state transitions end up in the fraud liquidation path and will perform actions as if fraud was detected even though it might be caused by an undercollateralized notification or courtesy timeout.\\n`startSignerAbortLiquidation` transitions to `FRAUD_LIQUIDATION_IN_PROGRESS` on non-fraud events `notifyUndercollateralizedLiquidation` and `notifyCourtesyTimeout`\\n```\\n/// @notice Starts signer liquidation due to abort or undercollateralization\\n/// @dev We first attempt to liquidate on chain, then by auction\\n/// @param \\_d deposit storage pointer\\nfunction startSignerAbortLiquidation(DepositUtils.Deposit storage \\_d) internal {\\n    \\_d.logStartedLiquidation(false);\\n    // Reclaim used state for gas savings\\n    \\_d.redemptionTeardown();\\n    \\_d.seizeSignerBonds();\\n\\n    \\_d.liquidationInitiated = block.timestamp;  // Store the timestamp for auction\\n    \\_d.liquidationInitiator = msg.sender;\\n    \\_d.setFraudLiquidationInProgress();\\n}\\n```\\nчVerify state transitions and either remove `LIQUIDATION_IN_PROGRESS` if it is redundant or fix the state transitions for non-fraud liquidations.\\nNote that Deposit states can be simplified by removing redundant states by setting a flag (e.g. fraudLiquidation) in the deposit instead of adding a state to track the fraud liquidation path.\\nAccording to the specification, we assume the following state transitions are desired:\\n`LIQUIDATION_IN_PROGRESS`\\nIn case of liquidation due to undercollateralization or abort, the remaining bond value is split 50-50 between the account which triggered the liquidation and the signers.\\n`FRAUD_LIQUIDATION_IN_PROGRESS`\\nIn case of liquidation due to fraud, the remaining bond value in full goes to the account which triggered the liquidation by proving fraud.чч```\\n/// @notice Starts signer liquidation due to abort or undercollateralization\\n/// @dev We first attempt to liquidate on chain, then by auction\\n/// @param \\_d deposit storage pointer\\nfunction startSignerAbortLiquidation(DepositUtils.Deposit storage \\_d) internal {\\n    \\_d.logStartedLiquidation(false);\\n    // Reclaim used state for gas savings\\n    \\_d.redemptionTeardown();\\n    \\_d.seizeSignerBonds();\\n\\n    \\_d.liquidationInitiated = block.timestamp;  // Store the timestamp for auction\\n    \\_d.liquidationInitiator = msg.sender;\\n    \\_d.setFraudLiquidationInProgress();\\n}\\n```\\n
tbtc - various deposit state transitions can be front-run (e.g. fraud proofs, timeouts)  Won't FixчhighчAn entity that can provide proof for fraudulent ECDSA signatures or SPV proofs in the liquidation flow is rewarded with part of the deposit contract ETH value.\\nSpecification: Liquidation Any signer bond left over after the deposit owner is compensated is distributed to the account responsible for reporting the misbehavior (for fraud) or between the signers and the account that triggered liquidation (for collateralization issues).\\nHowever, the methods under which proof is provided are not protected from front-running allowing anyone to observe transactions to provideECDSAFraudProof/ `provideSPVFraudProof` and submit the same proofs with providing a higher gas value.\\nPlease note that a similar issue exists for timeout states providing rewards for calling them out (i.e. they set the `liquidationInitiator` address).\\n`provideECDSAFraudProof` verifies the fraudulent proof\\n`r,s,v,signedDigest` appear to be the fraudulent signature. `_preimage` is the correct value.\\n```\\n/// @param \\_preimage The sha256 preimage of the digest\\nfunction provideECDSAFraudProof(\\n    DepositUtils.Deposit storage \\_d,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s,\\n    bytes32 \\_signedDigest,\\n    bytes memory \\_preimage\\n) public {\\n    require(\\n        !\\_d.inFunding() && !\\_d.inFundingFailure(),\\n        \"Use provideFundingECDSAFraudProof instead\"\\n    );\\n    require(\\n        !\\_d.inSignerLiquidation(),\\n        \"Signer liquidation already in progress\"\\n    );\\n    require(!\\_d.inEndState(), \"Contract has halted\");\\n    require(submitSignatureFraud(\\_d, \\_v, \\_r, \\_s, \\_signedDigest, \\_preimage), \"Signature is not fraud\");\\n    startSignerFraudLiquidation(\\_d);\\n}\\n```\\n\\n`startSignerFraudLiquidation` sets the address that provides the proof as the beneficiary\\n```\\nfunction provideFundingECDSAFraudProof(\\n    DepositUtils.Deposit storage \\_d,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s,\\n    bytes32 \\_signedDigest,\\n    bytes memory \\_preimage\\n) public {\\n    require(\\n        \\_d.inAwaitingBTCFundingProof(),\\n        \"Signer fraud during funding flow only available while awaiting funding\"\\n    );\\n\\n    bool \\_isFraud = \\_d.submitSignatureFraud(\\_v, \\_r, \\_s, \\_signedDigest, \\_preimage);\\n    require(\\_isFraud, \"Signature is not fraudulent\");\\n    \\_d.logFraudDuringSetup();\\n\\n    // If the funding timeout has elapsed, punish the funder too!\\n    if (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\\n        address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\\n        \\_d.setFailedSetup();\\n    } else {\\n        /\\* NB: This is reuse of the variable \\*/\\n        \\_d.fundingProofTimerStart = block.timestamp;\\n        \\_d.setFraudAwaitingBTCFundingProof();\\n    }\\n}\\n```\\n\\n`purchaseSignerBondsAtAuction` pays out the funds\\n```\\n    uint256 contractEthBalance = address(this).balance;\\n    address payable initiator = \\_d.liquidationInitiator;\\n\\n    if (initiator == address(0)){\\n        initiator = address(0xdead);\\n    }\\n    if (contractEthBalance > 1) {\\n        if (\\_wasFraud) {\\n            initiator.transfer(contractEthBalance);\\n        } else {\\n            // There will always be a liquidation initiator.\\n            uint256 split = contractEthBalance.div(2);\\n            \\_d.pushFundsToKeepGroup(split);\\n            initiator.transfer(split);\\n        }\\n    }\\n}\\n```\\nчFor fraud proofs, it should be required that the reporter uses a commit/reveal scheme to lock in a proof in one block, and reveal the details in another.чч```\\n/// @param \\_preimage The sha256 preimage of the digest\\nfunction provideECDSAFraudProof(\\n    DepositUtils.Deposit storage \\_d,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s,\\n    bytes32 \\_signedDigest,\\n    bytes memory \\_preimage\\n) public {\\n    require(\\n        !\\_d.inFunding() && !\\_d.inFundingFailure(),\\n        \"Use provideFundingECDSAFraudProof instead\"\\n    );\\n    require(\\n        !\\_d.inSignerLiquidation(),\\n        \"Signer liquidation already in progress\"\\n    );\\n    require(!\\_d.inEndState(), \"Contract has halted\");\\n    require(submitSignatureFraud(\\_d, \\_v, \\_r, \\_s, \\_signedDigest, \\_preimage), \"Signature is not fraud\");\\n    startSignerFraudLiquidation(\\_d);\\n}\\n```\\n
tbtc - Anyone can emit log events due to missing access controlчhighчAccess control for `DepositLog` is not implemented. `DepositLog` is inherited by `TBTCSystem` and its functionality is usually consumed by `Deposit` contracts to emit log events on `TBTCSystem`. Due to the missing access control, anyone can emit log events on `TBTCSystem`. Users, client-software or other components that rely on these events might be tricked into performing actions that were not authorized by the system.\\n```\\nfunction approvedToLog(address \\_caller) public pure returns (bool) {\\n    /\\* TODO: auth via system \\*/\\n    \\_caller;\\n    return true;\\n}\\n```\\nчLog events are typically initiated by the Deposit contract. Make sure only Deposit contracts deployed by an approved factory can emit logs on TBTCSystem.чч```\\nfunction approvedToLog(address \\_caller) public pure returns (bool) {\\n    /\\* TODO: auth via system \\*/\\n    \\_caller;\\n    return true;\\n}\\n```\\n
DKGResultVerification.verify unsafe packing in signed dataчmediumч`DKGResultVerification.verify` allows the sender to arbitrarily move bytes between `groupPubKey` and misbehaved:\\n```\\nbytes32 resultHash = keccak256(abi.encodePacked(groupPubKey, misbehaved));\\n```\\nчValidate the expected length of both and add a salt between the two.чч```\\nbytes32 resultHash = keccak256(abi.encodePacked(groupPubKey, misbehaved));\\n```\\n
keep-core - Service contract callbacks can be abused to call into other contractsчmediumч`KeepRandomBeaconServiceImplV1` allows senders to specify an arbitrary method and contract that will receive a callback once the beacon generates a relay entry:\\n```\\n/\\*\\*\\n \\* @dev Creates a request to generate a new relay entry, which will include\\n \\* a random number (by signing the previous entry's random number).\\n \\* @param callbackContract Callback contract address. Callback is called once a new relay entry has been generated.\\n \\* @param callbackMethod Callback contract method signature. String representation of your method with a single\\n \\* uint256 input parameter i.e. \"relayEntryCallback(uint256)\".\\n \\* @param callbackGas Gas required for the callback.\\n \\* The customer needs to ensure they provide a sufficient callback gas\\n \\* to cover the gas fee of executing the callback. Any surplus is returned\\n \\* to the customer. If the callback gas amount turns to be not enough to\\n \\* execute the callback, callback execution is skipped.\\n \\* @return An uint256 representing uniquely generated relay request ID. It is also returned as part of the event.\\n \\*/\\nfunction requestRelayEntry(\\n    address callbackContract,\\n    string memory callbackMethod,\\n    uint256 callbackGas\\n) public nonReentrant payable returns (uint256) {\\n```\\n\\nOnce an operator contract receives the relay entry, it calls executeCallback:\\n```\\n/\\*\\*\\n \\* @dev Executes customer specified callback for the relay entry request.\\n \\* @param requestId Request id tracked internally by this contract.\\n \\* @param entry The generated random number.\\n \\* @return Address to receive callback surplus.\\n \\*/\\nfunction executeCallback(uint256 requestId, uint256 entry) public returns (address payable surplusRecipient) {\\n    require(\\n        \\_operatorContracts.contains(msg.sender),\\n        \"Only authorized operator contract can call execute callback.\"\\n    );\\n\\n    require(\\n        \\_callbacks[requestId].callbackContract != address(0),\\n        \"Callback contract not found\"\\n    );\\n\\n    \\_callbacks[requestId].callbackContract.call(abi.encodeWithSignature(\\_callbacks[requestId].callbackMethod, entry));\\n\\n    surplusRecipient = \\_callbacks[requestId].surplusRecipient;\\n    delete \\_callbacks[requestId];\\n}\\n```\\n\\nArbitrary callbacks can be used to force the service contract to execute many functions within the keep contract system. Currently, the `KeepRandomBeaconOperator` includes an `onlyServiceContract` modifier:\\n```\\n/\\*\\*\\n \\* @dev Checks if sender is authorized.\\n \\*/\\nmodifier onlyServiceContract() {\\n    require(\\n        serviceContracts.contains(msg.sender),\\n        \"Caller is not an authorized contract\"\\n    );\\n    \\_;\\n}\\n```\\n\\nThe functions it protects cannot be targeted by the aforementioned service contract callbacks due to Solidity's `CALLDATASIZE` checking. However, the presence of the modifier suggests that the service contract is expected to be a permissioned actor within some contracts.чStick to a constant callback method signature, rather than allowing users to submit an arbitrary string. An example is `__beaconCallback__(uint256)`.\\nConsider disallowing arbitrary callback destinations. Instead, rely on contracts making requests directly, and default the callback destination to `msg.sender`. Ensure the sender is not an EOA.чч```\\n/\\*\\*\\n \\* @dev Creates a request to generate a new relay entry, which will include\\n \\* a random number (by signing the previous entry's random number).\\n \\* @param callbackContract Callback contract address. Callback is called once a new relay entry has been generated.\\n \\* @param callbackMethod Callback contract method signature. String representation of your method with a single\\n \\* uint256 input parameter i.e. \"relayEntryCallback(uint256)\".\\n \\* @param callbackGas Gas required for the callback.\\n \\* The customer needs to ensure they provide a sufficient callback gas\\n \\* to cover the gas fee of executing the callback. Any surplus is returned\\n \\* to the customer. If the callback gas amount turns to be not enough to\\n \\* execute the callback, callback execution is skipped.\\n \\* @return An uint256 representing uniquely generated relay request ID. It is also returned as part of the event.\\n \\*/\\nfunction requestRelayEntry(\\n    address callbackContract,\\n    string memory callbackMethod,\\n    uint256 callbackGas\\n) public nonReentrant payable returns (uint256) {\\n```\\n
tbtc - Disallow signatures with high-s values in DepositRedemption.provideRedemptionSignatureчmediumч`DepositRedemption.provideRedemptionSignature` is used by signers to publish a signature that can be used to redeem a deposit on Bitcoin. The function accepts a signature s value in the upper half of the secp256k1 curve:\\n```\\nfunction provideRedemptionSignature(\\n    DepositUtils.Deposit storage \\_d,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s\\n) public {\\n    require(\\_d.inAwaitingWithdrawalSignature(), \"Not currently awaiting a signature\");\\n\\n    // If we're outside of the signature window, we COULD punish signers here\\n    // Instead, we consider this a no-harm-no-foul situation.\\n    // The signers have not stolen funds. Most likely they've just inconvenienced someone\\n\\n    // The signature must be valid on the pubkey\\n    require(\\n        \\_d.signerPubkey().checkSig(\\n            \\_d.lastRequestedDigest,\\n            \\_v, \\_r, \\_s\\n        ),\\n        \"Invalid signature\"\\n    );\\n```\\n\\nAlthough `ecrecover` accepts signatures with these s values, they are no longer used in Bitcoin. As such, the signature will appear to be valid to the Ethereum smart contract, but will likely not be accepted on Bitcoin. If no users watching malleate the signature, the redemption process will likely enter a fee increase loop, incurring a cost on the deposit owner.чEnsure the passed-in s value is restricted to the lower half of the secp256k1 curve, as done in BondedECDSAKeep:\\n```\\n// Validate `s` value for a malleability concern described in EIP-2.\\n// Only signatures with `s` value in the lower half of the secp256k1\\n// curve's order are considered valid.\\nrequire(\\n    uint256(\\_s) <=\\n        0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0,\\n    \"Malleable signature - s should be in the low half of secp256k1 curve's order\"\\n);\\n```\\nчч```\\nfunction provideRedemptionSignature(\\n    DepositUtils.Deposit storage \\_d,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s\\n) public {\\n    require(\\_d.inAwaitingWithdrawalSignature(), \"Not currently awaiting a signature\");\\n\\n    // If we're outside of the signature window, we COULD punish signers here\\n    // Instead, we consider this a no-harm-no-foul situation.\\n    // The signers have not stolen funds. Most likely they've just inconvenienced someone\\n\\n    // The signature must be valid on the pubkey\\n    require(\\n        \\_d.signerPubkey().checkSig(\\n            \\_d.lastRequestedDigest,\\n            \\_v, \\_r, \\_s\\n        ),\\n        \"Invalid signature\"\\n    );\\n```\\n
Consistent use of SafeERC20 for external tokensчmediumчUse `SafeERC20` features to interact with potentially broken tokens used in the system. E.g. `TokenGrant.receiveApproval()` is using `safeTransferFrom` while other contracts aren't.\\n`TokenGrant.receiveApproval` using `safeTransferFrom`\\n```\\ntoken.safeTransferFrom(\\_from, address(this), \\_amount);\\n```\\n\\n`TokenStaking.receiveApproval` not using `safeTransferFrom` while `safeTransfer` is being used.\\n```\\ntoken.transferFrom(\\_from, address(this), \\_value);\\n```\\n\\n```\\ntoken.safeTransfer(owner, amount);\\n```\\n\\n```\\ntoken.transfer(tattletale, tattletaleReward);\\n```\\n\\n`distributeERC20ToMembers` not using `safeTransferFrom`\\n```\\ntoken.transferFrom(\\n    msg.sender,\\n    tokenStaking.magpieOf(members[i]),\\n    dividend\\n);\\n```\\nчConsistently use `SafeERC20` to support potentially broken tokens external to the system.чч```\\ntoken.safeTransferFrom(\\_from, address(this), \\_amount);\\n```\\n
Initialize implementations for proxy contracts and protect initialization methodsчmediumчIt should be avoided that the implementation for proxy contracts can be initialized by third parties. This can be the case if the `initialize` function is unprotected. Since the implementation contract is not meant to be used directly without a proxy delegate-calling it is recommended to protect the initialization method of the implementation by initializing on deployment.\\nChanging the proxies implementation (upgradeTo()) to a version that does not protect the initialization method may allow someone to front-run and initialize the contract if it is not done within the same transaction.\\n`KeepVendor` delegates to `KeepVendorImplV1`. The implementations initialization method is unprotected.\\n```\\n/// @notice Initializes Keep Vendor contract implementation.\\n/// @param registryAddress Keep registry contract linked to this contract.\\nfunction initialize(\\n    address registryAddress\\n)\\n    public\\n{\\n    require(!initialized(), \"Contract is already initialized.\");\\n    \\_initialized[\"BondedECDSAKeepVendorImplV1\"] = true;\\n    registry = Registry(registryAddress);\\n}\\n```\\n\\n`KeepRandomBeaconServiceImplV1` and `KeepRandomBeaconServiceUpgradeExample`\\n```\\nfunction initialize(\\n    uint256 priceFeedEstimate,\\n    uint256 fluctuationMargin,\\n    uint256 dkgContributionMargin,\\n    uint256 withdrawalDelay,\\n    address registry\\n)\\n    public\\n{\\n    require(!initialized(), \"Contract is already initialized.\");\\n    \\_initialized[\"KeepRandomBeaconServiceImplV1\"] = true;\\n    \\_priceFeedEstimate = priceFeedEstimate;\\n    \\_fluctuationMargin = fluctuationMargin;\\n    \\_dkgContributionMargin = dkgContributionMargin;\\n    \\_withdrawalDelay = withdrawalDelay;\\n    \\_pendingWithdrawal = 0;\\n    \\_previousEntry = \\_beaconSeed;\\n    \\_registry = registry;\\n    \\_baseCallbackGas = 18845;\\n}\\n```\\n\\n`Deposit` is deployed via `cloneFactory` delegating to a `masterDepositAddress` in `DepositFactory`. The `masterDepositAddress` (Deposit) might be left uninitialized.\\n```\\ncontract DepositFactoryAuthority {\\n\\n    bool internal \\_initialized = false;\\n    address internal \\_depositFactory;\\n\\n    /// @notice Set the address of the System contract on contract initialization\\n    function initialize(address \\_factory) public {\\n        require(! \\_initialized, \"Factory can only be initialized once.\");\\n\\n        \\_depositFactory = \\_factory;\\n        \\_initialized = true;\\n    }\\n```\\nчInitialize unprotected implementation contracts in the implementation's constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction.чч```\\n/// @notice Initializes Keep Vendor contract implementation.\\n/// @param registryAddress Keep registry contract linked to this contract.\\nfunction initialize(\\n    address registryAddress\\n)\\n    public\\n{\\n    require(!initialized(), \"Contract is already initialized.\");\\n    \\_initialized[\"BondedECDSAKeepVendorImplV1\"] = true;\\n    registry = Registry(registryAddress);\\n}\\n```\\n
keep-tecdsa - If caller sends more than is contained in the signer subsidy pool, the value is burnedчmediumчThe signer subsidy pool in `BondedECDSAKeepFactory` tracks funds sent to the contract. Each time a keep is opened, the subsidy pool is intended to be distributed to the members of the new keep:\\n```\\n// If subsidy pool is non-empty, distribute the value to signers but\\n// never distribute more than the payment for opening a keep.\\nuint256 signerSubsidy = subsidyPool < msg.value\\n    ? subsidyPool\\n    : msg.value;\\nif (signerSubsidy > 0) {\\n    subsidyPool -= signerSubsidy;\\n    keep.distributeETHToMembers.value(signerSubsidy)();\\n}\\n```\\n\\nThe tracking around subsidy pool increases is inconsistent, and can lead to sent value being burned. In the case that `subsidyPool` contains less Ether than is sent in `msg.value`, `msg.value` is unused and remains in the contract. It may or may not be added to `subsidyPool`, depending on the return status of the random beacon:\\n```\\n(bool success, ) = address(randomBeacon).call.gas(400000).value(msg.value)(\\n    abi.encodeWithSignature(\\n        \"requestRelayEntry(address,string,uint256)\",\\n        address(this),\\n        \"setGroupSelectionSeed(uint256)\",\\n        callbackGas\\n    )\\n);\\nif (!success) {\\n    subsidyPool += msg.value; // beacon is busy\\n}\\n```\\nчRather than tracking the `subsidyPool` individually, simply distribute `this.balance` to each new keep's members.чч```\\n// If subsidy pool is non-empty, distribute the value to signers but\\n// never distribute more than the payment for opening a keep.\\nuint256 signerSubsidy = subsidyPool < msg.value\\n    ? subsidyPool\\n    : msg.value;\\nif (signerSubsidy > 0) {\\n    subsidyPool -= signerSubsidy;\\n    keep.distributeETHToMembers.value(signerSubsidy)();\\n}\\n```\\n
keep-core - TokenGrant and TokenStaking allow staking zero amount of tokens and front-runningчmediumчTokens are staked via the callback `receiveApproval()` which is normally invoked when calling `approveAndCall()`. The method is not restricting who can initiate the staking of tokens and relies on the fact that the token transfer to the `TokenStaking` contract is pre-approved by the owner, otherwise, the call would revert.\\nHowever, `receiveApproval()` allows the staking of a zero amount of tokens. The only check performed on the number of tokens transferred is, that the token holders balance covers the amount to be transferred. This check is both relatively weak - having enough balance does not imply that tokens are approved for transfer - and does not cover the fact that someone can call the method with a zero amount of tokens.\\nThis way someone could create an arbitrary number of operators staking no tokens at all. This passes the token balance check, `token.transferFrom()` will succeed and an operator struct with a zero stake and arbitrary values for `operator, from, magpie, authorizer` can be set. Finally, an event is emitted for a zero stake.\\nAn attacker could front-run calls to `receiveApproval` to block staking of a legitimate operator by creating a zero stake entry for the operator before she is able to. This vector might allow someone to permanently inconvenience an operator's address. To recover from this situation one could be forced to `cancelStake` terminating the zero stake struct in order to call the contract with the correct stake again.\\nThe same issue exists for `TokenGrant`.\\n```\\n/\\*\\*\\n \\* @notice Receives approval of token transfer and stakes the approved amount.\\n \\* @dev Makes sure provided token contract is the same one linked to this contract.\\n \\* @param \\_from The owner of the tokens who approved them to transfer.\\n \\* @param \\_value Approved amount for the transfer and stake.\\n \\* @param \\_token Token contract address.\\n \\* @param \\_extraData Data for stake delegation. This byte array must have the\\n \\* following values concatenated: Magpie address (20 bytes) where the rewards for participation\\n \\* are sent, operator's (20 bytes) address, authorizer (20 bytes) address.\\n \\*/\\nfunction receiveApproval(address \\_from, uint256 \\_value, address \\_token, bytes memory \\_extraData) public {\\n    require(ERC20Burnable(\\_token) == token, \"Token contract must be the same one linked to this contract.\");\\n    require(\\_value <= token.balanceOf(\\_from), \"Sender must have enough tokens.\");\\n    require(\\_extraData.length == 60, \"Stake delegation data must be provided.\");\\n\\n    address payable magpie = address(uint160(\\_extraData.toAddress(0)));\\n    address operator = \\_extraData.toAddress(20);\\n    require(operators[operator].owner == address(0), \"Operator address is already in use.\");\\n    address authorizer = \\_extraData.toAddress(40);\\n\\n    // Transfer tokens to this contract.\\n    token.transferFrom(\\_from, address(this), \\_value);\\n\\n    operators[operator] = Operator(\\_value, block.number, 0, \\_from, magpie, authorizer);\\n    ownerOperators[\\_from].push(operator);\\n\\n    emit Staked(operator, \\_value);\\n}\\n```\\nчRequire tokens to be staked and explicitly disallow the zero amount of tokens case. The balance check can be removed.\\nNote: Consider checking the calls return value or calling the contract via `SafeERC20` to support potentially broken tokens that do not revert in error cases (token.transferFrom).чч```\\n/\\*\\*\\n \\* @notice Receives approval of token transfer and stakes the approved amount.\\n \\* @dev Makes sure provided token contract is the same one linked to this contract.\\n \\* @param \\_from The owner of the tokens who approved them to transfer.\\n \\* @param \\_value Approved amount for the transfer and stake.\\n \\* @param \\_token Token contract address.\\n \\* @param \\_extraData Data for stake delegation. This byte array must have the\\n \\* following values concatenated: Magpie address (20 bytes) where the rewards for participation\\n \\* are sent, operator's (20 bytes) address, authorizer (20 bytes) address.\\n \\*/\\nfunction receiveApproval(address \\_from, uint256 \\_value, address \\_token, bytes memory \\_extraData) public {\\n    require(ERC20Burnable(\\_token) == token, \"Token contract must be the same one linked to this contract.\");\\n    require(\\_value <= token.balanceOf(\\_from), \"Sender must have enough tokens.\");\\n    require(\\_extraData.length == 60, \"Stake delegation data must be provided.\");\\n\\n    address payable magpie = address(uint160(\\_extraData.toAddress(0)));\\n    address operator = \\_extraData.toAddress(20);\\n    require(operators[operator].owner == address(0), \"Operator address is already in use.\");\\n    address authorizer = \\_extraData.toAddress(40);\\n\\n    // Transfer tokens to this contract.\\n    token.transferFrom(\\_from, address(this), \\_value);\\n\\n    operators[operator] = Operator(\\_value, block.number, 0, \\_from, magpie, authorizer);\\n    ownerOperators[\\_from].push(operator);\\n\\n    emit Staked(operator, \\_value);\\n}\\n```\\n
tbtc - Inconsistency between increaseRedemptionFee and provideRedemptionProof may create un-provable redemptionsчmediumч`DepositRedemption.increaseRedemptionFee` is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.\\nFee increases can be performed every 4 hours:\\n```\\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\\n```\\n\\nIn addition, each increase must increment the fee by exactly the initial proposed fee:\\n```\\n// Check that we're incrementing the fee by exactly the redeemer's initial fee\\nuint256 \\_previousOutputValue = DepositUtils.bytes8LEToUint(\\_previousOutputValueBytes);\\n\\_newOutputValue = DepositUtils.bytes8LEToUint(\\_newOutputValueBytes);\\nrequire(\\_previousOutputValue.sub(\\_newOutputValue) == \\_d.initialRedemptionFee, \"Not an allowed fee step\");\\n```\\n\\nOutside of these two restrictions, there is no limit to the number of times `increaseRedemptionFee` can be called. Over a 20-hour period, for example, `increaseRedemptionFee` could be called 5 times, increasing the fee to `initialRedemptionFee * 5`. Over a 24-hour period, `increaseRedemptionFee` could be called 6 times, increasing the fee to `initialRedemptionFee * 6`.\\nEventually, it is expected that a transaction will be submitted and mined. At this point, anyone can call `DepositRedemption.provideRedemptionProof`, finalizing the redemption process and rewarding the signers. However, `provideRedemptionProof` will fail if the transaction fee is too high:\\n```\\nrequire((\\_d.utxoSize().sub(\\_fundingOutputValue)) <= \\_d.initialRedemptionFee \\* 5, \"Fee unexpectedly very high\");\\n```\\n\\nIn the case that `increaseRedemptionFee` is called 6 times and the signers provide a signature for this transaction, the transaction can be submitted and mined but `provideRedemptionProof` for this will always fail. Eventually, a redemption proof timeout will trigger the deposit into liquidation and the signers will be punished.чBecause it is difficult to say with certainty that a 5x fee increase will always ensure a transaction's redeemability, the upper bound on fee bumps should be removed from `provideRedemptionProof`.\\nThis should be implemented in tandem with https://github.com/ConsenSys/thesis-tbtc-audit-2020-01/issues/38, so that signers cannot provide a proof that bypasses `increaseRedemptionFee` flow to spend the highest fee possible.чч```\\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\\n```\\n
keep-tecdsa - keep cannot be closed if a members bond was seized or fully reassignedчmediumчA keep cannot be closed if the bonds have been completely reassigned or seized before, leaving at least one member with zero `lockedBonds`. In this case `closeKeep()` will throw in `freeMembersBonds()` because the requirement in `keepBonding.freeBond` is not satisfied anymore (lockedBonds[bondID] > 0). As a result of this, none of the potentially remaining bonds (reassign) are freed, the keep stays active even though it should be closed.\\n```\\n/// @notice Closes keep when owner decides that they no longer need it.\\n/// Releases bonds to the keep members. Keep can be closed only when\\n/// there is no signing in progress or requested signing process has timed out.\\n/// @dev The function can be called by the owner of the keep and only is the\\n/// keep has not been closed already.\\nfunction closeKeep() external onlyOwner onlyWhenActive {\\n    require(\\n        !isSigningInProgress() || hasSigningTimedOut(),\\n        \"Requested signing has not timed out yet\"\\n    );\\n\\n    isActive = false;\\n\\n    freeMembersBonds();\\n\\n    emit KeepClosed();\\n}\\n\\n/// @notice Returns bonds to the keep members.\\nfunction freeMembersBonds() internal {\\n    for (uint256 i = 0; i < members.length; i++) {\\n        keepBonding.freeBond(members[i], uint256(address(this)));\\n    }\\n}\\n```\\n\\n```\\n/// @notice Releases the bond and moves the bond value to the operator's\\n/// unbounded value pool.\\n/// @dev Function requires that caller is the holder of the bond which is\\n/// being released.\\n/// @param operator Address of the bonded operator.\\n/// @param referenceID Reference ID of the bond.\\nfunction freeBond(address operator, uint256 referenceID) public {\\n    address holder = msg.sender;\\n    bytes32 bondID = keccak256(\\n        abi.encodePacked(operator, holder, referenceID)\\n    );\\n\\n    require(lockedBonds[bondID] > 0, \"Bond not found\");\\n\\n    uint256 amount = lockedBonds[bondID];\\n    lockedBonds[bondID] = 0;\\n    unbondedValue[operator] = amount;\\n}\\n```\\nчMake sure the keep can be set to an end-state (closed/inactive) indicating its end-of-life even if the bond has been seized before. Avoid throwing an exception when freeing member bonds to avoid blocking the unlocking of bonds.чч```\\n/// @notice Closes keep when owner decides that they no longer need it.\\n/// Releases bonds to the keep members. Keep can be closed only when\\n/// there is no signing in progress or requested signing process has timed out.\\n/// @dev The function can be called by the owner of the keep and only is the\\n/// keep has not been closed already.\\nfunction closeKeep() external onlyOwner onlyWhenActive {\\n    require(\\n        !isSigningInProgress() || hasSigningTimedOut(),\\n        \"Requested signing has not timed out yet\"\\n    );\\n\\n    isActive = false;\\n\\n    freeMembersBonds();\\n\\n    emit KeepClosed();\\n}\\n\\n/// @notice Returns bonds to the keep members.\\nfunction freeMembersBonds() internal {\\n    for (uint256 i = 0; i < members.length; i++) {\\n        keepBonding.freeBond(members[i], uint256(address(this)));\\n    }\\n}\\n```\\n
tbtc - provideFundingECDSAFraudProof attempts to burn non-existent fundsчmediumчThe funding flow was recently changed from requiring the funder to provide a bond that stays in the Deposit contract to forwarding the funds to the keep, paying for the keep setup.\\nSo at a high level, the funding bond was designed to ensure that funders had some minimum skin in the game, so that DoSing signers/the system was expensive. The upside was that we could refund it in happy paths. Now that we've realized that opening the keep itself will cost enough to prevent DoS, the concept of refunding goes away entirely. We definitely missed cleaning up the funder handling in provideFundingECDSAFraudProof though.\\n```\\n// If the funding timeout has elapsed, punish the funder too!\\nif (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\\n    address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\\n    \\_d.setFailedSetup();\\n```\\nчRemove the line that attempts to punish the funder by burning the Deposit contract balance which is zero due to recent changes in how the payment provided with createNewDepositis handled.чч```\\n// If the funding timeout has elapsed, punish the funder too!\\nif (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\\n    address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\\n    \\_d.setFailedSetup();\\n```\\n
bitcoin-spv - Bitcoin output script length is not checked in wpkhSpendSighash  Won't Fixчmediumч`CheckBitcoinSigs.wpkhSpendSighash` calculates the sighash of a Bitcoin transaction. Among its parameters, it accepts `bytes memory _outpoint`, which is a 36-byte UTXO id consisting of a 32-byte transaction hash and a 4-byte output index.\\nThe function in question should not accept an `_outpoint` that is not 36-bytes, but no length check is made:\\n```\\nfunction wpkhSpendSighash(\\n    bytes memory \\_outpoint,  // 36 byte UTXO id\\n    bytes20 \\_inputPKH,       // 20 byte hash160\\n    bytes8 \\_inputValue,      // 8-byte LE\\n    bytes8 \\_outputValue,     // 8-byte LE\\n    bytes memory \\_outputScript    // lenght-prefixed output script\\n) internal pure returns (bytes32) {\\n    // Fixes elements to easily make a 1-in 1-out sighash digest\\n    // Does not support timelocks\\n    bytes memory \\_scriptCode = abi.encodePacked(\\n        hex\"1976a914\",  // length, dup, hash160, pkh\\_length\\n        \\_inputPKH,\\n        hex\"88ac\");  // equal, checksig\\n    bytes32 \\_hashOutputs = abi.encodePacked(\\n        \\_outputValue,  // 8-byte LE\\n        \\_outputScript).hash256();\\n    bytes memory \\_sighashPreimage = abi.encodePacked(\\n        hex\"01000000\",  // version\\n        \\_outpoint.hash256(),  // hashPrevouts\\n        hex\"8cb9012517c817fead650287d61bdd9c68803b6bf9c64133dcab3e65b5a50cb9\",  // hashSequence(00000000)\\n        \\_outpoint,  // outpoint\\n        \\_scriptCode,  // p2wpkh script code\\n        \\_inputValue,  // value of the input in 8-byte LE\\n        hex\"00000000\",  // input nSequence\\n        \\_hashOutputs,  // hash of the single output\\n        hex\"00000000\",  // nLockTime\\n        hex\"01000000\"  // SIGHASH\\_ALL\\n    );\\n    return \\_sighashPreimage.hash256();\\n}\\n```\\nчCheck that `_outpoint.length` is 36.чч```\\nfunction wpkhSpendSighash(\\n    bytes memory \\_outpoint,  // 36 byte UTXO id\\n    bytes20 \\_inputPKH,       // 20 byte hash160\\n    bytes8 \\_inputValue,      // 8-byte LE\\n    bytes8 \\_outputValue,     // 8-byte LE\\n    bytes memory \\_outputScript    // lenght-prefixed output script\\n) internal pure returns (bytes32) {\\n    // Fixes elements to easily make a 1-in 1-out sighash digest\\n    // Does not support timelocks\\n    bytes memory \\_scriptCode = abi.encodePacked(\\n        hex\"1976a914\",  // length, dup, hash160, pkh\\_length\\n        \\_inputPKH,\\n        hex\"88ac\");  // equal, checksig\\n    bytes32 \\_hashOutputs = abi.encodePacked(\\n        \\_outputValue,  // 8-byte LE\\n        \\_outputScript).hash256();\\n    bytes memory \\_sighashPreimage = abi.encodePacked(\\n        hex\"01000000\",  // version\\n        \\_outpoint.hash256(),  // hashPrevouts\\n        hex\"8cb9012517c817fead650287d61bdd9c68803b6bf9c64133dcab3e65b5a50cb9\",  // hashSequence(00000000)\\n        \\_outpoint,  // outpoint\\n        \\_scriptCode,  // p2wpkh script code\\n        \\_inputValue,  // value of the input in 8-byte LE\\n        hex\"00000000\",  // input nSequence\\n        \\_hashOutputs,  // hash of the single output\\n        hex\"00000000\",  // nLockTime\\n        hex\"01000000\"  // SIGHASH\\_ALL\\n    );\\n    return \\_sighashPreimage.hash256();\\n}\\n```\\n
tbtc - liquidationInitiator can block purchaseSignerBondsAtAuction indefinitelyчmediumчWhen reporting a fraudulent proof the deposits `liquidationInitiator` is set to the entity reporting and proofing the fraud. The deposit that is in a `*_liquidation_in_progress` state can be bought by anyone at an auction calling `purchaseSignerBondsAtAuction`.\\nInstead of receiving a share of the funds the `liquidationInitiator` can decide to intentionally reject the funds by raising an exception causing `initiator.transfer(contractEthBalance)` to throw, blocking the auction and forcing the liquidation to fail. The deposit will stay in one of the `*_liquidation_in_progress` states.\\n```\\n/// @notice Closes an auction and purchases the signer bonds. Payout to buyer, funder, then signers if not fraud\\n/// @dev For interface, reading auctionValue will give a past value. the current is better\\n/// @param \\_d deposit storage pointer\\nfunction purchaseSignerBondsAtAuction(DepositUtils.Deposit storage \\_d) public {\\n    bool \\_wasFraud = \\_d.inFraudLiquidationInProgress();\\n    require(\\_d.inSignerLiquidation(), \"No active auction\");\\n\\n    \\_d.setLiquidated();\\n    \\_d.logLiquidated();\\n\\n    // send the TBTC to the TDT holder. If the TDT holder is the Vending Machine, burn it to maintain the peg.\\n    address tdtHolder = \\_d.depositOwner();\\n\\n    TBTCToken \\_tbtcToken = TBTCToken(\\_d.TBTCToken);\\n\\n    uint256 lotSizeTbtc = \\_d.lotSizeTbtc();\\n    require(\\_tbtcToken.balanceOf(msg.sender) >= lotSizeTbtc, \"Not enough TBTC to cover outstanding debt\");\\n\\n    if(tdtHolder == \\_d.VendingMachine){\\n        \\_tbtcToken.burnFrom(msg.sender, lotSizeTbtc);  // burn minimal amount to cover size\\n    }\\n    else{\\n        \\_tbtcToken.transferFrom(msg.sender, tdtHolder, lotSizeTbtc);\\n    }\\n\\n    // Distribute funds to auction buyer\\n    uint256 \\_valueToDistribute = \\_d.auctionValue();\\n    msg.sender.transfer(\\_valueToDistribute);\\n\\n    // Send any TBTC left to the Fee Rebate Token holder\\n    \\_d.distributeFeeRebate();\\n\\n    // For fraud, pay remainder to the liquidation initiator.\\n    // For non-fraud, split 50-50 between initiator and signers. if the transfer amount is 1,\\n    // division will yield a 0 value which causes a revert; instead, \\n    // we simply ignore such a tiny amount and leave some wei dust in escrow\\n    uint256 contractEthBalance = address(this).balance;\\n    address payable initiator = \\_d.liquidationInitiator;\\n\\n    if (initiator == address(0)){\\n        initiator = address(0xdead);\\n    }\\n    if (contractEthBalance > 1) {\\n        if (\\_wasFraud) {\\n            initiator.transfer(contractEthBalance);\\n        } else {\\n            // There will always be a liquidation initiator.\\n            uint256 split = contractEthBalance.div(2);\\n            \\_d.pushFundsToKeepGroup(split);\\n            initiator.transfer(split);\\n        }\\n    }\\n}\\n```\\nчUse a pull vs push funds pattern or use `address.send` instead of `address.transfer` which might leave some funds locked in the contract if it fails.чч```\\n/// @notice Closes an auction and purchases the signer bonds. Payout to buyer, funder, then signers if not fraud\\n/// @dev For interface, reading auctionValue will give a past value. the current is better\\n/// @param \\_d deposit storage pointer\\nfunction purchaseSignerBondsAtAuction(DepositUtils.Deposit storage \\_d) public {\\n    bool \\_wasFraud = \\_d.inFraudLiquidationInProgress();\\n    require(\\_d.inSignerLiquidation(), \"No active auction\");\\n\\n    \\_d.setLiquidated();\\n    \\_d.logLiquidated();\\n\\n    // send the TBTC to the TDT holder. If the TDT holder is the Vending Machine, burn it to maintain the peg.\\n    address tdtHolder = \\_d.depositOwner();\\n\\n    TBTCToken \\_tbtcToken = TBTCToken(\\_d.TBTCToken);\\n\\n    uint256 lotSizeTbtc = \\_d.lotSizeTbtc();\\n    require(\\_tbtcToken.balanceOf(msg.sender) >= lotSizeTbtc, \"Not enough TBTC to cover outstanding debt\");\\n\\n    if(tdtHolder == \\_d.VendingMachine){\\n        \\_tbtcToken.burnFrom(msg.sender, lotSizeTbtc);  // burn minimal amount to cover size\\n    }\\n    else{\\n        \\_tbtcToken.transferFrom(msg.sender, tdtHolder, lotSizeTbtc);\\n    }\\n\\n    // Distribute funds to auction buyer\\n    uint256 \\_valueToDistribute = \\_d.auctionValue();\\n    msg.sender.transfer(\\_valueToDistribute);\\n\\n    // Send any TBTC left to the Fee Rebate Token holder\\n    \\_d.distributeFeeRebate();\\n\\n    // For fraud, pay remainder to the liquidation initiator.\\n    // For non-fraud, split 50-50 between initiator and signers. if the transfer amount is 1,\\n    // division will yield a 0 value which causes a revert; instead, \\n    // we simply ignore such a tiny amount and leave some wei dust in escrow\\n    uint256 contractEthBalance = address(this).balance;\\n    address payable initiator = \\_d.liquidationInitiator;\\n\\n    if (initiator == address(0)){\\n        initiator = address(0xdead);\\n    }\\n    if (contractEthBalance > 1) {\\n        if (\\_wasFraud) {\\n            initiator.transfer(contractEthBalance);\\n        } else {\\n            // There will always be a liquidation initiator.\\n            uint256 split = contractEthBalance.div(2);\\n            \\_d.pushFundsToKeepGroup(split);\\n            initiator.transfer(split);\\n        }\\n    }\\n}\\n```\\n
bitcoin-spv - verifyHash256Merkle allows existence proofs for the same leaf in multiple locations in the tree  Won't Fixчmediumч`BTCUtils.verifyHash256Merkle` is used by `ValidateSPV.prove` to validate a transaction's existence in a Bitcoin block. The function accepts as input a `_proof` and an `_index`. The `_proof` consists of, in order: the transaction hash, a list of intermediate nodes, and the merkle root.\\nThe proof is performed iteratively, and uses the `_index` to determine whether the next proof element represents a “left branch” or a “right branch:”\\n```\\nuint \\_idx = \\_index;\\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\\n\\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\\n    if (\\_idx % 2 == 1) {\\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\\n    } else {\\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\\n    }\\n    \\_idx = \\_idx  1;\\n}\\nreturn \\_current == \\_root;\\n```\\n\\nIf `_idx` is even, the computed hash is placed before the next proof element. If `_idx` is odd, the computed hash is placed after the next proof element. After each iteration, `_idx` is decremented by `_idx /= 2`.\\nBecause `verifyHash256Merkle` makes no requirements on the size of `_proof` relative to `_index`, it is possible to pass in invalid values for `_index` that prove a transaction's existence in multiple locations in the tree.\\nBy modifying existing tests, we showed that any transaction can be proven to exist at least one alternate index. This alternate index is calculated as `(2 ** treeHeight) + prevIndex` - though other alternate indices are possible. The modified test is below:\\n```\\nit('verifies a bitcoin merkle root', async () => {\\n  for (let i = 0; i < verifyHash256Merkle.length; i += 1) {\\n    const res = await instance.verifyHash256Merkle(\\n      verifyHash256Merkle[i].input.proof,\\n      verifyHash256Merkle[i].input.index\\n    ); // 0-indexed\\n    assert.strictEqual(res, verifyHash256Merkle[i].output);\\n\\n    // Now, attempt to use the same proof to verify the same leaf at\\n    // a different index in the tree:\\n    let pLen = verifyHash256Merkle[i].input.proof.length;\\n    let height = ((pLen - 2) / 64) - 2;\\n\\n    // Only attempt to verify roots that are meant to be verified\\n    if (verifyHash256Merkle[i].output && height >= 1) {\\n      let altIdx = (2 ** height) + verifyHash256Merkle[i].input.index;\\n\\n      const resNext = await instance.verifyHash256Merkle(\\n        verifyHash256Merkle[i].input.proof,\\n        altIdx\\n      );\\n\\n      assert.strictEqual(resNext, verifyHash256Merkle[i].output);\\n\\n      console.log('Verified transaction twice!');\\n    }\\n  }\\n});\\n```\\nчUse the length of `_proof` to determine the maximum allowed `_index`. `_index` should satisfy the following criterion: `_index < 2 ** (_proof.length.div(32) - 2)`.\\nNote that subtraction by 2 accounts for the transaction hash and merkle root, which are assumed to be encoded in the proof along with the intermediate nodes.чч```\\nuint \\_idx = \\_index;\\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\\n\\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\\n    if (\\_idx % 2 == 1) {\\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\\n    } else {\\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\\n    }\\n    \\_idx = \\_idx  1;\\n}\\nreturn \\_current == \\_root;\\n```\\n
keep-core - stake operator should not be eligible if undelegatedAt is setчlowчAn operator's stake should not be eligible if they stake an amount and immediately call `undelegate` in an attempt to indicate that they are going to recover their stake soon.\\n```\\nbool notUndelegated = block.number <= operator.undelegatedAt || operator.undelegatedAt == 0;\\n\\nif (isAuthorized && isActive && notUndelegated) {\\n    balance = operator.amount;\\n}\\n```\\nчA stake that is entering undelegation is indicated by `operator.undelegatedAt` being non-zero. Change the `notUndelegated` check block.number <= `operator.undelegatedAt` || `operator.undelegatedAt` == 0 to `operator.undelegatedAT == 0` as any value being set indicates that undelegation is in progress.\\nEnforce that within the initialization period stake is canceled instead of being undelegated.чч```\\nbool notUndelegated = block.number <= operator.undelegatedAt || operator.undelegatedAt == 0;\\n\\nif (isAuthorized && isActive && notUndelegated) {\\n    balance = operator.amount;\\n}\\n```\\n
keep-core - Specification inconsistency: TokenStaking amount to be slashed/seizedчlowчThe keep specification states that `slash` and `seize` affect at least the amount specified or the remaining stake of a member.\\nSlash each operator in the list misbehavers by the specified amount (or their remaining stake, whichever is lower).\\nPunish each operator in the list misbehavers by the specified amount or their remaining stake.\\nThe implementation, however, bails if one of the accounts does not have enough stake to be slashed or seized because of the use of `SafeMath.sub()`. This behavior is inconsistent with the specification which states that `min(amount, misbehaver.stake)` stake should be affected. The call to slash/seize will revert and no stakes are affected. At max, the staked amount of the lowest staker can be slashed/seized from every staker.\\nImplementing this method as stated in the specification using `min(amount, misbehaver.stake)` will cover the fact that slashing/seizing was only partially successful. If `misbehaver.stake` is zero no error might be emitted even though no stake was slashed/seized.\\n```\\n/\\*\\*\\n \\* @dev Slash provided token amount from every member in the misbehaved\\n \\* operators array and burn 100% of all the tokens.\\n \\* @param amount Token amount to slash from every misbehaved operator.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\\n    public\\n    onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    token.burn(misbehavedOperators.length.mul(amount));\\n}\\n\\n/\\*\\*\\n \\* @dev Seize provided token amount from every member in the misbehaved\\n \\* operators array. The tattletale is rewarded with 5% of the total seized\\n \\* amount scaled by the reward adjustment parameter and the rest 95% is burned.\\n \\* @param amount Token amount to seize from every misbehaved operator.\\n \\* @param rewardMultiplier Reward adjustment in percentage. Min 1% and 100% max.\\n \\* @param tattletale Address to receive the 5% reward.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction seize(\\n    uint256 amount,\\n    uint256 rewardMultiplier,\\n    address tattletale,\\n    address[] memory misbehavedOperators\\n) public onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    uint256 total = misbehavedOperators.length.mul(amount);\\n    uint256 tattletaleReward = (total.mul(5).div(100)).mul(rewardMultiplier).div(100);\\n\\n    token.transfer(tattletale, tattletaleReward);\\n    token.burn(total.sub(tattletaleReward));\\n}\\n```\\nчRequire that `minimumStake` has been provided and can be seized/slashed. Update the documentation to reflect the fact that the solution always seizes/slashes `minimumStake`. Ensure that stakers cannot cancel their stake while they are actively participating in the network.чч```\\n/\\*\\*\\n \\* @dev Slash provided token amount from every member in the misbehaved\\n \\* operators array and burn 100% of all the tokens.\\n \\* @param amount Token amount to slash from every misbehaved operator.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\\n    public\\n    onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    token.burn(misbehavedOperators.length.mul(amount));\\n}\\n\\n/\\*\\*\\n \\* @dev Seize provided token amount from every member in the misbehaved\\n \\* operators array. The tattletale is rewarded with 5% of the total seized\\n \\* amount scaled by the reward adjustment parameter and the rest 95% is burned.\\n \\* @param amount Token amount to seize from every misbehaved operator.\\n \\* @param rewardMultiplier Reward adjustment in percentage. Min 1% and 100% max.\\n \\* @param tattletale Address to receive the 5% reward.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction seize(\\n    uint256 amount,\\n    uint256 rewardMultiplier,\\n    address tattletale,\\n    address[] memory misbehavedOperators\\n) public onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    uint256 total = misbehavedOperators.length.mul(amount);\\n    uint256 tattletaleReward = (total.mul(5).div(100)).mul(rewardMultiplier).div(100);\\n\\n    token.transfer(tattletale, tattletaleReward);\\n    token.burn(total.sub(tattletaleReward));\\n}\\n```\\n
keep-tecdsa - Change state-mutability of checkSignatureFraud to viewчlowч```\\nfunction submitSignatureFraud(\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s,\\n    bytes32 \\_signedDigest,\\n    bytes calldata \\_preimage\\n) external returns (bool \\_isFraud) {\\n    require(publicKey.length != 0, \"Public key was not set yet\");\\n\\n    bytes32 calculatedDigest = sha256(\\_preimage);\\n    require(\\n        \\_signedDigest == calculatedDigest,\\n        \"Signed digest does not match double sha256 hash of the preimage\"\\n    );\\n\\n    bool isSignatureValid = publicKeyToAddress(publicKey) ==\\n        ecrecover(\\_signedDigest, \\_v, \\_r, \\_s);\\n\\n    // Check if the signature is valid but was not requested.\\n    require(\\n        isSignatureValid && !digests[\\_signedDigest],\\n        \"Signature is not fraudulent\"\\n    );\\n\\n    return true;\\n}\\n```\\nчDeclare method as `view`. Consider renaming `submitSignatureFraud` to e.g. `checkSignatureFraud` to emphasize that it is only checking the signature and not actually changing state.чч```\\nfunction submitSignatureFraud(\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s,\\n    bytes32 \\_signedDigest,\\n    bytes calldata \\_preimage\\n) external returns (bool \\_isFraud) {\\n    require(publicKey.length != 0, \"Public key was not set yet\");\\n\\n    bytes32 calculatedDigest = sha256(\\_preimage);\\n    require(\\n        \\_signedDigest == calculatedDigest,\\n        \"Signed digest does not match double sha256 hash of the preimage\"\\n    );\\n\\n    bool isSignatureValid = publicKeyToAddress(publicKey) ==\\n        ecrecover(\\_signedDigest, \\_v, \\_r, \\_s);\\n\\n    // Check if the signature is valid but was not requested.\\n    require(\\n        isSignatureValid && !digests[\\_signedDigest],\\n        \"Signature is not fraudulent\"\\n    );\\n\\n    return true;\\n}\\n```\\n
keep-core - Specification inconsistency: TokenStaking.slash() is never calledчlowчAccording to the keep specification stake should be slashed if a staker violates the protocol:\\nSlashing If a staker violates the protocol of an operation in a way which can be proven on-chain, they will be penalized by having their stakes slashed.\\nWhile this functionality can only be called by the approved operator contract, it is not being used throughout the system. In contrast `seize()` is being called when reporting unauthorized signing or relay entry timeout.\\n```\\n/\\*\\*\\n \\* @dev Slash provided token amount from every member in the misbehaved\\n \\* operators array and burn 100% of all the tokens.\\n \\* @param amount Token amount to slash from every misbehaved operator.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\\n    public\\n    onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    token.burn(misbehavedOperators.length.mul(amount));\\n}\\n```\\nчImplement slashing according to the specification.чч```\\n/\\*\\*\\n \\* @dev Slash provided token amount from every member in the misbehaved\\n \\* operators array and burn 100% of all the tokens.\\n \\* @param amount Token amount to slash from every misbehaved operator.\\n \\* @param misbehavedOperators Array of addresses to seize the tokens from.\\n \\*/\\nfunction slash(uint256 amount, address[] memory misbehavedOperators)\\n    public\\n    onlyApprovedOperatorContract(msg.sender) {\\n    for (uint i = 0; i < misbehavedOperators.length; i++) {\\n        address operator = misbehavedOperators[i];\\n        require(authorizations[msg.sender][operator], \"Not authorized\");\\n        operators[operator].amount = operators[operator].amount.sub(amount);\\n    }\\n\\n    token.burn(misbehavedOperators.length.mul(amount));\\n}\\n```\\n
tbtc - Remove notifyDepositExpiryCourtesyCall and allow exitCourtesyCall exiting the courtesy call at termчlowчFollowing a deep dive into state transitions with the client it was agreed that `notifyDepositExpiryCourtesyCall` should be removed from the system as it is a left-over of a previous version of the deposit contract.\\nAdditionally, `exitCourtesyCall` should be callable at any time.\\n```\\n/// @notice Goes from courtesy call to active\\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\\n/// @param \\_d deposit storage pointer\\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\\n    \\_d.setActive();\\n    \\_d.logExitedCourtesyCall();\\n}\\n```\\nчRemove the `notifyDepositExpiryCourtesyCall` state transition and remove the requirement on `exitCourtesyCall` being callable only before the deposit expires.чч```\\n/// @notice Goes from courtesy call to active\\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\\n/// @param \\_d deposit storage pointer\\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\\n    \\_d.setActive();\\n    \\_d.logExitedCourtesyCall();\\n}\\n```\\n
keep-tecdsa - withdraw should check for zero value transferчlowчRequesting the withdrawal of zero `ETH` in `KeepBonding.withdraw` should fail as this would allow the method to succeed, calling the user-provided destination even though the sender has no unbonded value.\\n```\\nfunction withdraw(uint256 amount, address payable destination) public {\\n    require(\\n        unbondedValue[msg.sender] >= amount,\\n        \"Insufficient unbonded value\"\\n    );\\n\\n    unbondedValue[msg.sender] -= amount;\\n\\n    (bool success, ) = destination.call.value(amount)(\"\");\\n    require(success, \"Transfer failed\");\\n}\\n```\\n\\nAnd a similar instance in BondedECDSAKeep:\\n```\\n/// @notice Withdraws amount of ether hold in the keep for the member.\\n/// The value is sent to the beneficiary of the specific member.\\n/// @param \\_member Keep member address.\\nfunction withdraw(address \\_member) external {\\n    uint256 value = memberETHBalances[\\_member];\\n    memberETHBalances[\\_member] = 0;\\n\\n    /\\* solium-disable-next-line security/no-call-value \\*/\\n    (bool success, ) = tokenStaking.magpieOf(\\_member).call.value(value)(\"\");\\n\\n    require(success, \"Transfer failed\");\\n}\\n```\\nчRequire that the amount to be withdrawn is greater than zero.чч```\\nfunction withdraw(uint256 amount, address payable destination) public {\\n    require(\\n        unbondedValue[msg.sender] >= amount,\\n        \"Insufficient unbonded value\"\\n    );\\n\\n    unbondedValue[msg.sender] -= amount;\\n\\n    (bool success, ) = destination.call.value(amount)(\"\");\\n    require(success, \"Transfer failed\");\\n}\\n```\\n
tbtc - Signer collusion may bypass increaseRedemptionFee flowчlowчDepositRedemption.increaseRedemptionFee is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.\\nFee increases can be performed every 4 hours:\\n```\\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\\n```\\n\\nIn addition, each increase must increment the fee by exactly the initial proposed fee:\\n```\\n// Check that we're incrementing the fee by exactly the redeemer's initial fee\\nuint256 \\_previousOutputValue = DepositUtils.bytes8LEToUint(\\_previousOutputValueBytes);\\n\\_newOutputValue = DepositUtils.bytes8LEToUint(\\_newOutputValueBytes);\\nrequire(\\_previousOutputValue.sub(\\_newOutputValue) == \\_d.initialRedemptionFee, \"Not an allowed fee step\");\\n```\\n\\nOutside of these two restrictions, there is no limit to the number of times `increaseRedemptionFee` can be called. Over a 20-hour period, for example, `increaseRedemptionFee` could be called 5 times, increasing the fee to `initialRedemptionFee * 5`.\\nRather than calling `increaseRedemptionFee` 5 times over 20 hours, colluding signers may immediately create and sign a transaction with a fee of `initialRedemptionFee * 5`, wait for it to be mined, then submit it to `provideRedemptionProof`. Because `provideRedemptionProof` does not check that a transaction signature signs an approved digest, interested parties would need to monitor the bitcoin blockchain, notice the spend, and provide an ECDSA fraud proof before `provideRedemptionProof` is called.чResolution\\nIssue addressed in keep-network/tbtc#522\\nTrack the latest approved fee, and ensure the transaction in `provideRedemptionProof` does not include a higher fee.чч```\\nrequire(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\\n```\\n
tbtc - liquidating a deposit does not send the complete remainder of the contract balance to recipientsчlowч`purchaseSignerBondsAtAuction` might leave a wei in the contract if:\\nthere is only one wei remaining in the contract\\nthere is more than one wei remaining but the contract balance is odd.\\ncontract balances must be > 1 wei otherwise no transfer is attempted\\nthe division at line 271 floors the result if dividing an odd balance. The contract is sending `floor(contract.balance / 2)` to the keep group and liquidationInitiator leaving one 1 in the contract.\\n```\\nif (contractEthBalance > 1) {\\n    if (\\_wasFraud) {\\n        initiator.transfer(contractEthBalance);\\n    } else {\\n        // There will always be a liquidation initiator.\\n        uint256 split = contractEthBalance.div(2);\\n        \\_d.pushFundsToKeepGroup(split);\\n        initiator.transfer(split);\\n    }\\n}\\n```\\nчDefine a reasonable minimum amount when awarding the fraud reporter or liquidation initiator. Alternatively, always transfer the contract balance. When splitting the amount use the contract balance after the first transfer as the value being sent to the second recipient. Use the presence of locked funds in a contract as an error indicator unless funds were sent forcefully to the contract.чч```\\nif (contractEthBalance > 1) {\\n    if (\\_wasFraud) {\\n        initiator.transfer(contractEthBalance);\\n    } else {\\n        // There will always be a liquidation initiator.\\n        uint256 split = contractEthBalance.div(2);\\n        \\_d.pushFundsToKeepGroup(split);\\n        initiator.transfer(split);\\n    }\\n}\\n```\\n
tbtc - approveAndCall unused return parameterчlowч`approveAndCall` always returns false because the return value `bool success` is never set.\\n```\\n/// @notice Set allowance for other address and notify.\\n/// Allows `\\_spender` to transfer the specified TDT\\n/// on your behalf and then ping the contract about it.\\n/// @dev The `\\_spender` should implement the `tokenRecipient` interface below\\n/// to receive approval notifications.\\n/// @param \\_spender Address of contract authorized to spend.\\n/// @param \\_tdtId The TDT they can spend.\\n/// @param \\_extraData Extra information to send to the approved contract.\\nfunction approveAndCall(address \\_spender, uint256 \\_tdtId, bytes memory \\_extraData) public returns (bool success) {\\n    tokenRecipient spender = tokenRecipient(\\_spender);\\n    approve(\\_spender, \\_tdtId);\\n    spender.receiveApproval(msg.sender, \\_tdtId, address(this), \\_extraData);\\n}\\n```\\nчReturn the correct success state.чч```\\n/// @notice Set allowance for other address and notify.\\n/// Allows `\\_spender` to transfer the specified TDT\\n/// on your behalf and then ping the contract about it.\\n/// @dev The `\\_spender` should implement the `tokenRecipient` interface below\\n/// to receive approval notifications.\\n/// @param \\_spender Address of contract authorized to spend.\\n/// @param \\_tdtId The TDT they can spend.\\n/// @param \\_extraData Extra information to send to the approved contract.\\nfunction approveAndCall(address \\_spender, uint256 \\_tdtId, bytes memory \\_extraData) public returns (bool success) {\\n    tokenRecipient spender = tokenRecipient(\\_spender);\\n    approve(\\_spender, \\_tdtId);\\n    spender.receiveApproval(msg.sender, \\_tdtId, address(this), \\_extraData);\\n}\\n```\\n
bitcoin-spv - Unnecessary memory allocation in BTCUtils  Pendingчlowч`BTCUtils` makes liberal use of `BytesLib.slice`, which returns a freshly-allocated slice of an existing bytes array. In many cases, the desired behavior is simply to read a 32-byte slice of a byte array. As a result, the typical pattern used is: `bytesVar.slice(start, start + 32).toBytes32()`.\\nThis pattern introduces unnecessary complexity and memory allocation in a critically important library: cloning a portion of the array, storing that clone in memory, and then reading it from memory. A simpler alternative would be to implement `BytesLib.readBytes32(bytes _b, uint _idx)` and other “memory-read” functions.\\nRather than moving the free memory pointer and redundantly reading, storing, then re-reading memory, `readBytes32` and similar functions would perform a simple length check and `mload` directly from the desired index in the array.\\nextractInputTxIdLE:\\n```\\n/// @notice Extracts the outpoint tx id from an input\\n/// @dev 32 byte tx id\\n/// @param \\_input The input\\n/// @return The tx id (little-endian bytes)\\nfunction extractInputTxIdLE(bytes memory \\_input) internal pure returns (bytes32) {\\n    return \\_input.slice(0, 32).toBytes32();\\n}\\n```\\n\\nverifyHash256Merkle:\\n```\\nuint \\_idx = \\_index;\\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\\n\\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\\n    if (\\_idx % 2 == 1) {\\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\\n    } else {\\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\\n    }\\n    \\_idx = \\_idx  1;\\n}\\nreturn \\_current == \\_root;\\n```\\nчImplement `BytesLib.readBytes32` and favor its use over the `bytesVar.slice(start, start + 32).toBytes32()` pattern. Implement other memory-read functions where possible, and avoid the use of `slice`.\\nNote, too, that implementing this change in `verifyHash256Merkle` would allow `_hash256MerkleStep` to accept 2 `bytes32` inputs (rather than bytes), removing additional unnecessary casting and memory allocation.чч```\\n/// @notice Extracts the outpoint tx id from an input\\n/// @dev 32 byte tx id\\n/// @param \\_input The input\\n/// @return The tx id (little-endian bytes)\\nfunction extractInputTxIdLE(bytes memory \\_input) internal pure returns (bytes32) {\\n    return \\_input.slice(0, 32).toBytes32();\\n}\\n```\\n
bitcoin-spv - ValidateSPV.validateHeaderChain does not completely validate input  Won't Fixчlowч`ValidateSPV.validateHeaderChain` takes as input a sequence of Bitcoin headers and calculates the total accumulated difficulty across the entire sequence. The input headers are checked to ensure they are relatively well-formed:\\n```\\n// Check header chain length\\nif (\\_headers.length % 80 != 0) {return ERR\\_BAD\\_LENGTH;}\\n```\\n\\nHowever, the function lacks a check for nonzero length of `_headers`. Although the total difficulty returned would be zero, an explicit check would make this more clear.чIf `headers.length` is zero, return `ERR_BAD_LENGTH`чч```\\n// Check header chain length\\nif (\\_headers.length % 80 != 0) {return ERR\\_BAD\\_LENGTH;}\\n```\\n
bitcoin-spv - unnecessary intermediate castчlowч`CheckBitcoinSigs.accountFromPubkey()` casts the `bytes32` keccack256 hash of the `pubkey` to `uint256`, then `uint160` and then finally to `address` while the intermediate cast is not required.\\n```\\n/// @notice Derives an Ethereum Account address from a pubkey\\n/// @dev The address is the last 20 bytes of the keccak256 of the address\\n/// @param \\_pubkey The public key X & Y. Unprefixed, as a 64-byte array\\n/// @return The account address\\nfunction accountFromPubkey(bytes memory \\_pubkey) internal pure returns (address) {\\n    require(\\_pubkey.length == 64, \"Pubkey must be 64-byte raw, uncompressed key.\");\\n\\n    // keccak hash of uncompressed unprefixed pubkey\\n    bytes32 \\_digest = keccak256(\\_pubkey);\\n    return address(uint160(uint256(\\_digest)));\\n}\\n```\\nчThe intermediate cast from `uint256` to `uint160` can be omitted. Refactor to `return address(uint256(_digest))` instead.чч```\\n/// @notice Derives an Ethereum Account address from a pubkey\\n/// @dev The address is the last 20 bytes of the keccak256 of the address\\n/// @param \\_pubkey The public key X & Y. Unprefixed, as a 64-byte array\\n/// @return The account address\\nfunction accountFromPubkey(bytes memory \\_pubkey) internal pure returns (address) {\\n    require(\\_pubkey.length == 64, \"Pubkey must be 64-byte raw, uncompressed key.\");\\n\\n    // keccak hash of uncompressed unprefixed pubkey\\n    bytes32 \\_digest = keccak256(\\_pubkey);\\n    return address(uint160(uint256(\\_digest)));\\n}\\n```\\n
bitcoin-spv - unnecessary logic in BytesLib.toBytes32()чlowчThe heavily used library function `BytesLib.toBytes32()` unnecessarily casts `_source` to `bytes` (same type) and creates a copy of the dynamic byte array to check it's length, while this can be done directly on the user-provided `bytes _source`.\\n```\\nfunction toBytes32(bytes memory \\_source) pure internal returns (bytes32 result) {\\n    bytes memory tempEmptyStringTest = bytes(\\_source);\\n    if (tempEmptyStringTest.length == 0) {\\n        return 0x0;\\n    }\\n\\n    assembly {\\n        result := mload(add(\\_source, 32))\\n    }\\n}\\n```\\nч```\\nfunction toBytes32(bytes memory \\_source) pure internal returns (bytes32 result) {\\n        if (\\_source.length == 0) {\\n            return 0x0;\\n        }\\n\\n        assembly {\\n            result := mload(add(\\_source, 32))\\n        }\\n    }\\n```\\nчч```\\nfunction toBytes32(bytes memory \\_source) pure internal returns (bytes32 result) {\\n    bytes memory tempEmptyStringTest = bytes(\\_source);\\n    if (tempEmptyStringTest.length == 0) {\\n        return 0x0;\\n    }\\n\\n    assembly {\\n        result := mload(add(\\_source, 32))\\n    }\\n}\\n```\\n
bitcoin-spv - redundant functionality  Won't FixчlowчThe library exposes redundant implementations of bitcoins double `sha256`.\\nsolidity native implementation with an overzealous type correction issue 5.45\\n```\\n/// @notice Implements bitcoin's hash256 (double sha2)\\n/// @dev abi.encodePacked changes the return to bytes instead of bytes32\\n/// @param \\_b The pre-image\\n/// @return The digest\\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\\n}\\n```\\n\\nassembly implementation\\nNote this implementation does not handle errors when staticcall'ing the precompiled `sha256` contract (private chains).\\n```\\n/// @notice Implements bitcoin's hash256 (double sha2)\\n/// @dev sha2 is precompiled smart contract located at address(2)\\n/// @param \\_b The pre-image\\n/// @return The digest\\nfunction hash256View(bytes memory \\_b) internal view returns (bytes32 res) {\\n    assembly {\\n        let ptr := mload(0x40)\\n        pop(staticcall(gas, 2, add(\\_b, 32), mload(\\_b), ptr, 32))\\n        pop(staticcall(gas, 2, ptr, 32, ptr, 32))\\n        res := mload(ptr)\\n    }\\n}\\n```\\nчWe recommend providing only one implementation for calculating the double `sha256` as maintaining two interfaces for the same functionality is not desirable. Furthermore, even though the assembly implementation is saving gas, we recommend keeping the language provided implementation.чч```\\n/// @notice Implements bitcoin's hash256 (double sha2)\\n/// @dev abi.encodePacked changes the return to bytes instead of bytes32\\n/// @param \\_b The pre-image\\n/// @return The digest\\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\\n}\\n```\\n
bitcoin-spv - unnecessary type correctionчlowчThe type correction `encodePacked().toBytes32()` is not needed as `sha256` already returns `bytes32`.\\n```\\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\\n}\\n```\\nчRefactor to `return sha256(abi.encodePacked(sha256(_b)));` to save gas.чч```\\nfunction hash256(bytes memory \\_b) internal pure returns (bytes32) {\\n    return abi.encodePacked(sha256(abi.encodePacked(sha256(\\_b)))).toBytes32();\\n}\\n```\\n
tbtc - Where possible, a specific contract type should be used rather than addressчlowчRather than storing addresses and then casting to the known contract type, it's better to use the best type available so the compiler can check for type safety.\\n`TBTCSystem.priceFeed` is of type `address`, but it could be type `IBTCETHPriceFeed` instead. Not only would this give a little more type safety when deploying new modules, but it would avoid repeated casts throughout the codebase of the form `IBTCETHPriceFeed(priceFeed)`, `IRelay(relay)`, `TBTCSystem()`, and others.\\n```\\nstruct Deposit {\\n\\n    // SET DURING CONSTRUCTION\\n    address TBTCSystem;\\n    address TBTCToken;\\n    address TBTCDepositToken;\\n    address FeeRebateToken;\\n    address VendingMachine;\\n    uint256 lotSizeSatoshis;\\n    uint8 currentState;\\n    uint256 signerFeeDivisor;\\n    uint128 undercollateralizedThresholdPercent;\\n    uint128 severelyUndercollateralizedThresholdPercent;\\n```\\n\\n```\\ncontract DepositFactory is CloneFactory, TBTCSystemAuthority{\\n\\n    // Holds the address of the deposit contract\\n    // which will be used as a master contract for cloning.\\n    address public masterDepositAddress;\\n    address public tbtcSystem;\\n    address public tbtcToken;\\n    address public tbtcDepositToken;\\n    address public feeRebateToken;\\n    address public vendingMachine;\\n    uint256 public keepThreshold;\\n    uint256 public keepSize;\\n```\\n\\nRemediation\\nWhere possible, use more specific types instead of `address`. This goes for parameter types as well as state variable types.чResolution\\nThis issue has been addressed with https://github.com/keep-network/tbtc/issues/507 and keep-network/tbtc#542.чч```\\nstruct Deposit {\\n\\n    // SET DURING CONSTRUCTION\\n    address TBTCSystem;\\n    address TBTCToken;\\n    address TBTCDepositToken;\\n    address FeeRebateToken;\\n    address VendingMachine;\\n    uint256 lotSizeSatoshis;\\n    uint8 currentState;\\n    uint256 signerFeeDivisor;\\n    uint128 undercollateralizedThresholdPercent;\\n    uint128 severelyUndercollateralizedThresholdPercent;\\n```\\n
tbtc - Variable shadowing in DepositFactoryчlowч`DepositFactory` inherits from `TBTCSystemAuthority`. Both contracts declare a state variable with the same name, `tbtcSystem`.\\n```\\naddress public tbtcSystem;\\n```\\nчRemove the shadowed variable.чч```\\naddress public tbtcSystem;\\n```\\n
tbtc - Values may contain dirty lower-order bits  Pendingчlowч`FundingScript` and `RedemptionScript` use `mload` to cast the first bytes of a byte array to `bytes4`. Because `mload` deals with 32-byte chunks, the resulting `bytes4` value may contain dirty lower-order bits.\\nFundingScript.receiveApproval:\\n```\\n// Verify \\_extraData is a call to unqualifiedDepositToTbtc.\\nbytes4 functionSignature;\\nassembly { functionSignature := mload(add(\\_extraData, 0x20)) }\\nrequire(\\n    functionSignature == vendingMachine.unqualifiedDepositToTbtc.selector,\\n    \"Bad \\_extraData signature. Call must be to unqualifiedDepositToTbtc.\"\\n);\\n```\\n\\nRedemptionScript.receiveApproval:\\n```\\n// Verify \\_extraData is a call to tbtcToBtc.\\nbytes4 functionSignature;\\nassembly { functionSignature := mload(add(\\_extraData, 0x20)) }\\nrequire(\\n    functionSignature == vendingMachine.tbtcToBtc.selector,\\n    \"Bad \\_extraData signature. Call must be to tbtcToBtc.\"\\n);\\n```\\nчSolidity truncates these unneeded bytes in the subsequent comparison operations, so there is no action required. However, this is good to keep in mind if these values are ever used for anything outside of strict comparison.чч```\\n// Verify \\_extraData is a call to unqualifiedDepositToTbtc.\\nbytes4 functionSignature;\\nassembly { functionSignature := mload(add(\\_extraData, 0x20)) }\\nrequire(\\n    functionSignature == vendingMachine.unqualifiedDepositToTbtc.selector,\\n    \"Bad \\_extraData signature. Call must be to unqualifiedDepositToTbtc.\"\\n);\\n```\\n
tbtc - Revert error string may be malformed  Pendingчlowч`FundingScript` handles an error from a call to `VendingMachine` like so.\\n```\\n// Call the VendingMachine.\\n// We could explictly encode the call to vending machine, but this would\\n// involve manually parsing \\_extraData and allocating variables.\\n(bool success, bytes memory returnData) = address(vendingMachine).call(\\n    \\_extraData\\n);\\nrequire(success, string(returnData));\\n```\\n\\nOn a high-level revert, `returnData` will already include the typical “error selector”. As `FundingScript` propagates this error message, it will add another error selector, which may make it difficult to read the error message.\\nThe same issue is present in RedemptionScript:\\n```\\n(bool success, bytes memory returnData) = address(vendingMachine).call(\\_extraData);\\n// By default, `address.call` will catch any revert messages.\\n// Converting the `returnData` to a string will effectively forward any revert messages.\\n// https://ethereum.stackexchange.com/questions/69133/forward-revert-message-from-low-level-solidity-call\\n// TODO: there's some noisy couple bytes at the beginning of the converted string, maybe the ABI-coded length?\\nrequire(success, string(returnData));\\n```\\nчRather than adding an assembly-level revert to the affected contracts, ensure nested error selectors are handled in external libraries.чч```\\n// Call the VendingMachine.\\n// We could explictly encode the call to vending machine, but this would\\n// involve manually parsing \\_extraData and allocating variables.\\n(bool success, bytes memory returnData) = address(vendingMachine).call(\\n    \\_extraData\\n);\\nrequire(success, string(returnData));\\n```\\n
tbtc - Where possible, use constant rather than state variablesчlowч`TBTCSystem` uses a state variable for `pausedDuration`, but this value is never changed.\\n```\\nuint256 pausedDuration = 10 days;\\n```\\nчConsider using the `constant` keyword.чч```\\nuint256 pausedDuration = 10 days;\\n```\\n
tbtc - Variable shadowing in TBTCDepositToken constructorчlowч`TBTCDepositToken` inherits from `DepositFactoryAuthority`, which has a single state variable, `_depositFactory`. This variable is shadowed in the `TBTCDepositToken` constructor.\\n```\\nconstructor(address \\_depositFactory)\\n    ERC721Metadata(\"tBTC Deopsit Token\", \"TDT\")\\n    DepositFactoryAuthority(\\_depositFactory)\\npublic {\\n    // solium-disable-previous-line no-empty-blocks\\n}\\n```\\nчRename the parameter or state variable.чч```\\nconstructor(address \\_depositFactory)\\n    ERC721Metadata(\"tBTC Deopsit Token\", \"TDT\")\\n    DepositFactoryAuthority(\\_depositFactory)\\npublic {\\n    // solium-disable-previous-line no-empty-blocks\\n}\\n```\\n
Incorrect response from price feed if called during an onERC1155Received callback  AcknowledgedчmediumчThe ERC 1155 standard requires that smart contracts must implement `onERC1155Received` and `onERC1155BatchReceived` to accept transfers.\\nThis means that on any token received, code run on the receiving smart contract.\\nIn `NiftyswapExchange` when adding / removing liquidity or buying tokens, the methods mentioned above are called when the tokens are sent. When this happens, the state of the contract is changed but not completed, the tokens are sent to the receiving smart contract but the state is not completely updated.\\nThis happens in these cases\\n`_baseToToken` (when buying tokens)\\n```\\n// // Refund Base Token if any\\nif (totalRefundBaseTokens > 0) {\\n  baseToken.safeTransferFrom(address(this), \\_recipient, baseTokenID, totalRefundBaseTokens, \"\");\\n}\\n\\n// Send Tokens all tokens purchased\\ntoken.safeBatchTransferFrom(address(this), \\_recipient, \\_tokenIds, \\_tokensBoughtAmounts, \"\");\\n```\\n\\n`_removeLiquidity`\\n```\\n// Transfer total Base Tokens and all Tokens ids\\nbaseToken.safeTransferFrom(address(this), \\_provider, baseTokenID, totalBaseTokens, \"\");\\ntoken.safeBatchTransferFrom(address(this), \\_provider, \\_tokenIds, tokenAmounts, \"\");\\n```\\n\\n`_addLiquidity`\\n```\\n// Mint liquidity pool tokens\\n\\_batchMint(\\_provider, \\_tokenIds, liquiditiesToMint, \"\");\\n\\n// Transfer all Base Tokens to this contract\\nbaseToken.safeTransferFrom(\\_provider, address(this), baseTokenID, totalBaseTokens, abi.encode(DEPOSIT\\_SIG));\\n```\\n\\nEach of these examples send some tokens to the smart contract, which triggers calling some code on the receiving smart contract.\\nWhile these methods have the `nonReentrant` modifier which protects them from re-netrancy, the result of the methods `getPrice_baseToToken` and `getPrice_tokenToBase` is affected. These 2 methods do not have the `nonReentrant` modifier.\\nThe price reported by the `getPrice_baseToToken` and `getPrice_tokenToBase` methods is incorrect (until after the end of the transaction) because they rely on the number of tokens owned by the NiftyswapExchange; which between the calls is not finalized. Hence the price reported will be incorrect.\\nThis gives the smart contract which receives the tokens, the opportunity to use other systems (if they exist) that rely on the result of `getPrice_baseToToken` and `getPrice_tokenToBase` to use the returned price to its advantage.\\nIt's important to note that this is a bug only if other systems rely on the price reported by this `NiftyswapExchange`. Also the current contract is not affected, nor its balances or internal ledger, only other systems relying on its reported price will be fooled.чResolution\\nThe design will not be modified. Horizon Games should clearly document this risk for 3rd parties seeking to use Niftyswap as a price feed.\\nBecause there is no way to enforce how other systems work, a restriction can be added on `NiftyswapExchange` to protect other systems (if any) that rely on `NiftyswapExchange` for price discovery.\\nAdding a `nonReentrant` modifier on the view methods `getPrice_baseToToken` and `getPrice_tokenToBase` will add a bit of protection for the ecosystem.чч```\\n// // Refund Base Token if any\\nif (totalRefundBaseTokens > 0) {\\n  baseToken.safeTransferFrom(address(this), \\_recipient, baseTokenID, totalRefundBaseTokens, \"\");\\n}\\n\\n// Send Tokens all tokens purchased\\ntoken.safeBatchTransferFrom(address(this), \\_recipient, \\_tokenIds, \\_tokensBoughtAmounts, \"\");\\n```\\n
Ether send function remainder handlingчlowчThe Ether send function depicted below implements logic to reimburse the sender if an extraneous amount is left in the contract after the disbursement.\\n```\\nfunction sendEth(address payable [] memory \\_to, uint256[] memory \\_value) public restrictedToOwner payable returns (bool \\_success) {\\n    // input validation\\n    require(\\_to.length == \\_value.length);\\n    require(\\_to.length <= 255);\\n\\n    // count values for refunding sender\\n    uint256 beforeValue = msg.value;\\n    uint256 afterValue = 0;\\n\\n    // loop through to addresses and send value\\n    for (uint8 i = 0; i < \\_to.length; i++) {\\n        afterValue = afterValue.add(\\_value[i]);\\n        assert(\\_to[i].send(\\_value[i]));\\n    }\\n\\n    // send back remaining value to sender\\n    uint256 remainingValue = beforeValue.sub(afterValue);\\n    if (remainingValue > 0) {\\n        assert(msg.sender.send(remainingValue));\\n    }\\n    return true;\\n}\\n```\\n\\nIt is also the only place where the `SafeMath` dependency is being used. More specifically to check there was no underflow in the arithmetic adding up the disbursed amounts.\\nHowever, since the individual sends would revert themselves should more Ether than what was available in the balance be specified these protection measures seem unnecessary.\\nNot only the above is true but the current codebase does not allow to take funds locked within the contract out in the off chance someone forced funds into this smart contract (e.g., by self-destructing some other smart contract containing funds into this one).чThe easiest way to handle both retiring `SafeMath` and returning locked funds would be to phase out all the intra-function arithmetic and just transferring `address(this).balance` to `msg.sender` at the end of the disbursement. Since all the funds in there are meant to be from the caller of the function this serves the purpose of returning extraneous funds to him well and, adding to that, it allows for some front-running fun if someone “self-destructed” funds to this smart contract by mistake.чч```\\nfunction sendEth(address payable [] memory \\_to, uint256[] memory \\_value) public restrictedToOwner payable returns (bool \\_success) {\\n    // input validation\\n    require(\\_to.length == \\_value.length);\\n    require(\\_to.length <= 255);\\n\\n    // count values for refunding sender\\n    uint256 beforeValue = msg.value;\\n    uint256 afterValue = 0;\\n\\n    // loop through to addresses and send value\\n    for (uint8 i = 0; i < \\_to.length; i++) {\\n        afterValue = afterValue.add(\\_value[i]);\\n        assert(\\_to[i].send(\\_value[i]));\\n    }\\n\\n    // send back remaining value to sender\\n    uint256 remainingValue = beforeValue.sub(afterValue);\\n    if (remainingValue > 0) {\\n        assert(msg.sender.send(remainingValue));\\n    }\\n    return true;\\n}\\n```\\n
Unneeded type cast of contract typeчlowчThe typecast being done on the `address` parameter in the lien below is unneeded.\\n```\\nERC20 token = ERC20(\\_tokenAddress);\\n```\\nчAssign the right type at the function parameter definition like so:\\n```\\n    function sendErc20(ERC20 _tokenAddress, address[] memory _to, uint256[] memory _value) public restrictedToOwner returns (bool _success) {\\n```\\nчч```\\nERC20 token = ERC20(\\_tokenAddress);\\n```\\n
Inadequate use of assertчlowчThe usage of `require` vs `assert` has always been a matter of discussion because of the fine lines distinguishing these transaction-terminating expressions.\\nHowever, the usage of the `assert` syntax in this case is not the most appropriate.\\nBorrowing the explanation from the latest solidity docs (v. https://solidity.readthedocs.io/en/latest/control-structures.html#id4) :\\n```\\nThe assert function should only be used to test for internal errors, and to check invariants. \\n```\\n\\nSince assert-style exceptions (using the `0xfe` opcode) consume all gas available to the call and require-style ones (using the `0xfd` opcode) do not since the Metropolis release when the `REVERT` instruction was added, the usage of `require` in the lines depicted in the examples section would only result in gas savings and the same security assumptions.\\nIn this case, even though the calls are being made to external contracts the supposedly abide to a predefined specification, this is by no means an invariant of the presented system since the component is external to the built system and its integrity cannot be formally verified.\\n```\\nassert(\\_to[i].send(\\_value[i]));\\n```\\n\\n```\\nassert(msg.sender.send(remainingValue));\\n```\\n\\n```\\nassert(token.transferFrom(msg.sender, \\_to[i], \\_value[i]) == true);\\n```\\nчExchange the `assert` statements for `require` ones.чч```\\nThe assert function should only be used to test for internal errors, and to check invariants. \\n```\\n
uint overflow may lead to stealing fundsчhighчIt's possible to create a delegation with a very huge amount which may result in a lot of critically bad malicious usages:\\n```\\nuint holderBalance = SkaleToken(contractManager.getContract(\"SkaleToken\")).balanceOf(holder);\\nuint lockedToDelegate = tokenState.getLockedCount(holder) - tokenState.getPurchasedAmount(holder);\\nrequire(holderBalance >= amount + lockedToDelegate, \"Delegator hasn't enough tokens to delegate\");\\n```\\n\\n`amount` is passed by a user as a parameter, so if it's close to `uint` max value, `amount + lockedToDelegate` would overflow and this requirement would pass.\\nHaving delegation with an almost infinite amount of tokens can lead to many various attacks on the system up to stealing funds and breaking everything.чUsing `SafeMath` everywhere should prevent this and other similar issues. There should be more critical attacks caused by overflows/underflows, so `SafeMath` should be used everywhere in the codebase.чч```\\nuint holderBalance = SkaleToken(contractManager.getContract(\"SkaleToken\")).balanceOf(holder);\\nuint lockedToDelegate = tokenState.getLockedCount(holder) - tokenState.getPurchasedAmount(holder);\\nrequire(holderBalance >= amount + lockedToDelegate, \"Delegator hasn't enough tokens to delegate\");\\n```\\n
Holders can burn locked fundsчhighчSkale token is a modified ERC-777 that allows locking some part of the balance. Locking is checked during every transfer:\\n```\\n// Property of the company SKALE Labs inc.---------------------------------\\n        uint locked = \\_getLockedOf(from);\\n        if (locked > 0) {\\n            require(\\_balances[from] >= locked + amount, \"Token should be unlocked for transferring\");\\n        }\\n//-------------------------------------------------------------------------\\n        \\_balances[from] = \\_balances[from].sub(amount);\\n        \\_balances[to] = \\_balances[to].add(amount);\\n```\\n\\nBut it's not checked during `burn` function and it's possible to “burn” `locked` tokens. Tokens will be burned, but `locked` amount will remain the same. That will result in having more `locked` tokens than the balance which may have very unpredictable behaviour.чAllow burning only unlocked tokens.чч```\\n// Property of the company SKALE Labs inc.---------------------------------\\n        uint locked = \\_getLockedOf(from);\\n        if (locked > 0) {\\n            require(\\_balances[from] >= locked + amount, \"Token should be unlocked for transferring\");\\n        }\\n//-------------------------------------------------------------------------\\n        \\_balances[from] = \\_balances[from].sub(amount);\\n        \\_balances[to] = \\_balances[to].add(amount);\\n```\\n
Node can unlink validatorчhighчValidators can link a node address to them by calling `linkNodeAddress` function:\\n```\\nfunction linkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\\n    uint validatorId = getValidatorId(validatorAddress);\\n    require(\\_validatorAddressToId[nodeAddress] == 0, \"Validator cannot override node address\");\\n    \\_validatorAddressToId[nodeAddress] = validatorId;\\n}\\n\\nfunction unlinkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\\n    uint validatorId = getValidatorId(validatorAddress);\\n    require(\\_validatorAddressToId[nodeAddress] == validatorId, \"Validator hasn't permissions to unlink node\");\\n    \\_validatorAddressToId[nodeAddress] = 0;\\n}\\n```\\n\\nAfter that, the node has the same rights and is almost indistinguishable from the validator. So the node can even remove validator's address from `_validatorAddressToId` list and take over full control over validator. Additionally, the node can even remove itself by calling `unlinkNodeAddress`, leaving validator with no control at all forever.\\nAlso, even without nodes, a validator can initially call `unlinkNodeAddress` to remove itself.чLinked nodes (and validator) should not be able to unlink validator's address from the `_validatorAddressToId` mapping.чч```\\nfunction linkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\\n    uint validatorId = getValidatorId(validatorAddress);\\n    require(\\_validatorAddressToId[nodeAddress] == 0, \"Validator cannot override node address\");\\n    \\_validatorAddressToId[nodeAddress] = validatorId;\\n}\\n\\nfunction unlinkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\\n    uint validatorId = getValidatorId(validatorAddress);\\n    require(\\_validatorAddressToId[nodeAddress] == validatorId, \"Validator hasn't permissions to unlink node\");\\n    \\_validatorAddressToId[nodeAddress] = 0;\\n}\\n```\\n
Unlocking funds after slashingчhighчThe initial funds can be unlocked if 51+% of them are delegated. However if any portion of the funds are slashed, the rest of the funds will not be unlocked at the end of the delegation period.\\n```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n```\\nчConsider slashed tokens as delegated, or include them in the calculation for process to unlock in `endingDelegatedToUnlocked`чч```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n```\\n
Bounties and fees should only be locked for the first 3 monthsчhighчBounties are currently locked for the first 3 months after delegation:\\n```\\nskaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\\n```\\n\\nInstead, they should be locked for the first 3 months after the token launch.чIt's better just to forbid any withdrawals for the first 3 months, no need to track it separately for every delegation. This recommendation is mainly to simplify the process.чч```\\nskaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\\n```\\n
getLockedCount is iterating over all history of delegationsчhighч`getLockedCount` is iterating over all delegations of a specific holder and may even change the state of these delegations by calling `getState`.\\n```\\nfunction getLockedCount(address holder) external returns (uint amount) {\\n    amount = 0;\\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\\n    uint[] memory delegationIds = delegationController.getDelegationsByHolder(holder);\\n    for (uint i = 0; i < delegationIds.length; ++i) {\\n        uint id = delegationIds[i];\\n        if (isLocked(getState(id))) {\\n            amount += delegationController.getDelegation(id).amount;\\n        }\\n    }\\n    return amount + getPurchasedAmount(holder) + this.getSlashedAmount(holder);\\n}\\n```\\n\\nThis problem is major because delegations number is growing over time and may even potentially grow more than the gas limit and lock all tokens forever. `getLockedCount` is called during every transfer which makes any token transfer much more expensive than it should be.чRemove iterations over a potentially unlimited amount of tokens. All the necessary data can be precalculated before and `getLockedCount` function can have O(1) complexity.чч```\\nfunction getLockedCount(address holder) external returns (uint amount) {\\n    amount = 0;\\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\\n    uint[] memory delegationIds = delegationController.getDelegationsByHolder(holder);\\n    for (uint i = 0; i < delegationIds.length; ++i) {\\n        uint id = delegationIds[i];\\n        if (isLocked(getState(id))) {\\n            amount += delegationController.getDelegation(id).amount;\\n        }\\n    }\\n    return amount + getPurchasedAmount(holder) + this.getSlashedAmount(holder);\\n}\\n```\\n
Tokens are unlocked only when delegation endsчhighчAfter the first 3 months since at least 50% of tokens are delegated, all tokens should be unlocked. In practice, they are only unlocked if at least 50% of tokens, that were bought on the initial launch, are undelegated.\\n```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n}\\n```\\nчImplement lock mechanism according to the legal requirement.чч```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n}\\n```\\n
Tokens after delegation should not be unlocked automaticallyчhighчWhen some amount of tokens are delegated to a validator when the delegation period ends, these tokens are unlocked. However these tokens should be added to `_purchased` as they were in that state before their delegation.\\n```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n}\\n```\\nчTokens should only be unlocked if the main legal requirement `(_totalDelegated[holder] >= _purchased[holder])` is satisfied, which in the above case this has not happened.чч```\\nif (\\_isPurchased[delegationId]) {\\n    address holder = delegation.holder;\\n    \\_totalDelegated[holder] += delegation.amount;\\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\\n        purchasedToUnlocked(holder);\\n    }\\n}\\n```\\n
Some unlocked tokens can become locked after delegation is rejectedчhighчWhen some amount of tokens are requested to be delegated to a validator, the validator can reject the request. The previous status of these tokens should be intact and not changed (locked or unlocked).\\nHere the initial status of tokens gets stored and it's either completely `locked` or unlocked:\\n```\\nif (\\_purchased[delegation.holder] > 0) {\\n    \\_isPurchased[delegationId] = true;\\n    if (\\_purchased[delegation.holder] > delegation.amount) {\\n        \\_purchased[delegation.holder] -= delegation.amount;\\n    } else {\\n        \\_purchased[delegation.holder] = 0;\\n    }\\n} else {\\n    \\_isPurchased[delegationId] = false;\\n}\\n```\\n\\nThe problem is that if some amount of these tokens are locked at the time of the request and the rest tokens are unlocked, they will all be considered as locked after the delegation was rejected.\\n```\\nfunction \\_cancel(uint delegationId, DelegationController.Delegation memory delegation) internal returns (State state) {\\n    if (\\_isPurchased[delegationId]) {\\n        state = purchasedProposedToPurchased(delegationId, delegation);\\n    } else {\\n        state = proposedToUnlocked(delegationId);\\n    }\\n}\\n```\\nчDon't change the status of the rejected tokens.чч```\\nif (\\_purchased[delegation.holder] > 0) {\\n    \\_isPurchased[delegationId] = true;\\n    if (\\_purchased[delegation.holder] > delegation.amount) {\\n        \\_purchased[delegation.holder] -= delegation.amount;\\n    } else {\\n        \\_purchased[delegation.holder] = 0;\\n    }\\n} else {\\n    \\_isPurchased[delegationId] = false;\\n}\\n```\\n
Gas limit for bounty and slashing distributionчhighчAfter every bounty payment (should be once per month) to a validator, the bounty is distributed to all delegators. In order to do that, there is a `for` loop that iterates over all active delegators and sends their bounty to `SkaleBalances` contract:\\n```\\nfor (uint i = 0; i < shares.length; ++i) {\\n    skaleToken.send(address(skaleBalances), shares[i].amount, abi.encode(shares[i].holder));\\n\\n    uint created = delegationController.getDelegation(shares[i].delegationId).created;\\n    uint delegationStarted = timeHelpers.getNextMonthStartFromDate(created);\\n    skaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\\n}\\n```\\n\\nThere are also few more loops over all the active delegators. This leads to a huge gas cost of distribution mechanism. A number of active delegators that can be processed before hitting the gas limit is limited and not big enough.\\nThe same issue is with slashing:\\n```\\nfunction slash(uint validatorId, uint amount) external allow(\"SkaleDKG\") {\\n    ValidatorService validatorService = ValidatorService(contractManager.getContract(\"ValidatorService\"));\\n    require(validatorService.validatorExists(validatorId), \"Validator does not exist\");\\n\\n    Distributor distributor = Distributor(contractManager.getContract(\"Distributor\"));\\n    TokenState tokenState = TokenState(contractManager.getContract(\"TokenState\"));\\n\\n    Distributor.Share[] memory shares = distributor.distributePenalties(validatorId, amount);\\n    for (uint i = 0; i < shares.length; ++i) {\\n        tokenState.slash(shares[i].delegationId, shares[i].amount);\\n    }\\n}\\n```\\nчThe best solution would require major changes to the codebase, but would eventually make it simpler and safer. Instead of distributing and centrally calculating bounty for each delegator during one call it's better to just store all the necessary values, so delegator would be able to calculate the bounty on withdrawal. Amongst the necessary values, there should be history of total delegated amounts per validator during each bounty payment and history of all delegations with durations of their active state.чч```\\nfor (uint i = 0; i < shares.length; ++i) {\\n    skaleToken.send(address(skaleBalances), shares[i].amount, abi.encode(shares[i].holder));\\n\\n    uint created = delegationController.getDelegation(shares[i].delegationId).created;\\n    uint delegationStarted = timeHelpers.getNextMonthStartFromDate(created);\\n    skaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\\n}\\n```\\n
Delegations might stuck in non-active validator  PendingчmediumчIf a validator does not get enough funds to run a node (MSR - Minimum staking requirement), all token holders that delegated tokens to the validator cannot switch to a different validator, and might result in funds getting stuck with the nonfunctioning validator for up to 12 months.\\nExample\\n```\\nrequire((validatorNodes.length + 1) \\* msr <= delegationsTotal, \"Validator has to meet Minimum Staking Requirement\");\\n```\\nчResolution\\nSkale team acknowledged this issue and will address this in future versions.\\nAllow token holders to withdraw delegation earlier if the validator didn't get enough funds for running nodes.чч```\\nrequire((validatorNodes.length + 1) \\* msr <= delegationsTotal, \"Validator has to meet Minimum Staking Requirement\");\\n```\\n
Disabled Validators still have delegated funds  PendingчmediumчThe owner of `ValidatorService` contract can enable and disable validators. The issue is that when a validator is disabled, it still has its delegations, and delegated funds will be locked until the end of their delegation period (up to 12 months).\\n```\\nfunction enableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\\n    trustedValidators[validatorId] = true;\\n}\\n\\nfunction disableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\\n    trustedValidators[validatorId] = false;\\n}\\n```\\nчIt might make sense to release all delegations and stop validator's nodes if it's not trusted anymore. However, the rationale behind disabling the validators might be different that what we think, in any case there should be a way to handle this scenario, where the validator is disabled but there are funds delegated to it.чч```\\nfunction enableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\\n    trustedValidators[validatorId] = true;\\n}\\n\\nfunction disableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\\n    trustedValidators[validatorId] = false;\\n}\\n```\\n
_endingDelegations list is redundantчmediumч`_endingDelegations` is a list of delegations that is created for optimisation purposes. But the only place it's used is in `getPurchasedAmount` function, so only a subset of all delegations is going to be updated.\\n```\\nfunction getPurchasedAmount(address holder) public returns (uint amount) {\\n    // check if any delegation was ended\\n    for (uint i = 0; i < \\_endingDelegations[holder].length; ++i) {\\n        getState(\\_endingDelegations[holder][i]);\\n    }\\n    return \\_purchased[holder];\\n```\\n\\nBut `getPurchasedAmount` function is mostly used after iterating over all delegations of the holder.чResolution\\nIssue is fixed as a part of the major code changes in skalenetwork/skale-manager#92\\nRemove `_endingDelegations` and switch to a mechanism that does not require looping through delegations list of potentially unlimited size.чч```\\nfunction getPurchasedAmount(address holder) public returns (uint amount) {\\n    // check if any delegation was ended\\n    for (uint i = 0; i < \\_endingDelegations[holder].length; ++i) {\\n        getState(\\_endingDelegations[holder][i]);\\n    }\\n    return \\_purchased[holder];\\n```\\n
Some functions are defined but not implementedчmediumчThere are many functions that are defined but not implemented. They have a revert with a message as not implemented.\\nThis results in complex code and reduces readability. Here is a some of these functions within the scope of this audit:\\n```\\nfunction getAllDelegationRequests() external returns(uint[] memory) {\\n    revert(\"Not implemented\");\\n}\\n\\nfunction getDelegationRequestsForValidator(uint validatorId) external returns (uint[] memory) {\\n    revert(\"Not implemented\");\\n}\\n```\\nчIf these functions are needed for this release, they must be implemented. If they are for future plan, it's better to remove the extra code in the smart contracts.чч```\\nfunction getAllDelegationRequests() external returns(uint[] memory) {\\n    revert(\"Not implemented\");\\n}\\n\\nfunction getDelegationRequestsForValidator(uint validatorId) external returns (uint[] memory) {\\n    revert(\"Not implemented\");\\n}\\n```\\n
tokenState.setState redundant checksчmediumч`tokenState.setState` is used to change the state of the token from:\\nPROPOSED to ACCEPTED (in accept())\\nDELEGATED to ENDING_DELEGATED (in `requestUndelegation()`\\nThe if/else statement in `setState` is too complicated and can be simplified, both to optimize gas usage and to increase readability.\\n```\\nfunction setState(uint delegationId, State newState) internal {\\n    TimeHelpers timeHelpers = TimeHelpers(contractManager.getContract(\"TimeHelpers\"));\\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\\n\\n    require(newState != State.PROPOSED, \"Can't set state to proposed\");\\n\\n    if (newState == State.ACCEPTED) {\\n        State currentState = getState(delegationId);\\n        require(currentState == State.PROPOSED, \"Can't set state to accepted\");\\n\\n        \\_state[delegationId] = State.ACCEPTED;\\n        \\_timelimit[delegationId] = timeHelpers.getNextMonthStart();\\n    } else if (newState == State.DELEGATED) {\\n        revert(\"Can't set state to delegated\");\\n    } else if (newState == State.ENDING\\_DELEGATED) {\\n        require(getState(delegationId) == State.DELEGATED, \"Can't set state to ending delegated\");\\n        DelegationController.Delegation memory delegation = delegationController.getDelegation(delegationId);\\n\\n        \\_state[delegationId] = State.ENDING\\_DELEGATED;\\n        \\_timelimit[delegationId] = timeHelpers.calculateDelegationEndTime(delegation.created, delegation.delegationPeriod, 3);\\n        \\_endingDelegations[delegation.holder].push(delegationId);\\n    } else {\\n        revert(\"Unknown state\");\\n    }\\n}\\n```\\nчSome of the changes that do not change the functionality of the `setState` function:\\nRemove `reverts()` and add the valid states to the `require()` at the beginning of the function\\nRemove multiple calls to `getState()`\\nRemove final else/revert as this is an internal function and States passed should be valid More optimization can be done which requires further understanding of the system and the state machine.\\n```\\nfunction setState(uint delegationId, State newState) internal {\\n        TimeHelpers timeHelpers = TimeHelpers(contractManager.getContract(\"TimeHelpers\"));\\n        DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\\n\\n        require(newState != State.PROPOSED || newState != State.DELEGATED, \"Invalid state change\");\\n        State currentState = getState(delegationId);\\n\\n        if (newState == State.ACCEPTED) {\\n            require(currentState == State.PROPOSED, \"Can't set state to accepted\");\\n\\n            \\_state[delegationId] = State.ACCEPTED;\\n            \\_timelimit[delegationId] = timeHelpers.getNextMonthStart();\\n        } else if (newState == State.ENDING\\_DELEGATED) {\\n            require(currentState == State.DELEGATED, \"Can't set state to ending delegated\");\\n            DelegationController.Delegation memory delegation = delegationController.getDelegation(delegationId);\\n\\n            \\_state[delegationId] = State.ENDING\\_DELEGATED;\\n            \\_timelimit[delegationId] = timeHelpers.calculateDelegationEndTime(delegation.created, delegation.delegationPeriod, 3);\\n            \\_endingDelegations[delegation.holder].push(delegationId);\\n        }\\n    }\\n```\\nчч```\\nfunction setState(uint delegationId, State newState) internal {\\n    TimeHelpers timeHelpers = TimeHelpers(contractManager.getContract(\"TimeHelpers\"));\\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\\n\\n    require(newState != State.PROPOSED, \"Can't set state to proposed\");\\n\\n    if (newState == State.ACCEPTED) {\\n        State currentState = getState(delegationId);\\n        require(currentState == State.PROPOSED, \"Can't set state to accepted\");\\n\\n        \\_state[delegationId] = State.ACCEPTED;\\n        \\_timelimit[delegationId] = timeHelpers.getNextMonthStart();\\n    } else if (newState == State.DELEGATED) {\\n        revert(\"Can't set state to delegated\");\\n    } else if (newState == State.ENDING\\_DELEGATED) {\\n        require(getState(delegationId) == State.DELEGATED, \"Can't set state to ending delegated\");\\n        DelegationController.Delegation memory delegation = delegationController.getDelegation(delegationId);\\n\\n        \\_state[delegationId] = State.ENDING\\_DELEGATED;\\n        \\_timelimit[delegationId] = timeHelpers.calculateDelegationEndTime(delegation.created, delegation.delegationPeriod, 3);\\n        \\_endingDelegations[delegation.holder].push(delegationId);\\n    } else {\\n        revert(\"Unknown state\");\\n    }\\n}\\n```\\n
Users can burn delegated tokens using re-entrancy attackчhighчWhen a user burns tokens, the following code is called:\\n```\\n        uint locked = \\_getAndUpdateLockedAmount(from);\\n        if (locked > 0) {\\n            require(\\_balances[from] >= locked.add(amount), \"Token should be unlocked for burning\");\\n        }\\n//-------------------------------------------------------------------------\\n\\n        \\_callTokensToSend(\\n            operator, from, address(0), amount, data, operatorData\\n        );\\n\\n        // Update state variables\\n        \\_totalSupply = \\_totalSupply.sub(amount);\\n        \\_balances[from] = \\_balances[from].sub(amount);\\n```\\n\\nThere is a callback function right after the check that there are enough unlocked tokens to burn. In this callback, the user can delegate all the tokens right before burning them without breaking the code flow.чResolution\\nMitigated in skalenetwork/skale-manager#128\\n`_callTokensToSend` should be called before checking for the unlocked amount of tokens, which is better defined as Checks-Effects-Interactions Pattern.чч```\\n        uint locked = \\_getAndUpdateLockedAmount(from);\\n        if (locked > 0) {\\n            require(\\_balances[from] >= locked.add(amount), \"Token should be unlocked for burning\");\\n        }\\n//-------------------------------------------------------------------------\\n\\n        \\_callTokensToSend(\\n            operator, from, address(0), amount, data, operatorData\\n        );\\n\\n        // Update state variables\\n        \\_totalSupply = \\_totalSupply.sub(amount);\\n        \\_balances[from] = \\_balances[from].sub(amount);\\n```\\n
Rounding errors after slashingчhighчWhen slashing happens `_delegatedToValidator` and `_effectiveDelegatedToValidator` values are reduced.\\n```\\nfunction confiscate(uint validatorId, uint amount) external {\\n    uint currentMonth = getCurrentMonth();\\n    Fraction memory coefficient = reduce(\\_delegatedToValidator[validatorId], amount, currentMonth);\\n    reduce(\\_effectiveDelegatedToValidator[validatorId], coefficient, currentMonth);\\n    putToSlashingLog(\\_slashesOfValidator[validatorId], coefficient, currentMonth);\\n    \\_slashes.push(SlashingEvent({reducingCoefficient: coefficient, validatorId: validatorId, month: currentMonth}));\\n}\\n```\\n\\nWhen holders process slashings, they reduce `_delegatedByHolderToValidator`, `_delegatedByHolder`, `_effectiveDelegatedByHolderToValidator` values.\\n```\\nif (oldValue > 0) {\\n    reduce(\\n        \\_delegatedByHolderToValidator[holder][validatorId],\\n        \\_delegatedByHolder[holder],\\n        \\_slashes[index].reducingCoefficient,\\n        month);\\n    reduce(\\n        \\_effectiveDelegatedByHolderToValidator[holder][validatorId],\\n        \\_slashes[index].reducingCoefficient,\\n        month);\\n    slashingSignals[index.sub(begin)].holder = holder;\\n    slashingSignals[index.sub(begin)].penalty = oldValue.sub(getAndUpdateDelegatedByHolderToValidator(holder, validatorId, month));\\n}\\n```\\n\\nAlso when holders are undelegating, they are calculating how many tokens from `delegations[delegationId].amount` were slashed.\\n```\\nuint amountAfterSlashing = calculateDelegationAmountAfterSlashing(delegationId);\\n```\\n\\nAll these values should be calculated one from another, but they all will have different rounding errors after slashing. For example, the assumptions that the total sum of all delegations from holder `X` to validator `Y` should still be equal to `_delegatedByHolderToValidator[X][Y]` is not true anymore. The problem is that these assumptions are still used. For example, when undelegating some delegation with delegated `amount` equals amount(after slashing), the holder will reduce `_delegatedByHolderToValidator[X][Y]`, `_delegatedByHolder[X]` and `_delegatedToValidator[Y]` by `amount`. Since rounding errors of all these values are different that will lead to 2 possible scenarios:\\nIf rounding error reduces `amount` not that much as other values, we can have `uint` underflow. This is especially dangerous because all calculations are delayed and we will know about underflow and `SafeMath` revert in the next month or later.\\nDevelopers already made sure that rounding errors are aligned in a correct way, and that the reduced value should always be larger than the subtracted, so there should not be underflow. This solution is very unstable because it's hard to verify it and keep in mind even during a small code change. 2. If rounding errors make `amount` smaller then it should be, when other values should be zero (for example, when all the delegations are undelegated), these values will become some very small values. The problem here is that it would be impossible to compare values to zero.чConsider not calling `revert` on these subtractions and make result value be equals to zero if underflow happens.\\nConsider comparing to some small `epsilon` value instead of zero. Or similar to the previous point, on every subtraction check if the value is smaller then `epsilon`, and make it zero if it is.чч```\\nfunction confiscate(uint validatorId, uint amount) external {\\n    uint currentMonth = getCurrentMonth();\\n    Fraction memory coefficient = reduce(\\_delegatedToValidator[validatorId], amount, currentMonth);\\n    reduce(\\_effectiveDelegatedToValidator[validatorId], coefficient, currentMonth);\\n    putToSlashingLog(\\_slashesOfValidator[validatorId], coefficient, currentMonth);\\n    \\_slashes.push(SlashingEvent({reducingCoefficient: coefficient, validatorId: validatorId, month: currentMonth}));\\n}\\n```\\n
Slashes do not affect bounty distributionчhighчWhen slashes are processed by a holder, only `_delegatedByHolderToValidator` and `_delegatedByHolder` values are reduced. But `_effectiveDelegatedByHolderToValidator` value remains the same. This value is used to distribute bounties amongst delegators. So slashing will not affect that distribution.\\n```\\nuint oldValue = getAndUpdateDelegatedByHolderToValidator(holder, validatorId);\\nif (oldValue > 0) {\\n    uint month = \\_slashes[index].month;\\n    reduce(\\n        \\_delegatedByHolderToValidator[holder][validatorId],\\n        \\_delegatedByHolder[holder],\\n        \\_slashes[index].reducingCoefficient,\\n        month);\\n    slashingSignals[index.sub(begin)].holder = holder;\\n    slashingSignals[index.sub(begin)].penalty = oldValue.sub(getAndUpdateDelegatedByHolderToValidator(holder, validatorId));\\n}\\n```\\nчReduce `_effectiveDelegatedByHolderToValidator` and `_effectiveDelegatedToValidator` when slashes are processed.чч```\\nuint oldValue = getAndUpdateDelegatedByHolderToValidator(holder, validatorId);\\nif (oldValue > 0) {\\n    uint month = \\_slashes[index].month;\\n    reduce(\\n        \\_delegatedByHolderToValidator[holder][validatorId],\\n        \\_delegatedByHolder[holder],\\n        \\_slashes[index].reducingCoefficient,\\n        month);\\n    slashingSignals[index.sub(begin)].holder = holder;\\n    slashingSignals[index.sub(begin)].penalty = oldValue.sub(getAndUpdateDelegatedByHolderToValidator(holder, validatorId));\\n}\\n```\\n
Storage operations optimizationчmediumчThere are a lot of operations that write some value to the storage (uses `SSTORE` opcode) without actually changing it.\\nIn `getAndUpdateValue` function of `DelegationController` and TokenLaunchLocker:\\n```\\nfor (uint i = sequence.firstUnprocessedMonth; i <= month; ++i) {\\n    sequence.value = sequence.value.add(sequence.addDiff[i]).sub(sequence.subtractDiff[i]);\\n    delete sequence.addDiff[i];\\n    delete sequence.subtractDiff[i];\\n}\\n```\\n\\nIn `handleSlash` function of `Punisher` contract `amount` will be zero in most cases:\\n```\\nfunction handleSlash(address holder, uint amount) external allow(\"DelegationController\") {\\n    \\_locked[holder] = \\_locked[holder].add(amount);\\n}\\n```\\nчResolution\\nMitigated in skalenetwork/skale-manager#179\\nCheck if the value is the same and don't write it to the storage in that case.чч```\\nfor (uint i = sequence.firstUnprocessedMonth; i <= month; ++i) {\\n    sequence.value = sequence.value.add(sequence.addDiff[i]).sub(sequence.subtractDiff[i]);\\n    delete sequence.addDiff[i];\\n    delete sequence.subtractDiff[i];\\n}\\n```\\n
Function overloadingчlowчSome functions in the codebase are overloaded. That makes code less readable and increases the probability of missing bugs.\\nFor example, there are a lot of `reduce` function implementations in DelegationController:\\n```\\nfunction reduce(PartialDifferencesValue storage sequence, uint amount, uint month) internal returns (Fraction memory) {\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return createFraction(0);\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return createFraction(0);\\n    }\\n\\n    uint \\_amount = amount;\\n    if (value < amount) {\\n        \\_amount = value;\\n    }\\n\\n    Fraction memory reducingCoefficient = createFraction(value.sub(\\_amount), value);\\n    reduce(sequence, reducingCoefficient, month);\\n    return reducingCoefficient;\\n}\\n\\nfunction reduce(PartialDifferencesValue storage sequence, Fraction memory reducingCoefficient, uint month) internal {\\n    reduce(\\n        sequence,\\n        sequence,\\n        reducingCoefficient,\\n        month,\\n        false);\\n}\\n\\nfunction reduce(\\n    PartialDifferencesValue storage sequence,\\n    PartialDifferencesValue storage sumSequence,\\n    Fraction memory reducingCoefficient,\\n    uint month) internal\\n{\\n    reduce(\\n        sequence,\\n        sumSequence,\\n        reducingCoefficient,\\n        month,\\n        true);\\n}\\n\\nfunction reduce(\\n    PartialDifferencesValue storage sequence,\\n    PartialDifferencesValue storage sumSequence,\\n    Fraction memory reducingCoefficient,\\n    uint month,\\n    bool hasSumSequence) internal\\n{\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    if (hasSumSequence) {\\n        require(month.add(1) >= sumSequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    }\\n    require(reducingCoefficient.numerator <= reducingCoefficient.denominator, \"Increasing of values is not implemented\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return;\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return;\\n    }\\n\\n    uint newValue = sequence.value.mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n    if (hasSumSequence) {\\n        subtract(sumSequence, sequence.value.sub(newValue), month);\\n    }\\n    sequence.value = newValue;\\n\\n    for (uint i = month.add(1); i <= sequence.lastChangedMonth; ++i) {\\n        uint newDiff = sequence.subtractDiff[i].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n        if (hasSumSequence) {\\n            sumSequence.subtractDiff[i] = sumSequence.subtractDiff[i].sub(sequence.subtractDiff[i].sub(newDiff));\\n        }\\n        sequence.subtractDiff[i] = newDiff;\\n    }\\n}\\n\\nfunction reduce(\\n    PartialDifferences storage sequence,\\n    Fraction memory reducingCoefficient,\\n    uint month) internal\\n{\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    require(reducingCoefficient.numerator <= reducingCoefficient.denominator, \"Increasing of values is not implemented\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return;\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return;\\n    }\\n\\n    sequence.value[month] = sequence.value[month].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n\\n    for (uint i = month.add(1); i <= sequence.lastChangedMonth; ++i) {\\n        sequence.subtractDiff[i] = sequence.subtractDiff[i].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n    }\\n}\\n```\\nчResolution\\nFixed in skalenetwork/skale-manager#181\\nAvoid function overloading as a general guideline.чч```\\nfunction reduce(PartialDifferencesValue storage sequence, uint amount, uint month) internal returns (Fraction memory) {\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return createFraction(0);\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return createFraction(0);\\n    }\\n\\n    uint \\_amount = amount;\\n    if (value < amount) {\\n        \\_amount = value;\\n    }\\n\\n    Fraction memory reducingCoefficient = createFraction(value.sub(\\_amount), value);\\n    reduce(sequence, reducingCoefficient, month);\\n    return reducingCoefficient;\\n}\\n\\nfunction reduce(PartialDifferencesValue storage sequence, Fraction memory reducingCoefficient, uint month) internal {\\n    reduce(\\n        sequence,\\n        sequence,\\n        reducingCoefficient,\\n        month,\\n        false);\\n}\\n\\nfunction reduce(\\n    PartialDifferencesValue storage sequence,\\n    PartialDifferencesValue storage sumSequence,\\n    Fraction memory reducingCoefficient,\\n    uint month) internal\\n{\\n    reduce(\\n        sequence,\\n        sumSequence,\\n        reducingCoefficient,\\n        month,\\n        true);\\n}\\n\\nfunction reduce(\\n    PartialDifferencesValue storage sequence,\\n    PartialDifferencesValue storage sumSequence,\\n    Fraction memory reducingCoefficient,\\n    uint month,\\n    bool hasSumSequence) internal\\n{\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    if (hasSumSequence) {\\n        require(month.add(1) >= sumSequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    }\\n    require(reducingCoefficient.numerator <= reducingCoefficient.denominator, \"Increasing of values is not implemented\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return;\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return;\\n    }\\n\\n    uint newValue = sequence.value.mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n    if (hasSumSequence) {\\n        subtract(sumSequence, sequence.value.sub(newValue), month);\\n    }\\n    sequence.value = newValue;\\n\\n    for (uint i = month.add(1); i <= sequence.lastChangedMonth; ++i) {\\n        uint newDiff = sequence.subtractDiff[i].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n        if (hasSumSequence) {\\n            sumSequence.subtractDiff[i] = sumSequence.subtractDiff[i].sub(sequence.subtractDiff[i].sub(newDiff));\\n        }\\n        sequence.subtractDiff[i] = newDiff;\\n    }\\n}\\n\\nfunction reduce(\\n    PartialDifferences storage sequence,\\n    Fraction memory reducingCoefficient,\\n    uint month) internal\\n{\\n    require(month.add(1) >= sequence.firstUnprocessedMonth, \"Can't reduce value in the past\");\\n    require(reducingCoefficient.numerator <= reducingCoefficient.denominator, \"Increasing of values is not implemented\");\\n    if (sequence.firstUnprocessedMonth == 0) {\\n        return;\\n    }\\n    uint value = getAndUpdateValue(sequence, month);\\n    if (value == 0) {\\n        return;\\n    }\\n\\n    sequence.value[month] = sequence.value[month].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n\\n    for (uint i = month.add(1); i <= sequence.lastChangedMonth; ++i) {\\n        sequence.subtractDiff[i] = sequence.subtractDiff[i].mul(reducingCoefficient.numerator).div(reducingCoefficient.denominator);\\n    }\\n}\\n```\\n
ERC20Lockable - inconsistent locking statusчlowч`Vega_Token.is_tradable()` will incorrectly return `false` if the token is never manually unlocked by the owner but `unlock_time` has passed, which will automatically unlock trading.\\n```\\n/\\*\\*\\n \\* @dev locked status, only applicable before unlock\\_date\\n \\*/\\nbool public \\_is\\_locked = true;\\n\\n/\\*\\*\\n \\* @dev Modifier that only allows function to run if either token is unlocked or time has expired.\\n \\* Throws if called while token is locked.\\n \\*/\\nmodifier onlyUnlocked() {\\n    require(!\\_is\\_locked || now > unlock\\_date);\\n    \\_;\\n}\\n\\n/\\*\\*\\n \\* @dev Internal function that unlocks token. Can only be ran before expiration (give that it's irrelevant after)\\n \\*/\\nfunction \\_unlock() internal {\\n    require(now <= unlock\\_date);\\n    \\_is\\_locked = false;\\n```\\nчdeclare `_is_locked` as `private` instead of `public`\\ncreate a getter method that correctly returns the locking status\\n```\\nfunction \\_isLocked() internal view {\\n       return !\\_is\\_locked || now > unlock\\_date;\\n}\\n```\\n\\nmake `modifier onlyUnlocked()` use the newly created getter (_isLocked())\\nmake `Vega_Token.is_tradeable()` use the newly created getter (_isLocked())\\n`_unlock()` should raise an errorcondition when called on an already unlocked contract\\nit could make sense to emit a “contract hast been unlocked” event for auditing purposesчч```\\n/\\*\\*\\n \\* @dev locked status, only applicable before unlock\\_date\\n \\*/\\nbool public \\_is\\_locked = true;\\n\\n/\\*\\*\\n \\* @dev Modifier that only allows function to run if either token is unlocked or time has expired.\\n \\* Throws if called while token is locked.\\n \\*/\\nmodifier onlyUnlocked() {\\n    require(!\\_is\\_locked || now > unlock\\_date);\\n    \\_;\\n}\\n\\n/\\*\\*\\n \\* @dev Internal function that unlocks token. Can only be ran before expiration (give that it's irrelevant after)\\n \\*/\\nfunction \\_unlock() internal {\\n    require(now <= unlock\\_date);\\n    \\_is\\_locked = false;\\n```\\n
Merkle.checkMembership allows existence proofs for the same leaf in multiple locations in the treeчhighч`checkMembership` is used by several contracts to prove that transactions exist in the child chain. The function uses a `leaf`, an `index`, and a `proof` to construct a hypothetical root hash. This constructed hash is compared to the passed in `rootHash` parameter. If the two are equivalent, the `proof` is considered valid.\\nThe proof is performed iteratively, and uses a pseudo-index (j) to determine whether the next proof element represents a “left branch” or “right branch”:\\n```\\nuint256 j = index;\\n// Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\\nfor (uint256 i = 32; i <= proof.length; i += 32) {\\n    // solhint-disable-next-line no-inline-assembly\\n    assembly {\\n        proofElement := mload(add(proof, i))\\n    }\\n    if (j % 2 == 0) {\\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, computedHash, proofElement));\\n    } else {\\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, proofElement, computedHash));\\n    }\\n    j = j / 2;\\n}\\n```\\n\\nIf `j` is even, the computed hash is placed before the next proof element. If `j` is odd, the computed hash is placed after the next proof element. After each iteration, `j` is decremented by `j` = `j` / 2.\\nBecause `checkMembership` makes no requirements on the height of the tree or the size of the proof relative to the provided `index`, it is possible to pass in invalid values for `index` that prove a leaf's existence in multiple locations in the tree.\\nBy modifying existing tests, we showed that for a tree with 3 leaves, leaf 2 can be proven to exist at indices 2, 6, and 10 using the same proof each time. The modified test can be found here: https://gist.github.com/wadeAlexC/01b60099282a026f8dc1ac85d83489fd#file-merkle-test-js-L40-L67\\n```\\nit('should accidentally allow different indices to use the same proof', async () => {\\n  const rootHash = this.merkleTree.root;\\n  const proof = this.merkleTree.getInclusionProof(leaves[2]);\\n\\n  const result = await this.merkleContract.checkMembership(\\n    leaves[2],\\n    2,\\n    rootHash,\\n    proof,\\n  );\\n  expect(result).to.be.true;\\n\\n  const nextResult = await this.merkleContract.checkMembership(\\n    leaves[2],\\n    6,\\n    rootHash,\\n    proof,\\n  );\\n  expect(nextResult).to.be.true;\\n\\n  const nextNextResult = await this.merkleContract.checkMembership(\\n    leaves[2],\\n    10,\\n    rootHash,\\n    proof,\\n  );\\n  expect(nextNextResult).to.be.true;\\n});\\n```\\n\\nConclusion\\nExit processing is meant to bypass exits processed more than once. This is implemented using an “output id” system, where each exited output should correspond to a unique id that gets flagged in the `ExitGameController` contract as it's exited. Before an exit is processed, its output id is calculated and checked against `ExitGameController`. If the output has already been exited, the exit being processed is deleted and skipped. Crucially, output id is calculated differently for standard transactions and deposit transactions: deposit output ids factor in the transaction index.\\nBy using the behavior described in this issue in conjunction with methods discussed in issue 5.8 and https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/20, we showed that deposit transactions can be exited twice using indices `0` and `2**16`. Because of the distinct output id calculation, these exits have different output ids and can be processed twice, allowing users to exit double their deposited amount.\\nA modified `StandardExit.load.test.js` shows that exits are successfully enqueued with a transaction index of 65536: https://gist.github.com/wadeAlexC/4ad459b7510e512bc9556e7c919e0965#file-standardexit-load-test-js-L55чUse the length of the proof to determine the maximum allowed index. The passed-in index should satisfy the following criterion: `index < 2**(proof.length/32)`. Additionally, ensure range checks on transaction position decoding are sufficiently restrictive (see https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/20).\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/546чч```\\nuint256 j = index;\\n// Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\\nfor (uint256 i = 32; i <= proof.length; i += 32) {\\n    // solhint-disable-next-line no-inline-assembly\\n    assembly {\\n        proofElement := mload(add(proof, i))\\n    }\\n    if (j % 2 == 0) {\\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, computedHash, proofElement));\\n    } else {\\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, proofElement, computedHash));\\n    }\\n    j = j / 2;\\n}\\n```\\n
Improper initialization of spending condition abstraction allows “v2 transactions” to exit using PaymentExitGameчhighч`PaymentOutputToPaymentTxCondition` is an abstraction around the transaction signature check needed for many components of the exit games. Its only function, `verify`, returns `true` if one transaction (inputTxBytes) is spent by another transaction (spendingTxBytes):\\n```\\nfunction verify(\\n    bytes calldata inputTxBytes,\\n    uint16 outputIndex,\\n    uint256 inputTxPos,\\n    bytes calldata spendingTxBytes,\\n    uint16 inputIndex,\\n    bytes calldata signature,\\n    bytes calldata /\\*optionalArgs\\*/\\n)\\n    external\\n    view\\n    returns (bool)\\n{\\n    PaymentTransactionModel.Transaction memory inputTx = PaymentTransactionModel.decode(inputTxBytes);\\n    require(inputTx.txType == supportInputTxType, \"Input tx is an unsupported payment tx type\");\\n\\n    PaymentTransactionModel.Transaction memory spendingTx = PaymentTransactionModel.decode(spendingTxBytes);\\n    require(spendingTx.txType == supportSpendingTxType, \"The spending tx is an unsupported payment tx type\");\\n\\n    UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.build(TxPosLib.TxPos(inputTxPos), outputIndex);\\n    require(\\n        spendingTx.inputs[inputIndex] == bytes32(utxoPos.value),\\n        \"Spending tx points to the incorrect output UTXO position\"\\n    );\\n\\n    address payable owner = inputTx.outputs[outputIndex].owner();\\n    require(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");\\n\\n    return true;\\n}\\n```\\n\\nVerification process\\nThe verification process is relatively straightforward. The contract performs some basic input validation, checking that the input transaction's `txType` matches `supportInputTxType`, and that the spending transaction's `txType` matches `supportSpendingTxType`. These values are set during construction.\\nNext, `verify` checks that the spending transaction contains an input that matches the position of one of the input transaction's outputs.\\nFinally, `verify` performs an EIP-712 hash on the spending transaction, and ensures it is signed by the owner of the output in question.\\nImplications of the abstraction\\nThe abstraction used requires several files to be visited to fully understand the function of each line of code: `ISpendingCondition`, `PaymentEIP712Lib`, `UtxoPosLib`, `TxPosLib`, `PaymentTransactionModel`, `PaymentOutputModel`, `RLPReader`, `ECDSA`, and `SpendingConditionRegistry`. Additionally, the abstraction obfuscates the underlying spending condition verification primitive where used.\\nFinally, understanding the abstraction requires an understanding of how `SpendingConditionRegistry` is initialized, as well as the nature of its relationship with `PlasmaFramework` and `ExitGameRegistry`. The aforementioned `txType` values, `supportInputTxType` and `supportSpendingTxType`, are set during construction. Their use in `ExitGameRegistry` seems to suggest they are intended to represent different versions of transaction types, and that separate exit game contracts are meant to handle different transaction types:\\n```\\n/\\*\\*\\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\\n \\* @dev Emits ExitGameRegistered event to notify clients\\n \\* @param \\_txType The tx type where the exit game wants to register\\n \\* @param \\_contract Address of the exit game contract\\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\\n \\*/\\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\\n    require(\\_txType != 0, \"Should not register with tx type 0\");\\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\\n\\n    \\_exitGames[\\_txType] = \\_contract;\\n    \\_exitGameToTxType[\\_contract] = \\_txType;\\n    \\_protocols[\\_txType] = \\_protocol;\\n    \\_exitGameQuarantine.quarantine(\\_contract);\\n\\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\\n}\\n```\\n\\nMigration and initialization\\nThe migration script seems to corroborate this interpretation:\\ncode/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L109-L124\\n```\\n// handle spending condition\\nawait deployer.deploy(\\n    PaymentOutputToPaymentTxCondition,\\n    plasmaFramework.address,\\n    PAYMENT\\_OUTPUT\\_TYPE,\\n    PAYMENT\\_TX\\_TYPE,\\n);\\nconst paymentToPaymentCondition = await PaymentOutputToPaymentTxCondition.deployed();\\n\\nawait deployer.deploy(\\n    PaymentOutputToPaymentTxCondition,\\n    plasmaFramework.address,\\n    PAYMENT\\_OUTPUT\\_TYPE,\\n    PAYMENT\\_V2\\_TX\\_TYPE,\\n);\\nconst paymentToPaymentV2Condition = await PaymentOutputToPaymentTxCondition.deployed();\\n```\\n\\nThe migration script shown above deploys two different versions of `PaymentOutputToPaymentTxCondition`. The first sets `supportInputTxType` and `supportSpendingTxType` to `PAYMENT_OUTPUT_TYPE` and `PAYMENT_TX_TYPE`, respectively. The second sets those same variables to `PAYMENT_OUTPUT_TYPE` and `PAYMENT_V2_TX_TYPE`, respectively.\\nThe migration script then registers both of these contracts in `SpendingConditionRegistry`, and then calls `renounceOwnership`, freezing the spending conditions registered permanently:\\ncode/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L126-L135\\n```\\nconsole.log(`Registering paymentToPaymentCondition (${paymentToPaymentCondition.address}) to spendingConditionRegistry`);\\nawait spendingConditionRegistry.registerSpendingCondition(\\n    PAYMENT\\_OUTPUT\\_TYPE, PAYMENT\\_TX\\_TYPE, paymentToPaymentCondition.address,\\n);\\n\\nconsole.log(`Registering paymentToPaymentV2Condition (${paymentToPaymentV2Condition.address}) to spendingConditionRegistry`);\\nawait spendingConditionRegistry.registerSpendingCondition(\\n    PAYMENT\\_OUTPUT\\_TYPE, PAYMENT\\_V2\\_TX\\_TYPE, paymentToPaymentV2Condition.address,\\n);\\nawait spendingConditionRegistry.renounceOwnership();\\n```\\n\\nFinally, the migration script registers a single exit game contract in PlasmaFramework:\\ncode/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L137-L143\\n```\\n// register the exit game to framework\\nawait plasmaFramework.registerExitGame(\\n    PAYMENT\\_TX\\_TYPE,\\n    paymentExitGame.address,\\n    config.frameworks.protocols.moreVp,\\n    { from: maintainerAddress },\\n);\\n```\\n\\nNote that the associated `_txType` is permanently associated with the deployed exit game contract:\\n```\\n/\\*\\*\\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\\n \\* @dev Emits ExitGameRegistered event to notify clients\\n \\* @param \\_txType The tx type where the exit game wants to register\\n \\* @param \\_contract Address of the exit game contract\\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\\n \\*/\\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\\n    require(\\_txType != 0, \"Should not register with tx type 0\");\\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\\n\\n    \\_exitGames[\\_txType] = \\_contract;\\n    \\_exitGameToTxType[\\_contract] = \\_txType;\\n    \\_protocols[\\_txType] = \\_protocol;\\n    \\_exitGameQuarantine.quarantine(\\_contract);\\n\\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\\n}\\n```\\n\\nConclusion\\nCrucially, this association is never used. It is implied heavily that transactions with some `txType` must use a certain registered exit game contract. In fact, this is not true. When using `PaymentExitGame`, its routers, and their associated controllers, the `txType` is invariably inferred from the encoded transaction, not from the mappings in `ExitGameRegistry`. If initialized as-is, both `PAYMENT_TX_TYPE` and `PAYMENT_V2_TX_TYPE` transactions may be exited using `PaymentExitGame`, provided they exist in the plasma chain.чRemove `PaymentOutputToPaymentTxCondition` and `SpendingConditionRegistry`\\nImplement checks for specific spending conditions directly in exit game controllers. Emphasize clarity of function: ensure it is clear when called from the top level that a signature verification check and spending condition check are being performed.\\nIf the inferred relationship between `txType` and `PaymentExitGame` is correct, ensure that each `PaymentExitGame` router checks for its supported `txType`. Alternatively, the check could be made in `PaymentExitGame` itself.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/472чч```\\nfunction verify(\\n    bytes calldata inputTxBytes,\\n    uint16 outputIndex,\\n    uint256 inputTxPos,\\n    bytes calldata spendingTxBytes,\\n    uint16 inputIndex,\\n    bytes calldata signature,\\n    bytes calldata /\\*optionalArgs\\*/\\n)\\n    external\\n    view\\n    returns (bool)\\n{\\n    PaymentTransactionModel.Transaction memory inputTx = PaymentTransactionModel.decode(inputTxBytes);\\n    require(inputTx.txType == supportInputTxType, \"Input tx is an unsupported payment tx type\");\\n\\n    PaymentTransactionModel.Transaction memory spendingTx = PaymentTransactionModel.decode(spendingTxBytes);\\n    require(spendingTx.txType == supportSpendingTxType, \"The spending tx is an unsupported payment tx type\");\\n\\n    UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.build(TxPosLib.TxPos(inputTxPos), outputIndex);\\n    require(\\n        spendingTx.inputs[inputIndex] == bytes32(utxoPos.value),\\n        \"Spending tx points to the incorrect output UTXO position\"\\n    );\\n\\n    address payable owner = inputTx.outputs[outputIndex].owner();\\n    require(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");\\n\\n    return true;\\n}\\n```\\n
RLPReader - Leading zeroes allow multiple valid encodings and exit / output ids for the same transactionчhighчThe current implementation of RLP decoding can take 2 different `txBytes` and decode them to the same structure. Specifically, the `RLPReader.toUint` method can decode 2 different types of bytes to the same number. For example:\\n`0x821234` is decoded to `uint(0x1234)`\\n`0x83001234` is decoded to `uint(0x1234)`\\n`0xc101` can decode to `uint(1)`, even though the tag specifies a short list\\n`0x01` can decode to `uint(1)`, even though the tag specifies a single byte\\nAs explanation for this encoding:\\n`0x821234` is broken down into 2 parts:\\n`0x82` - represents `0x80` (the string tag) + `0x02` bytes encoded\\n`0x1234` - are the encoded bytes\\nThe same for 0x83001234:\\n`0x83` - represents `0x80` (the string tag) + `0x03` bytes encoded\\n`0x001234` - are the encoded bytes\\nThe current implementation casts the encoded bytes into a uint256, so these different encodings are interpreted by the contracts as the same number:\\n`uint(0x1234) = uint(0x001234)`\\n```\\nresult := mload(memPtr)\\n```\\n\\nHaving different valid encodings for the same data is a problem because the encodings are used to create hashes that are used as unique ids. This means that multiple ids can be created for the same data. The data should only have one possible id.\\nThe encoding is used to create ids in these parts of the code:\\n```\\nreturn keccak256(abi.encodePacked(\\_txBytes, \\_outputIndex, \\_utxoPosValue));\\n```\\n\\n```\\nreturn keccak256(abi.encodePacked(\\_txBytes, \\_outputIndex));\\n```\\n\\n```\\nbytes32 hashData = keccak256(abi.encodePacked(\\_txBytes, \\_utxoPos.value));\\n```\\n\\n```\\nreturn uint160((uint256(keccak256(\\_txBytes))  105).setBit(151));\\n```\\n\\n```\\nbytes32 leafData = keccak256(data.txBytes);\\n```\\n\\nOther methods that are affected because they rely on the return values of these methods:чEnforce strict-length decoding for `txBytes`, and specify that `uint` is decoded from a 32-byte short string.\\nEnforcing a 32-byte length for `uint` means that `0x1234` should always be encoded as:\\n`0xa00000000000000000000000000000000000000000000000000000000000001234`\\n`0xa0` represents the tag + the length: `0x80 + 32`\\n`0000000000000000000000000000000000000000000000000000000000001234` is the number 32 bytes long with leading zeroes\\nUnfortunately, using leading zeroes is against the RLP spec:\\nhttps://github.com/ethereum/wiki/wiki/RLP\\npositive RLP integers must be represented in big endian binary form with no leading zeroes\\nThis means that libraries interacting with OMG contracts which are going to correctly and fully implement the spec will generate “incorrect” encodings for uints; encodings that are not going to be recognized by the OMG contracts.\\nFully correct spec encoding: `0x821234`. Proposed encoding in this solution: `0xa00000000000000000000000000000000000000000000000000000000000001234`.\\nSimilarly enforce restrictions where they can be added; this is possible because of the strict structure format that needs to be encoded.\\nSome other potential solutions are included below. Note that these solutions are not recommended for reasons included below:\\nNormalize the encoding that gets passed to methods that hash the transaction for use as an id:\\nThis can be implemented in the methods that call `keccak256` on `txBytes` and should decode and re-encode the passed `txBytes` in order to normalize the passed encoding.\\na `txBytes` is passed\\nthe `txBytes` are decoded into structure: `tmpDecodedStruct` = decode(txBytes)\\nthe `tmpDecodedStruct` is re-encoded in order to normalize it: `normalizedTxBytes = encode(txBytes)`\\nThis method is not recommended because it needs a Solidity encoder to be implemented and a lot of gas will be used to decode and re-encode the initial `txBytes`.\\nCorrectly and fully implement RLP decoding\\nThis is another solution that adds a lot of code and is prone to errors.\\nThe solution would be to enforce all of the restrictions when decoding and not accept any encoding that doesn't fully follow the spec. This for example means that is should not accept uints with leading zeroes.\\nThis is a problem because it needs a lot of code that is not easy to write in Solidity (or EVM).чч```\\nresult := mload(memPtr)\\n```\\n
Recommendation: Remove TxFinalizationModel and TxFinalizationVerifier. Implement stronger checks in Merkleчmediumч`TxFinalizationVerifier` is an abstraction around the block inclusion check needed for many of the features of plasma exit games. It uses a struct defined in `TxFinalizationModel` as inputs to its two functions: `isStandardFinalized` and `isProtocolFinalized`.\\n`isStandardFinalized` returns the result of an inclusion proof. Although there are several branches, only the first is used:\\n```\\n/\\*\\*\\n\\* @notice Checks whether a transaction is \"standard finalized\"\\n\\* @dev MVP: requires that both inclusion proof and confirm signature is checked\\n\\* @dev MoreVp: checks inclusion proof only\\n\\*/\\nfunction isStandardFinalized(Model.Data memory data) public view returns (bool) {\\n    if (data.protocol == Protocol.MORE\\_VP()) {\\n        return checkInclusionProof(data);\\n    } else if (data.protocol == Protocol.MVP()) {\\n        revert(\"MVP is not yet supported\");\\n    } else {\\n        revert(\"Invalid protocol value\");\\n    }\\n}\\n```\\n\\n`isProtocolFinalized` is unused:\\n```\\n/\\*\\*\\n\\* @notice Checks whether a transaction is \"protocol finalized\"\\n\\* @dev MVP: must be standard finalized\\n\\* @dev MoreVp: allows in-flight tx, so only checks for the existence of the transaction\\n\\*/\\nfunction isProtocolFinalized(Model.Data memory data) public view returns (bool) {\\n    if (data.protocol == Protocol.MORE\\_VP()) {\\n        return data.txBytes.length > 0;\\n    } else if (data.protocol == Protocol.MVP()) {\\n        revert(\"MVP is not yet supported\");\\n    } else {\\n        revert(\"Invalid protocol value\");\\n    }\\n}\\n```\\n\\nThe abstraction used introduces branching logic and requires several files to be visited to fully understand the function of each line of code: `ITxFinalizationVerifier`, `TxFinalizationModel`, `TxPosLib`, `Protocol`, `BlockController`, and `Merkle`. Additionally, the abstraction obfuscates the underlying inclusion proof primitive when used in the exit game contracts. `isStandardFinalized` is not clearly an inclusion proof, and `isProtocolFinalized` simply adds confusion.\\n```\\nfunction checkInclusionProof(Model.Data memory data) private view returns (bool) {\\n    if (data.inclusionProof.length == 0) {\\n        return false;\\n    }\\n\\n    (bytes32 root,) = data.framework.blocks(data.txPos.blockNum());\\n    bytes32 leafData = keccak256(data.txBytes);\\n    return Merkle.checkMembership(\\n        leafData, data.txPos.txIndex(), root, data.inclusionProof\\n    );\\n}\\n```\\n\\nBy introducing the abstraction of `TxFinalizationVerifier`, the input validation performed by `Merkle` is split across multiple files, and the reasonable-seeming decision of calling `Merkle.checkMembership` directly becomes unsafe. In fact, this occurs in one location in the contracts:\\n```\\nfunction verifyAndDeterminePositionOfTransactionIncludedInBlock(\\n    bytes memory txbytes,\\n    UtxoPosLib.UtxoPos memory utxoPos,\\n    bytes32 root,\\n    bytes memory inclusionProof\\n)\\n    private\\n    pure\\n    returns(uint256)\\n{\\n    bytes32 leaf = keccak256(txbytes);\\n    require(\\n        Merkle.checkMembership(leaf, utxoPos.txIndex(), root, inclusionProof),\\n        \"Transaction is not included in block of Plasma chain\"\\n    );\\n\\n    return utxoPos.value;\\n}\\n```\\nчPaymentChallengeIFEOutputSpent.verifyInFlightTransactionStandardFinalized:\\n```\\nrequire(controller.txFinalizationVerifier.isStandardFinalized(finalizationData), \"In-flight transaction not finalized\");\\n```\\n\\nPaymentChallengeIFENotCanonical.verifyCompetingTxFinalized:\\n```\\nrequire(self.txFinalizationVerifier.isStandardFinalized(finalizationData), \"Failed to verify the position of competing tx\");\\n```\\n\\nPaymentStartInFlightExit.verifyInputTransactionIsStandardFinalized:\\n```\\nrequire(exitData.controller.txFinalizationVerifier.isStandardFinalized(finalizationData),\\n        \"Input transaction is not standard finalized\");\\n```\\n\\nIf none of the above recommendations are implemented, ensure that `PaymentChallengeIFENotCanonical` uses the abstraction `TxFinalizationVerifier` so that a length check is performed on the inclusion proof.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/471чч```\\n/\\*\\*\\n\\* @notice Checks whether a transaction is \"standard finalized\"\\n\\* @dev MVP: requires that both inclusion proof and confirm signature is checked\\n\\* @dev MoreVp: checks inclusion proof only\\n\\*/\\nfunction isStandardFinalized(Model.Data memory data) public view returns (bool) {\\n    if (data.protocol == Protocol.MORE\\_VP()) {\\n        return checkInclusionProof(data);\\n    } else if (data.protocol == Protocol.MVP()) {\\n        revert(\"MVP is not yet supported\");\\n    } else {\\n        revert(\"Invalid protocol value\");\\n    }\\n}\\n```\\n
Merkle - The implementation does not enforce inclusion of leaf nodes.чmediumчA observation with the current Merkle tree implementation is that it may be possible to validate nodes other than leaves. This is done by providing `checkMembership` with a reference to a hash within the tree, rather than a leaf.\\n```\\n/\\*\\*\\n \\* @notice Checks that a leaf hash is contained in a root hash\\n \\* @param leaf Leaf hash to verify\\n \\* @param index Position of the leaf hash in the Merkle tree\\n \\* @param rootHash Root of the Merkle tree\\n \\* @param proof A Merkle proof demonstrating membership of the leaf hash\\n \\* @return True, if the leaf hash is in the Merkle tree; otherwise, False\\n\\*/\\nfunction checkMembership(bytes32 leaf, uint256 index, bytes32 rootHash, bytes memory proof)\\n    internal\\n    pure\\n    returns (bool)\\n{\\n    require(proof.length % 32 == 0, \"Length of Merkle proof must be a multiple of 32\");\\n\\n    bytes32 proofElement;\\n    bytes32 computedHash = leaf;\\n    uint256 j = index;\\n    // Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\\n    for (uint256 i = 32; i <= proof.length; i += 32) {\\n        // solhint-disable-next-line no-inline-assembly\\n        assembly {\\n            proofElement := mload(add(proof, i))\\n        }\\n        if (j % 2 == 0) {\\n            computedHash = keccak256(abi.encodePacked(computedHash, proofElement));\\n        } else {\\n            computedHash = keccak256(abi.encodePacked(proofElement, computedHash));\\n        }\\n        j = j / 2;\\n    }\\n\\n    return computedHash == rootHash;\\n}\\n```\\n\\nThe current implementation will validate the provided “leaf” and return `true`. This is a known problem of Merkle trees https://en.wikipedia.org/wiki/Merkle_tree#Second_preimage_attack.\\nProvide a hash from within the Merkle tree as the `leaf` argument. The index has to match the index of that node in regards to its current level in the tree. The `rootHash` has to be the correct Merkle tree `rootHash`. The proof has to skip the necessary number of levels because the nodes “underneath” the provided “leaf” will not be processed.чA remediation needs a fixed Merkle tree size as well as the addition of a byte prepended to each node in the tree. Another way would be to create a structure for the Merkle node and mark it as `leaf` or no `leaf`.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/425чч```\\n/\\*\\*\\n \\* @notice Checks that a leaf hash is contained in a root hash\\n \\* @param leaf Leaf hash to verify\\n \\* @param index Position of the leaf hash in the Merkle tree\\n \\* @param rootHash Root of the Merkle tree\\n \\* @param proof A Merkle proof demonstrating membership of the leaf hash\\n \\* @return True, if the leaf hash is in the Merkle tree; otherwise, False\\n\\*/\\nfunction checkMembership(bytes32 leaf, uint256 index, bytes32 rootHash, bytes memory proof)\\n    internal\\n    pure\\n    returns (bool)\\n{\\n    require(proof.length % 32 == 0, \"Length of Merkle proof must be a multiple of 32\");\\n\\n    bytes32 proofElement;\\n    bytes32 computedHash = leaf;\\n    uint256 j = index;\\n    // Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\\n    for (uint256 i = 32; i <= proof.length; i += 32) {\\n        // solhint-disable-next-line no-inline-assembly\\n        assembly {\\n            proofElement := mload(add(proof, i))\\n        }\\n        if (j % 2 == 0) {\\n            computedHash = keccak256(abi.encodePacked(computedHash, proofElement));\\n        } else {\\n            computedHash = keccak256(abi.encodePacked(proofElement, computedHash));\\n        }\\n        j = j / 2;\\n    }\\n\\n    return computedHash == rootHash;\\n}\\n```\\n
Maintainer can bypass exit game quarantine by registering not-yet-deployed contractsчmediumчThe plasma framework uses an `ExitGameRegistry` to allow the maintainer to add new exit games after deployment. An exit game is any arbitrary contract. In order to prevent the maintainer from adding malicious exit games that steal user funds, the framework uses a “quarantine” system whereby newly-registered exit games have restricted permissions until their quarantine period has expired. The quarantine period is by default `3 * minExitPeriod`, and is intended to facilitate auditing of the new exit game's functionality by the plasma users.\\nHowever, by registering an exit game at a contract which has not yet been deployed, the maintainer can prevent plasma users from auditing the game until the quarantine period has expired. After the quarantine period has expired, the maintainer can deploy the malicious exit game and immediately steal funds.\\nExplanation\\nExit games are registered in the following function, callable only by the plasma contract maintainer:\\n```\\n/\\*\\*\\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\\n \\* @dev Emits ExitGameRegistered event to notify clients\\n \\* @param \\_txType The tx type where the exit game wants to register\\n \\* @param \\_contract Address of the exit game contract\\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\\n \\*/\\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\\n    require(\\_txType != 0, \"Should not register with tx type 0\");\\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\\n\\n    \\_exitGames[\\_txType] = \\_contract;\\n    \\_exitGameToTxType[\\_contract] = \\_txType;\\n    \\_protocols[\\_txType] = \\_protocol;\\n    \\_exitGameQuarantine.quarantine(\\_contract);\\n\\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\\n}\\n```\\n\\nNotably, the function does not check the `extcodesize` of the submitted contract. As such, the maintainer can submit the address of a contract which does not yet exist and is not auditable.\\nAfter at least `3 * minExitPeriod` seconds pass, the submitted contract now has full permissions as a registered exit game and can pass all checks using the `onlyFromNonQuarantinedExitGame` modifier:\\n```\\n/\\*\\*\\n \\* @notice A modifier to verify that the call is from a non-quarantined exit game\\n \\*/\\nmodifier onlyFromNonQuarantinedExitGame() {\\n    require(\\_exitGameToTxType[msg.sender] != 0, \"The call is not from a registered exit game contract\");\\n    require(!\\_exitGameQuarantine.isQuarantined(msg.sender), \"ExitGame is quarantined\");\\n    \\_;\\n}\\n```\\n\\nAdditionally, the submitted contract passes checks made by external contracts using the `isExitGameSafeToUse` function:\\n```\\n/\\*\\*\\n \\* @notice Checks whether the contract is safe to use and is not under quarantine\\n \\* @dev Exposes information about exit games quarantine\\n \\* @param \\_contract Address of the exit game contract\\n \\* @return boolean Whether the contract is safe to use and is not under quarantine\\n \\*/\\nfunction isExitGameSafeToUse(address \\_contract) public view returns (bool) {\\n    return \\_exitGameToTxType[\\_contract] != 0 && !\\_exitGameQuarantine.isQuarantined(\\_contract);\\n}\\n```\\n\\nThese permissions allow a registered quarantine to:\\nWithdraw any users' tokens from ERC20Vault:\\n```\\nfunction withdraw(address payable receiver, address token, uint256 amount) external onlyFromNonQuarantinedExitGame {\\n    IERC20(token).safeTransfer(receiver, amount);\\n    emit Erc20Withdrawn(receiver, token, amount);\\n}\\n```\\n\\nWithdraw any users' ETH from EthVault:\\n```\\nfunction withdraw(address payable receiver, uint256 amount) external onlyFromNonQuarantinedExitGame {\\n    // we do not want to block exit queue if transfer is unucessful\\n    // solhint-disable-next-line avoid-call-value\\n    (bool success, ) = receiver.call.value(amount)(\"\");\\n    if (success) {\\n        emit EthWithdrawn(receiver, amount);\\n    } else {\\n        emit WithdrawFailed(receiver, amount);\\n    }\\n```\\n\\nActivate and deactivate the `ExitGameController` reentrancy mutex:\\n```\\nfunction activateNonReentrant() external onlyFromNonQuarantinedExitGame() {\\n    require(!mutex, \"Reentrant call\");\\n    mutex = true;\\n}\\n```\\n\\n```\\nfunction deactivateNonReentrant() external onlyFromNonQuarantinedExitGame() {\\n    require(mutex, \"Not locked\");\\n    mutex = false;\\n}\\n```\\n\\n`enqueue` arbitrary exits:\\n```\\nfunction enqueue(\\n    uint256 vaultId,\\n    address token,\\n    uint64 exitableAt,\\n    TxPosLib.TxPos calldata txPos,\\n    uint160 exitId,\\n    IExitProcessor exitProcessor\\n)\\n    external\\n    onlyFromNonQuarantinedExitGame\\n    returns (uint256)\\n{\\n    bytes32 key = exitQueueKey(vaultId, token);\\n    require(hasExitQueue(key), \"The queue for the (vaultId, token) pair is not yet added to the Plasma framework\");\\n    PriorityQueue queue = exitsQueues[key];\\n\\n    uint256 priority = ExitPriority.computePriority(exitableAt, txPos, exitId);\\n\\n    queue.insert(priority);\\n    delegations[priority] = exitProcessor;\\n\\n    emit ExitQueued(exitId, priority);\\n    return priority;\\n}\\n```\\n\\nFlag outputs as “spent”:\\n```\\nfunction flagOutputSpent(bytes32 \\_outputId) external onlyFromNonQuarantinedExitGame {\\n    require(\\_outputId != bytes32(\"\"), \"Should not flag with empty outputId\");\\n    isOutputSpent[\\_outputId] = true;\\n}\\n```\\nч`registerExitGame` should check that `extcodesize` of the submitted contract is non-zero.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/410чч```\\n/\\*\\*\\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\\n \\* @dev Emits ExitGameRegistered event to notify clients\\n \\* @param \\_txType The tx type where the exit game wants to register\\n \\* @param \\_contract Address of the exit game contract\\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\\n \\*/\\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\\n    require(\\_txType != 0, \"Should not register with tx type 0\");\\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\\n\\n    \\_exitGames[\\_txType] = \\_contract;\\n    \\_exitGameToTxType[\\_contract] = \\_txType;\\n    \\_protocols[\\_txType] = \\_protocol;\\n    \\_exitGameQuarantine.quarantine(\\_contract);\\n\\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\\n}\\n```\\n
EthVault - Unused state variableчlowчThe state variable `withdrawEntryCounter` is not used in the code.\\n```\\nuint256 private withdrawEntryCounter = 0;\\n```\\nчRemove it from the contract.чч```\\nuint256 private withdrawEntryCounter = 0;\\n```\\n
ECDSA error value is not handledчlowчResolution\\nThis was addressed in commit 32288ccff5b867a7477b4eaf3beb0587a4684d7a by adding a check that the returned value is nonzero.\\nThe OpenZeppelin `ECDSA` library returns `address(0x00)` for many cases with malformed signatures:\\n```\\nif (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {\\n    return address(0);\\n}\\n\\nif (v != 27 && v != 28) {\\n    return address(0);\\n}\\n```\\n\\nThe `PaymentOutputToPaymentTxCondition` contract does not explicitly handle this case:\\n```\\naddress payable owner = inputTx.outputs[outputIndex].owner();\\nrequire(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");\\n\\nreturn true;\\n```\\nчAdding a check to handle this case will make it easier to reason about the code.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/454чч```\\nif (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {\\n    return address(0);\\n}\\n\\nif (v != 27 && v != 28) {\\n    return address(0);\\n}\\n```\\n
No existence checks on framework block and timestamp readsчlowчThe exit game libraries make several queries to the main `PlasmaFramework` contract where plasma block hashes and timestamps are stored. In multiple locations, the return values of these queries are not checked for existence.\\nPaymentStartStandardExit.setupStartStandardExitData:\\n```\\n(, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());\\n```\\n\\nPaymentChallengeIFENotCanonical.respond:\\n```\\n(bytes32 root, ) = self.framework.blocks(utxoPos.blockNum());\\n```\\n\\nPaymentPiggybackInFlightExit.enqueue:\\n```\\n(, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());\\n```\\n\\nTxFinalizationVerifier.checkInclusionProof:\\n```\\n(bytes32 root,) = data.framework.blocks(data.txPos.blockNum());\\n```\\nчAlthough none of these examples seem exploitable, adding existence checks makes it easier to reason about the code. Each query to `PlasmaFramework.blocks` should be followed with a check that the returned value is nonzero.\\nCorresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/463чч```\\n(, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());\\n```\\n
BondSize - effectiveUpdateTime should be uint64чlowчIn BondSize, the mechanism to update the size of the bond has a grace period after which the new bond size becomes active.\\nWhen updating the bond size, the time is casted as a `uint64` and saved in a `uint128` variable.\\n```\\nuint128 effectiveUpdateTime;\\n```\\n\\n```\\nuint64 constant public WAITING\\_PERIOD = 2 days;\\n```\\n\\n```\\nself.effectiveUpdateTime = uint64(now) + WAITING\\_PERIOD;\\n```\\n\\nThere's no need to use a `uint128` to save the time if it never will take up that much space.чChange the type of the `effectiveUpdateTime` to `uint64`.\\n```\\n- uint128 effectiveUpdateTime;\\n+ uint64 effectiveUpdateTime;\\n```\\nчч```\\nuint128 effectiveUpdateTime;\\n```\\n
PaymentExitGame contains several redundant plasmaFramework declarationsчlowч`PaymentExitGame` inherits from both `PaymentInFlightExitRouter` and `PaymentStandardExitRouter`. All three contracts declare and initialize their own `PlasmaFramework` variable. This pattern can be misleading, and may lead to subtle issues in future versions of the code.\\n`PaymentExitGame` declaration:\\n```\\nPlasmaFramework private plasmaFramework;\\n```\\n\\n`PaymentInFlightExitRouter` declaration:\\n```\\nPlasmaFramework private framework;\\n```\\n\\n`PaymentStandardExitRouter` declaration:\\n```\\nPlasmaFramework private framework;\\n```\\n\\nEach variable is initialized in the corresponding file's constructor.чIntroduce an inherited contract common to `PaymentStandardExitRouter` and `PaymentInFlightExitRouter` with the `PlasmaFramework` variable. Make the variable internal so it is visible to inheriting contracts.чч```\\nPlasmaFramework private plasmaFramework;\\n```\\n
Creating proposal is not trustless Pull PatternчhighчUsually, if someone submits a proposal and transfers some amount of tribute tokens, these tokens are transferred back if the proposal is rejected. But if the proposal is not processed before the emergency processing, these tokens will not be transferred back to the proposer. This might happen if a tribute token or a deposit token transfers are blocked.\\n```\\nif (!emergencyProcessing) {\\n    require(\\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\\n        \"failing vote token transfer failed\"\\n    );\\n```\\n\\nTokens are not completely lost in that case, they now belong to the LAO shareholders and they might try to return that money back. But that requires a lot of coordination and time and everyone who ragequits during that time will take a part of that tokens with them.чResolution\\nthis issue no longer exists in the Pull Pattern update, due to the fact that emergency processing and in function ERC20 transfers are removed.\\nPull pattern for token transfers would solve the issue.чч```\\nif (!emergencyProcessing) {\\n    require(\\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\\n        \"failing vote token transfer failed\"\\n    );\\n```\\n
Emergency processing can be blocked Pull PatternчhighчThe main reason for the emergency processing mechanism is that there is a chance that some token transfers might be blocked. For example, a sender or a receiver is in the USDC blacklist. Emergency processing saves from this problem by not transferring tribute token back to the user (if there is some) and rejecting the proposal.\\n```\\nif (!emergencyProcessing) {\\n    require(\\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\\n        \"failing vote token transfer failed\"\\n    );\\n```\\n\\nThe problem is that there is still a deposit transfer back to the sponsor and it could be potentially blocked too. If that happens, proposal can't be processed and the LAO is blocked.чImplementing pull pattern for all token withdrawals would solve the problem. The alternative solution would be to also keep the deposit tokens in the LAO, but that makes sponsoring the proposal more risky for the sponsor.чч```\\nif (!emergencyProcessing) {\\n    require(\\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\\n        \"failing vote token transfer failed\"\\n    );\\n```\\n
Token Overflow might result in system halt or loss of fundsчhighчIf a token overflows, some functionality such as `processProposal`, `cancelProposal` will break due to safeMath reverts. The overflow could happen because the supply of the token was artificially inflated to oblivion.\\nThis issue was pointed out by Heiko Fisch in Telegram chat.\\nAny function using `internalTransfer()` can result in an overflow:\\n```\\nfunction max(uint256 x, uint256 y) internal pure returns (uint256) {\\n    return x >= y ? x : y;\\n}\\n```\\nчWe recommend to allow overflow for broken or malicious tokens. This is to prevent system halt or loss of funds. It should be noted that in case an overflow occurs, the balance of the token will be incorrect for all token holders in the system.\\n`rageKick`, `rageQuit` were fixed by not using safeMath within the function code, however this fix is risky and not recommended, as there are other overflows in other functions that might still result in system halt or loss of funds.\\nOne suggestion is having a function named `unsafeInternalTransfer()` which does not use safeMath for the cases that overflow should be allowed. This mainly adds better readability to the code.\\nIt is still a risky fix and a better solution should be planned.чч```\\nfunction max(uint256 x, uint256 y) internal pure returns (uint256) {\\n    return x >= y ? x : y;\\n}\\n```\\n
Whitelisted tokens limitчhighч`_ragequit` function is iterating over all whitelisted tokens:\\n```\\nfor (uint256 i = 0; i < tokens.length; i++) {\\n    uint256 amountToRagequit = fairShare(userTokenBalances[GUILD][tokens[i]], sharesAndLootToBurn, initialTotalSharesAndLoot);\\n    // deliberately not using safemath here to keep overflows from preventing the function execution (which would break ragekicks)\\n    // if a token overflows, it is because the supply was artificially inflated to oblivion, so we probably don't care about it anyways\\n    userTokenBalances[GUILD][tokens[i]] -= amountToRagequit;\\n    userTokenBalances[memberAddress][tokens[i]] += amountToRagequit;\\n}\\n```\\n\\nIf the number of tokens is too big, a transaction can run out of gas and all funds will be blocked forever. Ballpark estimation of this number is around 300 tokens based on the current OpCode gas costs and the block gas limit.чA simple solution would be just limiting the number of whitelisted tokens.\\nIf the intention is to invest in many new tokens over time, and it's not an option to limit the number of whitelisted tokens, it's possible to add a function that removes tokens from the whitelist. For example, it's possible to add a new type of proposals, that is used to vote on token removal if the balance of this token is zero. Before voting for that, shareholders should sell all the balance of that token.чч```\\nfor (uint256 i = 0; i < tokens.length; i++) {\\n    uint256 amountToRagequit = fairShare(userTokenBalances[GUILD][tokens[i]], sharesAndLootToBurn, initialTotalSharesAndLoot);\\n    // deliberately not using safemath here to keep overflows from preventing the function execution (which would break ragekicks)\\n    // if a token overflows, it is because the supply was artificially inflated to oblivion, so we probably don't care about it anyways\\n    userTokenBalances[GUILD][tokens[i]] -= amountToRagequit;\\n    userTokenBalances[memberAddress][tokens[i]] += amountToRagequit;\\n}\\n```\\n
Whitelist proposal duplicate  Won't FixчlowчEvery time when a whitelist proposal is sponsored, it's checked that there is no other sponsored whitelist proposal with the same token. This is done in order to avoid proposal duplicates.\\n```\\n// whitelist proposal\\nif (proposal.flags[4]) {\\n    require(!tokenWhitelist[address(proposal.tributeToken)], \"cannot already have whitelisted the token\");\\n    require(!proposedToWhitelist[address(proposal.tributeToken)], 'already proposed to whitelist');\\n    proposedToWhitelist[address(proposal.tributeToken)] = true;\\n```\\n\\nThe issue is that even though you can't sponsor a duplicate proposal, you can still submit a new proposal with the same token.чCheck that there is currently no sponsored proposal with the same token on proposal submission.чч```\\n// whitelist proposal\\nif (proposal.flags[4]) {\\n    require(!tokenWhitelist[address(proposal.tributeToken)], \"cannot already have whitelisted the token\");\\n    require(!proposedToWhitelist[address(proposal.tributeToken)], 'already proposed to whitelist');\\n    proposedToWhitelist[address(proposal.tributeToken)] = true;\\n```\\n
Moloch - bool[6] flags can be changed to a dedicated structure  Won't FixчlowчThe Moloch contract uses a structure that includes an array of bools to store a few flags about the proposal:\\n```\\nbool[6] flags; // [sponsored, processed, didPass, cancelled, whitelist, guildkick]\\n```\\n\\nThis makes reasoning about the correctness of the code a bit complicated because one needs to remember what each item in the flag list stands for. The make the reader's life simpler a dedicated structure can be created that incorporates all of the required flags.\\n```\\n        bool[6] memory flags; // [sponsored, processed, didPass, cancelled, whitelist, guildkick]\\n```\\nчBased on the provided examples change the `bool[6] flags` to the proposed examples.\\nFlags as bool array with enum (proposed)\\nThis second contract implements the `flags` as a defined structure with each named element representing a specific flag. This method makes clear which flag is accessed because they are referred to by the name, not by the index.\\nThis third contract has the least amount of changes to the code and uses an enum structure to handle the index.\\n```\\npragma solidity 0.5.15;\\n\\ncontract FlagsEnum {\\n    struct Proposal {\\n        address applicant;\\n        uint value;\\n        bool[3] flags; // [sponsored, processed, kicked]\\n    }\\n   \\n    enum ProposalFlags {\\n        SPONSORED,\\n        PROCESSED,\\n        KICKED\\n    }\\n   \\n    uint proposalCount;\\n   \\n    mapping(uint256 => Proposal) public proposals;\\n   \\n    function addProposal(uint \\_value, bool \\_sponsored, bool \\_processed, bool \\_kicked) public returns (uint) {\\n        Proposal memory proposal = Proposal({\\n            applicant: msg.sender,\\n            value: \\_value,\\n            flags: [\\_sponsored, \\_processed, \\_kicked]\\n        });\\n       \\n        proposals[proposalCount] = proposal;\\n        proposalCount += 1;\\n       \\n        return (proposalCount);\\n    }\\n   \\n    function getProposal(uint \\_proposalId) public view returns (address, uint, bool, bool, bool) {\\n        return (\\n            proposals[\\_proposalId].applicant,\\n            proposals[\\_proposalId].value,\\n            proposals[\\_proposalId].flags[uint(ProposalFlags.SPONSORED)],\\n            proposals[\\_proposalId].flags[uint(ProposalFlags.PROCESSED)],\\n            proposals[\\_proposalId].flags[uint(ProposalFlags.KICKED)]\\n        );\\n    }\\n}\\n```\\nчч```\\nbool[6] flags; // [sponsored, processed, didPass, cancelled, whitelist, guildkick]\\n```\\n
Passing duplicate tokens to Redemptions and TokenRequest may have unintended consequencesчmediumчBoth `Redemptions` and `TokenRequest` are initialized with a list of acceptable tokens to use with each app. For `Redemptions`, the list of tokens corresponds to an organization's treasury assets. For `TokenRequest`, the list of tokens corresponds to tokens accepted for payment to join an organization. Neither contract makes a uniqueness check on input tokens during initialization, which can lead to unintended behavior.\\nIn `Redemptions`, each of an organization's assets are redeemed according to the sender's proportional ownership in the org. The redemption process iterates over the `redeemableTokens` list, paying out the sender their proportion of each token listed:\\n```\\nfor (uint256 i = 0; i < redeemableTokens.length; i++) {\\n    vaultTokenBalance = vault.balance(redeemableTokens[i]);\\n\\n    redemptionAmount = \\_burnableAmount.mul(vaultTokenBalance).div(burnableTokenTotalSupply);\\n    totalRedemptionAmount = totalRedemptionAmount.add(redemptionAmount);\\n\\n    if (redemptionAmount > 0) {\\n        vault.transfer(redeemableTokens[i], msg.sender, redemptionAmount);\\n    }\\n}\\n```\\n\\nIf a token address is included more than once, the sender will be paid out more than once, potentially earning many times more than their proportional share of the token.\\nIn `TokenRequest`, this behavior does not allow for any significant deviation from expected behavior. It was included because the initialization process is similar to that of `Redemptions`.чResolution\\nThis was addressed in Redemptions commit 2b0034206a5b9cdf239da7a51900e89d9931554f by checking `redeemableTokenAdded[token] == false` for each subsequent token added during initialization. Note that ordering is not enforced.\\nAdditionally, the issue in `TokenRequest` was addressed in commit eb4181961093439f142f2e74eb706b7f501eb5c0 by requiring that each subsequent token added during initialization has a value strictly greater than the previous token added.\\nDuring initialization in both apps, check that input token addresses are unique. One simple method is to require that token addresses are submitted in ascending order, and that each subsequent address added is greater than the one before.чч```\\nfor (uint256 i = 0; i < redeemableTokens.length; i++) {\\n    vaultTokenBalance = vault.balance(redeemableTokens[i]);\\n\\n    redemptionAmount = \\_burnableAmount.mul(vaultTokenBalance).div(burnableTokenTotalSupply);\\n    totalRedemptionAmount = totalRedemptionAmount.add(redemptionAmount);\\n\\n    if (redemptionAmount > 0) {\\n        vault.transfer(redeemableTokens[i], msg.sender, redemptionAmount);\\n    }\\n}\\n```\\n
The Delay app allows scripts to be paused even after execution time has elapsedчmediumчThe `Delay` app is used to configure a delay between when an evm script is created and when it is executed. The entry point for this process is `Delay.delayExecution`, which stores the input script with a future execution date:\\n```\\nfunction \\_delayExecution(bytes \\_evmCallScript) internal returns (uint256) {\\n    uint256 delayedScriptIndex = delayedScriptsNewIndex;\\n    delayedScriptsNewIndex++;\\n\\n    delayedScripts[delayedScriptIndex] = DelayedScript(getTimestamp64().add(executionDelay), 0, \\_evmCallScript);\\n\\n    emit DelayedScriptStored(delayedScriptIndex);\\n\\n    return delayedScriptIndex;\\n}\\n```\\n\\nAn auxiliary capability of the `Delay` app is the ability to “pause” the delayed script, which sets the script's `pausedAt` value to the current block timestamp:\\n```\\nfunction pauseExecution(uint256 \\_delayedScriptId) external auth(PAUSE\\_EXECUTION\\_ROLE) {\\n    require(!\\_isExecutionPaused(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_PAUSE);\\n    delayedScripts[\\_delayedScriptId].pausedAt = getTimestamp64();\\n\\n    emit ExecutionPaused(\\_delayedScriptId);\\n}\\n```\\n\\nA paused script cannot be executed until `resumeExecution` is called, which extends the script's `executionTime` by the amount of time paused. Essentially, the delay itself is paused:\\n```\\nfunction resumeExecution(uint256 \\_delayedScriptId) external auth(RESUME\\_EXECUTION\\_ROLE) {\\n    require(\\_isExecutionPaused(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_RESUME);\\n    DelayedScript storage delayedScript = delayedScripts[\\_delayedScriptId];\\n\\n    uint64 timePaused = getTimestamp64().sub(delayedScript.pausedAt);\\n    delayedScript.executionTime = delayedScript.executionTime.add(timePaused);\\n    delayedScript.pausedAt = 0;\\n\\n    emit ExecutionResumed(\\_delayedScriptId);\\n}\\n```\\n\\nA delayed script whose execution time has passed and is not currently paused should be able to be executed via the `execute` function. However, the `pauseExecution` function still allows the aforementioned script to be paused, halting execution.чAdd a check to `pauseExecution` to ensure that execution is not paused if the script's execution delay has already transpired.чч```\\nfunction \\_delayExecution(bytes \\_evmCallScript) internal returns (uint256) {\\n    uint256 delayedScriptIndex = delayedScriptsNewIndex;\\n    delayedScriptsNewIndex++;\\n\\n    delayedScripts[delayedScriptIndex] = DelayedScript(getTimestamp64().add(executionDelay), 0, \\_evmCallScript);\\n\\n    emit DelayedScriptStored(delayedScriptIndex);\\n\\n    return delayedScriptIndex;\\n}\\n```\\n
Misleading intentional misconfiguration possible through misuse of newToken and newBaseInstanceчmediumчThe instantiation process for a Dandelion organization requires two separate external calls to `DandelionOrg`. There are two primary functions: `installDandelionApps`, and `newTokenAndBaseInstance`.\\n`installDandelionApps` relies on cached results from prior calls to `newTokenAndBaseInstance` and completes the initialization step for a Dandelion org.\\n`newTokenAndBaseInstance` is a wrapper around two publicly accessible functions: `newToken` and `newBaseInstance`. Called together, the functions:\\nDeploy a new `MiniMeToken` used to represent shares in an organization, and cache the address of the created token:\\n```\\n/\\*\\*\\n\\* @dev Create a new MiniMe token and save it for the user\\n\\* @param \\_name String with the name for the token used by share holders in the organization\\n\\* @param \\_symbol String with the symbol for the token used by share holders in the organization\\n\\*/\\nfunction newToken(string memory \\_name, string memory \\_symbol) public returns (MiniMeToken) {\\n    MiniMeToken token = \\_createToken(\\_name, \\_symbol, TOKEN\\_DECIMALS);\\n    \\_saveToken(token);\\n    return token;\\n}\\n```\\n\\nCreate a new dao instance using Aragon's `BaseTemplate` contract:\\n```\\n/\\*\\*\\n\\* @dev Deploy a Dandelion Org DAO using a previously saved MiniMe token\\n\\* @param \\_id String with the name for org, will assign `[id].aragonid.eth`\\n\\* @param \\_holders Array of token holder addresses\\n\\* @param \\_stakes Array of token stakes for holders (token has 18 decimals, multiply token amount `\\* 10^18`)\\n\\* @param \\_useAgentAsVault Boolean to tell whether to use an Agent app as a more advanced form of Vault app\\n\\*/\\nfunction newBaseInstance(\\n    string memory \\_id,\\n    address[] memory \\_holders,\\n    uint256[] memory \\_stakes,\\n    uint64 \\_financePeriod,\\n    bool \\_useAgentAsVault\\n)\\n    public\\n{\\n    \\_validateId(\\_id);\\n    \\_ensureBaseSettings(\\_holders, \\_stakes);\\n\\n    (Kernel dao, ACL acl) = \\_createDAO();\\n    \\_setupBaseApps(dao, acl, \\_holders, \\_stakes, \\_financePeriod, \\_useAgentAsVault);\\n}\\n```\\n\\nSet up prepackaged Aragon apps, like `Vault`, `TokenManager`, and Finance:\\n```\\nfunction \\_setupBaseApps(\\n    Kernel \\_dao,\\n    ACL \\_acl,\\n    address[] memory \\_holders,\\n    uint256[] memory \\_stakes,\\n    uint64 \\_financePeriod,\\n    bool \\_useAgentAsVault\\n)\\n    internal\\n{\\n    MiniMeToken token = \\_getToken();\\n    Vault agentOrVault = \\_useAgentAsVault ? \\_installDefaultAgentApp(\\_dao) : \\_installVaultApp(\\_dao);\\n    TokenManager tokenManager = \\_installTokenManagerApp(\\_dao, token, TOKEN\\_TRANSFERABLE, TOKEN\\_MAX\\_PER\\_ACCOUNT);\\n    Finance finance = \\_installFinanceApp(\\_dao, agentOrVault, \\_financePeriod == 0 ? DEFAULT\\_FINANCE\\_PERIOD : \\_financePeriod);\\n\\n    \\_mintTokens(\\_acl, tokenManager, \\_holders, \\_stakes);\\n    \\_saveBaseApps(\\_dao, finance, tokenManager, agentOrVault);\\n    \\_saveAgentAsVault(\\_dao, \\_useAgentAsVault);\\n\\n}\\n```\\n\\nNote that `newToken` and `newBaseInstance` can be called separately. The token created in `newToken` is cached in `_saveToken`, which overwrites any previously-cached value:\\n```\\nfunction \\_saveToken(MiniMeToken \\_token) internal {\\n    DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];\\n\\n    senderDeployedContracts.token = address(\\_token);\\n}\\n```\\n\\nCached tokens are retrieved in _getToken:\\n```\\nfunction \\_getToken() internal returns (MiniMeToken) {\\n    DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];\\n    require(senderDeployedContracts.token != address(0), ERROR\\_MISSING\\_TOKEN\\_CONTRACT);\\n\\n    MiniMeToken token = MiniMeToken(senderDeployedContracts.token);\\n    return token;\\n}\\n```\\n\\nBy exploiting the overwriteable caching mechanism, it is possible to intentionally misconfigure Dandelion orgs.\\n`installDandelionApps` uses `_getToken` to associate a token with the `DandelionVoting` app. The value returned from `_getToken` depends on the sender's previous call to `newToken`, which overwrites any previously-cached value. The steps for intentional misconfiguration are as follows:\\nSender calls `newTokenAndBaseInstance`, creating token `m0` and DAO `A`.\\nThe `TokenManager` app in `A` is automatically configured to be the controller of `m0`.\\n`m0` is cached using `_saveToken`.\\nDAO `A` apps are cached for future use using `_saveBaseApps` and `_saveAgentAsVault`.\\nSender calls `newToken`, creating token `m1`, and overwriting the cache of `m0`.\\nFuture calls to `_getToken` will retrieve `m1`.\\nThe `DandelionOrg` contract is the controller of `m1`.\\nSender calls `installDandelionApps`, which installs Dandelion apps in DAO `A`\\nThe `DandelionVoting` app is configured to use the current cached token, `m1`, rather than the token associated with `A.TokenManager`, `m0`\\nFurther calls to `newBaseInstance` and `installDandelionApps` create DAO `B`, populate it with Dandelion apps, and assign `B.TokenManager` as the controller of the earlier `DandelionVoting` app token, `m0`.\\nMany different misconfigurations are possible, and some may be underhandedly abusable.чMake `newToken` and `newBaseInstance` internal so they are only callable via `newTokenAndBaseInstance`.чч```\\n/\\*\\*\\n\\* @dev Create a new MiniMe token and save it for the user\\n\\* @param \\_name String with the name for the token used by share holders in the organization\\n\\* @param \\_symbol String with the symbol for the token used by share holders in the organization\\n\\*/\\nfunction newToken(string memory \\_name, string memory \\_symbol) public returns (MiniMeToken) {\\n    MiniMeToken token = \\_createToken(\\_name, \\_symbol, TOKEN\\_DECIMALS);\\n    \\_saveToken(token);\\n    return token;\\n}\\n```\\n
Delay.execute can re-enter and re-execute the same script twiceчlowч`Delay.execute` does not follow the “checks-effects-interactions” pattern, and deletes a delayed script only after the script is run. Because the script being run executes arbitrary external calls, a script can be created that re-enters `Delay` and executes itself multiple times before being deleted:\\n```\\n/\\*\\*\\n\\* @notice Execute the script with ID `\\_delayedScriptId`\\n\\* @param \\_delayedScriptId The ID of the script to execute\\n\\*/\\nfunction execute(uint256 \\_delayedScriptId) external {\\n    require(canExecute(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_EXECUTE);\\n    runScript(delayedScripts[\\_delayedScriptId].evmCallScript, new bytes(0), new address[](0));\\n\\n    delete delayedScripts[\\_delayedScriptId];\\n\\n    emit ExecutedScript(\\_delayedScriptId);\\n}\\n```\\nчAdd the `Delay` contract address to the `runScript` blacklist, or delete the delayed script from storage before it is run.чч```\\n/\\*\\*\\n\\* @notice Execute the script with ID `\\_delayedScriptId`\\n\\* @param \\_delayedScriptId The ID of the script to execute\\n\\*/\\nfunction execute(uint256 \\_delayedScriptId) external {\\n    require(canExecute(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_EXECUTE);\\n    runScript(delayedScripts[\\_delayedScriptId].evmCallScript, new bytes(0), new address[](0));\\n\\n    delete delayedScripts[\\_delayedScriptId];\\n\\n    emit ExecutedScript(\\_delayedScriptId);\\n}\\n```\\n
Delay.cancelExecution should revert on a non-existent script idчlowч`cancelExecution` makes no existence check on the passed-in script ID, clearing its storage slot and emitting an event:\\n```\\n/\\*\\*\\n\\* @notice Cancel script execution with ID `\\_delayedScriptId`\\n\\* @param \\_delayedScriptId The ID of the script execution to cancel\\n\\*/\\nfunction cancelExecution(uint256 \\_delayedScriptId) external auth(CANCEL\\_EXECUTION\\_ROLE) {\\n    delete delayedScripts[\\_delayedScriptId];\\n\\n    emit ExecutionCancelled(\\_delayedScriptId);\\n}\\n```\\nчAdd a check that the passed-in script exists.чч```\\n/\\*\\*\\n\\* @notice Cancel script execution with ID `\\_delayedScriptId`\\n\\* @param \\_delayedScriptId The ID of the script execution to cancel\\n\\*/\\nfunction cancelExecution(uint256 \\_delayedScriptId) external auth(CANCEL\\_EXECUTION\\_ROLE) {\\n    delete delayedScripts[\\_delayedScriptId];\\n\\n    emit ExecutionCancelled(\\_delayedScriptId);\\n}\\n```\\n
ID validation check missing for installDandelionAppsчlowч`DandelionOrg` allows users to kickstart an Aragon organization by using a dao template. There are two primary functions to instantiate an org: `newTokenAndBaseInstance`, and `installDandelionApps`. Both functions accept a parameter, `string _id`, meant to represent an ENS subdomain that will be assigned to the new org during the instantiation process. The two functions are called independently, but depend on each other.\\nIn `newTokenAndBaseInstance`, a sanity check is performed on the `_id` parameter, which ensures the `_id` length is nonzero:\\n```\\n\\_validateId(\\_id);\\n```\\n\\nNote that the value of `_id` is otherwise unused in `newTokenAndBaseInstance`.\\nIn `installDandelionApps`, this check is missing. The check is only important in this function, since it is in `installDandelionApps` that the ENS subdomain registration is actually performed.чUse `_validateId` in `installDandelionApps` rather than `newTokenAndBaseInstance`. Since the `_id` parameter is otherwise unused in `newTokenAndBaseInstance`, it can be removed.\\nAlternatively, the value of the submitted `_id` could be cached between calls and validated in `newTokenAndBaseInstance`, similarly to `newToken`.чч```\\n\\_validateId(\\_id);\\n```\\n
EOPBCTemplate - permission documentation inconsistenciesчhighчUndocumented\\nThe template documentation provides an overview of the permissions set with the template. The following permissions are set by the template contract but are not documented in the accompanied `fundraising/templates/externally_owned_presale_bonding_curve/README.md`.\\nTokenManager\\n```\\n\\_createPermissions(\\_acl, grantees, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.MINT\\_ROLE(), \\_owner);\\n\\_acl.createPermission(\\_fundraisingApps.marketMaker, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.BURN\\_ROLE(), \\_owner);\\n```\\n\\ncode/fundraising/templates/externally_owned_presale_bonding_curve/eopbc.yaml:L33-L44\\n```\\n- app: anj-token-manager\\n  role: MINT\\_ROLE\\n  grantee: market-maker\\n  manager: owner\\n- app: anj-token-manager\\n  role: MINT\\_ROLE\\n  grantee: presale\\n  manager: owner\\n- app: anj-token-manager\\n  role: BURN\\_ROLE\\n  grantee: market-maker\\n  manager: owner\\n```\\n\\nInconsistent\\nThe following permissions are set by the template but are inconsistent to the outline in the documentation:\\nController\\n`owner` has the following permissions even though they are documented as not being set https://github.com/ConsenSys/aragonone-presale-audit-2019-11/blob/9ddae8c7fde9dea3af3982b965a441239d81f370/code/fundraising/templates/externally_owned_presale_bonding_curve/README.md#controller.\\n```\\n| App        | Permission                            | Grantee | Manager |\\n| ---------- | ------------------------------------- | ------- | ------- |\\n| Controller | UPDATE_BENEFICIARY                    | NULL    | NULL    |\\n| Controller | UPDATE_FEES                           | NULL    | NULL    |\\n| Controller | ADD_COLLATERAL_TOKEN                  | Owner   | Owner   |\\n| Controller | REMOVE_COLLATERAL_TOKEN               | Owner   | Owner   |\\n| Controller | UPDATE_COLLATERAL_TOKEN               | Owner   | Owner   |\\n| Controller | UPDATE_MAXIMUM_TAP_RATE_INCREASE_PCT  | NULL    | NULL    |\\n| Controller | UPDATE_MAXIMUM_TAP_FLOOR_DECREASE_PCT | NULL    | NULL    |\\n| Controller | ADD_TOKEN_TAP                         | NULL    | NULL    |\\n| Controller | UPDATE_TOKEN_TAP                      | NULL    | NULL    |\\n| Controller | OPEN_PRESALE                          | Owner   | Owner   |\\n| Controller | OPEN_TRADING                          | Presale | Owner   |\\n| Controller | CONTRIBUTE                            | Any     | Owner   |\\n| Controller | OPEN_BUY_ORDER                        | Any     | Owner   |\\n| Controller | OPEN_SELL_ORDER                       | Any     | Owner   |\\n| Controller | WITHDRAW                              | NULL    | NULL    |\\n```\\n\\n```\\n\\_acl.createPermission(\\_owner, \\_fundraisingApps.controller, \\_fundraisingApps.controller.UPDATE\\_BENEFICIARY\\_ROLE(), \\_owner);\\n\\_acl.createPermission(\\_owner, \\_fundraisingApps.controller, \\_fundraisingApps.controller.UPDATE\\_FEES\\_ROLE(), \\_owner);\\n```\\nчResolution\\nFixed with aragonone/[email protected]bafe100 by adding the undocumented and deviating permissions to the documentation.\\nFor transparency, all permissions set-up by the template must be documented.чч```\\n\\_createPermissions(\\_acl, grantees, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.MINT\\_ROLE(), \\_owner);\\n\\_acl.createPermission(\\_fundraisingApps.marketMaker, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.BURN\\_ROLE(), \\_owner);\\n```\\n
EOPBCTemplate - AppId of BalanceRedirectPresale should be different from AragonBlack/Presale namehash to avoid collisionsчhighчThe template references the new presale contract with `apmNamehash` `0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5`. However, this namehash is already used by the aragonBlack/Presale contract. To avoid confusion and collision a unique `apmNamehash` should be used for this variant of the contract.\\nNote that the contract that is referenced from an `apmNamehash` is controlled by the `ENS` resolver that is configured when deploying the template contract. Using the same namehash for both variants of the contract does not allow a single registry to simultaneously provide both variants of the contract and might lead to confusion as to which application is actually deployed. This also raises the issue that the `ENS` registry must be verified before actually using the contract as a malicious registry could force the template to deploy potentially malicious applications.\\naragonOne/Fundraising:\\n```\\nbytes32   private constant PRESALE\\_ID                    = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;\\n```\\n\\naragonBlack/Fundraising:\\n```\\nbytes32   private constant PRESALE\\_ID             = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;\\n```\\n\\n`bytes32 private constant PRESALE_ID = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;`чCreate a new `apmNamehash` for `BalanceRedirectPresale`.чч```\\nbytes32   private constant PRESALE\\_ID                    = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;\\n```\\n
BalanceRedirectPresale - Presale can be extended indefinitely  Won't FixчhighчThe `OPEN_ROLE` can indefinitely extend the Presale even after users contributed funds to it by adjusting the presale period. The period might be further manipulated to avoid that token trading in the MarketMaker is opened.\\n```\\nfunction setPeriod(uint64 \\_period) external auth(OPEN\\_ROLE) {\\n    \\_setPeriod(\\_period);\\n}\\n```\\n\\n```\\nfunction \\_setPeriod(uint64 \\_period) internal {\\n    require(\\_period > 0, ERROR\\_TIME\\_PERIOD\\_ZERO);\\n    require(openDate == 0 || openDate + \\_period > getTimestamp64(), ERROR\\_INVALID\\_TIME\\_PERIOD);\\n    period = \\_period;\\n}\\n```\\nчDo not allow to extend the presale after funds have been contributed to it or only allow period adjustments in `State.PENDING`.чч```\\nfunction setPeriod(uint64 \\_period) external auth(OPEN\\_ROLE) {\\n    \\_setPeriod(\\_period);\\n}\\n```\\n
BalanceRedirectPresale - setPeriod uint64 overflow in validation checkчmediumч`setPeriod()` allows setting an arbitrary Presale starting date. The method can be called by an entity with the `OPEN_ROLE` permission. Providing a large enough value for `uint64 _period` can overflow the second input validation check. The result is unwanted behaviour where for relatively large values of `period` the require might fail because the overflow `openDate + _period` is less than or equal the current timestamp (getTimestamp64()) but if high enough it still might succeed because `openDate + _period` is higher than the current timestamp. The overflow has no effect on the presale end as it is calculated against `_timeSinceOpen`.\\n```\\nfunction \\_setPeriod(uint64 \\_period) internal {\\n    require(\\_period > 0, ERROR\\_TIME\\_PERIOD\\_ZERO);\\n    require(openDate == 0 || openDate + \\_period > getTimestamp64(), ERROR\\_INVALID\\_TIME\\_PERIOD);\\n    period = \\_period;\\n}\\n```\\n\\nчResolution\\nFixed with aragonone/[email protected]bafe100 by performing the addition using `SafeMath`.\\nUse `SafeMath` which is already imported to protect from overflow scenarios.чч```\\nfunction \\_setPeriod(uint64 \\_period) internal {\\n    require(\\_period > 0, ERROR\\_TIME\\_PERIOD\\_ZERO);\\n    require(openDate == 0 || openDate + \\_period > getTimestamp64(), ERROR\\_INVALID\\_TIME\\_PERIOD);\\n    period = \\_period;\\n}\\n```\\n
EOPBCTemplate - misleading method names _cacheFundraisingApps and _cacheFundraisingParamsчlowчThe methods `_cacheFundraisingApps` and `_cacheFundraisingParams` suggest that parameters are cached as state variables in the contract similar to the multi-step deployment contract used for AragonBlack/Fundraising. However, the methods are just returning memory structs.\\n```\\nfunction \\_cacheFundraisingApps(\\n    Agent          \\_reserve,\\n    Presale        \\_presale,\\n    MarketMaker    \\_marketMaker,\\n    Tap            \\_tap,\\n    Controller     \\_controller,\\n    TokenManager   \\_tokenManager\\n)\\n    internal\\n    returns (FundraisingApps memory fundraisingApps)\\n{\\n    fundraisingApps.reserve            = \\_reserve;\\n    fundraisingApps.presale            = \\_presale;\\n    fundraisingApps.marketMaker        = \\_marketMaker;\\n    fundraisingApps.tap                = \\_tap;\\n    fundraisingApps.controller         = \\_controller;\\n    fundraisingApps.bondedTokenManager = \\_tokenManager;\\n}\\n\\nfunction \\_cacheFundraisingParams(\\n    address       \\_owner,\\n    string        \\_id,\\n    ERC20         \\_collateralToken,\\n    MiniMeToken   \\_bondedToken,\\n    uint64        \\_period,\\n    uint256       \\_exchangeRate,\\n    uint64        \\_openDate,\\n    uint256       \\_reserveRatio,\\n    uint256       \\_batchBlocks,\\n    uint256       \\_slippage\\n)\\n    internal\\n    returns (FundraisingParams fundraisingParams)\\n{\\n    fundraisingParams = FundraisingParams({\\n        owner:           \\_owner,\\n        id:              \\_id,\\n        collateralToken: \\_collateralToken,\\n        bondedToken:     \\_bondedToken,\\n        period:          \\_period,\\n        exchangeRate:    \\_exchangeRate,\\n        openDate:        \\_openDate,\\n        reserveRatio:    \\_reserveRatio,\\n        batchBlocks:     \\_batchBlocks,\\n        slippage:        \\_slippage\\n    });\\n}\\n```\\nчThe functions are only called once throughout the deployment process. The structs can therefore be created directly in the main method. Otherwise rename the functions to properly reflect their purpose.чч```\\nfunction \\_cacheFundraisingApps(\\n    Agent          \\_reserve,\\n    Presale        \\_presale,\\n    MarketMaker    \\_marketMaker,\\n    Tap            \\_tap,\\n    Controller     \\_controller,\\n    TokenManager   \\_tokenManager\\n)\\n    internal\\n    returns (FundraisingApps memory fundraisingApps)\\n{\\n    fundraisingApps.reserve            = \\_reserve;\\n    fundraisingApps.presale            = \\_presale;\\n    fundraisingApps.marketMaker        = \\_marketMaker;\\n    fundraisingApps.tap                = \\_tap;\\n    fundraisingApps.controller         = \\_controller;\\n    fundraisingApps.bondedTokenManager = \\_tokenManager;\\n}\\n\\nfunction \\_cacheFundraisingParams(\\n    address       \\_owner,\\n    string        \\_id,\\n    ERC20         \\_collateralToken,\\n    MiniMeToken   \\_bondedToken,\\n    uint64        \\_period,\\n    uint256       \\_exchangeRate,\\n    uint64        \\_openDate,\\n    uint256       \\_reserveRatio,\\n    uint256       \\_batchBlocks,\\n    uint256       \\_slippage\\n)\\n    internal\\n    returns (FundraisingParams fundraisingParams)\\n{\\n    fundraisingParams = FundraisingParams({\\n        owner:           \\_owner,\\n        id:              \\_id,\\n        collateralToken: \\_collateralToken,\\n        bondedToken:     \\_bondedToken,\\n        period:          \\_period,\\n        exchangeRate:    \\_exchangeRate,\\n        openDate:        \\_openDate,\\n        reserveRatio:    \\_reserveRatio,\\n        batchBlocks:     \\_batchBlocks,\\n        slippage:        \\_slippage\\n    });\\n}\\n```\\n
EOPBCTemplate - inconsistent storage location declarationчlowч`_cacheFundraisingParams()` does not explicitly declare the return value memory location.\\n```\\nfunction \\_cacheFundraisingParams(\\n    address       \\_owner,\\n    string        \\_id,\\n    ERC20         \\_collateralToken,\\n    MiniMeToken   \\_bondedToken,\\n    uint64        \\_period,\\n    uint256       \\_exchangeRate,\\n    uint64        \\_openDate,\\n    uint256       \\_reserveRatio,\\n    uint256       \\_batchBlocks,\\n    uint256       \\_slippage\\n)\\n    internal\\n    returns (FundraisingParams fundraisingParams)\\n```\\n\\n`_cacheFundraisingApps()` explicitly declares to return a copy of the storage struct.\\n```\\nfunction \\_cacheFundraisingApps(\\n    Agent          \\_reserve,\\n    Presale        \\_presale,\\n    MarketMaker    \\_marketMaker,\\n    Tap            \\_tap,\\n    Controller     \\_controller,\\n    TokenManager   \\_tokenManager\\n)\\n    internal\\n    returns (FundraisingApps memory fundraisingApps)\\n{\\n    fundraisingApps.reserve            = \\_reserve;\\n    fundraisingApps.presale            = \\_presale;\\n    fundraisingApps.marketMaker        = \\_marketMaker;\\n    fundraisingApps.tap                = \\_tap;\\n    fundraisingApps.controller         = \\_controller;\\n    fundraisingApps.bondedTokenManager = \\_tokenManager;\\n}\\n```\\nчResolution\\nFixed with aragonone/[email protected]bafe100 by adding the missing storage location declaration.\\nStorage declarations should be consistent.чч```\\nfunction \\_cacheFundraisingParams(\\n    address       \\_owner,\\n    string        \\_id,\\n    ERC20         \\_collateralToken,\\n    MiniMeToken   \\_bondedToken,\\n    uint64        \\_period,\\n    uint256       \\_exchangeRate,\\n    uint64        \\_openDate,\\n    uint256       \\_reserveRatio,\\n    uint256       \\_batchBlocks,\\n    uint256       \\_slippage\\n)\\n    internal\\n    returns (FundraisingParams fundraisingParams)\\n```\\n
EOPBCTemplate - EtherTokenConstant is never usedчlowчThe constant value `EtherTokenConstant.ETH` is never used.\\n```\\ncontract EOPBCTemplate is EtherTokenConstant, BaseTemplate {\\n```\\nчResolution\\nFixed with aragonone/[email protected]bafe100 by removing the `EtherTokenConstant` dependency.\\nRemove all references to `EtherTokenConstant`.чч```\\ncontract EOPBCTemplate is EtherTokenConstant, BaseTemplate {\\n```\\n
Staking node can be inappropriately removed from the treeчhighчThe following code in `OrchidDirectory.pull()` is responsible for reattaching a child from a removed tree node:\\n```\\nif (name(stake.left\\_) == key) {\\n    current.right\\_ = stake.right\\_;\\n    current.after\\_ = stake.after\\_;\\n} else {\\n    current.left\\_ = stake.left\\_;\\n    current.before\\_ = stake.before\\_;\\n}\\n```\\n\\nThe condition name(stake.left_) == `key` can never hold because `key` is the `key` for `stake` itself.\\nThe result of this bug is somewhat catastrophic. The child is not reattached, but it still has a link to the rest of the tree via its ‘parent_' pointer. This means reducing the stake of that node can underflow the ancestors' before/after amounts, leading to improper random selection or failing altogether.\\nThe node replacing the removed node also ends up with itself as a child, which violates the basic tree structure and is again likely to produce integer underflows and other failures.чAs a simple fix, use `if(name(stake.left_) == name(last))` as already suggested by the development team when this bug was first shared.\\nTwo suggestions for better long-term fixes:\\nUse a strict interface for tree operations. It should be impossible to update a node's parent without simultaneously updating that parent's child pointer.\\nAs suggested in (https://github.com/ConsenSys/orchid-audit-2019-10/issues/7), simplify the logic in `pull()` to avoid this logic altogether.чч```\\nif (name(stake.left\\_) == key) {\\n    current.right\\_ = stake.right\\_;\\n    current.after\\_ = stake.after\\_;\\n} else {\\n    current.left\\_ = stake.left\\_;\\n    current.before\\_ = stake.before\\_;\\n}\\n```\\n
Verifiers need to be pure, but it's very difficult to validate purenessчmediumчAfter the initial audit, a “verifier” was introduced to the `OrchidLottery` code. Each `Pot` can have an associated `OrchidVerifier`. This is a contract with a `good()` function that accepts three parameters:\\n```\\nfunction good(bytes calldata shared, address target, bytes calldata receipt) external pure returns (bool);\\n```\\n\\nThe verifier returns a boolean indicating whether a given micropayment should be allowed or not. An example use case is a verifier that only allows certain `target` addresses to be paid. In this case, `shared` (a single value for a given Pot) is a merkle root, `target` is (as always) the address being paid, and `receipt` (specified by the payment recipient) is a merkle proof that the `target` address is within the merkle tree with the given root.\\nA server providing bandwidth needs to know whether to accept a certain receipt. To do that, it needs to know that at some time in the future, a call to the verifier's `good()` function with a particular set of parameters will return `true`. The proposed scheme for determining that is for the server to run the contract's code locally and ensure that it returns `true` and that it doesn't execute any EVM opcodes that would read state. This prevents, for example, a contract from returning `true` until a certain timestamp and then start returning `false`. If a contract could do that, the server would be tricked into providing bandwidth without then receiving payment.\\nUnfortunately, this simple scheme is insufficient. As a simple example, a verifier contract could be created with the `CREATE2` opcode. It could be demonstrated that it reads no state when `good()` is called. Then the contract could be destroyed by calling a function that performs a `SELFDESTRUCT`, and it could be replaced via another `CREATE2` call with different code.\\nThis could be mitigated by rejecting any verifier contract that contains the `SELFDESTRUCT` opcode, but this would also catch harmless occurrences of that particular byte. https://gist.github.com/Arachnid/e8f0638dc9f5687ff8170a95c47eac1e attempts to find `SELFDESTRUCT` opcodes but fails to account for tricks where the `SELFDESTRUCT` appears to be data but can actually be executed. (See Recmo's comment.) In general, this approach is difficult to get right and probably requires full data flow analysis to be correct.\\nAnother possible mitigation is to use a factory contract to deploy the verifiers, guaranteeing that they're not created with `CREATE2`. This should render `SELFDESTRUCT` harmless, but there's no guarantee that future forks won't introduce new vectors here.\\nFinally, requiring servers to implement potentially complex contract validation opens up potential for denial-of-service attacks. A server will have to implement mitigations to prevent repeatedly checking the same verifier or spending inordinate resources checking a maliciously crafted contract (e.g. one with high branching factors).чThe verifiers add quite a bit of complexity and risk. We recommend looking for an alternative approach, such as including a small number of vetted verifiers (e.g. a merkle proof verifier) or having servers use their own “allow list” for verifiers that they trust.чч```\\nfunction good(bytes calldata shared, address target, bytes calldata receipt) external pure returns (bool);\\n```\\n
Use consistent staker, stakee ordering in OrchidDirectoryчlowч```\\nfunction lift(bytes32 key, Stake storage stake, uint128 amount, address stakee, address staker) private {\\n```\\n\\n`OrchidDirectory.lift()` has a parameter `stakee` that precedes `staker`, while the rest of the code always places `staker` first. Because Solidity doesn't have named parameters, it's a good idea to use a consistent ordering to avoid mistakes.чResolution\\nThis is fixed in OrchidProtocol/[email protected]1cfef88.\\nSwitch `lift()` to follow the “staker then stakee” ordering convention of the rest of the contract.чч```\\nfunction lift(bytes32 key, Stake storage stake, uint128 amount, address stakee, address staker) private {\\n```\\n
In OrchidDirectory.step() and OrchidDirectory.lift(), use a signed amount  Won't Fixчlowч`step()` and `lift()` both accept a `uint128` parameter called `amount`. This `amount` is added to various struct fields, which are also of type `uint128`.\\nThe contract intentionally underflows this `amount` to represent negative numbers. This is roughly equivalent to using a signed integer, except that:\\nUnsigned integers aren't sign extended when they're cast to a larger integer type, so care must be taken to avoid this.\\nTools that look for integer overflow/underflow will detect this possibility as a bug. It's then hard to determine which overflows are intentional and which are not.\\n```\\nlift(key, stake, -amount, stakee, staker);\\n```\\n\\n```\\nstep(key, stake, -current.amount\\_, current.parent\\_);\\n```\\nчResolution\\nThe variables in question are now uint256s. The amount of type casts that would be needed in case the recommended change was implemented would defeat the purpose of simplification.\\nUse `int128` instead, and ensure that amounts can never exceed the maximum `int128` value. (This is trivially achieved by limiting the total number of tokens that can exist.)чч```\\nlift(key, stake, -amount, stakee, staker);\\n```\\n
Document that math in OrchidDirectory assumes a maximum number of tokensчlowч`OrchidDirectory` relies on mathematical operations being unable to overflow due to the particular ERC20 token being used being capped at less than `2**128`.\\nThe following code in `step()` assumes that no before/after amount can reach 2**128:\\n```\\nif (name(stake.left\\_) == key)\\n    stake.before\\_ += amount;\\nelse\\n    stake.after\\_ += amount;\\n```\\n\\nThe following code in `lift()` assumes that no staked amount (or total amount for a given stakee) can reach 2**128:\\n```\\nuint128 local = stake.amount\\_;\\nlocal += amount;\\nstake.amount\\_ = local;\\nemit Update(staker, stakee, local);\\n\\nuint128 global = stakees\\_[stakee].amount\\_;\\nglobal += amount;\\nstakees\\_[stakee].amount\\_ = global;\\n```\\n\\nThe following code in `have()` assumes that the total amount staked cannot reach 2**128:\\n```\\nreturn stake.before\\_ + stake.after\\_ + stake.amount\\_;\\n```\\nчDocument this assumption in the form of code comments where potential overflows exist.\\nConsider also asserting the ERC20 token's total supply in the constructor to attempt to block using a token that violates this constraint and/or checking in `push()` that the total amount staked will remain less than `2**128`. This recommendation is in line with the mitigation proposed for issue 6.7.чч```\\nif (name(stake.left\\_) == key)\\n    stake.before\\_ += amount;\\nelse\\n    stake.after\\_ += amount;\\n```\\n
Fees can be changed during the batchчhighчShareholders can vote to change the fees. For buy orders, fees are withdrawn immediately when order is submitted and the only risk is frontrunning by the shareholder's voting contract.\\nFor sell orders, fees are withdrawn when a trader claims an order and withdraws funds in `_claimSellOrder` function:\\n```\\nif (fee > 0) {\\n    reserve.transfer(\\_collateral, beneficiary, fee);\\n}\\n```\\n\\nFees can be changed between opening order and claiming this order which makes the fees unpredictable.чResolution\\nFixed with AragonBlack/[email protected]0941f53 by storing current fee in meta batch.\\nFees for an order should not be updated during its lifetime.чч```\\nif (fee > 0) {\\n    reserve.transfer(\\_collateral, beneficiary, fee);\\n}\\n```\\n
Bancor formula should not be updated during the batchчhighчShareholders can vote to change the bancor formula contract. That can make a price in the current batch unpredictable.\\n```\\nfunction updateFormula(IBancorFormula \\_formula) external auth(UPDATE\\_FORMULA\\_ROLE) {\\n    require(isContract(\\_formula), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateFormula(\\_formula);\\n}\\n```\\nчBancor formula update should be executed in the next batch or with a timelock that is greater than batch duration.чч```\\nfunction updateFormula(IBancorFormula \\_formula) external auth(UPDATE\\_FORMULA\\_ROLE) {\\n    require(isContract(\\_formula), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateFormula(\\_formula);\\n}\\n```\\n
Maximum slippage shouldn't be updated for the current batchчhighчWhen anyone submits a new order, the batch price is updated and it's checked whether the price slippage is acceptable. The problem is that the maximum slippage can be updated during the batch and traders cannot be sure that price is limited as they initially expected.\\n```\\nfunction \\_slippageIsValid(Batch storage \\_batch, address \\_collateral) internal view returns (bool) {\\n    uint256 staticPricePPM = \\_staticPricePPM(\\_batch.supply, \\_batch.balance, \\_batch.reserveRatio);\\n    uint256 maximumSlippage = collaterals[\\_collateral].slippage;\\n```\\n\\nAdditionally, if a maximum slippage is updated to a lower value, some of the orders that should lower the current slippage will also revert.чSave a slippage value on batch initialization and use it during the current batch.чч```\\nfunction \\_slippageIsValid(Batch storage \\_batch, address \\_collateral) internal view returns (bool) {\\n    uint256 staticPricePPM = \\_staticPricePPM(\\_batch.supply, \\_batch.balance, \\_batch.reserveRatio);\\n    uint256 maximumSlippage = collaterals[\\_collateral].slippage;\\n```\\n
AragonFundraisingController - an untapped address in toReset can block attempts of opening Trading after presaleчhighчAragonFundraisingController can be initialized with a list of token addresses `_toReset` that are to be reset when trading opens after the presale. These addresses are supposed to be addresses of tapped tokens. However, the list needs to be known when initializing the contract but the tapped tokens are added after initialization when calling `addCollateralToken` (and tapped with _rate>0). This can lead to an inconsistency that blocks `openTrading`.\\n```\\nfor (uint256 i = 0; i < \\_toReset.length; i++) {\\n    require(\\_tokenIsContractOrETH(\\_toReset[i]), ERROR\\_INVALID\\_TOKENS);\\n    toReset.push(\\_toReset[i]);\\n}\\n```\\n\\nIn case a token address makes it into the list of `toReset` tokens that is not tapped it will be impossible to `openTrading` as `tap.resetTappedToken(toReset[i]);` throws for untapped tokens. According to the permission setup in `FundraisingMultisigTemplate` only Controller can call `Marketmaker.open`\\n```\\nfunction openTrading() external auth(OPEN\\_TRADING\\_ROLE) {\\n    for (uint256 i = 0; i < toReset.length; i++) {\\n        tap.resetTappedToken(toReset[i]);\\n    }\\n\\n    marketMaker.open();\\n}\\n```\\nчInstead of initializing the Controller with a list of tapped tokens to be reset when trading opens, add a flag to `addCollateralToken` to indicate that the token should be reset when calling `openTrading`, making sure only tapped tokens are added to this list. This also allows adding tapped tokens that are to be reset at a later point in time.чч```\\nfor (uint256 i = 0; i < \\_toReset.length; i++) {\\n    require(\\_tokenIsContractOrETH(\\_toReset[i]), ERROR\\_INVALID\\_TOKENS);\\n    toReset.push(\\_toReset[i]);\\n}\\n```\\n
[New] Tapped collaterals can be bought by traders  Won't FixчmediumчWhen a trader submits a sell order, `_openSellOrder()` function checks that there are enough tokens in `reserve` by calling `_poolBalanceIsSufficient` function\\n```\\nfunction \\_poolBalanceIsSufficient(address \\_collateral) internal view returns (bool) {\\n    return controller.balanceOf(address(reserve), \\_collateral) >= collateralsToBeClaimed[\\_collateral];\\n}\\n```\\n\\nthe problem is that because `collateralsToBeClaimed[_collateral]` has increased, `controller.balanceOf(address(reserve), _collateral)` could also increase. It happens so because `controller.balanceOf()` function subtracts tapped amount from the reserve's balance.\\n```\\nfunction balanceOf(address \\_who, address \\_token) public view isInitialized returns (uint256) {\\n    uint256 balance = \\_token == ETH ? \\_who.balance : ERC20(\\_token).staticBalanceOf(\\_who);\\n\\n    if (\\_who == address(reserve)) {\\n        return balance.sub(tap.getMaximumWithdrawal(\\_token));\\n    } else {\\n        return balance;\\n    }\\n}\\n```\\n\\nAnd `tap.getMaximumWithdrawal(_token)` could decrease because it depends on `collateralsToBeClaimed[_collateral]`\\n```\\nfunction \\_tappedAmount(address \\_token) internal view returns (uint256) {\\n    uint256 toBeKept = controller.collateralsToBeClaimed(\\_token).add(floors[\\_token]);\\n    uint256 balance = \\_token == ETH ? address(reserve).balance : ERC20(\\_token).staticBalanceOf(reserve);\\n    uint256 flow = (\\_currentBatchId().sub(lastTappedAmountUpdates[\\_token])).mul(rates[\\_token]);\\n    uint256 tappedAmount = tappedAmounts[\\_token].add(flow);\\n    /\\*\\*\\n \\* whatever happens enough collateral should be\\n \\* kept in the reserve pool to guarantee that\\n \\* its balance is kept above the floor once\\n \\* all pending sell orders are claimed\\n \\*/\\n\\n    /\\*\\*\\n \\* the reserve's balance is already below the balance to be kept\\n \\* the tapped amount should be reset to zero\\n \\*/\\n    if (balance <= toBeKept) {\\n        return 0;\\n    }\\n\\n    /\\*\\*\\n \\* the reserve's balance minus the upcoming tap flow would be below the balance to be kept\\n \\* the flow should be reduced to balance - toBeKept\\n \\*/\\n    if (balance <= toBeKept.add(tappedAmount)) {\\n        return balance.sub(toBeKept);\\n    }\\n\\n    /\\*\\*\\n \\* the reserve's balance minus the upcoming flow is above the balance to be kept\\n \\* the flow can be added to the tapped amount\\n \\*/\\n    return tappedAmount;\\n}\\n```\\n\\nThat means that the amount that beneficiary can withdraw has just decreased, which should not be possible.чEnsure that `tappedAmount` cannot be decreased once updated.чч```\\nfunction \\_poolBalanceIsSufficient(address \\_collateral) internal view returns (bool) {\\n    return controller.balanceOf(address(reserve), \\_collateral) >= collateralsToBeClaimed[\\_collateral];\\n}\\n```\\n
Presale - contributionToken double cast and invalid comparisonчmediumчThe Presale can be configured to accept `ETH` or a valid `ERC20` `token`. This `token` is stored as an `ERC20` contract type in the state variable `contributionToken`. It is then directly compared to constant `ETH` which is `address(0x0)` in various locations. Additionally, the `_transfer` function double casts the `token` to `ERC20` if the `contributionToken` is passed as an argument.\\n`contribute` - invalid comparison of contract type against `address(0x00)`. Even though this is accepted in solidity `<0.5.0` it is going to raise a compiler error with newer versions (>=0.5.0).\\n```\\nfunction contribute(address \\_contributor, uint256 \\_value) external payable nonReentrant auth(CONTRIBUTE\\_ROLE) {\\n    require(state() == State.Funding, ERROR\\_INVALID\\_STATE);\\n\\n    if (contributionToken == ETH) {\\n        require(msg.value == \\_value, ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    } else {\\n        require(msg.value == 0,      ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    }\\n```\\n\\n`_transfer` - double cast `token` to `ERC20` if it is the contribution `token`.\\n```\\nrequire(ERC20(\\_token).safeTransfer(\\_to, \\_amount), ERROR\\_TOKEN\\_TRANSFER\\_REVERTED);\\n```\\nч`contributionToken` can either be `ETH` or a valid `ERC20` contract address. It is therefore recommended to store the token as an address type instead of the more precise contract type to resolve the double cast and the invalid contract type to address comparison or cast the `ERC20` type to `address()` before comparison.чч```\\nfunction contribute(address \\_contributor, uint256 \\_value) external payable nonReentrant auth(CONTRIBUTE\\_ROLE) {\\n    require(state() == State.Funding, ERROR\\_INVALID\\_STATE);\\n\\n    if (contributionToken == ETH) {\\n        require(msg.value == \\_value, ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    } else {\\n        require(msg.value == 0,      ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    }\\n```\\n
Fees are not returned for buy orders if a batch is canceled  Won't FixчmediumчEvery trader pays fees on each buy order and transfers it directly to the `beneficiary`.\\n```\\nuint256 fee = \\_value.mul(buyFeePct).div(PCT\\_BASE);\\nuint256 value = \\_value.sub(fee);\\n\\n// collect fee and collateral\\nif (fee > 0) {\\n    \\_transfer(\\_buyer, beneficiary, \\_collateral, fee);\\n}\\n\\_transfer(\\_buyer, address(reserve), \\_collateral, value);\\n```\\n\\nIf the batch is canceled, fees are not returned to the traders because there is no access to the beneficiary account.\\nAdditionally, fees are returned to traders for all the sell orders if the batch is canceled.чConsider transferring fees to a beneficiary only after the batch is over.чч```\\nuint256 fee = \\_value.mul(buyFeePct).div(PCT\\_BASE);\\nuint256 value = \\_value.sub(fee);\\n\\n// collect fee and collateral\\nif (fee > 0) {\\n    \\_transfer(\\_buyer, beneficiary, \\_collateral, fee);\\n}\\n\\_transfer(\\_buyer, address(reserve), \\_collateral, value);\\n```\\n
Tap - Controller should not be updateableчmediumчSimilar to the issue 6.11, `Tap` allows updating the `Controller` contract it is using. The permission is currently not assigned in the `FundraisingMultisigTemplate` but might be used in custom deployments.\\n```\\n/\\*\\*\\n \\* @notice Update controller to `\\_controller`\\n \\* @param \\_controller The address of the new controller contract\\n\\*/\\nfunction updateController(IAragonFundraisingController \\_controller) external auth(UPDATE\\_CONTROLLER\\_ROLE) {\\n    require(isContract(\\_controller), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateController(\\_controller);\\n}\\n```\\nчTo avoid inconsistencies, we suggest to remove this functionality and provide a guideline on how to safely upgrade components of the system.чч```\\n/\\*\\*\\n \\* @notice Update controller to `\\_controller`\\n \\* @param \\_controller The address of the new controller contract\\n\\*/\\nfunction updateController(IAragonFundraisingController \\_controller) external auth(UPDATE\\_CONTROLLER\\_ROLE) {\\n    require(isContract(\\_controller), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateController(\\_controller);\\n}\\n```\\n
Tap - reserve can be updated in Tap but not in MarketMaker or ControllerчmediumчThe address of the pool/reserve contract can be updated in `Tap` if someone owns the `UPDATE_RESERVE_ROLE` permission. The permission is currently not assigned in the template.\\nThe reserve is being referenced by multiple Contracts. `Tap` interacts with it to transfer funds to the beneficiary, `Controller` adds new protected tokens, and `MarketMaker` transfers funds when someone sells their Shareholder token.\\nUpdating reserve only in `Tap` is inconsistent with the system as the other contracts are still referencing the old reserve unless they are updated via the Aragon Application update mechanisms.\\n```\\n/\\*\\*\\n \\* @notice Update reserve to `\\_reserve`\\n \\* @param \\_reserve The address of the new reserve [pool] contract\\n\\*/\\nfunction updateReserve(Vault \\_reserve) external auth(UPDATE\\_RESERVE\\_ROLE) {\\n    require(isContract(\\_reserve), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateReserve(\\_reserve);\\n}\\n```\\nчRemove the possibility to update reserve in `Tap` to keep the system consistent. Provide information about update mechanisms in case the reserve needs to be updated for all components.чч```\\n/\\*\\*\\n \\* @notice Update reserve to `\\_reserve`\\n \\* @param \\_reserve The address of the new reserve [pool] contract\\n\\*/\\nfunction updateReserve(Vault \\_reserve) external auth(UPDATE\\_RESERVE\\_ROLE) {\\n    require(isContract(\\_reserve), ERROR\\_CONTRACT\\_IS\\_EOA);\\n\\n    \\_updateReserve(\\_reserve);\\n}\\n```\\n
Presale can be opened earlier than initially assigned dateчmediumчThere are 2 ways how presale opening date can be assigned. Either it's defined on initialization or the presale will start when `open()` function is executed.\\n```\\nif (\\_openDate != 0) {\\n    \\_setOpenDate(\\_openDate);\\n}\\n```\\n\\nThe problem is that even if `openDate` is assigned to some non-zero date, it can still be opened earlier by calling `open()` function.\\n```\\nfunction open() external auth(OPEN\\_ROLE) {\\n    require(state() == State.Pending, ERROR\\_INVALID\\_STATE);\\n\\n    \\_open();\\n}\\n```\\nчRequire that `openDate` is not set (0) when someone manually calls the `open()` function.чч```\\nif (\\_openDate != 0) {\\n    \\_setOpenDate(\\_openDate);\\n}\\n```\\n
Presale - should not allow zero value contributionsчlowчThe Presale accepts zero value contributions emitting a contribution event if none of the Aragon components (TokenManager, MinimeToken) raises an exception.\\n```\\nfunction contribute(address \\_contributor, uint256 \\_value) external payable nonReentrant auth(CONTRIBUTE\\_ROLE) {\\n    require(state() == State.Funding, ERROR\\_INVALID\\_STATE);\\n\\n    if (contributionToken == ETH) {\\n        require(msg.value == \\_value, ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    } else {\\n        require(msg.value == 0,      ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    }\\n\\n    \\_contribute(\\_contributor, \\_value);\\n}\\n```\\nчReject zero value `ETH` or `ERC20` contributions.чч```\\nfunction contribute(address \\_contributor, uint256 \\_value) external payable nonReentrant auth(CONTRIBUTE\\_ROLE) {\\n    require(state() == State.Funding, ERROR\\_INVALID\\_STATE);\\n\\n    if (contributionToken == ETH) {\\n        require(msg.value == \\_value, ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    } else {\\n        require(msg.value == 0,      ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\\n    }\\n\\n    \\_contribute(\\_contributor, \\_value);\\n}\\n```\\n
FundraisingMultisigTemplate - should use BaseTemplate._createPermissionForTemplate() to assign permissions to itselfчlowчThe template temporarily assigns permissions to itself to be able to configure parts of the system. This can either be done by calling `acl.createPermission(address(this), app, role, manager)` or by using a distinct method provided with the DAO-Templates BaseTemplate `_createPermissionForTemplate`.\\nWe suggest that in order to make it clear that permissions are assigned to the template and make it easier to audit that permissions are either revoked or transferred before the DAO is transferred to the new user, the method provided and used with the default Aragon DAO-Templates should be used.\\nuse `createPermission` if permissions are assigned to an entity other than the template contract.\\nuse `_createPermissionForTemplate` when creating permissions for the template contract.\\n```\\n// create and grant ADD\\_PROTECTED\\_TOKEN\\_ROLE to this template\\nacl.createPermission(this, controller, controller.ADD\\_COLLATERAL\\_TOKEN\\_ROLE(), this);\\n```\\n\\nSidenote: pass `address(this)` instead of the contract instance to `createPermission`.чResolution\\nFixed with AragonBlack/[email protected]dd153e0.\\nUse `BaseTemplate._createPermissionForTemplate` to assign permissions to the template.чч```\\n// create and grant ADD\\_PROTECTED\\_TOKEN\\_ROLE to this template\\nacl.createPermission(this, controller, controller.ADD\\_COLLATERAL\\_TOKEN\\_ROLE(), this);\\n```\\n
FundraisingMultisigTemplate - misleading commentsчlowчThe comment mentionsADD_PROTECTED_TOKEN_ROLE but permissions for `ADD_COLLATERAL_TOKEN_ROLE` are created.\\n```\\n// create and grant ADD\\_PROTECTED\\_TOKEN\\_ROLE to this template\\nacl.createPermission(this, controller, controller.ADD\\_COLLATERAL\\_TOKEN\\_ROLE(), this);\\n```\\n\\n```\\n// transfer ADD\\_PROTECTED\\_TOKEN\\_ROLE\\n\\_transferPermissionFromTemplate(acl, controller, shareVoting, controller.ADD\\_COLLATERAL\\_TOKEN\\_ROLE(), shareVoting);\\n```\\nч`ADD_PROTECTED_TOKEN_ROLE` in the comment should be `ADD_COLLATERAL_TOKEN_ROLE`.чч```\\n// create and grant ADD\\_PROTECTED\\_TOKEN\\_ROLE to this template\\nacl.createPermission(this, controller, controller.ADD\\_COLLATERAL\\_TOKEN\\_ROLE(), this);\\n```\\n
FundraisingMultisigTemplate - unnecessary cast to addressчlowчThe addresses of DAI (argument `address` _dai) and AND (argument `address` _ant) are unnecessarily cast to `address`.\\n```\\nconstructor(\\n    DAOFactory              \\_daoFactory,\\n    ENS                     \\_ens,\\n    MiniMeTokenFactory      \\_miniMeFactory,\\n    IFIFSResolvingRegistrar \\_aragonID,\\n    address                 \\_dai,\\n    address                 \\_ant\\n)\\n    BaseTemplate(\\_daoFactory, \\_ens, \\_miniMeFactory, \\_aragonID)\\n    public\\n{\\n    \\_ensureAragonIdIsValid(\\_aragonID);\\n    \\_ensureMiniMeFactoryIsValid(\\_miniMeFactory);\\n    \\_ensureTokenIsContractOrETH(\\_dai);\\n    \\_ensureTokenIsContractOrETH(\\_ant);\\n\\n    collaterals.push(address(\\_dai));\\n    collaterals.push(address(\\_ant));\\n}\\n```\\nчBoth arguments are already of type `address`, therefore remove the explicit cast to `address()` when pushing to the `collaterals` array.чч```\\nconstructor(\\n    DAOFactory              \\_daoFactory,\\n    ENS                     \\_ens,\\n    MiniMeTokenFactory      \\_miniMeFactory,\\n    IFIFSResolvingRegistrar \\_aragonID,\\n    address                 \\_dai,\\n    address                 \\_ant\\n)\\n    BaseTemplate(\\_daoFactory, \\_ens, \\_miniMeFactory, \\_aragonID)\\n    public\\n{\\n    \\_ensureAragonIdIsValid(\\_aragonID);\\n    \\_ensureMiniMeFactoryIsValid(\\_miniMeFactory);\\n    \\_ensureTokenIsContractOrETH(\\_dai);\\n    \\_ensureTokenIsContractOrETH(\\_ant);\\n\\n    collaterals.push(address(\\_dai));\\n    collaterals.push(address(\\_ant));\\n}\\n```\\n
FundraisingMultisigTemplate - DAI/ANT token address cannot be zeroчlowчThe fundraising template is configured with the `DAI` and `ANT` token address upon deployment and checks if the provided addresses are valid. The check performed is `_ensureTokenIsContractOrETH()` which allows the `address(0)` (constant for ETH) for the token contracts. However, `address(0)` is not a valid option for either `DAI` or `ANT` and the contract expects a valid token address to be provided as the deployment of a new DAO will have unexpected results (collateral `ETH` is added instead of an ERC20 token) or fail (DAI == `ANT` == 0x0).\\n```\\n\\_ensureTokenIsContractOrETH(\\_dai);\\n\\_ensureTokenIsContractOrETH(\\_ant);\\n```\\n\\n```\\n function \\_ensureTokenIsContractOrETH(address \\_token) internal view returns (bool) {\\n    require(isContract(\\_token) || \\_token == ETH, ERROR\\_BAD\\_SETTINGS);\\n}\\n```\\nчResolution\\nFixed with AragonBlack/[email protected]da561ce.\\nUse `isContract()` instead of `_ensureTokenIsContractOrETH()` and optionally require that `collateral[0] != collateral[1]` as an additional check to prevent that the fundraising template is being deployed with an invalid configuration.чч```\\n\\_ensureTokenIsContractOrETH(\\_dai);\\n\\_ensureTokenIsContractOrETH(\\_ant);\\n```\\n
Anyone can remove a maker's pending pool join statusчhighчUsing behavior described in https://github.com/ConsenSys/0x-v3-staking-audit-2019-10/issues/11, it is possible to delete the pending join status of any maker in any pool by passing in `NIL_POOL_ID` to `removeMakerFromStakingPool`. Note that the attacker in the following example must not be a confirmed member of any pool:\\nThe attacker calls `addMakerToStakingPool(NIL_POOL_ID, makerAddress)`. In this case, `makerAddress` can be almost any address, as long as it has not called `joinStakingPoolAsMaker` (an easy example is address(0)). The key goal of this call is to increment the number of makers in pool 0:\\n```\\n\\_poolById[poolId].numberOfMakers = uint256(pool.numberOfMakers).safeAdd(1).downcastToUint32();\\n```\\n\\nThe attacker calls `removeMakerFromStakingPool(NIL_POOL_ID, targetAddress)`. This function queries `getStakingPoolIdOfMaker(targetAddress)` and compares it to the passed-in pool id. Because the target is an unconfirmed maker, their staking pool id is NIL_POOL_ID:\\n```\\nbytes32 makerPoolId = getStakingPoolIdOfMaker(makerAddress);\\nif (makerPoolId != poolId) {\\n    LibRichErrors.rrevert(LibStakingRichErrors.MakerPoolAssignmentError(\\n        LibStakingRichErrors.MakerPoolAssignmentErrorCodes.MakerAddressNotRegistered,\\n        makerAddress,\\n        makerPoolId\\n    ));\\n}\\n```\\n\\nThe check passes, and the target's `_poolJoinedByMakerAddress` struct is deleted. Additionally, the number of makers in pool 0 is decreased:\\n```\\ndelete \\_poolJoinedByMakerAddress[makerAddress];\\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\\n```\\n\\nThis can be used to prevent any makers from being confirmed into a pool.чSee `issue 5.6`.чч```\\n\\_poolById[poolId].numberOfMakers = uint256(pool.numberOfMakers).safeAdd(1).downcastToUint32();\\n```\\n
MixinParams.setParams bypasses safety checks made by standard StakingProxy upgrade path.чmediumчThe staking contracts use a set of configurable parameters to determine the behavior of various parts of the system. The parameters dictate the duration of epochs, the ratio of delegated stake weight vs operator stake, the minimum pool stake, and the Cobb-Douglas numerator and denominator. These parameters can be configured in two ways:\\n```\\n// Call `init()` on the staking contract to initialize storage.\\n(bool didInitSucceed, bytes memory initReturnData) = stakingContract.delegatecall(\\n    abi.encodeWithSelector(IStorageInit(0).init.selector)\\n);\\nif (!didInitSucceed) {\\n    assembly {\\n        revert(add(initReturnData, 0x20), mload(initReturnData))\\n    }\\n}\\n  \\n// Assert initialized storage values are valid\\n\\_assertValidStorageParams();\\n```\\n\\nAn authorized address can call `MixinParams.setParams` at any time and set the contract's parameters to arbitrary values.\\nThe latter method introduces the possibility of setting unsafe or nonsensical values for the contract parameters: `epochDurationInSeconds` can be set to 0, `cobbDouglassAlphaNumerator` can be larger than `cobbDouglassAlphaDenominator`, `rewardDelegatedStakeWeight` can be set to a value over 100% of the staking reward, and more.\\nNote, too, that by using `MixinParams.setParams` to set all parameters to 0, the `Staking` contract can be re-initialized by way of `Staking.init`. Additionally, it can be re-attached by way of `StakingProxy.attachStakingContract`, as the delegatecall to `Staking.init` will succeed.чResolution\\nThis is fixed in 0xProject/0x-monorepo#2279. Now the parameter validity is asserted in `setParams()`.\\nEnsure that calls to `setParams` check that the provided values are within the same range currently enforced by the proxy.чч```\\n// Call `init()` on the staking contract to initialize storage.\\n(bool didInitSucceed, bytes memory initReturnData) = stakingContract.delegatecall(\\n    abi.encodeWithSelector(IStorageInit(0).init.selector)\\n);\\nif (!didInitSucceed) {\\n    assembly {\\n        revert(add(initReturnData, 0x20), mload(initReturnData))\\n    }\\n}\\n  \\n// Assert initialized storage values are valid\\n\\_assertValidStorageParams();\\n```\\n
Authorized addresses can indefinitely stall ZrxVaultBackstop catastrophic failure modeчmediumчThe `ZrxVaultBackstop` contract was added to allow anyone to activate the staking system's “catastrophic failure” mode if the `StakingProxy` is in “read-only” mode for at least 40 days. To enable this behavior, the `StakingProxy` contract was modified to track the last timestamp at which “read-only” mode was activated. This is done by way of StakingProxy.setReadOnlyMode:\\n```\\n/// @dev Set read-only mode (state cannot be changed).\\nfunction setReadOnlyMode(bool shouldSetReadOnlyMode)\\n    external\\n    onlyAuthorized\\n{\\n    // solhint-disable-next-line not-rely-on-time\\n    uint96 timestamp = block.timestamp.downcastToUint96();\\n    if (shouldSetReadOnlyMode) {\\n        stakingContract = readOnlyProxy;\\n        readOnlyState = IStructs.ReadOnlyState({\\n            isReadOnlyModeSet: true,\\n            lastSetTimestamp: timestamp\\n        });\\n```\\n\\nBecause the timestamp is updated even if “read-only” mode is already active, any authorized address can prevent `ZrxVaultBackstop` from activating catastrophic failure mode by repeatedly calling `setReadOnlyMode`.чIf “read-only” mode is already active, `setReadOnlyMode(true)` should result in a no-op.чч```\\n/// @dev Set read-only mode (state cannot be changed).\\nfunction setReadOnlyMode(bool shouldSetReadOnlyMode)\\n    external\\n    onlyAuthorized\\n{\\n    // solhint-disable-next-line not-rely-on-time\\n    uint96 timestamp = block.timestamp.downcastToUint96();\\n    if (shouldSetReadOnlyMode) {\\n        stakingContract = readOnlyProxy;\\n        readOnlyState = IStructs.ReadOnlyState({\\n            isReadOnlyModeSet: true,\\n            lastSetTimestamp: timestamp\\n        });\\n```\\n
Pool 0 can be used to temporarily prevent makers from joining another poolчmediumч`removeMakerFromStakingPool` reverts if the number of makers currently in the pool is 0, due to `safeSub` catching an underflow:\\n```\\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\\n```\\n\\nBecause of this, edge behavior described in issue 5.6 can allow an attacker to temporarily prevent makers from joining a pool:\\nThe attacker calls `addMakerToStakingPool(NIL_POOL_ID, victimAddress)`. This sets the victim's `MakerPoolJoinStatus.confirmed` field to `true` and increases the number of makers in pool 0 to 1:\\n```\\npoolJoinStatus = IStructs.MakerPoolJoinStatus({\\n    poolId: poolId,\\n    confirmed: true\\n});\\n\\_poolJoinedByMakerAddress[makerAddress] = poolJoinStatus;\\n\\_poolById[poolId].numberOfMakers = uint256(pool.numberOfMakers).safeAdd(1).downcastToUint32();\\n```\\n\\nThe attacker calls `removeMakerFromStakingPool(NIL_POOL_ID, randomAddress)`. The net effect of this call simply decreases the number of makers in pool 0 by 1, back to 0:\\n```\\ndelete \\_poolJoinedByMakerAddress[makerAddress];\\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\\n```\\n\\nTypically, the victim should be able to remove themselves from pool 0 by calling `removeMakerFromStakingPool(NIL_POOL_ID, victimAddress)`, but because the attacker can set the pool's number of makers to 0, the aforementioned underflow causes this call to fail. The victim must first understand what is happening in `MixinStakingPool` before they are able to remedy the situation:\\nThe victim must call `addMakerToStakingPool(NIL_POOL_ID, randomAddress2)` to increase pool 0's number of makers back to 1.\\nThe victim can now call `removeMakerFromStakingPool(NIL_POOL_ID, victimAddress)`, and remove their confirmed status.\\nAdditionally, if the victim in question currently has a pending join, the attacker can use issue 5.1 to first remove their pending status before locking them in pool 0.чSee issue 5.1.чч```\\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\\n```\\n
Recommendation: Fix weak assertions in MixinStakingPool stemming from use of NIL_POOL_IDчmediumчThe modifier `onlyStakingPoolOperatorOrMaker(poolId)` is used to authorize actions taken on a given pool. The sender must be either the operator or a confirmed maker of the pool in question. However, the modifier queries `getStakingPoolIdOfMaker(maker)`, which returns `NIL_POOL_ID` if the maker's `MakerPoolJoinStatus` struct is not confirmed. This implicitly makes anyone a maker of the nonexistent “pool 0”:\\n```\\nfunction getStakingPoolIdOfMaker(address makerAddress)\\n    public\\n    view\\n    returns (bytes32)\\n{\\n    IStructs.MakerPoolJoinStatus memory poolJoinStatus = \\_poolJoinedByMakerAddress[makerAddress];\\n    if (poolJoinStatus.confirmed) {\\n        return poolJoinStatus.poolId;\\n    } else {\\n        return NIL\\_POOL\\_ID;\\n    }\\n}\\n```\\n\\n`joinStakingPoolAsMaker(poolId)` makes no existence checks on the provided pool id, and allows makers to become pending makers in nonexistent pools.\\n`addMakerToStakingPool(poolId, maker)` makes no existence checks on the provided pool id, allowing makers to be added to nonexistent pools (as long as the sender is an operator or maker in the pool).чAvoid use of `0x00...00` for `NIL_POOL_ID`. Instead, use `2**256 - 1`.\\nImplement stronger checks for pool existence. Each time a pool id is supplied, it should be checked that the pool id is between 0 and `nextPoolId`.\\n`onlyStakingPoolOperatorOrMaker` should revert if `poolId == NIL_POOL_ID` or if `poolId` is not in the valid range: (0, nextPoolId).чч```\\nfunction getStakingPoolIdOfMaker(address makerAddress)\\n    public\\n    view\\n    returns (bytes32)\\n{\\n    IStructs.MakerPoolJoinStatus memory poolJoinStatus = \\_poolJoinedByMakerAddress[makerAddress];\\n    if (poolJoinStatus.confirmed) {\\n        return poolJoinStatus.poolId;\\n    } else {\\n        return NIL\\_POOL\\_ID;\\n    }\\n}\\n```\\n
LibFixedMath functions fail to catch a number of overflowsчmediumчThe `__add()`, `__mul()`, and `__div()` functions perform arithmetic on 256-bit signed integers, and they all miss some specific overflows.\\nAddition Overflows\\n```\\n/// @dev Adds two numbers, reverting on overflow.\\nfunction \\_add(int256 a, int256 b) private pure returns (int256 c) {\\n    c = a + b;\\n    if (c > 0 && a < 0 && b < 0) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.SUBTRACTION\\_OVERFLOW,\\n            a,\\n            b\\n        ));\\n    }\\n    if (c < 0 && a > 0 && b > 0) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.ADDITION\\_OVERFLOW,\\n            a,\\n            b\\n        ));\\n    }\\n}\\n```\\n\\nThe two overflow conditions it tests for are:\\nAdding two positive numbers shouldn't result in a negative number.\\nAdding two negative numbers shouldn't result in a positive number.\\n`__add(-2**255, -2**255)` returns `0` without reverting because the overflow didn't match either of the above conditions.\\nMultiplication Overflows\\n```\\n/// @dev Returns the multiplication two numbers, reverting on overflow.\\nfunction \\_mul(int256 a, int256 b) private pure returns (int256 c) {\\n    if (a == 0) {\\n        return 0;\\n    }\\n    c = a \\* b;\\n    if (c / a != b) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.MULTIPLICATION\\_OVERFLOW,\\n            a,\\n            b\\n        ));\\n    }\\n}\\n```\\n\\nThe function checks via division for most types of overflows, but it fails to catch one particular case. `__mul(-2**255, -1)` returns `-2**255` without error.\\nDivision Overflows\\n```\\n/// @dev Returns the division of two numbers, reverting on division by zero.\\nfunction \\_div(int256 a, int256 b) private pure returns (int256 c) {\\n    if (b == 0) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.DIVISION\\_BY\\_ZERO,\\n            a,\\n            b\\n        ));\\n    }\\n    c = a / b;\\n}\\n```\\n\\nIt does not check for overflow. Due to this, `__div(-2**255, -1)` erroneously returns `-2**255`.чFor addition, the specific case of `__add(-2**255, -2**255)` can be detected by using a `>= 0` check instead of `> 0`, but the below seems like a clearer check for all cases:\\n```\\n// if b is negative, then the result should be less than a\\nif (b < 0 && c >= a) { /\\* subtraction overflow \\*/ }\\n\\n// if b is positive, then the result should be greater than a\\nif (b > 0 && c <= a) { /\\* addition overflow \\*/ }\\n```\\n\\nFor multiplication and division, the specific values of `-2**255` and `-1` are the only missing cases, so that can be explicitly checked in the `__mul()` and `__div()` functions.чч```\\n/// @dev Adds two numbers, reverting on overflow.\\nfunction \\_add(int256 a, int256 b) private pure returns (int256 c) {\\n    c = a + b;\\n    if (c > 0 && a < 0 && b < 0) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.SUBTRACTION\\_OVERFLOW,\\n            a,\\n            b\\n        ));\\n    }\\n    if (c < 0 && a > 0 && b > 0) {\\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\\n            LibFixedMathRichErrors.BinOpErrorCodes.ADDITION\\_OVERFLOW,\\n            a,\\n            b\\n        ));\\n    }\\n}\\n```\\n
Misleading MoveStake event when moving stake from UNDELEGATED to UNDELEGATEDчlowчAlthough moving stake between the same status (UNDELEGATED <=> UNDELEGATED) should be a no-op, calls to `moveStake` succeed even for invalid `amount` and nonsensical `poolId`. The resulting `MoveStake` event can log garbage, potentially confusing those observing events.\\nWhen moving between `UNDELEGATED` and `UNDELEGATED`, each check and function call results in a no-op, save the final event:\\nNeither `from` nor `to` are `StakeStatus.DELEGATED`, so these checks are passed:\\n```\\nif (from.status == IStructs.StakeStatus.DELEGATED) {\\n    \\_undelegateStake(\\n        from.poolId,\\n        staker,\\n        amount\\n    );\\n}\\n  \\nif (to.status == IStructs.StakeStatus.DELEGATED) {\\n    \\_delegateStake(\\n        to.poolId,\\n        staker,\\n        amount\\n    );\\n}\\n```\\n\\nThe primary state changing function, `_moveStake`, immediately returns because the `from` and `to` balance pointers are equivalent:\\n```\\nif (\\_arePointersEqual(fromPtr, toPtr)) {\\n    return;\\n}\\n```\\n\\nFinally, the `MoveStake` event is invoked, which can log completely invalid values for `amount`, `from.poolId`, and to.poolId:\\n```\\nemit MoveStake(\\n    staker,\\n    amount,\\n    uint8(from.status),\\n    from.poolId,\\n    uint8(to.status),\\n    to.poolId\\n);\\n```\\nчIf `amount` is 0 or if moving between `UNDELEGATED` and `UNDELEGATED`, this function should no-op or revert. An explicit check for this case should be made near the start of the function.чч```\\nif (from.status == IStructs.StakeStatus.DELEGATED) {\\n    \\_undelegateStake(\\n        from.poolId,\\n        staker,\\n        amount\\n    );\\n}\\n  \\nif (to.status == IStructs.StakeStatus.DELEGATED) {\\n    \\_delegateStake(\\n        to.poolId,\\n        staker,\\n        amount\\n    );\\n}\\n```\\n
Remove unneeded fields from StoredBalance and Pool structsчlowчResolution\\nThis is fixed in 0xProject/0x-monorepo#2248. As part of a larger refactor, these fields were removed.\\nBoth structs have fields that are only written to, and never read:\\nStoredBalance.isInitialized:\\n```\\nbool isInitialized;\\n```\\n\\nPool.initialized:\\n```\\nbool initialized;\\n```\\nчThe unused fields should be removed.чч```\\nbool isInitialized;\\n```\\n
Pool IDs can just be incrementing integersчlowчPool IDs are currently `bytes32` values that increment by `2**128`. After discussion with the development team, it seems that this was in preparation for a feature that was ultimately not used. Pool IDs should instead just be incrementing integers.\\n```\\n// The upper 16 bytes represent the pool id, so this would be pool id 1. See MixinStakinPool for more information.\\nbytes32 constant internal INITIAL\\_POOL\\_ID = 0x0000000000000000000000000000000100000000000000000000000000000000;\\n\\n// The upper 16 bytes represent the pool id, so this would be an increment of 1. See MixinStakinPool for more information.\\nuint256 constant internal POOL\\_ID\\_INCREMENT\\_AMOUNT = 0x0000000000000000000000000000000100000000000000000000000000000000;\\n```\\n\\n```\\n/// @dev Computes the unique id that comes after the input pool id.\\n/// @param poolId Unique id of pool.\\n/// @return Next pool id after input pool.\\nfunction \\_computeNextStakingPoolId(bytes32 poolId)\\n    internal\\n    pure\\n    returns (bytes32)\\n{\\n    return bytes32(uint256(poolId).safeAdd(POOL\\_ID\\_INCREMENT\\_AMOUNT));\\n}\\n```\\nчResolution\\nThis is fixed in 0xProject/0x-monorepo#2250. Pool IDs now start at 1 and increment by 1 each time.\\nMake pool IDs `uint256` values and simply add 1 to generate the next ID.чч```\\n// The upper 16 bytes represent the pool id, so this would be pool id 1. See MixinStakinPool for more information.\\nbytes32 constant internal INITIAL\\_POOL\\_ID = 0x0000000000000000000000000000000100000000000000000000000000000000;\\n\\n// The upper 16 bytes represent the pool id, so this would be an increment of 1. See MixinStakinPool for more information.\\nuint256 constant internal POOL\\_ID\\_INCREMENT\\_AMOUNT = 0x0000000000000000000000000000000100000000000000000000000000000000;\\n```\\n
LibProxy.proxyCall() may overwrite important memoryчlowч`LibProxy.proxyCall()` copies from call data to memory, starting at address 0:\\n```\\nassembly {\\n    // store selector of destination function\\n    let freeMemPtr := 0\\n    if gt(customEgressSelector, 0) {\\n        mstore(0x0, customEgressSelector)\\n        freeMemPtr := add(freeMemPtr, 4)\\n    }\\n\\n    // adjust the calldata offset, if we should ignore the selector\\n    let calldataOffset := 0\\n    if gt(ignoreIngressSelector, 0) {\\n        calldataOffset := 4\\n    }\\n\\n    // copy calldata to memory\\n    calldatacopy(\\n        freeMemPtr,\\n        calldataOffset,\\n        calldatasize()\\n    )\\n```\\n\\nThe first 64 bytes of memory are treated as “scratch space” by the Solidity compiler. Writing beyond that point is dangerous, as it will overwrite the free memory pointer and the “zero slot” which is where length-0 arrays point.\\nAlthough the current callers of `proxyCall()` don't appear to use any memory after calling `proxyCall()`, future changes to the code may introduce very serious and subtle bugs due to this unsafe handling of memory.чUse the actual free memory pointer to determine where it's safe to write to memory.чч```\\nassembly {\\n    // store selector of destination function\\n    let freeMemPtr := 0\\n    if gt(customEgressSelector, 0) {\\n        mstore(0x0, customEgressSelector)\\n        freeMemPtr := add(freeMemPtr, 4)\\n    }\\n\\n    // adjust the calldata offset, if we should ignore the selector\\n    let calldataOffset := 0\\n    if gt(ignoreIngressSelector, 0) {\\n        calldataOffset := 4\\n    }\\n\\n    // copy calldata to memory\\n    calldatacopy(\\n        freeMemPtr,\\n        calldataOffset,\\n        calldatasize()\\n    )\\n```\\n
NodeRegistry - URL can be arbitrary dns resolvable names, IP's and even localhost or private subnetsчhighчAs outlined in issue 6.9 the `NodeRegistry` allows anyone to register nodes with arbitrary URLs. The `url` is then used by `in3-server` or clients to connect to other nodes in the system. Signers can only be convicted if they sign wrong blockhashes. However, if they never provide any signatures they can stay in the registry for as long as they want and sabotage the network. The Registry implements an admin functionality that is available for the first year to remove misbehaving nodes (or spam entries) from the Registry. However, this is insufficient as an attacker might just re-register nodes after the minimum timeout they specify or spend some more finneys on registering more nodes. Depending on the eth-price this will be more or less profitable.\\nFrom an attackers perspective the `NodeRegistry` is a good source of information for reconnaissance, allows to de-anonymize and profile nodes based on dns entries or netblocks or responses to `in3_stats` (https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/49), makes a good list of target for DoS attacks on the system or makes it easy to exploit nodes for certain yet unknown security vulnerabilities.\\nSince nodes and potentially clients (not in scope) do not validate the rpc URL received from the `NodeRegistry` they will try to connect to whatever is stored in a nodes `url` entry.\\ncode/in3-server/src/chains/signatures.ts:L58-L75\\n```\\nconst config = nodes.nodes.find(\\_ => \\_.address.toLowerCase() === adr.toLowerCase())\\nif (!config) // TODO do we need to throw here or is it ok to simply not deliver the signature?\\n  throw new Error('The ' + adr + ' does not exist within the current registered active nodeList!')\\n\\n// get cache signatures and remaining blocks that have no signatures\\nconst cachedSignatures: Signature[] = []\\nconst blocksToRequest = blocks.filter(b => {\\n  const s = signatureCaches.get(b.hash) && false\\n  return s ? cachedSignatures.push(s) \\* 0 : true\\n})\\n\\n// send the sign-request\\nlet response: RPCResponse\\ntry {\\n  response = (blocksToRequest.length\\n    ? await handler.transport.handle(config.url, { id: handler.counter++ || 1, jsonrpc: '2.0', method: 'in3\\_sign', params: blocksToRequest })\\n    : { result: [] }) as RPCResponse\\n  if (response.error) {\\n```\\n\\nThis allows for a wide range of attacks not limited to:\\nAn attacker might register a node with an empty or invalid URL. The `in3-server` does not validate the URL and therefore will attempt to connect to the invalid URL, spending resources (cpu, file-descriptors, ..) to find out that it is invalid.\\nAn attacker might register a node with a URL that is pointing to another node's rpc endpoint and specify weights that suggest that it is capable of service a lot of requests to draw more traffic towards that node in an attempt to cause a DoS situation.\\nAn attacker might register a node for a http/https website at any port in an extortion attempt directed to website owners. The incubed network nodes will have to learn themselves that the URL is invalid and they will at least attempt to connect the website once.\\nAn attacker might update the node information in the `NodeRegistry` for a specific node every block, providing a new `url` (or a slightly different URLs issue 6.9) to avoid client/node URL blacklists.\\nAn attacker might provide IP addresses instead of DNS resolvable names with the `url` in an attempt to draw traffic to targets, avoiding canonicalization and blacklisting features.\\nAn attacker might provide a URL that points to private IP netblocks for IPv4 or IPv6 in various formats. Combined with the ability to ask another node to connect to an attacker defined `url` (via blockproof, signatures[] -> signer_address -> signer.url) this might allow an attacker to enumerate services in the LAN of node operators.\\nAn attacker might provide the loopback IPv4, IPv6 or resolvable name as the URL in an attempt to make the node connect to local loopback services (service discovery, bypassing authentication for some local running services - however this is very limited to the requests nodes may execute).\\nURLs may be provided in various formats: resolvable dns names, IPv4, IPv6 and depending on the http handler implementation even in Decimal, Hex or Octal form (i.e. http://2130706433/)\\nA valid DNS resolvable name might point to a localhost or private IP netblock.\\nSince none of the rpc endpoints provide signatures they cannot be convicted or removed (unless the `unregisterKey` does it within the first year. However, that will not solve the problem that someone can re-register the same URLs over and over again)чResolution\\nThis issue has been addressed with the following commits:\\nIt is a design decision to base the Node registry on URLs (DNS resolvable names). This has the implications outlined in this issue and they cannot easily be mitigated. Adding a delay until nodes can be used after registration only delays the problem. Assuming that an entity curates the registry or a whitelist is in place centralizes the system. Adding DNS record verification still allows an owner of a DNS entry to point its name to any IP address they would like it to point to. It certainly makes it harder to add RPC URLs with DNS names that are not in control of the attacker but it also adds a whole lot more complexity to the system (including manual steps performed by the node operator). In the end, the system allows IP based URLs in the registry which cannot be used for DNS validation.\\nIt is a fundamental design decision of the system architecture to allow rpc urls in the Node Registry, therefore this issue can only be partially mitigated unless the system design is reworked. It is therefore suggested to add checks to both the registry contract (coarse validation to avoid adding invalid urls) and node implementations (rigorous validation of URL's and resolved IP addresses) and filter out any potentially harmful destinations.чч```\\nconst config = nodes.nodes.find(\\_ => \\_.address.toLowerCase() === adr.toLowerCase())\\nif (!config) // TODO do we need to throw here or is it ok to simply not deliver the signature?\\n  throw new Error('The ' + adr + ' does not exist within the current registered active nodeList!')\\n\\n// get cache signatures and remaining blocks that have no signatures\\nconst cachedSignatures: Signature[] = []\\nconst blocksToRequest = blocks.filter(b => {\\n  const s = signatureCaches.get(b.hash) && false\\n  return s ? cachedSignatures.push(s) \\* 0 : true\\n})\\n\\n// send the sign-request\\nlet response: RPCResponse\\ntry {\\n  response = (blocksToRequest.length\\n    ? await handler.transport.handle(config.url, { id: handler.counter++ || 1, jsonrpc: '2.0', method: 'in3\\_sign', params: blocksToRequest })\\n    : { result: [] }) as RPCResponse\\n  if (response.error) {\\n```\\n
in3-server - key management  PendingчhighчSecure and efficient key management is a challenge for any cryptographic system. Incubed nodes for example require an account on the ethereum blockchain to actively participate in the incubed network. The account and therefore a private-key is used to sign transactions on the ethereum blockchain and to provide signed proofs to other in3-nodes.\\nThis means that an attacker that is able to discover the keys used by an `in3-server` by any mechanism may be able to impersonate that node, steal the nodes funds or sign wrong data on behalf of the node which might also lead to a loss of funds.\\nThe private key for the `in3-server` can be specified in a configuration file called `config.json` residing in the program working dir. Settings from the `config.json` can be overridden via command-line options. The application keeps configuration parameters available internally in an `IN3RPCConfig` object and passes this object as an initialization parameter to other objects.\\nThe key can either be provided in plaintext as a hex-string starting with `0x` or within an ethereum keystore format compatible protected keystore file. Either way it is provided it will be held in plaintext in the object.\\nThe application accepts plaintext private keys and the keys are stored unprotected in the applications memory in JavaScript objects. The `in3-server` might even re-use the nodes private key which may weaken the security provided by the node. The repository leaks a series of presumably ‘test private keys' and the default config file already comes with a private key set that might be shared across unvary users that fail to override it.\\ncode/in3-server/config.json:L1-L4\\n```\\n{\\n  \"privateKey\": \"0xc858a0f49ce12df65031ba0eb0b353abc74f93f8ccd43df9682fd2e2293a4db3\",\\n  \"rpcUrl\": \"http://rpc-kovan.slock.it\"\\n}\\n```\\n\\ncode/in3-server/package.json:L20-L31\\nThe private key is also passed as arguments to other functions. In error cases these may leak the private key to log interfaces or remote log aggregation instances (sentry). See `txargs.privateKey` in the example below:\\ncode/in3-server/src/util/tx.ts:L100-L100\\n```\\nconst key = toBuffer(txargs.privateKey)\\n```\\n\\ncode/in3-server/src/util/tx.ts:L134-L140\\n```\\nconst txHash = await transport.handle(url, {\\n  jsonrpc: '2.0',\\n  id: idCount++,\\n  method: 'eth\\_sendRawTransaction',\\n  params: [toHex(tx.serialize())]\\n}).then((\\_: RPCResponse) => \\_.error ? Promise.reject(new SentryError('Error sending tx', 'tx\\_error', 'Error sending the tx ' + JSON.stringify(txargs) + ':' + JSON.stringify(\\_.error))) as any : \\_.result + '')\\n```\\nчResolution\\nThe breakdown of the fixes addressed with git.slock.it/PR/13 are as follows:\\nKeys should never be stored or accepted in plaintext format Keys should only be accepted in an encrypted and protected format\\nThe private key in `code/in3-server/config.json` has been removed. The repository still contains private keys at least in the following locations:\\n`package.json`\\n`vscode/launch.json`\\n`example_docker-compose.yml`\\nNote that private keys indexed by a git repository can be restored from the repository history.\\nThe following statement has been provided to address this issue:\\nWe have removed all examples and usage of plain private keys and replaced them with json-keystore files. Also in the documentation we added warnings on how to deal with keys, especially with hints to the bash history or enviroment\\n\\nA single key should be used for only one purpose. Keys should not be shared.\\nThe following statement has been provided to address this issue:\\nThis is why we seperated the owner and signer-key. This way you can use a multisig to securly protect the owner-key. The signer-key is used to sign blocks (and convict) and is not able to do anything else (not even changing its own url)\\n\\nThe application should support developers in understanding where cryptographic keys are stored within the application as well as in which memory regions they might be accessible for other applications\\nAddressed by wrapping the private key in an object that stores the key in encrypted form and only decrypts it when signing. The key is cleared after usage. The IN3-server still allows raw private keys to be configured. A warning is printed if that is the case. The loaded raw private key is temporarily assigned to a local variable and not explicitly cleared by the method.\\nWhile we used to keep the unlocked key as part of the config, we have now removed the key from the config and store them in a special signer-function.\\nhttps://git.slock.it/in3/ts/in3-server/merge_requests/113\\n\\nKeys should be protected in memory and only decrypted for the duration of time they are actively used. Keys should not be stored with the applications source-code repository\\nsee previous remediation note.\\nAfter unlocking the signer key, we encrypt it again and keep it encrypted only decrypting it when signing. This way the raw private key only exist for a very short time in memory and will be filled with 0 right after. ( https://git.slock.it/in3/ts/in3-server/merge_requests/113/diffs#653b04fa41e35b55181776b9f14620b661cff64c_54_73 )\\n\\nUse standard libraries for cryptographic operations\\nThe following statement has been provided to address this issue\\nWe are using ethereumjs-libs.\\n\\nUse the system keystore and API to sign and avoid to store key material at all\\nThe following statement has been provided to address this issue\\nWe are looking into using different signer-apis, even supporting hardware-modules like HSMs. But this may happen in future releases.\\n\\nThe application should store the keys eth-address (util.getAddress()) instead of re-calculating it multiple times from the private key.\\nFixed by generating the address for a private key once and storing it in a private key wrapper object.\\n\\nDo not leak credentials and key material in debug-mode, to local log-output or external log aggregators.\\n`txArgs` still contains a field `privateKey` as outlined in the issue description. However, this `privateKey` now represents the wrapper object noted in a previous comment which only provides access to the ETH address generated from the raw private key.\\nThe following statement has been provided to address this issue:\\nsince the private key and the passphrase are actually deleted from the config, logoutputs or even debug will not be able to leak this information.\\nKeys should never be stored or accepted in plaintext format.\\nKeys should not be stored in plaintext on the file-system as they might easily be exposed to other users. Credentials on the file-system must be tightly restricted by access control.\\nKeys should not be provided as plaintext via environment variables as this might make them available to other processes sharing the same environment (child-processes, e.g. same shell session)\\nKeys should not be provided as plaintext via command-line arguments as they might persist in the shell's command history or might be available to privileged system accounts that can query other processes startup parameters.\\nKeys should only be accepted in an encrypted and protected format.\\nA single key should be used for only one purpose. Keys should not be shared.\\nThe use of the same key for two different cryptographic processes may weaken the security provided by one or both of the processes.\\nThe use of the same key for two different applications may weaken the security provided by one or both of the applications.\\nLimiting the use of a key limits the damage that could be done if the key is compromised.\\nNode owners keys should not be re-used as signer keys.\\nThe application should support developers in understanding where cryptographic keys are stored within the application as well as in which memory regions they might be accessible for other applications.\\nKeys should be protected in memory and only decrypted for the duration of time they are actively used.\\nKeys should not be stored with the applications source-code repository.\\nUse standard libraries for cryptographic operations.\\nUse the system keystore and API to sign and avoid to store key material at all.\\nThe application should store the keys eth-address (util.getAddress()) instead of re-calculating it multiple times from the private key.\\nDo not leak credentials and key material in debug-mode, to local log-output or external log aggregators.чч```\\n{\\n  \"privateKey\": \"0xc858a0f49ce12df65031ba0eb0b353abc74f93f8ccd43df9682fd2e2293a4db3\",\\n  \"rpcUrl\": \"http://rpc-kovan.slock.it\"\\n}\\n```\\n
NodeRegistry - Multiple nodes can share slightly different RPC URLчhighчOne of the requirements for Node registration is to have a unique URL which is not already used by a different owner. The uniqueness check is done by hashing the provided `_url` and checking if someone already registered with that hash of `_url`.\\nHowever, byte-equality checks (via hashing in this case) to enforce uniqueness will not work for URLs. For example, while the following URLs are not equal and will result in different `urlHashes` they can logically be the same end-point:\\n`https://some-server.com/in3-rpc`\\n`https://some-server.com:443/in3-rpc`\\n`https://some-server.com/in3-rpc/`\\n`https://some-server.com/in3-rpc///`\\n`https://some-server.com/in3-rpc?something`\\n`https://some-server.com/in3-rpc?something&something`\\n`https://www.some-server.com/in3-rpc?something` (if www resolves to the same ip)\\n```\\nbytes32 urlHash = keccak256(bytes(\\_url));\\n\\n// make sure this url and also this owner was not registered before.\\n// solium-disable-next-line\\nrequire(!urlIndex[urlHash].used && signerIndex[\\_signer].stage == Stages.NotInUse,\\n    \"a node with the same url or signer is already registered\");\\n```\\n\\nThis leads to the following attack vectors:\\nA user signs up multiple nodes that resolve to the same end-point (URL). A minimum deposit of `0.01 ether` is required for each registration. Registering multiple nodes for the same end-point might allow an attacker to increase their chance of being picked to provide proofs. Registering multiple nodes requires unique `signer` addresses per node.\\nAlso one node can have multiple accounts, hence one node can have slightly different URL and different accounts as the signers.\\nDoS - A user might register nodes for URLs that do not serve in3-clients in an attempt to DDoS e.g. in an attempt to extort web-site operators. This is kind of a reflection attack where nodes will request other nodes from the contract and try to contact them over RPC. Since it is http-rpc it will consume resources on the receiving end.\\nDoS - A user might register Nodes with RPC URLs of other nodes, manipulating weights to cause more traffic than the node can actually handle. Nodes will try to communicate with that node. If no proof is requested the node will not even know that someone else signed up other nodes with their RPC URL to cause problems. If they request proof the original `signer` will return a signed proof and the node will fail due to a signature mismatch. However, the node cannot be convicted and therefore forced to lose the deposit as conviction is bound the `signer` and the block was not signed by the rogue node entry. There will be no way to remove the node from the registry other than the admin functionality.чCanonicalize URLs, but that will not completely prevent someone from registering nodes for other end-points or websites. Nodes can be removed by an admin in the first year but not after that. Rogue owners cannot be prevented from registering random nodes with high weights and minimum deposit. They cannot be convicted as they do not serve proofs. Rogue owners can still unregister to receive their deposit after messing with the system.чч```\\nbytes32 urlHash = keccak256(bytes(\\_url));\\n\\n// make sure this url and also this owner was not registered before.\\n// solium-disable-next-line\\nrequire(!urlIndex[urlHash].used && signerIndex[\\_signer].stage == Stages.NotInUse,\\n    \"a node with the same url or signer is already registered\");\\n```\\n
Impossible to remove malicious nodes after the initial periodчmediumчThe system has centralized power structure for the first year after deployment. An `unregisterKey` (creator of the contract) is allowed to remove Nodes that are in state `Stages.Active` from the registry, only in 1st year.\\nHowever, there is no possibility to remove malicious nodes from the registry after that.\\n```\\n/// @dev only callable in the 1st year after deployment\\nfunction removeNodeFromRegistry(address \\_signer)\\n    external\\n    onlyActiveState(\\_signer)\\n{\\n\\n    // solium-disable-next-line security/no-block-members\\n    require(block.timestamp < (blockTimeStampDeployment + YEAR\\_DEFINITION), \"only in 1st year\");// solhint-disable-line not-rely-on-time\\n    require(msg.sender == unregisterKey, \"only unregisterKey is allowed to remove nodes\");\\n\\n    SignerInformation storage si = signerIndex[\\_signer];\\n    In3Node memory n = nodes[si.index];\\n\\n    unregisterNodeInternal(si, n);\\n\\n}\\n```\\nчResolution\\nThis issue has been addressed with a large change-set that splits the NodeRegistry into two contracts, which results in a code flow that mitigates this issue by making the logic contract upgradable (after 47 days of notice). The resolution adds more complexity to the system, and this complexity is not covered by the original audit. Splitting up the contracts has the side-effect of events being emitted by two different contracts, requiring nodes to subscribe to both contracts' events.\\nThe need for removing malicious nodes from the registry, arises from the design decision to allow anyone to register any URL. These URLs might not actually belong to the registrar of the URL and might not be IN3 nodes. This is partially mitigated by a centralization feature introduced in the mitigation phase that implements whitelist functionality for adding nodes.\\nWe generally advocate against adding complexity, centralization and upgrading mechanisms that can allow one party to misuse functionalities of the contract system for their benefit (e.g. `adminSetNodeDeposit` is only used to reset the deposit but allows the Logic contract to set any deposit; the logic contract is set by the owner and there is a 47 day timelock).\\nWe believe the solution to this issue, should have not been this complex. The trust model of the system is changed with this solution, now the logic contract can allow the admin a wide range of control over the system state and data.\\nThe following statement has been provided with the change-set:\\nDuring the 1st year, we will keep the current mechanic even though it's a centralized approach. However, we changed the structure of the smart contracts and separated the NodeRegistry into two different smart contracts: NodeRegistryLogic and NodeRegistryData. After a successful deployment only the NodeRegistryLogic-contract is able to write data into the NodeRegistryData-contract. This way, we can keep the stored data (e.g. the nodeList) in the NodeRegistryData-contract while changing the way the data gets added/updated/removed is handled in the NodeRegistryLogic-contract. We also provided a function to update the NodeRegistryLogic-contract, so that we are able to change to a better solution for removing nodes in an updated contract.\\nProvide a solution for the network to remove fraudulent node entries. This could be done by voting mechanism (with staking, etc).чч```\\n/// @dev only callable in the 1st year after deployment\\nfunction removeNodeFromRegistry(address \\_signer)\\n    external\\n    onlyActiveState(\\_signer)\\n{\\n\\n    // solium-disable-next-line security/no-block-members\\n    require(block.timestamp < (blockTimeStampDeployment + YEAR\\_DEFINITION), \"only in 1st year\");// solhint-disable-line not-rely-on-time\\n    require(msg.sender == unregisterKey, \"only unregisterKey is allowed to remove nodes\");\\n\\n    SignerInformation storage si = signerIndex[\\_signer];\\n    In3Node memory n = nodes[si.index];\\n\\n    unregisterNodeInternal(si, n);\\n\\n}\\n```\\n
NodeRegistry.registerNodeFor() no replay protection and expiration  Won't FixчmediumчAn owner can register a node with the signer not being the owner by calling `registerNodeFor`. The owner submits a message signed for the owner including the properties of the node including the url.\\nThe signed data does not include the `registryID` nor the NodeRegistry's address and can therefore be used by the owner to submit the same node to multiple registries or chains without the signers consent.\\nThe signed data does not expire and can be re-used by the owner indefinitely to submit the same node again to future contracts or the same contract after the node has been removed.\\nArguments are not validated in the external function (also see issue 6.17)\\n```\\nbytes32 tempHash = keccak256(\\n    abi.encodePacked(\\n        \\_url,\\n        \\_props,\\n        \\_timeout,\\n        \\_weight,\\n        msg.sender\\n    )\\n);\\n```\\nчInclude `registryID` and an expiration timestamp that is checked in the contract with the signed data. Validate function arguments.чч```\\nbytes32 tempHash = keccak256(\\n    abi.encodePacked(\\n        \\_url,\\n        \\_props,\\n        \\_timeout,\\n        \\_weight,\\n        msg.sender\\n    )\\n);\\n```\\n
BlockhashRegistry - Structure of provided blockheaders should be validatedчmediumч`getParentAndBlockhash` takes an rlp-encoded blockheader blob, extracts the parent parent hash and returns both the parent hash and the calculated blockhash of the provided data. The method is used to add blockhashes to the registry that are older than 256 blocks as they are not available to the evm directly. This is done by establishing a trust-chain from a blockhash that is already in the registry up to an older block\\nThe method assumes that valid rlp encoded data is provided but the structure is not verified (rlp decodes completely; block number is correct; timestamp is younger than prevs, …), giving a wide range of freedom to an attacker with enough hashing power (or exploiting potential future issues with keccak) to forge blocks that would never be accepted by clients, but may be accepted by this smart contract. (threat: mining pool forging arbitrary non-conformant blocks to exploit the BlockhashRegistry)\\nIt is not checked that input was actually provided. However, accessing an array at an invalid index will raise an exception in the EVM. Providing a single byte > `0xf7` will yield a result and succeed even though it would have never been accepted by a real node.\\nIt is assumed that the first byte is the rlp encoded length byte and an offset into the provided `_blockheader` bytes-array is calculated. Memory is subsequently accessed via a low-level `mload` at this calculated offset. However, it is never validated that the offset actually lies within the provided range of bytes `_blockheader` leading to an out-of-bounds memory read access.\\nThe rlp encoded data is only partially decoded. For the first rlp list the number of length bytes is extracted. For the rlp encoded long string a length byte of 1 is assumed. The inline comment appears to be inaccurate or might be misleading. `// we also have to add \"2\" = 1 byte to it to skip the length-information`\\nInvalid intermediary blocks (e.g. with parent hash 0x00) will be accepted potentially allowing an attacker to optimize the effort needed to forge invalid blocks skipping to the desired blocknumber overwriting a certain blockhash (see issue 6.18)\\nWith one collisions (very unlikely) an attacker can add arbitrary or even random values to the BlockchainRegistry. The parent-hash of the starting blockheader cannot be verified by the contract ([target_block_random]<--parent_hash--[rnd]<--parent_hash--[rnd]<--parent_hash--...<--parent_hash--[collision]<--parent_hash_collission--[anchor_block]). While nodes can verify block structure and bail on invalid structure and check the first blocks hash and make sure the chain is in-tact the contract can't. Therefore one cannot assume the same trust in the blockchain registry when recreating blocks compared to running a full node.\\n```\\nfunction getParentAndBlockhash(bytes memory \\_blockheader) public pure returns (bytes32 parentHash, bytes32 bhash) {\\n\\n    /// we need the 1st byte of the blockheader to calculate the position of the parentHash\\n    uint8 first = uint8(\\_blockheader[0]);\\n\\n    /// calculates the offset\\n    /// by using the 1st byte (usually f9) and substracting f7 to get the start point of the parentHash information\\n    /// we also have to add \"2\" = 1 byte to it to skip the length-information\\n    require(first > 0xf7, \"invalid offset\");\\n    uint8 offset = first - 0xf7 + 2;\\n\\n    /// we are using assembly because it's the most efficent way to access the parent blockhash within the rlp-encoded blockheader\\n    // solium-disable-next-line security/no-inline-assembly\\n    assembly { // solhint-disable-line no-inline-assembly\\n        // mstore to get the memory pointer of the blockheader to 0x20\\n        mstore(0x20, \\_blockheader)\\n\\n        // we load the pointer we just stored\\n        // then we add 0x20 (32 bytes) to get to the start of the blockheader\\n        // then we add the offset we calculated\\n        // and load it to the parentHash variable\\n        parentHash :=mload(\\n            add(\\n                add(\\n                    mload(0x20), 0x20\\n                ), offset)\\n        )\\n    }\\n    bhash = keccak256(\\_blockheader);\\n```\\nчValidate that the provided data is within a sane range of bytes that is expected (min/max blockheader sizes).\\nValidate that the provided data is actually an rlp encoded blockheader.\\nValidate that the offset for the parent Hash is within the provided data.\\nValidate that the parent Hash is non zero.\\nValidate that blockhashes do not repeat.чч```\\nfunction getParentAndBlockhash(bytes memory \\_blockheader) public pure returns (bytes32 parentHash, bytes32 bhash) {\\n\\n    /// we need the 1st byte of the blockheader to calculate the position of the parentHash\\n    uint8 first = uint8(\\_blockheader[0]);\\n\\n    /// calculates the offset\\n    /// by using the 1st byte (usually f9) and substracting f7 to get the start point of the parentHash information\\n    /// we also have to add \"2\" = 1 byte to it to skip the length-information\\n    require(first > 0xf7, \"invalid offset\");\\n    uint8 offset = first - 0xf7 + 2;\\n\\n    /// we are using assembly because it's the most efficent way to access the parent blockhash within the rlp-encoded blockheader\\n    // solium-disable-next-line security/no-inline-assembly\\n    assembly { // solhint-disable-line no-inline-assembly\\n        // mstore to get the memory pointer of the blockheader to 0x20\\n        mstore(0x20, \\_blockheader)\\n\\n        // we load the pointer we just stored\\n        // then we add 0x20 (32 bytes) to get to the start of the blockheader\\n        // then we add the offset we calculated\\n        // and load it to the parentHash variable\\n        parentHash :=mload(\\n            add(\\n                add(\\n                    mload(0x20), 0x20\\n                ), offset)\\n        )\\n    }\\n    bhash = keccak256(\\_blockheader);\\n```\\n
Registries - Incomplete input validation and inconsistent order of validations  PendingчmediumчMethods and Functions usually live in one of two worlds:\\n`public` API - methods declared with visibility `public` or `external` exposed for interaction by other parties\\n`internal` API - methods declared with visibility `internal`, `private` that are not exposed for interaction by other parties\\nWhile it is good practice to visually distinguish internal from public API by following commonly accepted naming convention e.g. by prefixing internal functions with an underscore (_doSomething vs. doSomething) or adding the keyword `unsafe` to `unsafe` functions that are not performing checks and may have a dramatic effect to the system (_unsafePayout vs. RequestPayout), it is important to properly verify that inputs to methods are within expected ranges for the implementation.\\nInput validation checks should be explicit and well documented as part of the code's documentation. This is to make sure that smart-contracts are robust against erroneous inputs and reduce the potential attack surface for exploitation.\\nIt is good practice to verify the methods input as early as possible and only perform further actions if the validation succeeds. Methods can be split into an external or public API that performs initial checks and subsequently calls an internal method that performs the action.\\nThe following lists some public API methods that are not properly checking the provided data:\\n`BlockhashRegistry.reCalculateBlockheaders` - bhash can be zero; blockheaders can be empty\\nBlockhashRegistry.getParentAndBlockhash- blockheader structure can be random as long as parenthash can be extracted\\n`BlockhashRegistry.recreateBlockheaders` - blockheaders can be empty; Arguments should be validated before calculating values that depend on them:\\n```\\nassert(\\_blockNumber > \\_blockheaders.length);\\n```\\n\\n`BlockhashRegistry.searchForAvailableBlock` - `_startNumber + _numBlocks` can be > block.number; `_startNumber + _numBlocks` can overflow.\\n`NodeRegistry.removeNode` - should check `require(_nodeIndex < nodes.length)` first before any other action.\\n```\\nfunction removeNode(uint \\_nodeIndex) internal {\\n    // trigger event\\n    emit LogNodeRemoved(nodes[\\_nodeIndex].url, nodes[\\_nodeIndex].signer);\\n    // deleting the old entry\\n    delete urlIndex[keccak256(bytes(nodes[\\_nodeIndex].url))];\\n    uint length = nodes.length;\\n\\n    assert(length > 0);\\n```\\n\\n`NodeRegistry.registerNodeFor` - Signature version `v` should be checked to be either `27 || 28` before verifying it.\\n```\\nfunction registerNodeFor(\\n    string calldata \\_url,\\n    uint64 \\_props,\\n    uint64 \\_timeout,\\n    address \\_signer,\\n    uint64 \\_weight,\\n    uint8 \\_v,\\n    bytes32 \\_r,\\n    bytes32 \\_s\\n)\\n    external\\n    payable\\n{\\n```\\n\\n`NodeRegistry.revealConvict` - unchecked `signer`\\n```\\nSignerInformation storage si = signerIndex[\\_signer];\\n```\\n\\n`NodeRegistry.revealConvict` - signer status can be checked earlier.\\n```\\nrequire(si.stage != Stages.Convicted, \"node already convicted\");\\n```\\n\\n`NodeRegistry.updateNode` - the check if the `newURL` is registered can be done earlier\\n```\\nrequire(!urlIndex[newURl].used, \"url is already in use\");\\n```\\nчUse Checks-Effects-Interactions pattern for all functions.чч```\\nassert(\\_blockNumber > \\_blockheaders.length);\\n```\\n
BlockhashRegistry - recreateBlockheaders allows invalid parent hashes for intermediary blocksчmediumчIt is assumed that a blockhash of `0x00` is invalid, but the method accepts intermediary parent hashes extracted from blockheaders that are zero when establishing the trust chain.\\n`recreateBlockheaders` relies on `reCalculateBlockheaders` to correctly establish a chain of trust from the provided list of `_blockheaders` to a valid blockhash stored in the contract. However, `reCalculateBlockheaders` fails to raise an exception in case `getParentAndBlockhash` returns a blockhash of `0x00`. Subsequently it will skip over invalid blockhashes and continue to establish the trust chain without raising an error.\\nThis may allow an attacker with enough hashing power to store a blockheader hash that is actually invalid on the real chain but accepted within this smart contract. This may even only be done temporarily to overwrite an existing hash for a short period of time (see https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/24).\\n```\\nfor (uint i = 0; i < \\_blockheaders.length; i++) {\\n    (calcParent, calcBlockhash) = getParentAndBlockhash(\\_blockheaders[i]);\\n    if (calcBlockhash != currentBlockhash) {\\n        return 0x0;\\n    }\\n    currentBlockhash = calcParent;\\n}\\n```\\nчStop processing the array of `_blockheaders` immediately if a blockheader is invalid.чч```\\nfor (uint i = 0; i < \\_blockheaders.length; i++) {\\n    (calcParent, calcBlockhash) = getParentAndBlockhash(\\_blockheaders[i]);\\n    if (calcBlockhash != currentBlockhash) {\\n        return 0x0;\\n    }\\n    currentBlockhash = calcParent;\\n}\\n```\\n
BlockhashRegistry - recreateBlockheaders succeeds and emits an event even though no blockheaders have been providedчmediumчThe method is used to re-create blockhashes from a list of rlp-encoded `_blockheaders`. However, the method never checks if `_blockheaders` actually contains items. The result is, that the method will unnecessarily store the same value that is already in the `blockhashMapping` at the same location and wrongly log `LogBlockhashAdded` even though nothing has been added nor changed.\\nassume `_blockheaders` is empty and the registry already knows the blockhash of `_blockNumber`\\n```\\nfunction recreateBlockheaders(uint \\_blockNumber, bytes[] memory \\_blockheaders) public {\\n\\n    bytes32 currentBlockhash = blockhashMapping[\\_blockNumber];\\n    require(currentBlockhash != 0x0, \"parentBlock is not available\");\\n\\n    bytes32 calculatedHash = reCalculateBlockheaders(\\_blockheaders, currentBlockhash);\\n    require(calculatedHash != 0x0, \"invalid headers\");\\n```\\n\\nAn attempt is made to re-calculate the hash of an empty `_blockheaders` array (also passing the `currentBlockhash` from the registry)\\n```\\nbytes32 calculatedHash = reCalculateBlockheaders(\\_blockheaders, currentBlockhash);\\n```\\n\\nThe following loop in `reCalculateBlockheaders` is skipped and the `currentBlockhash` is returned.\\n```\\nfunction reCalculateBlockheaders(bytes[] memory \\_blockheaders, bytes32 \\_bHash) public pure returns (bytes32 bhash) {\\n\\n    bytes32 currentBlockhash = \\_bHash;\\n    bytes32 calcParent = 0x0;\\n    bytes32 calcBlockhash = 0x0;\\n\\n    /// save to use for up to 200 blocks, exponential increase of gas-usage afterwards\\n    for (uint i = 0; i < \\_blockheaders.length; i++) {\\n        (calcParent, calcBlockhash) = getParentAndBlockhash(\\_blockheaders[i]);\\n        if (calcBlockhash != currentBlockhash) {\\n            return 0x0;\\n        }\\n        currentBlockhash = calcParent;\\n    }\\n\\n    return currentBlockhash;\\n```\\n\\nThe assertion does not fire, the `bnr` to store the `calculatedHash` is the same as the one initially provided to the method as an argument.. Nothing has changed but an event is emitted.\\n```\\n    /// we should never fail this assert, as this would mean that we were able to recreate a invalid blockchain\\n    assert(\\_blockNumber > \\_blockheaders.length);\\n    uint bnr = \\_blockNumber - \\_blockheaders.length;\\n    blockhashMapping[bnr] = calculatedHash;\\n    emit LogBlockhashAdded(bnr, calculatedHash);\\n}\\n```\\nчThe method is crucial for the system to work correctly and must be tightly controlled by input validation. It should not be allowed to overwrite an existing value in the contract (issue 6.29) or emit an event even though nothing has happened. Therefore validate that user provided input is within safe bounds. In this case, that at least one `_blockheader` has been provided. Validate that `_blockNumber` is less than `block.number` and do not expect that parts of the code will throw and safe the contract from exploitation.чч```\\nfunction recreateBlockheaders(uint \\_blockNumber, bytes[] memory \\_blockheaders) public {\\n\\n    bytes32 currentBlockhash = blockhashMapping[\\_blockNumber];\\n    require(currentBlockhash != 0x0, \"parentBlock is not available\");\\n\\n    bytes32 calculatedHash = reCalculateBlockheaders(\\_blockheaders, currentBlockhash);\\n    require(calculatedHash != 0x0, \"invalid headers\");\\n```\\n
NodeRegistry.updateNode replaces signer with owner and emits inconsistent eventsчmediumчWhen the `owner` calls `updateNode()` function providing a new `url` for the node, the `signer` of the `url` is replaced by `msg.sender` which in this case is the `owner` of the node. Note that new URL can resolve to the same URL as before (See https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/36).\\n```\\nif (newURl != keccak256(bytes(node.url))) {\\n\\n    // deleting the old entry\\n    delete urlIndex[keccak256(bytes(node.url))];\\n\\n    // make sure the new url is not already in use\\n    require(!urlIndex[newURl].used, \"url is already in use\");\\n\\n    UrlInformation memory ui;\\n    ui.used = true;\\n    ui.signer = msg.sender;\\n    urlIndex[newURl] = ui;\\n    node.url = \\_url;\\n}\\n```\\n\\nFurthermore, the method emits a `LogNodeRegistered` event when the node structure is updated. However, the event will always emit `msg.sender` as the signer even though that might not be true. For example, if the `url` does not change, the signer can still be another account that was previously registered with `registerNodeFor` and is not necessarily the `owner`.\\n```\\nemit LogNodeRegistered(\\n    node.url,\\n    \\_props,\\n    msg.sender,\\n    node.deposit\\n);\\n```\\n\\n```\\nevent LogNodeRegistered(string url, uint props, address signer, uint deposit);\\n```\\nчThe `updateNode()` function gets the `signer` as an input used to reference the node structure and this `signer` should be set for the `UrlInformation`.\\n```\\nfunction updateNode(\\n        address \\_signer,\\n        string calldata \\_url,\\n        uint64 \\_props,\\n        uint64 \\_timeout,\\n        uint64 \\_weight\\n    )\\n```\\n\\nThe method should actually only allow to change node properties when `owner==signer` otherwise `updateNode` is bypassing the strict requirements enforced with `registerNodeFor` where e.g. the `url` needs to be signed by the signer in order to register it.\\nThe emitted event should always emit `node.signer` instead of `msg.signer` which can be wrong.\\nThe method should emit its own distinct event `LogNodeUpdated` for audit purposes and to be able to distinguish new node registrations from node structure updates. This might also require software changes to client/node implementations to listen for node updates.чч```\\nif (newURl != keccak256(bytes(node.url))) {\\n\\n    // deleting the old entry\\n    delete urlIndex[keccak256(bytes(node.url))];\\n\\n    // make sure the new url is not already in use\\n    require(!urlIndex[newURl].used, \"url is already in use\");\\n\\n    UrlInformation memory ui;\\n    ui.used = true;\\n    ui.signer = msg.sender;\\n    urlIndex[newURl] = ui;\\n    node.url = \\_url;\\n}\\n```\\n
NodeRegistry - In3Node memory n is never usedчlowчNodeRegistry `In3Node memory n` is never used inside the modifier `onlyActiveState`.\\n```\\nmodifier onlyActiveState(address \\_signer) {\\n\\n    SignerInformation memory si = signerIndex[\\_signer];\\n    require(si.stage == Stages.Active, \"address is not an in3-signer\");\\n\\n    In3Node memory n = nodes[si.index];\\n    assert(nodes[si.index].signer == \\_signer);\\n    \\_;\\n}\\n```\\nчUse `n` in the assertion to access the node signer `assert(n.signer == _signer);` or directly access it from storage and avoid copying the struct.чч```\\nmodifier onlyActiveState(address \\_signer) {\\n\\n    SignerInformation memory si = signerIndex[\\_signer];\\n    require(si.stage == Stages.Active, \"address is not an in3-signer\");\\n\\n    In3Node memory n = nodes[si.index];\\n    assert(nodes[si.index].signer == \\_signer);\\n    \\_;\\n}\\n```\\n
NodeRegistry - removeNode unnecessarily casts the nodeIndex to uint64 potentially truncating its valueчlowч`removeNode` removes a node from the Nodes array. This is done by copying the last node of the array to the `_nodeIndex` of the node that is to be removed. Finally the node array size is decreased.\\nA Node's index is also referenced in the `SignerInformation` struct. This index needs to be adjusted when removing a node from the array as the last node is copied to the index of the node that is to be removed.\\nWhen adjusting the Node's index in the `SignerInformation` struct `removeNode` casts the index to `uint64`. This is both unnecessary as the struct defines the index as `uint` and theoretically dangerous if a node at an index greater than `uint64_max` is removed. The resulting `SignerInformation` index will be truncated to `uint64` leading to an inconsistency in the contract.\\n```\\nstruct SignerInformation {\\n    uint64 lockedTime;                  /// timestamp until the deposit of an in3-node can not be withdrawn after the node was removed\\n    address owner;                      /// the owner of the node\\n\\n    Stages stage;                       /// state of the address\\n\\n    uint depositAmount;                 /// amount of deposit to be locked, used only after a node had been removed\\n\\n    uint index;                         /// current index-position of the node in the node-array\\n}\\n```\\n\\n```\\n// move the last entry to the removed one.\\nIn3Node memory m = nodes[length - 1];\\nnodes[\\_nodeIndex] = m;\\n\\nSignerInformation storage si = signerIndex[m.signer];\\nsi.index = uint64(\\_nodeIndex);\\nnodes.length--;\\n```\\nчResolution\\nFixed as per recommendation https://git.slock.it/in3/in3-contracts/commit/6c35dd422e27eec1b1d2f70e328268014cadb515.\\nDo not cast and therefore truncate the index.чч```\\nstruct SignerInformation {\\n    uint64 lockedTime;                  /// timestamp until the deposit of an in3-node can not be withdrawn after the node was removed\\n    address owner;                      /// the owner of the node\\n\\n    Stages stage;                       /// state of the address\\n\\n    uint depositAmount;                 /// amount of deposit to be locked, used only after a node had been removed\\n\\n    uint index;                         /// current index-position of the node in the node-array\\n}\\n```\\n
BlockhashRegistry- assembly code can be optimizedчlowчThe following code can be optimized by removing `mload` and mstore:\\n```\\nrequire(first > 0xf7, \"invalid offset\");\\nuint8 offset = first - 0xf7 + 2;\\n\\n/// we are using assembly because it's the most efficent way to access the parent blockhash within the rlp-encoded blockheader\\n// solium-disable-next-line security/no-inline-assembly\\nassembly { // solhint-disable-line no-inline-assembly\\n    // mstore to get the memory pointer of the blockheader to 0x20\\n    mstore(0x20, \\_blockheader)\\n\\n    // we load the pointer we just stored\\n    // then we add 0x20 (32 bytes) to get to the start of the blockheader\\n    // then we add the offset we calculated\\n    // and load it to the parentHash variable\\n    parentHash :=mload(\\n        add(\\n            add(\\n                mload(0x20), 0x20\\n            ), offset)\\n    )\\n}\\n```\\nч```\\nassembly { // solhint-disable-line no-inline-assembly\\n            // mstore to get the memory pointer of the blockheader to 0x20\\n            //mstore(0x20, \\_blockheader) //@audit should assign 0x20ptr to variable first and use it.\\n\\n            // we load the pointer we just stored\\n            // then we add 0x20 (32 bytes) to get to the start of the blockheader\\n            // then we add the offset we calculated\\n            // and load it to the parentHash variable\\n            parentHash :=mload(\\n                add(\\n                    add(\\n                        \\_blockheader, 0x20\\n                    ), offset)\\n            )\\n        }\\n```\\nчч```\\nrequire(first > 0xf7, \"invalid offset\");\\nuint8 offset = first - 0xf7 + 2;\\n\\n/// we are using assembly because it's the most efficent way to access the parent blockhash within the rlp-encoded blockheader\\n// solium-disable-next-line security/no-inline-assembly\\nassembly { // solhint-disable-line no-inline-assembly\\n    // mstore to get the memory pointer of the blockheader to 0x20\\n    mstore(0x20, \\_blockheader)\\n\\n    // we load the pointer we just stored\\n    // then we add 0x20 (32 bytes) to get to the start of the blockheader\\n    // then we add the offset we calculated\\n    // and load it to the parentHash variable\\n    parentHash :=mload(\\n        add(\\n            add(\\n                mload(0x20), 0x20\\n            ), offset)\\n    )\\n}\\n```\\n
BlockhashRegistry - Existing blockhashes can be overwrittenчlowчLast 256 blocks, that are available in the EVM environment, are stored in `BlockhashRegistry` by calling `snapshot()` or `saveBlockNumber(uint _blockNumber)` functions. Older blocks are recreated by calling `recreateBlockheaders`.\\nThe methods will overwrite existing blockhashes.\\n```\\nfunction saveBlockNumber(uint \\_blockNumber) public {\\n\\n    bytes32 bHash = blockhash(\\_blockNumber);\\n\\n    require(bHash != 0x0, \"block not available\");\\n\\n    blockhashMapping[\\_blockNumber] = bHash;\\n    emit LogBlockhashAdded(\\_blockNumber, bHash);\\n}\\n```\\n\\n```\\nblockhashMapping[bnr] = calculatedHash;\\n```\\nчResolution\\nAddressed with 80bb6ecf and 17d450cf by checking if blockhash exists and changing the `assert` to `require`.\\nIf a block is already saved in the smart contract, it can be checked and a SSTORE can be prevented to save gas. Require that blocknumber hash is not stored.\\n```\\nrequire(blockhashMapping[\\_blockNumber] == 0x0, \"block already saved\");\\n```\\nчч```\\nfunction saveBlockNumber(uint \\_blockNumber) public {\\n\\n    bytes32 bHash = blockhash(\\_blockNumber);\\n\\n    require(bHash != 0x0, \"block not available\");\\n\\n    blockhashMapping[\\_blockNumber] = bHash;\\n    emit LogBlockhashAdded(\\_blockNumber, bHash);\\n}\\n```\\n
An account that confirms a transaction via AssetProxyOwner can indefinitely block that transactionчhighчWhen a transaction reaches the required number of confirmations in `confirmTransaction()`, its confirmation time is recorded:\\n```\\n/// @dev Allows an owner to confirm a transaction.\\n/// @param transactionId Transaction ID.\\nfunction confirmTransaction(uint256 transactionId)\\n    public\\n    ownerExists(msg.sender)\\n    transactionExists(transactionId)\\n    notConfirmed(transactionId, msg.sender)\\n    notFullyConfirmed(transactionId)\\n{\\n    confirmations[transactionId][msg.sender] = true;\\n    emit Confirmation(msg.sender, transactionId);\\n    if (isConfirmed(transactionId)) {\\n        \\_setConfirmationTime(transactionId, block.timestamp);\\n    }\\n}\\n```\\n\\nBefore the time lock has elapsed and the transaction is executed, any of the owners that originally confirmed the transaction can revoke their confirmation via revokeConfirmation():\\n```\\n/// @dev Allows an owner to revoke a confirmation for a transaction.\\n/// @param transactionId Transaction ID.\\nfunction revokeConfirmation(uint256 transactionId)\\n    public\\n    ownerExists(msg.sender)\\n    confirmed(transactionId, msg.sender)\\n    notExecuted(transactionId)\\n{\\n    confirmations[transactionId][msg.sender] = false;\\n    emit Revocation(msg.sender, transactionId);\\n}\\n```\\n\\nImmediately after, that owner can call `confirmTransaction()` again, which will reset the confirmation time and thus the time lock.\\nThis is especially troubling in the case of a single compromised key, but it's also an issue for disagreement among owners, where any m of the n owners should be able to execute transactions but could be blocked.\\nMitigations\\nOnly an owner can do this, and that owner has to be part of the group that originally confirmed the transaction. This means the malicious owner may have to front run the others to make sure they're in that initial confirmation set.\\nEven once a malicious owner is in position to execute this perpetual delay, they need to call `revokeConfirmation()` and `confirmTransaction()` again each time. Another owner can attempt to front the attacker and execute their own `confirmTransaction()` immediately after the `revokeConfirmation()` to regain control.чThere are several ways to address this, but to best preserve the original `MultiSigWallet` semantics, once a transaction has reached the required number of confirmations, it should be impossible to revoke confirmations. In the original implementation, this is enforced by immediately executing the transaction when the final confirmation is received.чч```\\n/// @dev Allows an owner to confirm a transaction.\\n/// @param transactionId Transaction ID.\\nfunction confirmTransaction(uint256 transactionId)\\n    public\\n    ownerExists(msg.sender)\\n    transactionExists(transactionId)\\n    notConfirmed(transactionId, msg.sender)\\n    notFullyConfirmed(transactionId)\\n{\\n    confirmations[transactionId][msg.sender] = true;\\n    emit Confirmation(msg.sender, transactionId);\\n    if (isConfirmed(transactionId)) {\\n        \\_setConfirmationTime(transactionId, block.timestamp);\\n    }\\n}\\n```\\n
Orders with signatures that require regular validation can have their validation bypassed if the order is partially filledчhighчThe signature types `Wallet`, `Validator`, and `EIP1271Wallet` require explicit validation to authorize each action performed on a given order. This means that if an order was signed using one of these methods, the `Exchange` must perform a validation step on the signature each time the order is submitted for a partial fill. In contrast, the other canonical signature types (EIP712, `EthSign`, and PreSigned) are only required to be validated by the `Exchange` on the order's first fill; subsequent fills take the order's existing fill amount as implicit validation that the order has a valid, published signature.\\nThis re-validation step for `Wallet`, `Validator`, and `EIP1271Wallet` signatures is intended to facilitate their use with contracts whose validation depends on some state that may change over time. For example, a validating contract may call into a price feed and determine that some order is invalid if its price deviates from some expected range. In this case, the repeated validation allows 0x users to make orders with custom fill conditions which are evaluated at run-time.\\nWe found that if the sender provides the contract with an invalid signature after the order in question has already been partially filled, the regular validation check required for `Wallet`, `Validator`, and `EIP1271Wallet` signatures can be bypassed entirely.\\nSignature validation takes place in `MixinExchangeCore._assertFillableOrder`. A signature is only validated if it passes the following criteria:\\n```\\n// Validate either on the first fill or if the signature type requires\\n// regular validation.\\naddress makerAddress = order.makerAddress;\\nif (orderInfo.orderTakerAssetFilledAmount == 0 ||\\n    \\_doesSignatureRequireRegularValidation(\\n        orderInfo.orderHash,\\n        makerAddress,\\n        signature\\n    )\\n) {\\n```\\n\\nIn effect, signature validation only occurs if:\\n`orderInfo.orderTakerAssetFilledAmount == 0` OR\\n`_doesSignatureRequireRegularValidation(orderHash, makerAddress, signature)`\\nIf an order is partially filled, the first condition will evaluate to false. Then, that order's signature will only be validated if `_doesSignatureRequireRegularValidation` evaluates to true:\\n```\\nfunction \\_doesSignatureRequireRegularValidation(\\n    bytes32 hash,\\n    address signerAddress,\\n    bytes memory signature\\n)\\n    internal\\n    pure\\n    returns (bool needsRegularValidation)\\n{\\n    // Read the signatureType from the signature\\n    SignatureType signatureType = \\_readSignatureType(\\n        hash,\\n        signerAddress,\\n        signature\\n    );\\n\\n    // Any signature type that makes an external call needs to be revalidated\\n    // with every partial fill\\n    needsRegularValidation =\\n        signatureType == SignatureType.Wallet ||\\n        signatureType == SignatureType.Validator ||\\n        signatureType == SignatureType.EIP1271Wallet;\\n    return needsRegularValidation;\\n}\\n```\\n\\nThe `SignatureType` returned from `_readSignatureType` is directly cast from the final byte of the passed-in signature. Any value that does not cast to `Wallet`, `Validator`, and `EIP1271Wallet` will cause `_doesSignatureRequireRegularValidation` to return false, skipping validation.\\nThe result is that an order whose signature requires regular validation can be forced to skip validation if it has been partially filled, by passing in an invalid signature.чThere are a few options for remediation:\\nHave the `Exchange` validate the provided signature every time an order is filled.\\nRecord the first seen signature type or signature hash for each order, and check that subsequent actions are submitted with a matching signature.\\nThe first option requires the fewest changes, and does not require storing additional state. While this does mean some additional cost validating subsequent signatures, we feel the increase in flexibility is well worth it, as a maker could choose to create multiple valid signatures for use across different order books.чч```\\n// Validate either on the first fill or if the signature type requires\\n// regular validation.\\naddress makerAddress = order.makerAddress;\\nif (orderInfo.orderTakerAssetFilledAmount == 0 ||\\n    \\_doesSignatureRequireRegularValidation(\\n        orderInfo.orderHash,\\n        makerAddress,\\n        signature\\n    )\\n) {\\n```\\n
Changing the owners or required confirmations in the AssetProxyOwner can unconfirm a previously confirmed transactionчmediumчOnce a transaction has been confirmed in the `AssetProxyOwner`, it cannot be executed until a lock period has passed. During that time, any change to the number of required confirmations will cause this transaction to no longer be executable.\\nIf the number of required confirmations was decreased, then one or more owners will have to revoke their confirmation before the transaction can be executed.\\nIf the number of required confirmations was increased, then additional owners will have to confirm the transaction, and when the new required number of confirmations is reached, a new confirmation time will be recorded, and thus the time lock will restart.\\nSimilarly, if an owner that had previously confirmed the transaction is replaced, the number of confirmations will drop for existing transactions, and they will need to be confirmed again.\\nThis is not disastrous, but it's almost certainly unintended behavior and may make it difficult to make changes to the multisig owners and parameters.\\n`executeTransaction()` requires that at the time of execution, the transaction is confirmed:\\n```\\nfunction executeTransaction(uint256 transactionId)\\n    public\\n    notExecuted(transactionId)\\n    fullyConfirmed(transactionId)\\n```\\n\\n`isConfirmed()` checks for exact equality with the number of required confirmations. Having too many confirmations is just as bad as too few:\\n```\\n/// @dev Returns the confirmation status of a transaction.\\n/// @param transactionId Transaction ID.\\n/// @return Confirmation status.\\nfunction isConfirmed(uint256 transactionId)\\n    public\\n    view\\n    returns (bool)\\n{\\n    uint256 count = 0;\\n    for (uint256 i = 0; i < owners.length; i++) {\\n        if (confirmations[transactionId][owners[i]]) {\\n            count += 1;\\n        }\\n        if (count == required) {\\n            return true;\\n        }\\n    }\\n}\\n```\\n\\nIf additional confirmations are required to reconfirm a transaction, that resets the time lock:\\n```\\n/// @dev Allows an owner to confirm a transaction.\\n/// @param transactionId Transaction ID.\\nfunction confirmTransaction(uint256 transactionId)\\n    public\\n    ownerExists(msg.sender)\\n    transactionExists(transactionId)\\n    notConfirmed(transactionId, msg.sender)\\n    notFullyConfirmed(transactionId)\\n{\\n    confirmations[transactionId][msg.sender] = true;\\n    emit Confirmation(msg.sender, transactionId);\\n    if (isConfirmed(transactionId)) {\\n        \\_setConfirmationTime(transactionId, block.timestamp);\\n    }\\n}\\n```\\nчAs in https://github.com/ConsenSys/0x-v3-audit-2019-09/issues/39, the semantics of the original `MultiSigWallet` were that once a transaction is fully confirmed, it's immediately executed. The time lock means this is no longer possible, but it is possible to record that the transaction is confirmed and never allow this to change. In fact, the confirmation time already records this. Once the confirmation time is non-zero, a transaction should always be considered confirmed.чч```\\nfunction executeTransaction(uint256 transactionId)\\n    public\\n    notExecuted(transactionId)\\n    fullyConfirmed(transactionId)\\n```\\n
Reentrancy in executeTransaction()  Won't FixчmediumчIn `MixinTransactions`, `executeTransaction()` and `batchExecuteTransactions()` do not have the `nonReentrant` modifier. Because of that, it is possible to execute nested transactions or call these functions during other reentrancy attacks on the exchange. The reason behind that decision is to be able to call functions with `nonReentrant` modifier as delegated transactions.\\nNested transactions are partially prevented with a separate check that does not allow transaction execution if the exchange is currently in somebody else's context:\\n```\\n// Prevent `executeTransaction` from being called when context is already set\\naddress currentContextAddress\\_ = currentContextAddress;\\nif (currentContextAddress\\_ != address(0)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.TransactionInvalidContextError(\\n        transactionHash,\\n        currentContextAddress\\_\\n    ));\\n}\\n```\\n\\nThis check still leaves some possibility of reentrancy. Allowing that behavior is dangerous and may create possible attack vectors in the future.чAdd a new modifier to `executeTransaction()` and `batchExecuteTransactions()` which is similar to `nonReentrant` but uses different storage slot.чч```\\n// Prevent `executeTransaction` from being called when context is already set\\naddress currentContextAddress\\_ = currentContextAddress;\\nif (currentContextAddress\\_ != address(0)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.TransactionInvalidContextError(\\n        transactionHash,\\n        currentContextAddress\\_\\n    ));\\n}\\n```\\n
“Poison” order that consumes gas can block market trades  Won't FixчmediumчThe market buy/sell functions gather a list of orders together for the same asset and try to fill them in order until a target amount has been traded.\\nThese functions use `MixinWrapperFunctions._fillOrderNoThrow()` to attempt to fill each order but ignore failures. This way, if one order is unfillable for some reason, the overall market order can still succeed by filling other orders.\\nOrders can still force `_fillOrderNoThrow()` to revert by using an external contract for signature validation and having that contract consume all available gas.\\nThis makes it possible to advertise a “poison” order for a low price that will block all market orders from succeeding. It's reasonable to assume that off-chain order books will automatically include the best prices when constructing market orders, so this attack would likely be quite effective. Note that such an attack costs the attacker nothing because all they need is an on-chain contract that consumers all available gas (maybe via an assert). This makes it a very appealing attack vector for, e.g., an order book that wants to temporarily disable a competitor.\\nDetails\\n`_fillOrderNoThrow()` forwards all available gas when filling the order:\\n```\\n// ABI encode calldata for `fillOrder`\\nbytes memory fillOrderCalldata = abi.encodeWithSelector(\\n    IExchangeCore(address(0)).fillOrder.selector,\\n    order,\\n    takerAssetFillAmount,\\n    signature\\n);\\n\\n(bool didSucceed, bytes memory returnData) = address(this).delegatecall(fillOrderCalldata);\\n```\\n\\nSimilarly, when the `Exchange` attempts to fill an order that requires external signature validation (Wallet, `Validator`, or `EIP1271Wallet` signature types), it forwards all available gas:\\n```\\n(bool didSucceed, bytes memory returnData) = verifyingContractAddress.staticcall(callData);\\n```\\n\\nIf the verifying contract consumes all available gas, it can force the overall transaction to revert.\\nPedantic Note\\nTechnically, it's impossible to consume all remaining gas when called by another contract because the EVM holds back a small amount, but even at the block gas limit, the amount held back would be insufficient to complete the transaction.чConstrain the gas that is forwarded during signature validation. This can be constrained either as a part of the signature or as a parameter provided by the taker.чч```\\n// ABI encode calldata for `fillOrder`\\nbytes memory fillOrderCalldata = abi.encodeWithSelector(\\n    IExchangeCore(address(0)).fillOrder.selector,\\n    order,\\n    takerAssetFillAmount,\\n    signature\\n);\\n\\n(bool didSucceed, bytes memory returnData) = address(this).delegatecall(fillOrderCalldata);\\n```\\n
Front running in matchOrders()  Won't FixчmediumчCalls to `matchOrders()` are made to extract profit from the price difference between two opposite orders: left and right.\\n```\\nfunction matchOrders(\\n    LibOrder.Order memory leftOrder,\\n    LibOrder.Order memory rightOrder,\\n    bytes memory leftSignature,\\n    bytes memory rightSignature\\n)\\n```\\n\\nThe caller only pays protocol and transaction fees, so it's almost always profitable to front run every call to `matchOrders()`. That would lead to gas auctions and would make `matchOrders()` difficult to use.чConsider adding a commit-reveal scheme to `matchOrders()` to stop front running altogether.чч```\\nfunction matchOrders(\\n    LibOrder.Order memory leftOrder,\\n    LibOrder.Order memory rightOrder,\\n    bytes memory leftSignature,\\n    bytes memory rightSignature\\n)\\n```\\n
The Exchange owner should not be able to call executeTransaction or batchExecuteTransaction  Won't FixчmediumчIf the owner calls either of these functions, the resulting `delegatecall` can pass `onlyOwner` modifiers even if the transaction signer is not the owner. This is because, regardless of the `contextAddress` set through `_executeTransaction`, the `onlyOwner` modifier checks `msg.sender`.\\n`_executeTransaction` sets the context address to the signer address, which is not `msg.sender` in this case:\\n```\\n// Set the current transaction signer\\naddress signerAddress = transaction.signerAddress;\\n\\_setCurrentContextAddressIfRequired(signerAddress, signerAddress);\\n```\\n\\nThe resulting `delegatecall` could target an admin function like this one:\\n```\\n/// @dev Registers an asset proxy to its asset proxy id.\\n/// Once an asset proxy is registered, it cannot be unregistered.\\n/// @param assetProxy Address of new asset proxy to register.\\nfunction registerAssetProxy(address assetProxy)\\n    external\\n    onlyOwner\\n{\\n    // Ensure that no asset proxy exists with current id.\\n    bytes4 assetProxyId = IAssetProxy(assetProxy).getProxyId();\\n    address currentAssetProxy = \\_assetProxies[assetProxyId];\\n    if (currentAssetProxy != address(0)) {\\n        LibRichErrors.rrevert(LibExchangeRichErrors.AssetProxyExistsError(\\n            assetProxyId,\\n            currentAssetProxy\\n        ));\\n    }\\n  \\n    // Add asset proxy and log registration.\\n    \\_assetProxies[assetProxyId] = assetProxy;\\n    emit AssetProxyRegistered(\\n        assetProxyId,\\n        assetProxy\\n    );\\n}\\n```\\n\\nThe `onlyOwner` modifier does not check the context address, but checks msg.sender:\\n```\\nfunction \\_assertSenderIsOwner()\\n    internal\\n    view\\n{\\n    if (msg.sender != owner) {\\n        LibRichErrors.rrevert(LibOwnableRichErrors.OnlyOwnerError(\\n            msg.sender,\\n            owner\\n        ));\\n    }\\n}\\n```\\nчAdd a check to `_executeTransaction` that prevents the owner from calling this function.чч```\\n// Set the current transaction signer\\naddress signerAddress = transaction.signerAddress;\\n\\_setCurrentContextAddressIfRequired(signerAddress, signerAddress);\\n```\\n
By manipulating the gas limit, relayers can affect the outcome of ZeroExTransactions  Won't FixчlowчZeroExTransactions are meta transactions supported by the `Exchange`. They do not require that they are executed with a specific amount of gas, so the transaction relayer can choose how much gas to provide. By choosing a low gas limit, a relayer can affect the outcome of the transaction.\\nA `ZeroExTransaction` specifies a signer, an expiration, and call data for the transaction:\\n```\\nstruct ZeroExTransaction {\\n    uint256 salt;                   // Arbitrary number to ensure uniqueness of transaction hash.\\n    uint256 expirationTimeSeconds;  // Timestamp in seconds at which transaction expires.\\n    uint256 gasPrice;               // gasPrice that transaction is required to be executed with.\\n    address signerAddress;          // Address of transaction signer.\\n    bytes data;                     // AbiV2 encoded calldata.\\n}\\n```\\n\\nIn `MixinTransactions._executeTransaction()`, all available gas is forwarded in the delegate call, and the transaction is marked as executed:\\n```\\ntransactionsExecuted[transactionHash] = true;\\n(bool didSucceed, bytes memory returnData) = address(this).delegatecall(transaction.data);\\n```\\n\\nA likely attack vector for this is front running a `ZeroExTransaction` that ultimately invokes `_fillNoThrow()`. In this scenario, an attacker sees the call to `executeTransaction()` and makes their own call with a lower gas limit, causing the order being filled to run out of gas but allowing the transaction as a whole to succeed.\\nIf such an attack is successful, the `ZeroExTransaction` cannot be replayed, so the signer must produce a new signature and try again, ad infinitum.чResolution\\nFrom the development team:\\nWhile this is an annoyance when used in combination with `marketBuyOrdersNoThrow` and `marketSellOrdersNoThrow`, it does not seem worth it to add a `gasLimit` to 0x transactions for this reason alone. Instead, this quirk should be documented along with a recommendation to use the `fillOrKill` variants of each market fill function when used in combination with 0x transactions.\\nAdd a `gasLimit` field to `ZeroExTransaction` and forward exactly that much gas via `delegatecall`. (Note that you must explicitly check that sufficient gas is available because the EVM allows you to supply a gas parameter that exceeds the actual remaining gas.)чч```\\nstruct ZeroExTransaction {\\n    uint256 salt;                   // Arbitrary number to ensure uniqueness of transaction hash.\\n    uint256 expirationTimeSeconds;  // Timestamp in seconds at which transaction expires.\\n    uint256 gasPrice;               // gasPrice that transaction is required to be executed with.\\n    address signerAddress;          // Address of transaction signer.\\n    bytes data;                     // AbiV2 encoded calldata.\\n}\\n```\\n
Modifier ordering plays a significant role in modifier efficacyчlowчThe `nonReentrant` and `refundFinalBalance` modifiers always appear together across the 0x monorepo. When used, they invariably appear with `nonReentrant` listed first, followed by `refundFinalBalance`. This specific order appears inconsequential at first glance but is actually important. The order of execution is as follows:\\nThe `nonReentrant` modifier runs (_lockMutexOrThrowIfAlreadyLocked).\\nIf `refundFinalBalance` had a prefix, it would run now.\\nThe function itself runs.\\nThe `refundFinalBalance` modifier runs (_refundNonZeroBalanceIfEnabled).\\nThe `nonReentrant` modifier runs (_unlockMutex).\\nThe fact that the `refundFinalBalance` modifier runs before the mutex is unlocked is of particular importance because it potentially invokes an external call, which may reenter. If the order of the two modifiers were flipped, the mutex would unlock before the external call, defeating the purpose of the reentrancy guard.\\n```\\nnonReentrant\\nrefundFinalBalance\\n```\\nчResolution\\nThis is fixed in 0xProject/0x-monorepo#2228 by introducing a new modifier that combines the two: `refundFinalBalance`.\\nAlthough the order of the modifiers is correct as-is, this pattern introduces cognitive overhead when making or reviewing changes to the 0x codebase. Because the two modifiers always appear together, it may make sense to combine the two into a single modifier where the order of operations is explicit.чч```\\nnonReentrant\\nrefundFinalBalance\\n```\\n
Several overflows in LibBytesчlowчSeveral functions in `LibBytes` have integer overflows.\\n`LibBytes.readBytesWithLength` returns a pointer to a `bytes` array within an existing `bytes` array at some given `index`. The length of the nested array is added to the given `index` and checked against the parent array to ensure the data in the nested array is within the bounds of the parent. However, because the addition can overflow, the bounds check can be bypassed to return an array that points to data out of bounds of the parent array.\\n```\\nif (b.length < index + nestedBytesLength) {\\n    LibRichErrors.rrevert(LibBytesRichErrors.InvalidByteOperationError(\\n        LibBytesRichErrors\\n            .InvalidByteOperationErrorCodes.LengthGreaterThanOrEqualsNestedBytesLengthRequired,\\n        b.length,\\n        index + nestedBytesLength\\n    ));\\n}\\n```\\n\\nThe following functions have similar issues:\\n`readAddress`\\n`writeAddress`\\n`readBytes32`\\n`writeBytes32`\\n`readBytes4`чAn overflow check should be added to the function. Alternatively, because `readBytesWithLength` does not appear to be used anywhere in the 0x project, the function should be removed from `LibBytes`. Additionally, the following functions in `LibBytes` are also not used and should be considered for removal:\\n`popLast20Bytes`\\n`writeAddress`\\n`writeBytes32`\\n`writeUint256`\\n`writeBytesWithLength`\\n`deepCopyBytes`чч```\\nif (b.length < index + nestedBytesLength) {\\n    LibRichErrors.rrevert(LibBytesRichErrors.InvalidByteOperationError(\\n        LibBytesRichErrors\\n            .InvalidByteOperationErrorCodes.LengthGreaterThanOrEqualsNestedBytesLengthRequired,\\n        b.length,\\n        index + nestedBytesLength\\n    ));\\n}\\n```\\n
NSignatureTypes enum value bypasses Solidity safety checks  Won't FixчlowчThe `ISignatureValidator` contract defines an enum `SignatureType` to represent the different types of signatures recognized within the exchange. The final enum value, `NSignatureTypes`, is not a valid signature type. Instead, it is used by `MixinSignatureValidator` to check that the value read from the signature is a valid enum value. However, Solidity now includes its own check for enum casting, and casting a value over the maximum enum size to an enum is no longer possible.\\nBecause of the added `NSignatureTypes` value, Solidity's check now recognizes `0x08` as a valid `SignatureType` value.\\nThe check is made here:\\n```\\n// Ensure signature is supported\\nif (uint8(signatureType) >= uint8(SignatureType.NSignatureTypes)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.SignatureError(\\n        LibExchangeRichErrors.SignatureErrorCodes.UNSUPPORTED,\\n        hash,\\n        signerAddress,\\n        signature\\n    ));\\n}\\n```\\nчThe check should be removed, as should the `SignatureTypes.NSignatureTypes` value.чч```\\n// Ensure signature is supported\\nif (uint8(signatureType) >= uint8(SignatureType.NSignatureTypes)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.SignatureError(\\n        LibExchangeRichErrors.SignatureErrorCodes.UNSUPPORTED,\\n        hash,\\n        signerAddress,\\n        signature\\n    ));\\n}\\n```\\n
Intentional secret reuse can block borrower and lender from accepting liquidation paymentчhighчFor Dave (the liquidator) to claim the collateral he's purchasing, he must reveal secret D. Once that secret is revealed, Alice and Bob (the borrower and lender) can claim the payment.\\nSecrets must be provided via the `Sales.provideSecret()` function:\\n```\\n function provideSecret(bytes32 sale, bytes32 secret\\_) external {\\n  require(sales[sale].set);\\n  if      (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashA) { secretHashes[sale].secretA = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashB) { secretHashes[sale].secretB = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashC) { secretHashes[sale].secretC = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashD) { secretHashes[sale].secretD = secret\\_; }\\n        else                                                                          { revert(); }\\n }\\n```\\n\\nNote that if Dave chooses the same secret hash as either Alice, Bob, or Charlie (arbiter), there is no way to set `secretHashes[sale].secretD` because one of the earlier conditionals will execute.\\nFor Alice and Bob to later receive payment, they must be able to provide Dave's secret:\\n```\\n function accept(bytes32 sale) external {\\n        require(!accepted(sale));\\n        require(!off(sale));\\n  require(hasSecrets(sale));\\n  require(sha256(abi.encodePacked(secretHashes[sale].secretD)) == secretHashes[sale].secretHashD);\\n```\\n\\nDave can exploit this to obtain the collateral for free:\\nDave looks at Alice's secret hashes to see which will be used in the sale.\\nDave begins the liquidation process, using the same secret hash.\\nAlice and Bob reveal their secrets A and B through the process of moving the collateral.\\nDave now knows the preimage for the secret hash he provided. It was revealed by Alice already.\\nDave uses that secret to obtain the collateral.\\nAlice and Bob now want to receive payment, but they're unable to provide Dave's secret to the `Sales` smart contract due to the order of conditionals in `provideSecret()`.\\nAfter an expiration, Dave can claim a refund.\\nMitigating factors\\nAlice and Bob could notice that Dave chose a duplicate secret hash and refuse to proceed with the sale. This is not something they are likely to do.чEither change the way `provideSecret()` works to allow for duplicate secret hashes or reject duplicate hashes in `create()`.чч```\\n function provideSecret(bytes32 sale, bytes32 secret\\_) external {\\n  require(sales[sale].set);\\n  if      (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashA) { secretHashes[sale].secretA = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashB) { secretHashes[sale].secretB = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashC) { secretHashes[sale].secretC = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashD) { secretHashes[sale].secretD = secret\\_; }\\n        else                                                                          { revert(); }\\n }\\n```\\n
There is no way to convert between custom and non-custom funds  Won't FixчmediumчEach fund is created using either `Funds.create()` or `Funds.createCustom()`. Both enforce a limitation that there can only be one fund per account:\\n```\\nfunction create(\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n\\n```\\nfunction createCustom(\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  liquidationRatio\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n\\nThese functions are the only place where `bools[fund].custom` is set, and there's no way to delete a fund once it exists. This means there's no way for a given account to switch between a custom and non-custom fund.\\nThis could be a problem if, for example, the default parameters change in a way that a user finds unappealing. They may want to switch to using a custom fund but find themselves unable to do so without moving to a new Ethereum account.чEither allow funds to be deleted or allow funds to be switched between custom and non-custom.чч```\\nfunction create(\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n
Funds.maxFundDur has no effect if maxLoanDur is setчmediumч`Funds.maxFundDur` specifies the maximum amount of time a fund should be active. It's checked in `request()` to ensure the duration of the loan won't exceed that time, but the check is skipped if `maxLoanDur` is set:\\n```\\nif (maxLoanDur(fund) > 0) {\\n    require(loanDur\\_       <= maxLoanDur(fund));\\n} else {\\n    require(now + loanDur\\_ <= maxFundDur(fund));\\n}\\n```\\n\\nIf a user sets `maxLoanDur` (the maximum loan duration) to 1 week and sets the `maxFundDur` (timestamp when all loans should be complete) to December 1st, then there can actually be a loan that ends on December 7th.чCheck against `maxFundDur` even when `maxLoanDur` is set.чч```\\nif (maxLoanDur(fund) > 0) {\\n    require(loanDur\\_       <= maxLoanDur(fund));\\n} else {\\n    require(now + loanDur\\_ <= maxFundDur(fund));\\n}\\n```\\n
Funds.update() lets users update fields that may not have any effectчlowч`Funds.update()` allows users to update the following fields which are only used if `bools[fund].custom` is set:\\n`minLoanamt`\\n`maxLoanAmt`\\n`minLoanDur`\\n`interest`\\n`penalty`\\n`fee`\\n`liquidationRatio`\\nIf `bools[fund].custom` is not set, then these changes have no effect. This may be misleading to users.\\n```\\nfunction update(\\n    bytes32  fund,\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    uint256  liquidationRatio\\_,\\n    address  arbiter\\_\\n) external {\\n    require(msg.sender == lender(fund));\\n    funds[fund].minLoanAmt       = minLoanAmt\\_;\\n    funds[fund].maxLoanAmt       = maxLoanAmt\\_;\\n    funds[fund].minLoanDur       = minLoanDur\\_;\\n    funds[fund].maxLoanDur       = maxLoanDur\\_;\\n    funds[fund].maxFundDur       = maxFundDur\\_;\\n    funds[fund].interest         = interest\\_;\\n    funds[fund].penalty          = penalty\\_;\\n    funds[fund].fee              = fee\\_;\\n    funds[fund].liquidationRatio = liquidationRatio\\_;\\n    funds[fund].arbiter          = arbiter\\_;\\n}\\n```\\nчResolution\\nThis is fixed in AtomicLoans/atomicloans-eth-contracts#67.\\nThis could be addressed by creating two update functions: one for custom funds and one for non-custom funds. Only the update for custom funds would allow setting these values.чч```\\nfunction update(\\n    bytes32  fund,\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    uint256  liquidationRatio\\_,\\n    address  arbiter\\_\\n) external {\\n    require(msg.sender == lender(fund));\\n    funds[fund].minLoanAmt       = minLoanAmt\\_;\\n    funds[fund].maxLoanAmt       = maxLoanAmt\\_;\\n    funds[fund].minLoanDur       = minLoanDur\\_;\\n    funds[fund].maxLoanDur       = maxLoanDur\\_;\\n    funds[fund].maxFundDur       = maxFundDur\\_;\\n    funds[fund].interest         = interest\\_;\\n    funds[fund].penalty          = penalty\\_;\\n    funds[fund].fee              = fee\\_;\\n    funds[fund].liquidationRatio = liquidationRatio\\_;\\n    funds[fund].arbiter          = arbiter\\_;\\n}\\n```\\n
Ingress.setContractAddress() can cause duplicate entries in contractKeysчmediumч`setContractAddress()` checks `ContractDetails` existence by inspecting `contractAddress`. A `contractAddress` of `0` means that the contract does not already exist, and its name must be added to contractKeys:\\n```\\nfunction setContractAddress(bytes32 name, address addr) public returns (bool) {\\n    require(name > 0x0000000000000000000000000000000000000000000000000000000000000000, \"Contract name must not be empty.\");\\n    require(isAuthorized(msg.sender), \"Not authorized to update contract registry.\");\\n\\n    ContractDetails memory info = registry[name];\\n    // create info if it doesn't exist in the registry\\n    if (info.contractAddress == address(0)) {\\n        info = ContractDetails({\\n            owner: msg.sender,\\n            contractAddress: addr\\n        });\\n\\n        // Update registry indexing\\n        contractKeys.push(name);\\n   } else {\\n        info.contractAddress = addr;\\n   }\\n    // update record in the registry\\n    registry[name] = info;\\n\\n    emit RegistryUpdated(addr,name);\\n\\n    return true;\\n}\\n```\\n\\nIf, however, a contract is actually added with the address `0`, which is currently allowed in the code, then the contract does already exists, and adding the name to `contractKeys` again will result in a duplicate.\\nMitigation\\nAn admin can call `removeContract` repeatedly with the same name to remove multiple duplicate entries.чResolution\\nThis is fixed in PegaSysEng/[email protected]faff726.\\nEither disallow a contract address of `0` or check for existence via the `owner` field instead (which can never be 0).чч```\\nfunction setContractAddress(bytes32 name, address addr) public returns (bool) {\\n    require(name > 0x0000000000000000000000000000000000000000000000000000000000000000, \"Contract name must not be empty.\");\\n    require(isAuthorized(msg.sender), \"Not authorized to update contract registry.\");\\n\\n    ContractDetails memory info = registry[name];\\n    // create info if it doesn't exist in the registry\\n    if (info.contractAddress == address(0)) {\\n        info = ContractDetails({\\n            owner: msg.sender,\\n            contractAddress: addr\\n        });\\n\\n        // Update registry indexing\\n        contractKeys.push(name);\\n   } else {\\n        info.contractAddress = addr;\\n   }\\n    // update record in the registry\\n    registry[name] = info;\\n\\n    emit RegistryUpdated(addr,name);\\n\\n    return true;\\n}\\n```\\n
Use specific contract types instead of address where possibleчlowчFor clarity and to get more out of the Solidity type checker, it's generally preferred to use a specific contract type for variables rather than the generic `address`.\\n`AccountRules.ingressContractAddress` could instead be `AccountRules.ingressContract` and use the type IngressContract:\\n```\\naddress private ingressContractAddress;\\n```\\n\\n```\\nAccountIngress ingressContract = AccountIngress(ingressContractAddress);\\n```\\n\\n```\\nconstructor (address ingressAddress) public {\\n```\\n\\nThis same pattern is found in NodeRules:\\n```\\naddress private nodeIngressContractAddress;\\n```\\nчWhere possible, use a specific contract type rather than `address`.чч```\\naddress private ingressContractAddress;\\n```\\n
Ingress should use a setчlowчThe `AdminList`, `AccountRulesList`, and `NodeRulesList` contracts have been recently rewritten to use a set. `Ingress` has the semantics of a set but has not been written the same way.\\nThis leads to some inefficiencies. In particular, `Ingress.removeContract` is an O(n) operation:\\n```\\nfor (uint i = 0; i < contractKeys.length; i++) {\\n    // Delete the key from the array + mapping if it is present\\n    if (contractKeys[i] == name) {\\n        delete registry[contractKeys[i]];\\n        contractKeys[i] = contractKeys[contractKeys.length - 1];\\n        delete contractKeys[contractKeys.length - 1];\\n        contractKeys.length--;\\n```\\nчUse the same set implementation for Ingress: an array of `ContractDetails` and a mapping of names to indexes in that array.чч```\\nfor (uint i = 0; i < contractKeys.length; i++) {\\n    // Delete the key from the array + mapping if it is present\\n    if (contractKeys[i] == name) {\\n        delete registry[contractKeys[i]];\\n        contractKeys[i] = contractKeys[contractKeys.length - 1];\\n        delete contractKeys[contractKeys.length - 1];\\n        contractKeys.length--;\\n```\\n
ContractDetails.owner is never readчlowчThe `ContractDetails` struct used by `Ingress` contracts has an `owner` field that is written to, but it is never read.\\n```\\nstruct ContractDetails {\\n    address owner;\\n    address contractAddress;\\n}\\n\\nmapping(bytes32 => ContractDetails) registry;\\n```\\nчResolution\\nThis is fixed in PegaSysEng/[email protected]d3f505e.\\nIf `owner` is not (yet) needed, the `ContractDetails` struct should be removed altogether and the type of `Ingress.registry` should change to `mapping(bytes32 => address)`чч```\\nstruct ContractDetails {\\n    address owner;\\n    address contractAddress;\\n}\\n\\nmapping(bytes32 => ContractDetails) registry;\\n```\\n
Several overflows in LibBytesчlowчSeveral functions in `LibBytes` have integer overflows.\\n`LibBytes.readBytesWithLength` returns a pointer to a `bytes` array within an existing `bytes` array at some given `index`. The length of the nested array is added to the given `index` and checked against the parent array to ensure the data in the nested array is within the bounds of the parent. However, because the addition can overflow, the bounds check can be bypassed to return an array that points to data out of bounds of the parent array.\\n```\\nif (b.length < index + nestedBytesLength) {\\n    LibRichErrors.rrevert(LibBytesRichErrors.InvalidByteOperationError(\\n        LibBytesRichErrors\\n            .InvalidByteOperationErrorCodes.LengthGreaterThanOrEqualsNestedBytesLengthRequired,\\n        b.length,\\n        index + nestedBytesLength\\n    ));\\n}\\n```\\n\\nThe following functions have similar issues:\\n`readAddress`\\n`writeAddress`\\n`readBytes32`\\n`writeBytes32`\\n`readBytes4`чAn overflow check should be added to the function. Alternatively, because `readBytesWithLength` does not appear to be used anywhere in the 0x project, the function should be removed from `LibBytes`. Additionally, the following functions in `LibBytes` are also not used and should be considered for removal:\\n`popLast20Bytes`\\n`writeAddress`\\n`writeBytes32`\\n`writeUint256`\\n`writeBytesWithLength`\\n`deepCopyBytes`чч```\\nif (b.length < index + nestedBytesLength) {\\n    LibRichErrors.rrevert(LibBytesRichErrors.InvalidByteOperationError(\\n        LibBytesRichErrors\\n            .InvalidByteOperationErrorCodes.LengthGreaterThanOrEqualsNestedBytesLengthRequired,\\n        b.length,\\n        index + nestedBytesLength\\n    ));\\n}\\n```\\n
NSignatureTypes enum value bypasses Solidity safety checks  Won't FixчlowчThe `ISignatureValidator` contract defines an enum `SignatureType` to represent the different types of signatures recognized within the exchange. The final enum value, `NSignatureTypes`, is not a valid signature type. Instead, it is used by `MixinSignatureValidator` to check that the value read from the signature is a valid enum value. However, Solidity now includes its own check for enum casting, and casting a value over the maximum enum size to an enum is no longer possible.\\nBecause of the added `NSignatureTypes` value, Solidity's check now recognizes `0x08` as a valid `SignatureType` value.\\nThe check is made here:\\n```\\n// Ensure signature is supported\\nif (uint8(signatureType) >= uint8(SignatureType.NSignatureTypes)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.SignatureError(\\n        LibExchangeRichErrors.SignatureErrorCodes.UNSUPPORTED,\\n        hash,\\n        signerAddress,\\n        signature\\n    ));\\n}\\n```\\nчThe check should be removed, as should the `SignatureTypes.NSignatureTypes` value.чч```\\n// Ensure signature is supported\\nif (uint8(signatureType) >= uint8(SignatureType.NSignatureTypes)) {\\n    LibRichErrors.rrevert(LibExchangeRichErrors.SignatureError(\\n        LibExchangeRichErrors.SignatureErrorCodes.UNSUPPORTED,\\n        hash,\\n        signerAddress,\\n        signature\\n    ));\\n}\\n```\\n
Intentional secret reuse can block borrower and lender from accepting liquidation paymentчhighчFor Dave (the liquidator) to claim the collateral he's purchasing, he must reveal secret D. Once that secret is revealed, Alice and Bob (the borrower and lender) can claim the payment.\\nSecrets must be provided via the `Sales.provideSecret()` function:\\n```\\n function provideSecret(bytes32 sale, bytes32 secret\\_) external {\\n  require(sales[sale].set);\\n  if      (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashA) { secretHashes[sale].secretA = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashB) { secretHashes[sale].secretB = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashC) { secretHashes[sale].secretC = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashD) { secretHashes[sale].secretD = secret\\_; }\\n        else                                                                          { revert(); }\\n }\\n```\\n\\nNote that if Dave chooses the same secret hash as either Alice, Bob, or Charlie (arbiter), there is no way to set `secretHashes[sale].secretD` because one of the earlier conditionals will execute.\\nFor Alice and Bob to later receive payment, they must be able to provide Dave's secret:\\n```\\n function accept(bytes32 sale) external {\\n        require(!accepted(sale));\\n        require(!off(sale));\\n  require(hasSecrets(sale));\\n  require(sha256(abi.encodePacked(secretHashes[sale].secretD)) == secretHashes[sale].secretHashD);\\n```\\n\\nDave can exploit this to obtain the collateral for free:\\nDave looks at Alice's secret hashes to see which will be used in the sale.\\nDave begins the liquidation process, using the same secret hash.\\nAlice and Bob reveal their secrets A and B through the process of moving the collateral.\\nDave now knows the preimage for the secret hash he provided. It was revealed by Alice already.\\nDave uses that secret to obtain the collateral.\\nAlice and Bob now want to receive payment, but they're unable to provide Dave's secret to the `Sales` smart contract due to the order of conditionals in `provideSecret()`.\\nAfter an expiration, Dave can claim a refund.\\nMitigating factors\\nAlice and Bob could notice that Dave chose a duplicate secret hash and refuse to proceed with the sale. This is not something they are likely to do.чEither change the way `provideSecret()` works to allow for duplicate secret hashes or reject duplicate hashes in `create()`.чч```\\n function provideSecret(bytes32 sale, bytes32 secret\\_) external {\\n  require(sales[sale].set);\\n  if      (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashA) { secretHashes[sale].secretA = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashB) { secretHashes[sale].secretB = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashC) { secretHashes[sale].secretC = secret\\_; }\\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashD) { secretHashes[sale].secretD = secret\\_; }\\n        else                                                                          { revert(); }\\n }\\n```\\n
There is no way to convert between custom and non-custom funds  Won't FixчmediumчEach fund is created using either `Funds.create()` or `Funds.createCustom()`. Both enforce a limitation that there can only be one fund per account:\\n```\\nfunction create(\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n\\n```\\nfunction createCustom(\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  liquidationRatio\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n\\nThese functions are the only place where `bools[fund].custom` is set, and there's no way to delete a fund once it exists. This means there's no way for a given account to switch between a custom and non-custom fund.\\nThis could be a problem if, for example, the default parameters change in a way that a user finds unappealing. They may want to switch to using a custom fund but find themselves unable to do so without moving to a new Ethereum account.чEither allow funds to be deleted or allow funds to be switched between custom and non-custom.чч```\\nfunction create(\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    address  arbiter\\_,\\n    bool     compoundEnabled\\_,\\n    uint256  amount\\_\\n) external returns (bytes32 fund) {\\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\\n```\\n
Funds.maxFundDur has no effect if maxLoanDur is setчmediumч`Funds.maxFundDur` specifies the maximum amount of time a fund should be active. It's checked in `request()` to ensure the duration of the loan won't exceed that time, but the check is skipped if `maxLoanDur` is set:\\n```\\nif (maxLoanDur(fund) > 0) {\\n    require(loanDur\\_       <= maxLoanDur(fund));\\n} else {\\n    require(now + loanDur\\_ <= maxFundDur(fund));\\n}\\n```\\n\\nIf a user sets `maxLoanDur` (the maximum loan duration) to 1 week and sets the `maxFundDur` (timestamp when all loans should be complete) to December 1st, then there can actually be a loan that ends on December 7th.чCheck against `maxFundDur` even when `maxLoanDur` is set.чч```\\nif (maxLoanDur(fund) > 0) {\\n    require(loanDur\\_       <= maxLoanDur(fund));\\n} else {\\n    require(now + loanDur\\_ <= maxFundDur(fund));\\n}\\n```\\n
Funds.update() lets users update fields that may not have any effectчlowч`Funds.update()` allows users to update the following fields which are only used if `bools[fund].custom` is set:\\n`minLoanamt`\\n`maxLoanAmt`\\n`minLoanDur`\\n`interest`\\n`penalty`\\n`fee`\\n`liquidationRatio`\\nIf `bools[fund].custom` is not set, then these changes have no effect. This may be misleading to users.\\n```\\nfunction update(\\n    bytes32  fund,\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    uint256  liquidationRatio\\_,\\n    address  arbiter\\_\\n) external {\\n    require(msg.sender == lender(fund));\\n    funds[fund].minLoanAmt       = minLoanAmt\\_;\\n    funds[fund].maxLoanAmt       = maxLoanAmt\\_;\\n    funds[fund].minLoanDur       = minLoanDur\\_;\\n    funds[fund].maxLoanDur       = maxLoanDur\\_;\\n    funds[fund].maxFundDur       = maxFundDur\\_;\\n    funds[fund].interest         = interest\\_;\\n    funds[fund].penalty          = penalty\\_;\\n    funds[fund].fee              = fee\\_;\\n    funds[fund].liquidationRatio = liquidationRatio\\_;\\n    funds[fund].arbiter          = arbiter\\_;\\n}\\n```\\nчResolution\\nThis is fixed in AtomicLoans/atomicloans-eth-contracts#67.\\nThis could be addressed by creating two update functions: one for custom funds and one for non-custom funds. Only the update for custom funds would allow setting these values.чч```\\nfunction update(\\n    bytes32  fund,\\n    uint256  minLoanAmt\\_,\\n    uint256  maxLoanAmt\\_,\\n    uint256  minLoanDur\\_,\\n    uint256  maxLoanDur\\_,\\n    uint256  maxFundDur\\_,\\n    uint256  interest\\_,\\n    uint256  penalty\\_,\\n    uint256  fee\\_,\\n    uint256  liquidationRatio\\_,\\n    address  arbiter\\_\\n) external {\\n    require(msg.sender == lender(fund));\\n    funds[fund].minLoanAmt       = minLoanAmt\\_;\\n    funds[fund].maxLoanAmt       = maxLoanAmt\\_;\\n    funds[fund].minLoanDur       = minLoanDur\\_;\\n    funds[fund].maxLoanDur       = maxLoanDur\\_;\\n    funds[fund].maxFundDur       = maxFundDur\\_;\\n    funds[fund].interest         = interest\\_;\\n    funds[fund].penalty          = penalty\\_;\\n    funds[fund].fee              = fee\\_;\\n    funds[fund].liquidationRatio = liquidationRatio\\_;\\n    funds[fund].arbiter          = arbiter\\_;\\n}\\n```\\n
Ingress.setContractAddress() can cause duplicate entries in contractKeysчmediumч`setContractAddress()` checks `ContractDetails` existence by inspecting `contractAddress`. A `contractAddress` of `0` means that the contract does not already exist, and its name must be added to contractKeys:\\n```\\nfunction setContractAddress(bytes32 name, address addr) public returns (bool) {\\n    require(name > 0x0000000000000000000000000000000000000000000000000000000000000000, \"Contract name must not be empty.\");\\n    require(isAuthorized(msg.sender), \"Not authorized to update contract registry.\");\\n\\n    ContractDetails memory info = registry[name];\\n    // create info if it doesn't exist in the registry\\n    if (info.contractAddress == address(0)) {\\n        info = ContractDetails({\\n            owner: msg.sender,\\n            contractAddress: addr\\n        });\\n\\n        // Update registry indexing\\n        contractKeys.push(name);\\n   } else {\\n        info.contractAddress = addr;\\n   }\\n    // update record in the registry\\n    registry[name] = info;\\n\\n    emit RegistryUpdated(addr,name);\\n\\n    return true;\\n}\\n```\\n\\nIf, however, a contract is actually added with the address `0`, which is currently allowed in the code, then the contract does already exists, and adding the name to `contractKeys` again will result in a duplicate.\\nMitigation\\nAn admin can call `removeContract` repeatedly with the same name to remove multiple duplicate entries.чResolution\\nThis is fixed in PegaSysEng/[email protected]faff726.\\nEither disallow a contract address of `0` or check for existence via the `owner` field instead (which can never be 0).чч```\\nfunction setContractAddress(bytes32 name, address addr) public returns (bool) {\\n    require(name > 0x0000000000000000000000000000000000000000000000000000000000000000, \"Contract name must not be empty.\");\\n    require(isAuthorized(msg.sender), \"Not authorized to update contract registry.\");\\n\\n    ContractDetails memory info = registry[name];\\n    // create info if it doesn't exist in the registry\\n    if (info.contractAddress == address(0)) {\\n        info = ContractDetails({\\n            owner: msg.sender,\\n            contractAddress: addr\\n        });\\n\\n        // Update registry indexing\\n        contractKeys.push(name);\\n   } else {\\n        info.contractAddress = addr;\\n   }\\n    // update record in the registry\\n    registry[name] = info;\\n\\n    emit RegistryUpdated(addr,name);\\n\\n    return true;\\n}\\n```\\n
Use specific contract types instead of address where possibleчlowчFor clarity and to get more out of the Solidity type checker, it's generally preferred to use a specific contract type for variables rather than the generic `address`.\\n`AccountRules.ingressContractAddress` could instead be `AccountRules.ingressContract` and use the type IngressContract:\\n```\\naddress private ingressContractAddress;\\n```\\n\\n```\\nAccountIngress ingressContract = AccountIngress(ingressContractAddress);\\n```\\n\\n```\\nconstructor (address ingressAddress) public {\\n```\\n\\nThis same pattern is found in NodeRules:\\n```\\naddress private nodeIngressContractAddress;\\n```\\nчWhere possible, use a specific contract type rather than `address`.чч```\\naddress private ingressContractAddress;\\n```\\n
Ingress should use a setчlowчThe `AdminList`, `AccountRulesList`, and `NodeRulesList` contracts have been recently rewritten to use a set. `Ingress` has the semantics of a set but has not been written the same way.\\nThis leads to some inefficiencies. In particular, `Ingress.removeContract` is an O(n) operation:\\n```\\nfor (uint i = 0; i < contractKeys.length; i++) {\\n    // Delete the key from the array + mapping if it is present\\n    if (contractKeys[i] == name) {\\n        delete registry[contractKeys[i]];\\n        contractKeys[i] = contractKeys[contractKeys.length - 1];\\n        delete contractKeys[contractKeys.length - 1];\\n        contractKeys.length--;\\n```\\nчUse the same set implementation for Ingress: an array of `ContractDetails` and a mapping of names to indexes in that array.чч```\\nfor (uint i = 0; i < contractKeys.length; i++) {\\n    // Delete the key from the array + mapping if it is present\\n    if (contractKeys[i] == name) {\\n        delete registry[contractKeys[i]];\\n        contractKeys[i] = contractKeys[contractKeys.length - 1];\\n        delete contractKeys[contractKeys.length - 1];\\n        contractKeys.length--;\\n```\\n
ContractDetails.owner is never readчlowчThe `ContractDetails` struct used by `Ingress` contracts has an `owner` field that is written to, but it is never read.\\n```\\nstruct ContractDetails {\\n    address owner;\\n    address contractAddress;\\n}\\n\\nmapping(bytes32 => ContractDetails) registry;\\n```\\nчResolution\\nThis is fixed in PegaSysEng/[email protected]d3f505e.\\nIf `owner` is not (yet) needed, the `ContractDetails` struct should be removed altogether and the type of `Ingress.registry` should change to `mapping(bytes32 => address)`чч```\\nstruct ContractDetails {\\n    address owner;\\n    address contractAddress;\\n}\\n\\nmapping(bytes32 => ContractDetails) registry;\\n```\\n
